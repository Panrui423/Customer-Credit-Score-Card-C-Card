{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85055\n",
      "15010\n"
     ]
    }
   ],
   "source": [
    "def get_filenames(data_dir):\n",
    "    imagelist = []\n",
    "    p = os.path.join(data_dir, '*.npz')\n",
    "    imagelist.extend(glob.glob(p))\n",
    "    return imagelist\n",
    " \n",
    "train_path = 'D:\\\\MYJF\\\\data\\\\payday_npz2'\n",
    "train_images = get_filenames(train_path)\n",
    "#train_images = train_images[:50000]\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, images_dir):\n",
    "        self.images_dir = images_dir\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        data_array = np.load(self.images_dir[index])\n",
    "        update_interval = data_array['arr_1'][2]\n",
    "#    '是否周末及节假日', '是否工作时间', '通话次数', '主叫通话时长', '被叫通话时长', '未知方式通话时长','和紧急联系人通话',\\\n",
    "#    '和通讯录通话','和高危对象通话', '发送短信次数', '接收短信次数', '未知方式短信次数','和高危对象短信', '4G上网时间', \\\n",
    "#    '3G上网时间', '2G上网时间','占用流量总和'\n",
    "        if update_interval:\n",
    "            arr_是否周末及节假日 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,0])).reshape(-1,24)\n",
    "            arr_是否工作时间 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,1])).reshape(-1,24)\n",
    "            arr_通话次数 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,2])).reshape(-1,24)\n",
    "            arr_主叫通话时长 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,3])).reshape(-1,24)\n",
    "            arr_被叫通话时长 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,4])).reshape(-1,24)\n",
    "            arr_未知方式通话时长 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,5])).reshape(-1,24)\n",
    "            arr_和紧急联系人通话 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,6])).reshape(-1,24)\n",
    "            arr_和通讯录通话 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,7])).reshape(-1,24)\n",
    "            arr_和高危对象通话 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,8])).reshape(-1,24)\n",
    "            arr_发送短信次数 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,9])).reshape(-1,24)\n",
    "            arr_接收短信次数 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,10])).reshape(-1,24)\n",
    "            arr_未知方式短信次数 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,11])).reshape(-1,24)\n",
    "            arr_和高危对象短信 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,12])).reshape(-1,24)\n",
    "            arr_4G上网时间 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,13])).reshape(-1,24)\n",
    "            arr_3G上网时间 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,14])).reshape(-1,24)\n",
    "            arr_2G上网时间 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,15])).reshape(-1,24)\n",
    "            arr_占用流量总和 = np.hstack((np.zeros(update_interval),data_array['arr_0'][:-update_interval,16])).reshape(-1,24)\n",
    "        else:\n",
    "            arr_是否周末及节假日 = data_array['arr_0'][:,0].reshape(-1,24)\n",
    "            arr_是否工作时间 = data_array['arr_0'][:,1].reshape(-1,24)\n",
    "            arr_通话次数 = data_array['arr_0'][:,2].reshape(-1,24)\n",
    "            arr_主叫通话时长 = data_array['arr_0'][:,3].reshape(-1,24)\n",
    "            arr_被叫通话时长 = data_array['arr_0'][:,4].reshape(-1,24)\n",
    "            arr_未知方式通话时长 = data_array['arr_0'][:,5].reshape(-1,24)\n",
    "            arr_和紧急联系人通话 = data_array['arr_0'][:,6].reshape(-1,24)\n",
    "            arr_和通讯录通话 = data_array['arr_0'][:,7].reshape(-1,24)\n",
    "            arr_和高危对象通话 = data_array['arr_0'][:,8].reshape(-1,24)\n",
    "            arr_发送短信次数 = data_array['arr_0'][:,9].reshape(-1,24)\n",
    "            arr_接收短信次数 = data_array['arr_0'][:,10].reshape(-1,24)\n",
    "            arr_未知方式短信次数 = data_array['arr_0'][:,11].reshape(-1,24)\n",
    "            arr_和高危对象短信 = data_array['arr_0'][:,12].reshape(-1,24)\n",
    "            arr_4G上网时间 = data_array['arr_0'][:,13].reshape(-1,24)\n",
    "            arr_3G上网时间 = data_array['arr_0'][:,14].reshape(-1,24)\n",
    "            arr_2G上网时间 = data_array['arr_0'][:,15].reshape(-1,24)\n",
    "            arr_占用流量总和 = data_array['arr_0'][:,16].reshape(-1,24)\n",
    "            \n",
    "        arr_是否周末及节假日 = np.hstack((\n",
    "            arr_是否周末及节假日, np.vstack((arr_是否周末及节假日[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_是否工作时间 = np.hstack((\n",
    "            arr_是否工作时间, np.vstack((arr_是否工作时间[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_通话次数 = np.hstack((\n",
    "            arr_通话次数, np.vstack((arr_通话次数[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_主叫通话时长 = np.hstack((\n",
    "            arr_主叫通话时长, np.vstack((arr_主叫通话时长[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_被叫通话时长 = np.hstack((\n",
    "            arr_被叫通话时长, np.vstack((arr_被叫通话时长[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_未知方式通话时长 = np.hstack((\n",
    "            arr_未知方式通话时长, np.vstack((arr_未知方式通话时长[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_和紧急联系人通话 = np.hstack((\n",
    "            arr_和紧急联系人通话, np.vstack((arr_和紧急联系人通话[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_和通讯录通话 = np.hstack((\n",
    "            arr_和通讯录通话, np.vstack((arr_和通讯录通话[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_和高危对象通话 = np.hstack((\n",
    "            arr_和高危对象通话, np.vstack((arr_和高危对象通话[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_发送短信次数 = np.hstack((\n",
    "            arr_发送短信次数, np.vstack((arr_发送短信次数[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_接收短信次数 = np.hstack((\n",
    "            arr_接收短信次数, np.vstack((arr_接收短信次数[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_未知方式短信次数 = np.hstack((\n",
    "            arr_未知方式短信次数, np.vstack((arr_未知方式短信次数[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_和高危对象短信 = np.hstack((\n",
    "            arr_和高危对象短信, np.vstack((arr_和高危对象短信[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_4G上网时间 = np.hstack((\n",
    "            arr_4G上网时间, np.vstack((arr_4G上网时间[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_3G上网时间 = np.hstack((\n",
    "            arr_3G上网时间, np.vstack((arr_3G上网时间[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_2G上网时间 = np.hstack((\n",
    "            arr_2G上网时间, np.vstack((arr_2G上网时间[1:,:4], np.array([[0,0,0,0]])))))\n",
    "        arr_占用流量总和 = np.hstack((\n",
    "            arr_占用流量总和, np.vstack((arr_占用流量总和[1:,:4], np.array([[0,0,0,0]])))))/100000\n",
    "        arr_label = (data_array['arr_1'][0][:1] > 2)\n",
    "        \n",
    "        return np.array([arr_是否周末及节假日[:112,:],arr_是否工作时间[:112,:], arr_通话次数[:112,:],arr_主叫通话时长[:112,:],\\\n",
    "                         arr_被叫通话时长[:112,:],arr_未知方式通话时长[:112,:],arr_和紧急联系人通话[:112,:],\\\n",
    "                         arr_和通讯录通话[:112,:],arr_和高危对象通话[:112,:],arr_发送短信次数[:112,:],\\\n",
    "                        arr_接收短信次数[:112,:],arr_未知方式短信次数[:112,:],arr_和高危对象短信[:112,:]\n",
    "                        ]).astype('float32'),arr_label.astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_dir)\n",
    "random_st = random.choice(range(10000))\n",
    "# train_images, test_images = train_test_split(train_images,test_size=0.15, random_state=random_st)\n",
    "\n",
    "#跨时间排序\n",
    "train_images.sort()\n",
    "split = math.floor(0.85*len(train_images))\n",
    "train_images2 = train_images\n",
    "train_images = train_images2[:split]\n",
    "test_images = train_images2[split:]\n",
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "\n",
    "train_data = MyDataset(train_images)\n",
    "test_data = MyDataset(test_images)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=160, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=30, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "def Conv_3x3(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def Conv_1x1(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "def SepConv_3x3(inp, oup): #input=32, output=16\n",
    "    return nn.Sequential(\n",
    "        # dw\n",
    "        nn.Conv2d(inp, inp , 3, 1, 1, groups=inp, bias=False),\n",
    "        nn.BatchNorm2d(inp),\n",
    "        nn.ReLU6(inplace=True),\n",
    "        # pw-linear\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, kernel): # input_channel, output_channel, s, t, k\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "#         assert stride in [1, 2]\n",
    "\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # pw\n",
    "            nn.Conv2d(inp, inp * expand_ratio, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(inp * expand_ratio),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # dw\n",
    "            nn.Conv2d(inp * expand_ratio, inp * expand_ratio, kernel, stride, kernel // 2, \n",
    "                      groups=inp * expand_ratio, bias=False),\n",
    "            nn.BatchNorm2d(inp * expand_ratio),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(inp * expand_ratio, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MnasNet(nn.Module):\n",
    "    def __init__(self, n_class=1, input_size=224, width_mult=1.):\n",
    "        super(MnasNet, self).__init__()\n",
    "\n",
    "        # setting of inverted residual blocks\n",
    "        self.interverted_residual_setting = [\n",
    "            # t, c, n, s, k\n",
    "            [3, 24,  3, 2, 3],  # -> 56x56\n",
    "            [3, 40,  2, (2,1), 5],  # -> 28x28\n",
    "            [6, 80,  2, (2,1), 5],  # -> 14x14\n",
    "            [6, 96,  2, 1, 3],  # -> 14x14\n",
    "            [6, 192, 4, 2, 5],  # -> 7x7\n",
    "            [6, 320, 1, 1, 3],  # -> 7x7\n",
    "        ]\n",
    "        \n",
    "#         assert input_size % 32 == 0\n",
    "        input_channel = int(32 * width_mult)\n",
    "        self.last_channel = int(1280 * width_mult) if width_mult > 1.0 else 1280\n",
    "        self.features = [nn.BatchNorm2d(13)]\n",
    "        input_channel = 16\n",
    "        self.features .append(Conv_1x1(13, input_channel))\n",
    "\n",
    "        # building first two layer\n",
    "#         self.features = [Conv_3x3(3, input_channel, 2), SepConv_3x3(input_channel, 16)]\n",
    "\n",
    "        # building inverted residual blocks (MBConv)\n",
    "        for t, c, n, s, k in self.interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(InvertedResidual(input_channel, output_channel, s, t, k))\n",
    "                else:\n",
    "                    self.features.append(InvertedResidual(input_channel, output_channel, 1, t, k))\n",
    "                input_channel = output_channel\n",
    "\n",
    "        # building last several layers\n",
    "        self.features.append(Conv_1x1(input_channel, self.last_channel))\n",
    "        self.features.append(nn.AvgPool2d(7))\n",
    "\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.last_channel)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "net = MnasNet()\n",
    "x_image = torch.randn([1, 13, 112, 28])\n",
    "y = net(x_image)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnasNet(\n",
       "  (features): Sequential(\n",
       "    (0): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(13, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 1), padding=(2, 2), groups=72, bias=False)\n",
       "        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace)\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace)\n",
       "        (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): Sequential(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "    )\n",
       "    (17): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MnasNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnasNet()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device) \n",
    "criterion = nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1/11, round: 1/532, loss: 0.6095359325408936\n",
      "train epoch: 1/11, round: 2/532, loss: 0.46186384558677673\n",
      "train epoch: 1/11, round: 3/532, loss: 0.47775769233703613\n",
      "train epoch: 1/11, round: 4/532, loss: 0.39920419454574585\n",
      "train epoch: 1/11, round: 5/532, loss: 0.40526729822158813\n",
      "train epoch: 1/11, round: 6/532, loss: 0.6033232808113098\n",
      "train epoch: 1/11, round: 7/532, loss: 0.47736233472824097\n",
      "train epoch: 1/11, round: 8/532, loss: 0.4120855927467346\n",
      "train epoch: 1/11, round: 9/532, loss: 0.362922728061676\n",
      "train epoch: 1/11, round: 10/532, loss: 0.38715535402297974\n",
      "train epoch: 1/11, round: 11/532, loss: 0.4622225761413574\n",
      "train epoch: 1/11, round: 12/532, loss: 0.42515382170677185\n",
      "train epoch: 1/11, round: 13/532, loss: 0.37365466356277466\n",
      "train epoch: 1/11, round: 14/532, loss: 0.4789457321166992\n",
      "train epoch: 1/11, round: 15/532, loss: 0.5316734910011292\n",
      "train epoch: 1/11, round: 16/532, loss: 0.3837811350822449\n",
      "train epoch: 1/11, round: 17/532, loss: 0.40962713956832886\n",
      "train epoch: 1/11, round: 18/532, loss: 0.37669363617897034\n",
      "train epoch: 1/11, round: 19/532, loss: 0.38996630907058716\n",
      "train epoch: 1/11, round: 20/532, loss: 0.37804684042930603\n",
      "train epoch: 1/11, round: 21/532, loss: 0.4544075131416321\n",
      "train epoch: 1/11, round: 22/532, loss: 0.42261892557144165\n",
      "train epoch: 1/11, round: 23/532, loss: 0.4360900819301605\n",
      "train epoch: 1/11, round: 24/532, loss: 0.5414301753044128\n",
      "train epoch: 1/11, round: 25/532, loss: 0.44530972838401794\n",
      "train epoch: 1/11, round: 26/532, loss: 0.41207027435302734\n",
      "train epoch: 1/11, round: 27/532, loss: 0.4553159773349762\n",
      "train epoch: 1/11, round: 28/532, loss: 0.48101967573165894\n",
      "train epoch: 1/11, round: 29/532, loss: 0.39025577902793884\n",
      "train epoch: 1/11, round: 30/532, loss: 0.4318011403083801\n",
      "train epoch: 1/11, round: 31/532, loss: 0.48930925130844116\n",
      "train epoch: 1/11, round: 32/532, loss: 0.41634392738342285\n",
      "train epoch: 1/11, round: 33/532, loss: 0.4330587387084961\n",
      "train epoch: 1/11, round: 34/532, loss: 0.3502187728881836\n",
      "train epoch: 1/11, round: 35/532, loss: 0.5031368136405945\n",
      "train epoch: 1/11, round: 36/532, loss: 0.4107902944087982\n",
      "train epoch: 1/11, round: 37/532, loss: 0.362214595079422\n",
      "train epoch: 1/11, round: 38/532, loss: 0.46351736783981323\n",
      "train epoch: 1/11, round: 39/532, loss: 0.4014185070991516\n",
      "train epoch: 1/11, round: 40/532, loss: 0.44040027260780334\n",
      "train epoch: 1/11, round: 41/532, loss: 0.4539622664451599\n",
      "train epoch: 1/11, round: 42/532, loss: 0.5063923597335815\n",
      "train epoch: 1/11, round: 43/532, loss: 0.397365003824234\n",
      "train epoch: 1/11, round: 44/532, loss: 0.4476013779640198\n",
      "train epoch: 1/11, round: 45/532, loss: 0.44553813338279724\n",
      "train epoch: 1/11, round: 46/532, loss: 0.47431087493896484\n",
      "train epoch: 1/11, round: 47/532, loss: 0.4363980293273926\n",
      "train epoch: 1/11, round: 48/532, loss: 0.45351701974868774\n",
      "train epoch: 1/11, round: 49/532, loss: 0.47544413805007935\n",
      "train epoch: 1/11, round: 50/532, loss: 0.4334121644496918\n",
      "train epoch: 1/11, round: 51/532, loss: 0.42757779359817505\n",
      "train epoch: 1/11, round: 52/532, loss: 0.3699505925178528\n",
      "train epoch: 1/11, round: 53/532, loss: 0.4238511919975281\n",
      "train epoch: 1/11, round: 54/532, loss: 0.5102487802505493\n",
      "train epoch: 1/11, round: 55/532, loss: 0.5073164701461792\n",
      "train epoch: 1/11, round: 56/532, loss: 0.3859909474849701\n",
      "train epoch: 1/11, round: 57/532, loss: 0.47995179891586304\n",
      "train epoch: 1/11, round: 58/532, loss: 0.5081816911697388\n",
      "train epoch: 1/11, round: 59/532, loss: 0.35520949959754944\n",
      "train epoch: 1/11, round: 60/532, loss: 0.34129655361175537\n",
      "train epoch: 1/11, round: 61/532, loss: 0.5294506549835205\n",
      "train epoch: 1/11, round: 62/532, loss: 0.4232853949069977\n",
      "train epoch: 1/11, round: 63/532, loss: 0.4811486303806305\n",
      "train epoch: 1/11, round: 64/532, loss: 0.44756871461868286\n",
      "train epoch: 1/11, round: 65/532, loss: 0.42220139503479004\n",
      "train epoch: 1/11, round: 66/532, loss: 0.45069989562034607\n",
      "train epoch: 1/11, round: 67/532, loss: 0.3433428406715393\n",
      "train epoch: 1/11, round: 68/532, loss: 0.38749685883522034\n",
      "train epoch: 1/11, round: 69/532, loss: 0.47020548582077026\n",
      "train epoch: 1/11, round: 70/532, loss: 0.3711109757423401\n",
      "train epoch: 1/11, round: 71/532, loss: 0.39389604330062866\n",
      "train epoch: 1/11, round: 72/532, loss: 0.46665653586387634\n",
      "train epoch: 1/11, round: 73/532, loss: 0.36690568923950195\n",
      "train epoch: 1/11, round: 74/532, loss: 0.4746737480163574\n",
      "train epoch: 1/11, round: 75/532, loss: 0.4586162567138672\n",
      "train epoch: 1/11, round: 76/532, loss: 0.4320659637451172\n",
      "train epoch: 1/11, round: 77/532, loss: 0.42407727241516113\n",
      "train epoch: 1/11, round: 78/532, loss: 0.45637327432632446\n",
      "train epoch: 1/11, round: 79/532, loss: 0.44787606596946716\n",
      "train epoch: 1/11, round: 80/532, loss: 0.4091472625732422\n",
      "train epoch: 1/11, round: 81/532, loss: 0.4589509069919586\n",
      "train epoch: 1/11, round: 82/532, loss: 0.3652505874633789\n",
      "train epoch: 1/11, round: 83/532, loss: 0.42071977257728577\n",
      "train epoch: 1/11, round: 84/532, loss: 0.43704766035079956\n",
      "train epoch: 1/11, round: 85/532, loss: 0.4671316146850586\n",
      "train epoch: 1/11, round: 86/532, loss: 0.42238306999206543\n",
      "train epoch: 1/11, round: 87/532, loss: 0.5404647588729858\n",
      "train epoch: 1/11, round: 88/532, loss: 0.4530485272407532\n",
      "train epoch: 1/11, round: 89/532, loss: 0.5045570731163025\n",
      "train epoch: 1/11, round: 90/532, loss: 0.4032108187675476\n",
      "train epoch: 1/11, round: 91/532, loss: 0.4840865731239319\n",
      "train epoch: 1/11, round: 92/532, loss: 0.40304112434387207\n",
      "train epoch: 1/11, round: 93/532, loss: 0.4649592936038971\n",
      "train epoch: 1/11, round: 94/532, loss: 0.4431493282318115\n",
      "train epoch: 1/11, round: 95/532, loss: 0.437980592250824\n",
      "train epoch: 1/11, round: 96/532, loss: 0.3965469002723694\n",
      "train epoch: 1/11, round: 97/532, loss: 0.4467068612575531\n",
      "train epoch: 1/11, round: 98/532, loss: 0.37248462438583374\n",
      "train epoch: 1/11, round: 99/532, loss: 0.3769097924232483\n",
      "train epoch: 1/11, round: 100/532, loss: 0.3332153856754303\n",
      "train epoch: 1/11, round: 101/532, loss: 0.3476276099681854\n",
      "train epoch: 1/11, round: 102/532, loss: 0.4941544532775879\n",
      "train epoch: 1/11, round: 103/532, loss: 0.3347581923007965\n",
      "train epoch: 1/11, round: 104/532, loss: 0.5605614185333252\n",
      "train epoch: 1/11, round: 105/532, loss: 0.358847051858902\n",
      "train epoch: 1/11, round: 106/532, loss: 0.414459764957428\n",
      "train epoch: 1/11, round: 107/532, loss: 0.4235760569572449\n",
      "train epoch: 1/11, round: 108/532, loss: 0.35019782185554504\n",
      "train epoch: 1/11, round: 109/532, loss: 0.40393176674842834\n",
      "train epoch: 1/11, round: 110/532, loss: 0.399415522813797\n",
      "train epoch: 1/11, round: 111/532, loss: 0.3933355212211609\n",
      "train epoch: 1/11, round: 112/532, loss: 0.4029262065887451\n",
      "train epoch: 1/11, round: 113/532, loss: 0.48105064034461975\n",
      "train epoch: 1/11, round: 114/532, loss: 0.45371708273887634\n",
      "train epoch: 1/11, round: 115/532, loss: 0.5348140597343445\n",
      "train epoch: 1/11, round: 116/532, loss: 0.4431406855583191\n",
      "train epoch: 1/11, round: 117/532, loss: 0.32143113017082214\n",
      "train epoch: 1/11, round: 118/532, loss: 0.4868258535861969\n",
      "train epoch: 1/11, round: 119/532, loss: 0.4377923607826233\n",
      "train epoch: 1/11, round: 120/532, loss: 0.40417712926864624\n",
      "train epoch: 1/11, round: 121/532, loss: 0.44360119104385376\n",
      "train epoch: 1/11, round: 122/532, loss: 0.4111878275871277\n",
      "train epoch: 1/11, round: 123/532, loss: 0.40412014722824097\n",
      "train epoch: 1/11, round: 124/532, loss: 0.45139288902282715\n",
      "train epoch: 1/11, round: 125/532, loss: 0.3034417927265167\n",
      "train epoch: 1/11, round: 126/532, loss: 0.3542563319206238\n",
      "train epoch: 1/11, round: 127/532, loss: 0.3859075903892517\n",
      "train epoch: 1/11, round: 128/532, loss: 0.4342730641365051\n",
      "train epoch: 1/11, round: 129/532, loss: 0.3613593578338623\n",
      "train epoch: 1/11, round: 130/532, loss: 0.46588438749313354\n",
      "train epoch: 1/11, round: 131/532, loss: 0.519037127494812\n",
      "train epoch: 1/11, round: 132/532, loss: 0.4427763521671295\n",
      "train epoch: 1/11, round: 133/532, loss: 0.43596798181533813\n",
      "train epoch: 1/11, round: 134/532, loss: 0.48473477363586426\n",
      "train epoch: 1/11, round: 135/532, loss: 0.3853020668029785\n",
      "train epoch: 1/11, round: 136/532, loss: 0.44104665517807007\n",
      "train epoch: 1/11, round: 137/532, loss: 0.40790900588035583\n",
      "train epoch: 1/11, round: 138/532, loss: 0.4558696150779724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1/11, round: 139/532, loss: 0.43623486161231995\n",
      "train epoch: 1/11, round: 140/532, loss: 0.4004620611667633\n",
      "train epoch: 1/11, round: 141/532, loss: 0.3993839621543884\n",
      "train epoch: 1/11, round: 142/532, loss: 0.4587554335594177\n",
      "train epoch: 1/11, round: 143/532, loss: 0.5141721367835999\n",
      "train epoch: 1/11, round: 144/532, loss: 0.45599016547203064\n",
      "train epoch: 1/11, round: 145/532, loss: 0.44086846709251404\n",
      "train epoch: 1/11, round: 146/532, loss: 0.37754273414611816\n",
      "train epoch: 1/11, round: 147/532, loss: 0.43546780943870544\n",
      "train epoch: 1/11, round: 148/532, loss: 0.4786175787448883\n",
      "train epoch: 1/11, round: 149/532, loss: 0.47482091188430786\n",
      "train epoch: 1/11, round: 150/532, loss: 0.4914519786834717\n",
      "train epoch: 1/11, round: 151/532, loss: 0.38753122091293335\n",
      "train epoch: 1/11, round: 152/532, loss: 0.4053500294685364\n",
      "train epoch: 1/11, round: 153/532, loss: 0.45560646057128906\n",
      "train epoch: 1/11, round: 154/532, loss: 0.3770368695259094\n",
      "train epoch: 1/11, round: 155/532, loss: 0.42234355211257935\n",
      "train epoch: 1/11, round: 156/532, loss: 0.4005650579929352\n",
      "train epoch: 1/11, round: 157/532, loss: 0.5231648683547974\n",
      "train epoch: 1/11, round: 158/532, loss: 0.4749068319797516\n",
      "train epoch: 1/11, round: 159/532, loss: 0.39541658759117126\n",
      "train epoch: 1/11, round: 160/532, loss: 0.4202420115470886\n",
      "train epoch: 1/11, round: 161/532, loss: 0.4094630181789398\n",
      "train epoch: 1/11, round: 162/532, loss: 0.38989192247390747\n",
      "train epoch: 1/11, round: 163/532, loss: 0.38467103242874146\n",
      "train epoch: 1/11, round: 164/532, loss: 0.5437824130058289\n",
      "train epoch: 1/11, round: 165/532, loss: 0.4208667278289795\n",
      "train epoch: 1/11, round: 166/532, loss: 0.47913503646850586\n",
      "train epoch: 1/11, round: 167/532, loss: 0.43776172399520874\n",
      "train epoch: 1/11, round: 168/532, loss: 0.4217354655265808\n",
      "train epoch: 1/11, round: 169/532, loss: 0.4115276336669922\n",
      "train epoch: 1/11, round: 170/532, loss: 0.40043288469314575\n",
      "train epoch: 1/11, round: 171/532, loss: 0.4442024230957031\n",
      "train epoch: 1/11, round: 172/532, loss: 0.4225277900695801\n",
      "train epoch: 1/11, round: 173/532, loss: 0.3732684254646301\n",
      "train epoch: 1/11, round: 174/532, loss: 0.4577018618583679\n",
      "train epoch: 1/11, round: 175/532, loss: 0.42048874497413635\n",
      "train epoch: 1/11, round: 176/532, loss: 0.40874171257019043\n",
      "train epoch: 1/11, round: 177/532, loss: 0.4657719135284424\n",
      "train epoch: 1/11, round: 178/532, loss: 0.3617820739746094\n",
      "train epoch: 1/11, round: 179/532, loss: 0.4302099347114563\n",
      "train epoch: 1/11, round: 180/532, loss: 0.40609273314476013\n",
      "train epoch: 1/11, round: 181/532, loss: 0.49834758043289185\n",
      "train epoch: 1/11, round: 182/532, loss: 0.517494797706604\n",
      "train epoch: 1/11, round: 183/532, loss: 0.4175698161125183\n",
      "train epoch: 1/11, round: 184/532, loss: 0.41336092352867126\n",
      "train epoch: 1/11, round: 185/532, loss: 0.44558125734329224\n",
      "train epoch: 1/11, round: 186/532, loss: 0.4605521261692047\n",
      "train epoch: 1/11, round: 187/532, loss: 0.42041605710983276\n",
      "train epoch: 1/11, round: 188/532, loss: 0.4220291078090668\n",
      "train epoch: 1/11, round: 189/532, loss: 0.40486034750938416\n",
      "train epoch: 1/11, round: 190/532, loss: 0.4796786308288574\n",
      "train epoch: 1/11, round: 191/532, loss: 0.5040525197982788\n",
      "train epoch: 1/11, round: 192/532, loss: 0.4077645242214203\n",
      "train epoch: 1/11, round: 193/532, loss: 0.4230947494506836\n",
      "train epoch: 1/11, round: 194/532, loss: 0.3807452321052551\n",
      "train epoch: 1/11, round: 195/532, loss: 0.4304884970188141\n",
      "train epoch: 1/11, round: 196/532, loss: 0.44117385149002075\n",
      "train epoch: 1/11, round: 197/532, loss: 0.36101263761520386\n",
      "train epoch: 1/11, round: 198/532, loss: 0.5661660432815552\n",
      "train epoch: 1/11, round: 199/532, loss: 0.3956506848335266\n",
      "train epoch: 1/11, round: 200/532, loss: 0.35156551003456116\n",
      "train epoch: 1/11, round: 201/532, loss: 0.38157838582992554\n",
      "train epoch: 1/11, round: 202/532, loss: 0.4257710576057434\n",
      "train epoch: 1/11, round: 203/532, loss: 0.4679131507873535\n",
      "train epoch: 1/11, round: 204/532, loss: 0.30673912167549133\n",
      "train epoch: 1/11, round: 205/532, loss: 0.3982849717140198\n",
      "train epoch: 1/11, round: 206/532, loss: 0.4509730935096741\n",
      "train epoch: 1/11, round: 207/532, loss: 0.4584335684776306\n",
      "train epoch: 1/11, round: 208/532, loss: 0.48691320419311523\n",
      "train epoch: 1/11, round: 209/532, loss: 0.42467254400253296\n",
      "train epoch: 1/11, round: 210/532, loss: 0.3858775496482849\n",
      "train epoch: 1/11, round: 211/532, loss: 0.39359304308891296\n",
      "train epoch: 1/11, round: 212/532, loss: 0.39473310112953186\n",
      "train epoch: 1/11, round: 213/532, loss: 0.4775640368461609\n",
      "train epoch: 1/11, round: 214/532, loss: 0.42375507950782776\n",
      "train epoch: 1/11, round: 215/532, loss: 0.41654810309410095\n",
      "train epoch: 1/11, round: 216/532, loss: 0.38370954990386963\n",
      "train epoch: 1/11, round: 217/532, loss: 0.4805051386356354\n",
      "train epoch: 1/11, round: 218/532, loss: 0.536405622959137\n",
      "train epoch: 1/11, round: 219/532, loss: 0.442783921957016\n",
      "train epoch: 1/11, round: 220/532, loss: 0.3456379771232605\n",
      "train epoch: 1/11, round: 221/532, loss: 0.4583786129951477\n",
      "train epoch: 1/11, round: 222/532, loss: 0.44783124327659607\n",
      "train epoch: 1/11, round: 223/532, loss: 0.4399593770503998\n",
      "train epoch: 1/11, round: 224/532, loss: 0.4346383512020111\n",
      "train epoch: 1/11, round: 225/532, loss: 0.41040515899658203\n",
      "train epoch: 1/11, round: 226/532, loss: 0.4003874659538269\n",
      "train epoch: 1/11, round: 227/532, loss: 0.3920820355415344\n",
      "train epoch: 1/11, round: 228/532, loss: 0.3923395872116089\n",
      "train epoch: 1/11, round: 229/532, loss: 0.37169209122657776\n",
      "train epoch: 1/11, round: 230/532, loss: 0.4189724028110504\n",
      "train epoch: 1/11, round: 231/532, loss: 0.46805340051651\n",
      "train epoch: 1/11, round: 232/532, loss: 0.3659277856349945\n",
      "train epoch: 1/11, round: 233/532, loss: 0.42958205938339233\n",
      "train epoch: 1/11, round: 234/532, loss: 0.35442808270454407\n",
      "train epoch: 1/11, round: 235/532, loss: 0.5419275760650635\n",
      "train epoch: 1/11, round: 236/532, loss: 0.43858909606933594\n",
      "train epoch: 1/11, round: 237/532, loss: 0.43014174699783325\n",
      "train epoch: 1/11, round: 238/532, loss: 0.374885231256485\n",
      "train epoch: 1/11, round: 239/532, loss: 0.40734362602233887\n",
      "train epoch: 1/11, round: 240/532, loss: 0.4502319395542145\n",
      "train epoch: 1/11, round: 241/532, loss: 0.4449092745780945\n",
      "train epoch: 1/11, round: 242/532, loss: 0.370816171169281\n",
      "train epoch: 1/11, round: 243/532, loss: 0.4273752272129059\n",
      "train epoch: 1/11, round: 244/532, loss: 0.45568427443504333\n",
      "train epoch: 1/11, round: 245/532, loss: 0.4502430558204651\n",
      "train epoch: 1/11, round: 246/532, loss: 0.39253777265548706\n",
      "train epoch: 1/11, round: 247/532, loss: 0.3785354495048523\n",
      "train epoch: 1/11, round: 248/532, loss: 0.44605350494384766\n",
      "train epoch: 1/11, round: 249/532, loss: 0.46809205412864685\n",
      "train epoch: 1/11, round: 250/532, loss: 0.4452306628227234\n",
      "train epoch: 1/11, round: 251/532, loss: 0.4627135694026947\n",
      "train epoch: 1/11, round: 252/532, loss: 0.33627718687057495\n",
      "train epoch: 1/11, round: 253/532, loss: 0.45361265540122986\n",
      "train epoch: 1/11, round: 254/532, loss: 0.41705140471458435\n",
      "train epoch: 1/11, round: 255/532, loss: 0.40318259596824646\n",
      "train epoch: 1/11, round: 256/532, loss: 0.44618621468544006\n",
      "train epoch: 1/11, round: 257/532, loss: 0.44709324836730957\n",
      "train epoch: 1/11, round: 258/532, loss: 0.40858572721481323\n",
      "train epoch: 1/11, round: 259/532, loss: 0.3454756736755371\n",
      "train epoch: 1/11, round: 260/532, loss: 0.3963093161582947\n",
      "train epoch: 1/11, round: 261/532, loss: 0.3785618245601654\n",
      "train epoch: 1/11, round: 262/532, loss: 0.4491497874259949\n",
      "train epoch: 1/11, round: 263/532, loss: 0.3636518120765686\n",
      "train epoch: 1/11, round: 264/532, loss: 0.3696885406970978\n",
      "train epoch: 1/11, round: 265/532, loss: 0.4212911128997803\n",
      "train epoch: 1/11, round: 266/532, loss: 0.3346611559391022\n",
      "train epoch: 1/11, round: 267/532, loss: 0.42171579599380493\n",
      "train epoch: 1/11, round: 268/532, loss: 0.38177362084388733\n",
      "train epoch: 1/11, round: 269/532, loss: 0.40327882766723633\n",
      "train epoch: 1/11, round: 270/532, loss: 0.40009790658950806\n",
      "train epoch: 1/11, round: 271/532, loss: 0.468606561422348\n",
      "train epoch: 1/11, round: 272/532, loss: 0.34388095140457153\n",
      "train epoch: 1/11, round: 273/532, loss: 0.4046615660190582\n",
      "train epoch: 1/11, round: 274/532, loss: 0.47763100266456604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1/11, round: 275/532, loss: 0.3994697034358978\n",
      "train epoch: 1/11, round: 276/532, loss: 0.30715593695640564\n",
      "train epoch: 1/11, round: 277/532, loss: 0.38704913854599\n",
      "train epoch: 1/11, round: 278/532, loss: 0.4943629801273346\n",
      "train epoch: 1/11, round: 279/532, loss: 0.3579765856266022\n",
      "train epoch: 1/11, round: 280/532, loss: 0.38371139764785767\n",
      "train epoch: 1/11, round: 281/532, loss: 0.49297958612442017\n",
      "train epoch: 1/11, round: 282/532, loss: 0.34391817450523376\n",
      "train epoch: 1/11, round: 283/532, loss: 0.40104445815086365\n",
      "train epoch: 1/11, round: 284/532, loss: 0.3499120771884918\n",
      "train epoch: 1/11, round: 285/532, loss: 0.33998608589172363\n",
      "train epoch: 1/11, round: 286/532, loss: 0.3663008511066437\n",
      "train epoch: 1/11, round: 287/532, loss: 0.4244020879268646\n",
      "train epoch: 1/11, round: 288/532, loss: 0.374237596988678\n",
      "train epoch: 1/11, round: 289/532, loss: 0.5125390887260437\n",
      "train epoch: 1/11, round: 290/532, loss: 0.3740819990634918\n",
      "train epoch: 1/11, round: 291/532, loss: 0.35712435841560364\n",
      "train epoch: 1/11, round: 292/532, loss: 0.3921668529510498\n",
      "train epoch: 1/11, round: 293/532, loss: 0.3773517310619354\n",
      "train epoch: 1/11, round: 294/532, loss: 0.48960286378860474\n",
      "train epoch: 1/11, round: 295/532, loss: 0.4002629220485687\n",
      "train epoch: 1/11, round: 296/532, loss: 0.366691529750824\n",
      "train epoch: 1/11, round: 297/532, loss: 0.35435956716537476\n",
      "train epoch: 1/11, round: 298/532, loss: 0.4204951226711273\n",
      "train epoch: 1/11, round: 299/532, loss: 0.4538344442844391\n",
      "train epoch: 1/11, round: 300/532, loss: 0.5126636624336243\n",
      "train epoch: 1/11, round: 301/532, loss: 0.42351388931274414\n",
      "train epoch: 1/11, round: 302/532, loss: 0.3784332573413849\n",
      "train epoch: 1/11, round: 303/532, loss: 0.44771847128868103\n",
      "train epoch: 1/11, round: 304/532, loss: 0.4577976167201996\n",
      "train epoch: 1/11, round: 305/532, loss: 0.4324496388435364\n",
      "train epoch: 1/11, round: 306/532, loss: 0.43229979276657104\n",
      "train epoch: 1/11, round: 307/532, loss: 0.4316001832485199\n",
      "train epoch: 1/11, round: 308/532, loss: 0.4892217218875885\n",
      "train epoch: 1/11, round: 309/532, loss: 0.3654538691043854\n",
      "train epoch: 1/11, round: 310/532, loss: 0.4508604109287262\n",
      "train epoch: 1/11, round: 311/532, loss: 0.39138951897621155\n",
      "train epoch: 1/11, round: 312/532, loss: 0.407121479511261\n",
      "train epoch: 1/11, round: 313/532, loss: 0.35387542843818665\n",
      "train epoch: 1/11, round: 314/532, loss: 0.419536828994751\n",
      "train epoch: 1/11, round: 315/532, loss: 0.4593465328216553\n",
      "train epoch: 1/11, round: 316/532, loss: 0.40523940324783325\n",
      "train epoch: 1/11, round: 317/532, loss: 0.41913753747940063\n",
      "train epoch: 1/11, round: 318/532, loss: 0.4695473611354828\n",
      "train epoch: 1/11, round: 319/532, loss: 0.42194777727127075\n",
      "train epoch: 1/11, round: 320/532, loss: 0.6312093138694763\n",
      "train epoch: 1/11, round: 321/532, loss: 0.3833851218223572\n",
      "train epoch: 1/11, round: 322/532, loss: 0.46078982949256897\n",
      "train epoch: 1/11, round: 323/532, loss: 0.46305546164512634\n",
      "train epoch: 1/11, round: 324/532, loss: 0.43017640709877014\n",
      "train epoch: 1/11, round: 325/532, loss: 0.4579913020133972\n",
      "train epoch: 1/11, round: 326/532, loss: 0.4117296636104584\n",
      "train epoch: 1/11, round: 327/532, loss: 0.45015549659729004\n",
      "train epoch: 1/11, round: 328/532, loss: 0.42533937096595764\n",
      "train epoch: 1/11, round: 329/532, loss: 0.3821720480918884\n",
      "train epoch: 1/11, round: 330/532, loss: 0.433072030544281\n",
      "train epoch: 1/11, round: 331/532, loss: 0.3771442472934723\n",
      "train epoch: 1/11, round: 332/532, loss: 0.4339674413204193\n",
      "train epoch: 1/11, round: 333/532, loss: 0.4054873585700989\n",
      "train epoch: 1/11, round: 334/532, loss: 0.4232463240623474\n",
      "train epoch: 1/11, round: 335/532, loss: 0.37443286180496216\n",
      "train epoch: 1/11, round: 336/532, loss: 0.4701465666294098\n",
      "train epoch: 1/11, round: 337/532, loss: 0.5133603811264038\n",
      "train epoch: 1/11, round: 338/532, loss: 0.3933698236942291\n",
      "train epoch: 1/11, round: 339/532, loss: 0.47922277450561523\n",
      "train epoch: 1/11, round: 340/532, loss: 0.3793095052242279\n",
      "train epoch: 1/11, round: 341/532, loss: 0.4596133232116699\n",
      "train epoch: 1/11, round: 342/532, loss: 0.3862680196762085\n",
      "train epoch: 1/11, round: 343/532, loss: 0.4141171872615814\n",
      "train epoch: 1/11, round: 344/532, loss: 0.3725581765174866\n",
      "train epoch: 1/11, round: 345/532, loss: 0.5027680397033691\n",
      "train epoch: 1/11, round: 346/532, loss: 0.41404256224632263\n",
      "train epoch: 1/11, round: 347/532, loss: 0.37750008702278137\n",
      "train epoch: 1/11, round: 348/532, loss: 0.34438854455947876\n",
      "train epoch: 1/11, round: 349/532, loss: 0.3847198486328125\n",
      "train epoch: 1/11, round: 350/532, loss: 0.37390512228012085\n",
      "train epoch: 1/11, round: 351/532, loss: 0.3625187277793884\n",
      "train epoch: 1/11, round: 352/532, loss: 0.40631532669067383\n",
      "train epoch: 1/11, round: 353/532, loss: 0.38205060362815857\n",
      "train epoch: 1/11, round: 354/532, loss: 0.3525671362876892\n",
      "train epoch: 1/11, round: 355/532, loss: 0.43964630365371704\n",
      "train epoch: 1/11, round: 356/532, loss: 0.39154189825057983\n",
      "train epoch: 1/11, round: 357/532, loss: 0.3824329376220703\n",
      "train epoch: 1/11, round: 358/532, loss: 0.39255762100219727\n",
      "train epoch: 1/11, round: 359/532, loss: 0.4837588369846344\n",
      "train epoch: 1/11, round: 360/532, loss: 0.49067267775535583\n",
      "train epoch: 1/11, round: 361/532, loss: 0.39232534170150757\n",
      "train epoch: 1/11, round: 362/532, loss: 0.4344988763332367\n",
      "train epoch: 1/11, round: 363/532, loss: 0.39319390058517456\n",
      "train epoch: 1/11, round: 364/532, loss: 0.41868624091148376\n",
      "train epoch: 1/11, round: 365/532, loss: 0.3922111392021179\n",
      "train epoch: 1/11, round: 366/532, loss: 0.426856130361557\n",
      "train epoch: 1/11, round: 367/532, loss: 0.5084242224693298\n",
      "train epoch: 1/11, round: 368/532, loss: 0.4560334086418152\n",
      "train epoch: 1/11, round: 369/532, loss: 0.4865929186344147\n",
      "train epoch: 1/11, round: 370/532, loss: 0.4293643534183502\n",
      "train epoch: 1/11, round: 371/532, loss: 0.5008410215377808\n",
      "train epoch: 1/11, round: 372/532, loss: 0.36363980174064636\n",
      "train epoch: 1/11, round: 373/532, loss: 0.46988385915756226\n",
      "train epoch: 1/11, round: 374/532, loss: 0.3779362142086029\n",
      "train epoch: 1/11, round: 375/532, loss: 0.4147067666053772\n",
      "train epoch: 1/11, round: 376/532, loss: 0.4392734169960022\n",
      "train epoch: 1/11, round: 377/532, loss: 0.33786725997924805\n",
      "train epoch: 1/11, round: 378/532, loss: 0.3679746985435486\n",
      "train epoch: 1/11, round: 379/532, loss: 0.40220537781715393\n",
      "train epoch: 1/11, round: 380/532, loss: 0.40122857689857483\n",
      "train epoch: 1/11, round: 381/532, loss: 0.36215752363204956\n",
      "train epoch: 1/11, round: 382/532, loss: 0.38045892119407654\n",
      "train epoch: 1/11, round: 383/532, loss: 0.38122010231018066\n",
      "train epoch: 1/11, round: 384/532, loss: 0.43874216079711914\n",
      "train epoch: 1/11, round: 385/532, loss: 0.4905739724636078\n",
      "train epoch: 1/11, round: 386/532, loss: 0.2786371409893036\n",
      "train epoch: 1/11, round: 387/532, loss: 0.40283074975013733\n",
      "train epoch: 1/11, round: 388/532, loss: 0.40225666761398315\n",
      "train epoch: 1/11, round: 389/532, loss: 0.43622246384620667\n",
      "train epoch: 1/11, round: 390/532, loss: 0.4180412292480469\n",
      "train epoch: 1/11, round: 391/532, loss: 0.3837530016899109\n",
      "train epoch: 1/11, round: 392/532, loss: 0.5106850266456604\n",
      "train epoch: 1/11, round: 393/532, loss: 0.3820038139820099\n",
      "train epoch: 1/11, round: 394/532, loss: 0.47250133752822876\n",
      "train epoch: 1/11, round: 395/532, loss: 0.4743942618370056\n",
      "train epoch: 1/11, round: 396/532, loss: 0.4537737965583801\n",
      "train epoch: 1/11, round: 397/532, loss: 0.4056416451931\n",
      "train epoch: 1/11, round: 398/532, loss: 0.39955949783325195\n",
      "train epoch: 1/11, round: 399/532, loss: 0.4400274157524109\n",
      "train epoch: 1/11, round: 400/532, loss: 0.44935983419418335\n",
      "train epoch: 1/11, round: 401/532, loss: 0.4250273108482361\n",
      "train epoch: 1/11, round: 402/532, loss: 0.5260921716690063\n",
      "train epoch: 1/11, round: 403/532, loss: 0.35154885053634644\n",
      "train epoch: 1/11, round: 404/532, loss: 0.43599575757980347\n",
      "train epoch: 1/11, round: 405/532, loss: 0.3615315556526184\n",
      "train epoch: 1/11, round: 406/532, loss: 0.4093952178955078\n",
      "train epoch: 1/11, round: 407/532, loss: 0.41128110885620117\n",
      "train epoch: 1/11, round: 408/532, loss: 0.4448653757572174\n",
      "train epoch: 1/11, round: 409/532, loss: 0.34076744318008423\n",
      "train epoch: 1/11, round: 410/532, loss: 0.34648397564888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1/11, round: 411/532, loss: 0.4511660039424896\n",
      "train epoch: 1/11, round: 412/532, loss: 0.35550037026405334\n",
      "train epoch: 1/11, round: 413/532, loss: 0.4955320358276367\n",
      "train epoch: 1/11, round: 414/532, loss: 0.3792484700679779\n",
      "train epoch: 1/11, round: 415/532, loss: 0.42499858140945435\n",
      "train epoch: 1/11, round: 416/532, loss: 0.434422105550766\n",
      "train epoch: 1/11, round: 417/532, loss: 0.46905532479286194\n",
      "train epoch: 1/11, round: 418/532, loss: 0.3397729992866516\n",
      "train epoch: 1/11, round: 419/532, loss: 0.4094770848751068\n",
      "train epoch: 1/11, round: 420/532, loss: 0.346376895904541\n",
      "train epoch: 1/11, round: 421/532, loss: 0.43188023567199707\n",
      "train epoch: 1/11, round: 422/532, loss: 0.5684941411018372\n",
      "train epoch: 1/11, round: 423/532, loss: 0.36820974946022034\n",
      "train epoch: 1/11, round: 424/532, loss: 0.4058305621147156\n",
      "train epoch: 1/11, round: 425/532, loss: 0.3941088318824768\n",
      "train epoch: 1/11, round: 426/532, loss: 0.3895835280418396\n",
      "train epoch: 1/11, round: 427/532, loss: 0.41712871193885803\n",
      "train epoch: 1/11, round: 428/532, loss: 0.433652400970459\n",
      "train epoch: 1/11, round: 429/532, loss: 0.40911728143692017\n",
      "train epoch: 1/11, round: 430/532, loss: 0.37754741311073303\n",
      "train epoch: 1/11, round: 431/532, loss: 0.39683064818382263\n",
      "train epoch: 1/11, round: 432/532, loss: 0.39101535081863403\n",
      "train epoch: 1/11, round: 433/532, loss: 0.4059169888496399\n",
      "train epoch: 1/11, round: 434/532, loss: 0.3839399516582489\n",
      "train epoch: 1/11, round: 435/532, loss: 0.3629313111305237\n",
      "train epoch: 1/11, round: 436/532, loss: 0.3415122926235199\n",
      "train epoch: 1/11, round: 437/532, loss: 0.44025763869285583\n",
      "train epoch: 1/11, round: 438/532, loss: 0.45297789573669434\n",
      "train epoch: 1/11, round: 439/532, loss: 0.3958330750465393\n",
      "train epoch: 1/11, round: 440/532, loss: 0.477701336145401\n",
      "train epoch: 1/11, round: 441/532, loss: 0.4394911825656891\n",
      "train epoch: 1/11, round: 442/532, loss: 0.4302426278591156\n",
      "train epoch: 1/11, round: 443/532, loss: 0.4090655446052551\n",
      "train epoch: 1/11, round: 444/532, loss: 0.3757864832878113\n",
      "train epoch: 1/11, round: 445/532, loss: 0.4768059253692627\n",
      "train epoch: 1/11, round: 446/532, loss: 0.3923909366130829\n",
      "train epoch: 1/11, round: 447/532, loss: 0.40703338384628296\n",
      "train epoch: 1/11, round: 448/532, loss: 0.3958122134208679\n",
      "train epoch: 1/11, round: 449/532, loss: 0.3740757405757904\n",
      "train epoch: 1/11, round: 450/532, loss: 0.43170157074928284\n",
      "train epoch: 1/11, round: 451/532, loss: 0.3453189730644226\n",
      "train epoch: 1/11, round: 452/532, loss: 0.45124855637550354\n",
      "train epoch: 1/11, round: 453/532, loss: 0.35535869002342224\n",
      "train epoch: 1/11, round: 454/532, loss: 0.3474227488040924\n",
      "train epoch: 1/11, round: 455/532, loss: 0.36638176441192627\n",
      "train epoch: 1/11, round: 456/532, loss: 0.4146935045719147\n",
      "train epoch: 1/11, round: 457/532, loss: 0.5443658828735352\n",
      "train epoch: 1/11, round: 458/532, loss: 0.4555465281009674\n",
      "train epoch: 1/11, round: 459/532, loss: 0.41141921281814575\n",
      "train epoch: 1/11, round: 460/532, loss: 0.3992379903793335\n",
      "train epoch: 1/11, round: 461/532, loss: 0.44946345686912537\n",
      "train epoch: 1/11, round: 462/532, loss: 0.430492639541626\n",
      "train epoch: 1/11, round: 463/532, loss: 0.3593699038028717\n",
      "train epoch: 1/11, round: 464/532, loss: 0.3638887405395508\n",
      "train epoch: 1/11, round: 465/532, loss: 0.4350516200065613\n",
      "train epoch: 1/11, round: 466/532, loss: 0.3599165976047516\n",
      "train epoch: 1/11, round: 467/532, loss: 0.4267772138118744\n",
      "train epoch: 1/11, round: 468/532, loss: 0.3986683785915375\n",
      "train epoch: 1/11, round: 469/532, loss: 0.4791141450405121\n",
      "train epoch: 1/11, round: 470/532, loss: 0.4151694178581238\n",
      "train epoch: 1/11, round: 471/532, loss: 0.458488792181015\n",
      "train epoch: 1/11, round: 472/532, loss: 0.35884910821914673\n",
      "train epoch: 1/11, round: 473/532, loss: 0.3771926760673523\n",
      "train epoch: 1/11, round: 474/532, loss: 0.37999147176742554\n",
      "train epoch: 1/11, round: 475/532, loss: 0.4672524333000183\n",
      "train epoch: 1/11, round: 476/532, loss: 0.41877084970474243\n",
      "train epoch: 1/11, round: 477/532, loss: 0.4591670632362366\n",
      "train epoch: 1/11, round: 478/532, loss: 0.45087528228759766\n",
      "train epoch: 1/11, round: 479/532, loss: 0.3523338735103607\n",
      "train epoch: 1/11, round: 480/532, loss: 0.4602946639060974\n",
      "train epoch: 1/11, round: 481/532, loss: 0.4381047189235687\n",
      "train epoch: 1/11, round: 482/532, loss: 0.4791225492954254\n",
      "train epoch: 1/11, round: 483/532, loss: 0.4675273001194\n",
      "train epoch: 1/11, round: 484/532, loss: 0.4160514771938324\n",
      "train epoch: 1/11, round: 485/532, loss: 0.4676499366760254\n",
      "train epoch: 1/11, round: 486/532, loss: 0.4852229952812195\n",
      "train epoch: 1/11, round: 487/532, loss: 0.4115982949733734\n",
      "train epoch: 1/11, round: 488/532, loss: 0.4288012385368347\n",
      "train epoch: 1/11, round: 489/532, loss: 0.40015190839767456\n",
      "train epoch: 1/11, round: 490/532, loss: 0.4294711947441101\n",
      "train epoch: 1/11, round: 491/532, loss: 0.43528833985328674\n",
      "train epoch: 1/11, round: 492/532, loss: 0.5329247713088989\n",
      "train epoch: 1/11, round: 493/532, loss: 0.4332984983921051\n",
      "train epoch: 1/11, round: 494/532, loss: 0.40686988830566406\n",
      "train epoch: 1/11, round: 495/532, loss: 0.3809964060783386\n",
      "train epoch: 1/11, round: 496/532, loss: 0.4444260001182556\n",
      "train epoch: 1/11, round: 497/532, loss: 0.4065629839897156\n",
      "train epoch: 1/11, round: 498/532, loss: 0.4616197943687439\n",
      "train epoch: 1/11, round: 499/532, loss: 0.5003914833068848\n",
      "train epoch: 1/11, round: 500/532, loss: 0.37964946031570435\n",
      "train epoch: 1/11, round: 501/532, loss: 0.3888682425022125\n",
      "train epoch: 1/11, round: 502/532, loss: 0.4539068341255188\n",
      "train epoch: 1/11, round: 503/532, loss: 0.4441045820713043\n",
      "train epoch: 1/11, round: 504/532, loss: 0.4052041172981262\n",
      "train epoch: 1/11, round: 505/532, loss: 0.4363577365875244\n",
      "train epoch: 1/11, round: 506/532, loss: 0.45042818784713745\n",
      "train epoch: 1/11, round: 507/532, loss: 0.47976452112197876\n",
      "train epoch: 1/11, round: 508/532, loss: 0.4078804850578308\n",
      "train epoch: 1/11, round: 509/532, loss: 0.3804551661014557\n",
      "train epoch: 1/11, round: 510/532, loss: 0.45255738496780396\n",
      "train epoch: 1/11, round: 511/532, loss: 0.4233705401420593\n",
      "train epoch: 1/11, round: 512/532, loss: 0.36758142709732056\n",
      "train epoch: 1/11, round: 513/532, loss: 0.38575634360313416\n",
      "train epoch: 1/11, round: 514/532, loss: 0.4060550630092621\n",
      "train epoch: 1/11, round: 515/532, loss: 0.34521615505218506\n",
      "train epoch: 1/11, round: 516/532, loss: 0.4257342219352722\n",
      "train epoch: 1/11, round: 517/532, loss: 0.45963019132614136\n",
      "train epoch: 1/11, round: 518/532, loss: 0.40604180097579956\n",
      "train epoch: 1/11, round: 519/532, loss: 0.42142993211746216\n",
      "train epoch: 1/11, round: 520/532, loss: 0.45272618532180786\n",
      "train epoch: 1/11, round: 521/532, loss: 0.4287930428981781\n",
      "train epoch: 1/11, round: 522/532, loss: 0.3851156234741211\n",
      "train epoch: 1/11, round: 523/532, loss: 0.3972395956516266\n",
      "train epoch: 1/11, round: 524/532, loss: 0.442432701587677\n",
      "train epoch: 1/11, round: 525/532, loss: 0.2965172827243805\n",
      "train epoch: 1/11, round: 526/532, loss: 0.41740116477012634\n",
      "train epoch: 1/11, round: 527/532, loss: 0.4469914436340332\n",
      "train epoch: 1/11, round: 528/532, loss: 0.37341827154159546\n",
      "train epoch: 1/11, round: 529/532, loss: 0.42228978872299194\n",
      "train epoch: 1/11, round: 530/532, loss: 0.37211623787879944\n",
      "train epoch: 1/11, round: 531/532, loss: 0.3383100628852844\n",
      "train epoch: 1/11, round: 532/532, loss: 0.4186009466648102\n",
      "train epoch: 1/11, KS: 0.07498466019584782, ROC: 0.5517394592893184\n",
      "test epoch: 1/11, round: 1/501, loss: 0.39951473474502563\n",
      "test epoch: 1/11, round: 2/501, loss: 0.3536563813686371\n",
      "test epoch: 1/11, round: 3/501, loss: 0.25475648045539856\n",
      "test epoch: 1/11, round: 4/501, loss: 0.3923187255859375\n",
      "test epoch: 1/11, round: 5/501, loss: 0.4257754683494568\n",
      "test epoch: 1/11, round: 6/501, loss: 0.3317263424396515\n",
      "test epoch: 1/11, round: 7/501, loss: 0.45615217089653015\n",
      "test epoch: 1/11, round: 8/501, loss: 0.3870181739330292\n",
      "test epoch: 1/11, round: 9/501, loss: 0.5435523390769958\n",
      "test epoch: 1/11, round: 10/501, loss: 0.6812058091163635\n",
      "test epoch: 1/11, round: 11/501, loss: 0.18567845225334167\n",
      "test epoch: 1/11, round: 12/501, loss: 0.3906998038291931\n",
      "test epoch: 1/11, round: 13/501, loss: 0.34120890498161316\n",
      "test epoch: 1/11, round: 14/501, loss: 0.3668651580810547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 1/11, round: 15/501, loss: 0.4855014681816101\n",
      "test epoch: 1/11, round: 16/501, loss: 0.5286858677864075\n",
      "test epoch: 1/11, round: 17/501, loss: 0.4037284851074219\n",
      "test epoch: 1/11, round: 18/501, loss: 0.5574264526367188\n",
      "test epoch: 1/11, round: 19/501, loss: 0.5890697240829468\n",
      "test epoch: 1/11, round: 20/501, loss: 0.7816969752311707\n",
      "test epoch: 1/11, round: 21/501, loss: 0.40253162384033203\n",
      "test epoch: 1/11, round: 22/501, loss: 0.6200827360153198\n",
      "test epoch: 1/11, round: 23/501, loss: 0.5653849244117737\n",
      "test epoch: 1/11, round: 24/501, loss: 0.404579758644104\n",
      "test epoch: 1/11, round: 25/501, loss: 0.5836800336837769\n",
      "test epoch: 1/11, round: 26/501, loss: 0.6757588982582092\n",
      "test epoch: 1/11, round: 27/501, loss: 0.22583205997943878\n",
      "test epoch: 1/11, round: 28/501, loss: 0.44953230023384094\n",
      "test epoch: 1/11, round: 29/501, loss: 0.3210379183292389\n",
      "test epoch: 1/11, round: 30/501, loss: 0.5834327936172485\n",
      "test epoch: 1/11, round: 31/501, loss: 0.47706857323646545\n",
      "test epoch: 1/11, round: 32/501, loss: 0.4371083676815033\n",
      "test epoch: 1/11, round: 33/501, loss: 0.6456635594367981\n",
      "test epoch: 1/11, round: 34/501, loss: 0.5170589089393616\n",
      "test epoch: 1/11, round: 35/501, loss: 0.1953294724225998\n",
      "test epoch: 1/11, round: 36/501, loss: 0.47971099615097046\n",
      "test epoch: 1/11, round: 37/501, loss: 0.45504727959632874\n",
      "test epoch: 1/11, round: 38/501, loss: 0.45154666900634766\n",
      "test epoch: 1/11, round: 39/501, loss: 0.6659708023071289\n",
      "test epoch: 1/11, round: 40/501, loss: 0.580703616142273\n",
      "test epoch: 1/11, round: 41/501, loss: 0.424934446811676\n",
      "test epoch: 1/11, round: 42/501, loss: 0.3852338194847107\n",
      "test epoch: 1/11, round: 43/501, loss: 0.41630277037620544\n",
      "test epoch: 1/11, round: 44/501, loss: 0.5507913827896118\n",
      "test epoch: 1/11, round: 45/501, loss: 0.5870079398155212\n",
      "test epoch: 1/11, round: 46/501, loss: 0.5014551877975464\n",
      "test epoch: 1/11, round: 47/501, loss: 0.3097814619541168\n",
      "test epoch: 1/11, round: 48/501, loss: 0.4882505536079407\n",
      "test epoch: 1/11, round: 49/501, loss: 0.3073883056640625\n",
      "test epoch: 1/11, round: 50/501, loss: 0.2381305992603302\n",
      "test epoch: 1/11, round: 51/501, loss: 0.45315638184547424\n",
      "test epoch: 1/11, round: 52/501, loss: 0.46293947100639343\n",
      "test epoch: 1/11, round: 53/501, loss: 0.5585470795631409\n",
      "test epoch: 1/11, round: 54/501, loss: 0.5408572554588318\n",
      "test epoch: 1/11, round: 55/501, loss: 0.3086903989315033\n",
      "test epoch: 1/11, round: 56/501, loss: 0.4006575644016266\n",
      "test epoch: 1/11, round: 57/501, loss: 0.32050421833992004\n",
      "test epoch: 1/11, round: 58/501, loss: 0.4480922818183899\n",
      "test epoch: 1/11, round: 59/501, loss: 0.2670160233974457\n",
      "test epoch: 1/11, round: 60/501, loss: 0.45765069127082825\n",
      "test epoch: 1/11, round: 61/501, loss: 0.4892713725566864\n",
      "test epoch: 1/11, round: 62/501, loss: 0.6137761473655701\n",
      "test epoch: 1/11, round: 63/501, loss: 0.7059171795845032\n",
      "test epoch: 1/11, round: 64/501, loss: 0.30850908160209656\n",
      "test epoch: 1/11, round: 65/501, loss: 0.5657256841659546\n",
      "test epoch: 1/11, round: 66/501, loss: 0.49853000044822693\n",
      "test epoch: 1/11, round: 67/501, loss: 0.5154039859771729\n",
      "test epoch: 1/11, round: 68/501, loss: 0.6863599419593811\n",
      "test epoch: 1/11, round: 69/501, loss: 0.5086588859558105\n",
      "test epoch: 1/11, round: 70/501, loss: 0.44209569692611694\n",
      "test epoch: 1/11, round: 71/501, loss: 0.6292392611503601\n",
      "test epoch: 1/11, round: 72/501, loss: 0.585228681564331\n",
      "test epoch: 1/11, round: 73/501, loss: 0.5041652917861938\n",
      "test epoch: 1/11, round: 74/501, loss: 0.5720741748809814\n",
      "test epoch: 1/11, round: 75/501, loss: 0.6160747408866882\n",
      "test epoch: 1/11, round: 76/501, loss: 0.7215978503227234\n",
      "test epoch: 1/11, round: 77/501, loss: 0.42100098729133606\n",
      "test epoch: 1/11, round: 78/501, loss: 0.5945605039596558\n",
      "test epoch: 1/11, round: 79/501, loss: 0.39240607619285583\n",
      "test epoch: 1/11, round: 80/501, loss: 0.5846325159072876\n",
      "test epoch: 1/11, round: 81/501, loss: 0.807997465133667\n",
      "test epoch: 1/11, round: 82/501, loss: 0.6529537439346313\n",
      "test epoch: 1/11, round: 83/501, loss: 0.44436365365982056\n",
      "test epoch: 1/11, round: 84/501, loss: 0.5750769376754761\n",
      "test epoch: 1/11, round: 85/501, loss: 0.5940725803375244\n",
      "test epoch: 1/11, round: 86/501, loss: 0.3256392180919647\n",
      "test epoch: 1/11, round: 87/501, loss: 0.43887436389923096\n",
      "test epoch: 1/11, round: 88/501, loss: 0.45951512455940247\n",
      "test epoch: 1/11, round: 89/501, loss: 0.2661367654800415\n",
      "test epoch: 1/11, round: 90/501, loss: 0.6270521879196167\n",
      "test epoch: 1/11, round: 91/501, loss: 0.33068159222602844\n",
      "test epoch: 1/11, round: 92/501, loss: 0.5897042155265808\n",
      "test epoch: 1/11, round: 93/501, loss: 0.44050806760787964\n",
      "test epoch: 1/11, round: 94/501, loss: 0.6426143646240234\n",
      "test epoch: 1/11, round: 95/501, loss: 0.3810330629348755\n",
      "test epoch: 1/11, round: 96/501, loss: 0.3401270806789398\n",
      "test epoch: 1/11, round: 97/501, loss: 0.6955779790878296\n",
      "test epoch: 1/11, round: 98/501, loss: 0.4069804847240448\n",
      "test epoch: 1/11, round: 99/501, loss: 0.5756361484527588\n",
      "test epoch: 1/11, round: 100/501, loss: 0.524710476398468\n",
      "test epoch: 1/11, round: 101/501, loss: 0.5756462812423706\n",
      "test epoch: 1/11, round: 102/501, loss: 0.31205427646636963\n",
      "test epoch: 1/11, round: 103/501, loss: 0.45090097188949585\n",
      "test epoch: 1/11, round: 104/501, loss: 0.6506350636482239\n",
      "test epoch: 1/11, round: 105/501, loss: 0.3861338496208191\n",
      "test epoch: 1/11, round: 106/501, loss: 0.5155761241912842\n",
      "test epoch: 1/11, round: 107/501, loss: 0.3853870928287506\n",
      "test epoch: 1/11, round: 108/501, loss: 0.5861881375312805\n",
      "test epoch: 1/11, round: 109/501, loss: 0.3671768009662628\n",
      "test epoch: 1/11, round: 110/501, loss: 0.7873839139938354\n",
      "test epoch: 1/11, round: 111/501, loss: 0.24954910576343536\n",
      "test epoch: 1/11, round: 112/501, loss: 0.2182895392179489\n",
      "test epoch: 1/11, round: 113/501, loss: 0.4632626175880432\n",
      "test epoch: 1/11, round: 114/501, loss: 0.42263901233673096\n",
      "test epoch: 1/11, round: 115/501, loss: 0.27918556332588196\n",
      "test epoch: 1/11, round: 116/501, loss: 0.35892292857170105\n",
      "test epoch: 1/11, round: 117/501, loss: 0.3439146876335144\n",
      "test epoch: 1/11, round: 118/501, loss: 0.41530030965805054\n",
      "test epoch: 1/11, round: 119/501, loss: 0.32723724842071533\n",
      "test epoch: 1/11, round: 120/501, loss: 0.38202202320098877\n",
      "test epoch: 1/11, round: 121/501, loss: 0.40934842824935913\n",
      "test epoch: 1/11, round: 122/501, loss: 0.3609806001186371\n",
      "test epoch: 1/11, round: 123/501, loss: 0.35211431980133057\n",
      "test epoch: 1/11, round: 124/501, loss: 0.5670566558837891\n",
      "test epoch: 1/11, round: 125/501, loss: 0.42035236954689026\n",
      "test epoch: 1/11, round: 126/501, loss: 0.3630933165550232\n",
      "test epoch: 1/11, round: 127/501, loss: 0.40179502964019775\n",
      "test epoch: 1/11, round: 128/501, loss: 0.20384177565574646\n",
      "test epoch: 1/11, round: 129/501, loss: 0.5019233822822571\n",
      "test epoch: 1/11, round: 130/501, loss: 0.7500346899032593\n",
      "test epoch: 1/11, round: 131/501, loss: 0.598659873008728\n",
      "test epoch: 1/11, round: 132/501, loss: 0.4502663314342499\n",
      "test epoch: 1/11, round: 133/501, loss: 0.7266371250152588\n",
      "test epoch: 1/11, round: 134/501, loss: 0.4845432639122009\n",
      "test epoch: 1/11, round: 135/501, loss: 0.3174937665462494\n",
      "test epoch: 1/11, round: 136/501, loss: 0.3933647871017456\n",
      "test epoch: 1/11, round: 137/501, loss: 0.45037907361984253\n",
      "test epoch: 1/11, round: 138/501, loss: 0.4589213728904724\n",
      "test epoch: 1/11, round: 139/501, loss: 0.5273226499557495\n",
      "test epoch: 1/11, round: 140/501, loss: 0.4584785997867584\n",
      "test epoch: 1/11, round: 141/501, loss: 0.3836733400821686\n",
      "test epoch: 1/11, round: 142/501, loss: 0.5442009568214417\n",
      "test epoch: 1/11, round: 143/501, loss: 0.3973080515861511\n",
      "test epoch: 1/11, round: 144/501, loss: 0.5339096188545227\n",
      "test epoch: 1/11, round: 145/501, loss: 0.34196916222572327\n",
      "test epoch: 1/11, round: 146/501, loss: 0.5888690948486328\n",
      "test epoch: 1/11, round: 147/501, loss: 0.5009915828704834\n",
      "test epoch: 1/11, round: 148/501, loss: 0.4815828204154968\n",
      "test epoch: 1/11, round: 149/501, loss: 0.33302074670791626\n",
      "test epoch: 1/11, round: 150/501, loss: 0.5269520878791809\n",
      "test epoch: 1/11, round: 151/501, loss: 0.4009905457496643\n",
      "test epoch: 1/11, round: 152/501, loss: 0.47766485810279846\n",
      "test epoch: 1/11, round: 153/501, loss: 0.5311392545700073\n",
      "test epoch: 1/11, round: 154/501, loss: 0.5885447263717651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 1/11, round: 155/501, loss: 0.3850448727607727\n",
      "test epoch: 1/11, round: 156/501, loss: 0.340469628572464\n",
      "test epoch: 1/11, round: 157/501, loss: 0.3085707128047943\n",
      "test epoch: 1/11, round: 158/501, loss: 0.4954741299152374\n",
      "test epoch: 1/11, round: 159/501, loss: 0.41637343168258667\n",
      "test epoch: 1/11, round: 160/501, loss: 0.37239935994148254\n",
      "test epoch: 1/11, round: 161/501, loss: 0.38650405406951904\n",
      "test epoch: 1/11, round: 162/501, loss: 0.4854332208633423\n",
      "test epoch: 1/11, round: 163/501, loss: 0.43745169043540955\n",
      "test epoch: 1/11, round: 164/501, loss: 0.3431266248226166\n",
      "test epoch: 1/11, round: 165/501, loss: 0.4927515685558319\n",
      "test epoch: 1/11, round: 166/501, loss: 0.2622857391834259\n",
      "test epoch: 1/11, round: 167/501, loss: 0.15793178975582123\n",
      "test epoch: 1/11, round: 168/501, loss: 0.13935953378677368\n",
      "test epoch: 1/11, round: 169/501, loss: 0.33461564779281616\n",
      "test epoch: 1/11, round: 170/501, loss: 0.38100677728652954\n",
      "test epoch: 1/11, round: 171/501, loss: 0.5000413060188293\n",
      "test epoch: 1/11, round: 172/501, loss: 0.5647790431976318\n",
      "test epoch: 1/11, round: 173/501, loss: 0.27656814455986023\n",
      "test epoch: 1/11, round: 174/501, loss: 0.6116723418235779\n",
      "test epoch: 1/11, round: 175/501, loss: 0.23603878915309906\n",
      "test epoch: 1/11, round: 176/501, loss: 0.5519894361495972\n",
      "test epoch: 1/11, round: 177/501, loss: 0.2669123411178589\n",
      "test epoch: 1/11, round: 178/501, loss: 0.1925727277994156\n",
      "test epoch: 1/11, round: 179/501, loss: 0.19922730326652527\n",
      "test epoch: 1/11, round: 180/501, loss: 0.29987362027168274\n",
      "test epoch: 1/11, round: 181/501, loss: 0.5956516861915588\n",
      "test epoch: 1/11, round: 182/501, loss: 0.6066431403160095\n",
      "test epoch: 1/11, round: 183/501, loss: 0.43041718006134033\n",
      "test epoch: 1/11, round: 184/501, loss: 0.6696158051490784\n",
      "test epoch: 1/11, round: 185/501, loss: 0.4968114197254181\n",
      "test epoch: 1/11, round: 186/501, loss: 0.6349937319755554\n",
      "test epoch: 1/11, round: 187/501, loss: 0.5727850794792175\n",
      "test epoch: 1/11, round: 188/501, loss: 0.5415012240409851\n",
      "test epoch: 1/11, round: 189/501, loss: 0.7706320881843567\n",
      "test epoch: 1/11, round: 190/501, loss: 0.48520928621292114\n",
      "test epoch: 1/11, round: 191/501, loss: 0.3038731515407562\n",
      "test epoch: 1/11, round: 192/501, loss: 0.6102749109268188\n",
      "test epoch: 1/11, round: 193/501, loss: 0.5679497122764587\n",
      "test epoch: 1/11, round: 194/501, loss: 0.4919271469116211\n",
      "test epoch: 1/11, round: 195/501, loss: 0.4409485459327698\n",
      "test epoch: 1/11, round: 196/501, loss: 0.25106188654899597\n",
      "test epoch: 1/11, round: 197/501, loss: 0.480663925409317\n",
      "test epoch: 1/11, round: 198/501, loss: 0.507831335067749\n",
      "test epoch: 1/11, round: 199/501, loss: 0.46164125204086304\n",
      "test epoch: 1/11, round: 200/501, loss: 0.7344681024551392\n",
      "test epoch: 1/11, round: 201/501, loss: 0.33803674578666687\n",
      "test epoch: 1/11, round: 202/501, loss: 0.4210751950740814\n",
      "test epoch: 1/11, round: 203/501, loss: 0.45236533880233765\n",
      "test epoch: 1/11, round: 204/501, loss: 0.6418015360832214\n",
      "test epoch: 1/11, round: 205/501, loss: 0.39559319615364075\n",
      "test epoch: 1/11, round: 206/501, loss: 0.2599618136882782\n",
      "test epoch: 1/11, round: 207/501, loss: 0.47805550694465637\n",
      "test epoch: 1/11, round: 208/501, loss: 0.4945603907108307\n",
      "test epoch: 1/11, round: 209/501, loss: 0.2897573411464691\n",
      "test epoch: 1/11, round: 210/501, loss: 0.4532993733882904\n",
      "test epoch: 1/11, round: 211/501, loss: 0.25142908096313477\n",
      "test epoch: 1/11, round: 212/501, loss: 0.2616980969905853\n",
      "test epoch: 1/11, round: 213/501, loss: 0.2529405653476715\n",
      "test epoch: 1/11, round: 214/501, loss: 0.1778872162103653\n",
      "test epoch: 1/11, round: 215/501, loss: 0.11475971341133118\n",
      "test epoch: 1/11, round: 216/501, loss: 0.10898742824792862\n",
      "test epoch: 1/11, round: 217/501, loss: 0.11358024179935455\n",
      "test epoch: 1/11, round: 218/501, loss: 0.1719946563243866\n",
      "test epoch: 1/11, round: 219/501, loss: 0.18933264911174774\n",
      "test epoch: 1/11, round: 220/501, loss: 0.3984985649585724\n",
      "test epoch: 1/11, round: 221/501, loss: 0.37891286611557007\n",
      "test epoch: 1/11, round: 222/501, loss: 0.11698269844055176\n",
      "test epoch: 1/11, round: 223/501, loss: 0.11667821556329727\n",
      "test epoch: 1/11, round: 224/501, loss: 0.12229040265083313\n",
      "test epoch: 1/11, round: 225/501, loss: 0.12669451534748077\n",
      "test epoch: 1/11, round: 226/501, loss: 0.1165439561009407\n",
      "test epoch: 1/11, round: 227/501, loss: 0.1697685569524765\n",
      "test epoch: 1/11, round: 228/501, loss: 0.18631654977798462\n",
      "test epoch: 1/11, round: 229/501, loss: 0.414241760969162\n",
      "test epoch: 1/11, round: 230/501, loss: 0.25529587268829346\n",
      "test epoch: 1/11, round: 231/501, loss: 0.3223751187324524\n",
      "test epoch: 1/11, round: 232/501, loss: 0.4541987180709839\n",
      "test epoch: 1/11, round: 233/501, loss: 0.48983627557754517\n",
      "test epoch: 1/11, round: 234/501, loss: 0.5139272212982178\n",
      "test epoch: 1/11, round: 235/501, loss: 0.27300992608070374\n",
      "test epoch: 1/11, round: 236/501, loss: 0.29063770174980164\n",
      "test epoch: 1/11, round: 237/501, loss: 0.34572699666023254\n",
      "test epoch: 1/11, round: 238/501, loss: 0.3705882430076599\n",
      "test epoch: 1/11, round: 239/501, loss: 0.3900291323661804\n",
      "test epoch: 1/11, round: 240/501, loss: 0.205644890666008\n",
      "test epoch: 1/11, round: 241/501, loss: 0.38840630650520325\n",
      "test epoch: 1/11, round: 242/501, loss: 0.2877342104911804\n",
      "test epoch: 1/11, round: 243/501, loss: 0.2981671392917633\n",
      "test epoch: 1/11, round: 244/501, loss: 0.24774684011936188\n",
      "test epoch: 1/11, round: 245/501, loss: 0.3978930711746216\n",
      "test epoch: 1/11, round: 246/501, loss: 0.4009350836277008\n",
      "test epoch: 1/11, round: 247/501, loss: 0.47292032837867737\n",
      "test epoch: 1/11, round: 248/501, loss: 0.18947434425354004\n",
      "test epoch: 1/11, round: 249/501, loss: 0.3300343453884125\n",
      "test epoch: 1/11, round: 250/501, loss: 0.27801722288131714\n",
      "test epoch: 1/11, round: 251/501, loss: 0.3249659836292267\n",
      "test epoch: 1/11, round: 252/501, loss: 0.31462809443473816\n",
      "test epoch: 1/11, round: 253/501, loss: 0.3217792809009552\n",
      "test epoch: 1/11, round: 254/501, loss: 0.28165721893310547\n",
      "test epoch: 1/11, round: 255/501, loss: 0.3177589476108551\n",
      "test epoch: 1/11, round: 256/501, loss: 0.45546868443489075\n",
      "test epoch: 1/11, round: 257/501, loss: 0.33533382415771484\n",
      "test epoch: 1/11, round: 258/501, loss: 0.41029441356658936\n",
      "test epoch: 1/11, round: 259/501, loss: 0.24100062251091003\n",
      "test epoch: 1/11, round: 260/501, loss: 0.4341772794723511\n",
      "test epoch: 1/11, round: 261/501, loss: 0.5628693699836731\n",
      "test epoch: 1/11, round: 262/501, loss: 0.4737984836101532\n",
      "test epoch: 1/11, round: 263/501, loss: 0.40104392170906067\n",
      "test epoch: 1/11, round: 264/501, loss: 0.45957663655281067\n",
      "test epoch: 1/11, round: 265/501, loss: 0.6094736456871033\n",
      "test epoch: 1/11, round: 266/501, loss: 0.37705838680267334\n",
      "test epoch: 1/11, round: 267/501, loss: 0.38663846254348755\n",
      "test epoch: 1/11, round: 268/501, loss: 0.2924491763114929\n",
      "test epoch: 1/11, round: 269/501, loss: 0.568182647228241\n",
      "test epoch: 1/11, round: 270/501, loss: 0.26925286650657654\n",
      "test epoch: 1/11, round: 271/501, loss: 0.534789502620697\n",
      "test epoch: 1/11, round: 272/501, loss: 0.4083940386772156\n",
      "test epoch: 1/11, round: 273/501, loss: 0.3539808392524719\n",
      "test epoch: 1/11, round: 274/501, loss: 0.5003505349159241\n",
      "test epoch: 1/11, round: 275/501, loss: 0.31542402505874634\n",
      "test epoch: 1/11, round: 276/501, loss: 0.43509405851364136\n",
      "test epoch: 1/11, round: 277/501, loss: 0.36764684319496155\n",
      "test epoch: 1/11, round: 278/501, loss: 0.6747955679893494\n",
      "test epoch: 1/11, round: 279/501, loss: 0.3056456744670868\n",
      "test epoch: 1/11, round: 280/501, loss: 0.23846343159675598\n",
      "test epoch: 1/11, round: 281/501, loss: 0.188131183385849\n",
      "test epoch: 1/11, round: 282/501, loss: 0.2599135935306549\n",
      "test epoch: 1/11, round: 283/501, loss: 0.19641581177711487\n",
      "test epoch: 1/11, round: 284/501, loss: 0.31784024834632874\n",
      "test epoch: 1/11, round: 285/501, loss: 0.5284277200698853\n",
      "test epoch: 1/11, round: 286/501, loss: 0.3754352927207947\n",
      "test epoch: 1/11, round: 287/501, loss: 0.6154700517654419\n",
      "test epoch: 1/11, round: 288/501, loss: 0.24418401718139648\n",
      "test epoch: 1/11, round: 289/501, loss: 0.3482874631881714\n",
      "test epoch: 1/11, round: 290/501, loss: 0.32456862926483154\n",
      "test epoch: 1/11, round: 291/501, loss: 0.4693174362182617\n",
      "test epoch: 1/11, round: 292/501, loss: 0.4919498860836029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 1/11, round: 293/501, loss: 0.5084311962127686\n",
      "test epoch: 1/11, round: 294/501, loss: 0.2066756635904312\n",
      "test epoch: 1/11, round: 295/501, loss: 0.3160804212093353\n",
      "test epoch: 1/11, round: 296/501, loss: 0.4383290708065033\n",
      "test epoch: 1/11, round: 297/501, loss: 0.36794769763946533\n",
      "test epoch: 1/11, round: 298/501, loss: 0.42313745617866516\n",
      "test epoch: 1/11, round: 299/501, loss: 0.40063005685806274\n",
      "test epoch: 1/11, round: 300/501, loss: 0.514183759689331\n",
      "test epoch: 1/11, round: 301/501, loss: 0.403307169675827\n",
      "test epoch: 1/11, round: 302/501, loss: 0.2683860957622528\n",
      "test epoch: 1/11, round: 303/501, loss: 0.5954509973526001\n",
      "test epoch: 1/11, round: 304/501, loss: 0.6449233889579773\n",
      "test epoch: 1/11, round: 305/501, loss: 0.19311554729938507\n",
      "test epoch: 1/11, round: 306/501, loss: 0.29108741879463196\n",
      "test epoch: 1/11, round: 307/501, loss: 0.5237768888473511\n",
      "test epoch: 1/11, round: 308/501, loss: 0.24377679824829102\n",
      "test epoch: 1/11, round: 309/501, loss: 0.43733587861061096\n",
      "test epoch: 1/11, round: 310/501, loss: 0.3817497789859772\n",
      "test epoch: 1/11, round: 311/501, loss: 0.5357144474983215\n",
      "test epoch: 1/11, round: 312/501, loss: 0.3638822138309479\n",
      "test epoch: 1/11, round: 313/501, loss: 0.37701892852783203\n",
      "test epoch: 1/11, round: 314/501, loss: 0.30851319432258606\n",
      "test epoch: 1/11, round: 315/501, loss: 0.32907232642173767\n",
      "test epoch: 1/11, round: 316/501, loss: 0.3190865218639374\n",
      "test epoch: 1/11, round: 317/501, loss: 0.34397685527801514\n",
      "test epoch: 1/11, round: 318/501, loss: 0.37494829297065735\n",
      "test epoch: 1/11, round: 319/501, loss: 0.644612729549408\n",
      "test epoch: 1/11, round: 320/501, loss: 0.35726282000541687\n",
      "test epoch: 1/11, round: 321/501, loss: 0.2934052348136902\n",
      "test epoch: 1/11, round: 322/501, loss: 0.3958759605884552\n",
      "test epoch: 1/11, round: 323/501, loss: 0.4882734417915344\n",
      "test epoch: 1/11, round: 324/501, loss: 0.34413036704063416\n",
      "test epoch: 1/11, round: 325/501, loss: 0.42555099725723267\n",
      "test epoch: 1/11, round: 326/501, loss: 0.4744485318660736\n",
      "test epoch: 1/11, round: 327/501, loss: 0.6668725609779358\n",
      "test epoch: 1/11, round: 328/501, loss: 0.19758062064647675\n",
      "test epoch: 1/11, round: 329/501, loss: 0.43531712889671326\n",
      "test epoch: 1/11, round: 330/501, loss: 0.547366201877594\n",
      "test epoch: 1/11, round: 331/501, loss: 0.41031232476234436\n",
      "test epoch: 1/11, round: 332/501, loss: 0.3381439745426178\n",
      "test epoch: 1/11, round: 333/501, loss: 0.4011445939540863\n",
      "test epoch: 1/11, round: 334/501, loss: 0.21925793588161469\n",
      "test epoch: 1/11, round: 335/501, loss: 0.37257176637649536\n",
      "test epoch: 1/11, round: 336/501, loss: 0.38701826333999634\n",
      "test epoch: 1/11, round: 337/501, loss: 0.5741005539894104\n",
      "test epoch: 1/11, round: 338/501, loss: 0.3939756155014038\n",
      "test epoch: 1/11, round: 339/501, loss: 0.9934820532798767\n",
      "test epoch: 1/11, round: 340/501, loss: 0.4343481957912445\n",
      "test epoch: 1/11, round: 341/501, loss: 0.47889792919158936\n",
      "test epoch: 1/11, round: 342/501, loss: 0.3725645840167999\n",
      "test epoch: 1/11, round: 343/501, loss: 0.3562833368778229\n",
      "test epoch: 1/11, round: 344/501, loss: 0.2597288489341736\n",
      "test epoch: 1/11, round: 345/501, loss: 0.2047366350889206\n",
      "test epoch: 1/11, round: 346/501, loss: 0.364266574382782\n",
      "test epoch: 1/11, round: 347/501, loss: 0.353761225938797\n",
      "test epoch: 1/11, round: 348/501, loss: 0.3508024215698242\n",
      "test epoch: 1/11, round: 349/501, loss: 0.3394503891468048\n",
      "test epoch: 1/11, round: 350/501, loss: 0.4297543168067932\n",
      "test epoch: 1/11, round: 351/501, loss: 0.4255408048629761\n",
      "test epoch: 1/11, round: 352/501, loss: 0.511689305305481\n",
      "test epoch: 1/11, round: 353/501, loss: 0.40217095613479614\n",
      "test epoch: 1/11, round: 354/501, loss: 0.5260964035987854\n",
      "test epoch: 1/11, round: 355/501, loss: 0.38384106755256653\n",
      "test epoch: 1/11, round: 356/501, loss: 0.556198000907898\n",
      "test epoch: 1/11, round: 357/501, loss: 0.46092066168785095\n",
      "test epoch: 1/11, round: 358/501, loss: 0.38071784377098083\n",
      "test epoch: 1/11, round: 359/501, loss: 0.3699341118335724\n",
      "test epoch: 1/11, round: 360/501, loss: 0.5522196292877197\n",
      "test epoch: 1/11, round: 361/501, loss: 0.5801888704299927\n",
      "test epoch: 1/11, round: 362/501, loss: 0.415901243686676\n",
      "test epoch: 1/11, round: 363/501, loss: 0.5725104212760925\n",
      "test epoch: 1/11, round: 364/501, loss: 0.48769646883010864\n",
      "test epoch: 1/11, round: 365/501, loss: 0.45280835032463074\n",
      "test epoch: 1/11, round: 366/501, loss: 0.5858435034751892\n",
      "test epoch: 1/11, round: 367/501, loss: 0.7166011929512024\n",
      "test epoch: 1/11, round: 368/501, loss: 0.2744617462158203\n",
      "test epoch: 1/11, round: 369/501, loss: 0.36476942896842957\n",
      "test epoch: 1/11, round: 370/501, loss: 0.35131320357322693\n",
      "test epoch: 1/11, round: 371/501, loss: 0.3982914090156555\n",
      "test epoch: 1/11, round: 372/501, loss: 0.3307963013648987\n",
      "test epoch: 1/11, round: 373/501, loss: 0.419365257024765\n",
      "test epoch: 1/11, round: 374/501, loss: 0.3410525619983673\n",
      "test epoch: 1/11, round: 375/501, loss: 0.3887581527233124\n",
      "test epoch: 1/11, round: 376/501, loss: 0.5205700993537903\n",
      "test epoch: 1/11, round: 377/501, loss: 0.143821582198143\n",
      "test epoch: 1/11, round: 378/501, loss: 0.1426142007112503\n",
      "test epoch: 1/11, round: 379/501, loss: 0.47248154878616333\n",
      "test epoch: 1/11, round: 380/501, loss: 0.26993808150291443\n",
      "test epoch: 1/11, round: 381/501, loss: 0.3911674916744232\n",
      "test epoch: 1/11, round: 382/501, loss: 0.2593197822570801\n",
      "test epoch: 1/11, round: 383/501, loss: 0.365934282541275\n",
      "test epoch: 1/11, round: 384/501, loss: 0.23033064603805542\n",
      "test epoch: 1/11, round: 385/501, loss: 0.5347960591316223\n",
      "test epoch: 1/11, round: 386/501, loss: 0.6334630846977234\n",
      "test epoch: 1/11, round: 387/501, loss: 0.3118215799331665\n",
      "test epoch: 1/11, round: 388/501, loss: 0.26070311665534973\n",
      "test epoch: 1/11, round: 389/501, loss: 0.33428189158439636\n",
      "test epoch: 1/11, round: 390/501, loss: 0.41266873478889465\n",
      "test epoch: 1/11, round: 391/501, loss: 0.391361266374588\n",
      "test epoch: 1/11, round: 392/501, loss: 0.42322394251823425\n",
      "test epoch: 1/11, round: 393/501, loss: 0.3585360646247864\n",
      "test epoch: 1/11, round: 394/501, loss: 0.6261582970619202\n",
      "test epoch: 1/11, round: 395/501, loss: 0.2615625262260437\n",
      "test epoch: 1/11, round: 396/501, loss: 0.3931085467338562\n",
      "test epoch: 1/11, round: 397/501, loss: 0.47817671298980713\n",
      "test epoch: 1/11, round: 398/501, loss: 0.5027391910552979\n",
      "test epoch: 1/11, round: 399/501, loss: 0.3055720627307892\n",
      "test epoch: 1/11, round: 400/501, loss: 0.29637718200683594\n",
      "test epoch: 1/11, round: 401/501, loss: 0.6154294610023499\n",
      "test epoch: 1/11, round: 402/501, loss: 0.42490071058273315\n",
      "test epoch: 1/11, round: 403/501, loss: 0.29091110825538635\n",
      "test epoch: 1/11, round: 404/501, loss: 0.21102161705493927\n",
      "test epoch: 1/11, round: 405/501, loss: 0.7051307559013367\n",
      "test epoch: 1/11, round: 406/501, loss: 0.4506683349609375\n",
      "test epoch: 1/11, round: 407/501, loss: 0.48401933908462524\n",
      "test epoch: 1/11, round: 408/501, loss: 0.4987793564796448\n",
      "test epoch: 1/11, round: 409/501, loss: 0.5729799866676331\n",
      "test epoch: 1/11, round: 410/501, loss: 0.3497221767902374\n",
      "test epoch: 1/11, round: 411/501, loss: 0.3769007921218872\n",
      "test epoch: 1/11, round: 412/501, loss: 0.46924299001693726\n",
      "test epoch: 1/11, round: 413/501, loss: 0.4606548845767975\n",
      "test epoch: 1/11, round: 414/501, loss: 0.3502081036567688\n",
      "test epoch: 1/11, round: 415/501, loss: 0.353866308927536\n",
      "test epoch: 1/11, round: 416/501, loss: 0.4255031943321228\n",
      "test epoch: 1/11, round: 417/501, loss: 0.28177064657211304\n",
      "test epoch: 1/11, round: 418/501, loss: 0.34638512134552\n",
      "test epoch: 1/11, round: 419/501, loss: 0.41195517778396606\n",
      "test epoch: 1/11, round: 420/501, loss: 0.31171756982803345\n",
      "test epoch: 1/11, round: 421/501, loss: 0.43096819519996643\n",
      "test epoch: 1/11, round: 422/501, loss: 0.3534327447414398\n",
      "test epoch: 1/11, round: 423/501, loss: 0.5925986170768738\n",
      "test epoch: 1/11, round: 424/501, loss: 0.39543768763542175\n",
      "test epoch: 1/11, round: 425/501, loss: 0.3248869776725769\n",
      "test epoch: 1/11, round: 426/501, loss: 0.5142530798912048\n",
      "test epoch: 1/11, round: 427/501, loss: 0.31345662474632263\n",
      "test epoch: 1/11, round: 428/501, loss: 0.5273785591125488\n",
      "test epoch: 1/11, round: 429/501, loss: 0.6319102048873901\n",
      "test epoch: 1/11, round: 430/501, loss: 0.5184433460235596\n",
      "test epoch: 1/11, round: 431/501, loss: 0.426051527261734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 1/11, round: 432/501, loss: 0.32577481865882874\n",
      "test epoch: 1/11, round: 433/501, loss: 0.4136117994785309\n",
      "test epoch: 1/11, round: 434/501, loss: 0.30485600233078003\n",
      "test epoch: 1/11, round: 435/501, loss: 0.3335604965686798\n",
      "test epoch: 1/11, round: 436/501, loss: 0.34993794560432434\n",
      "test epoch: 1/11, round: 437/501, loss: 0.4455679655075073\n",
      "test epoch: 1/11, round: 438/501, loss: 0.5654886364936829\n",
      "test epoch: 1/11, round: 439/501, loss: 0.33065834641456604\n",
      "test epoch: 1/11, round: 440/501, loss: 0.49367615580558777\n",
      "test epoch: 1/11, round: 441/501, loss: 0.3791549801826477\n",
      "test epoch: 1/11, round: 442/501, loss: 0.3246205747127533\n",
      "test epoch: 1/11, round: 443/501, loss: 0.2762714624404907\n",
      "test epoch: 1/11, round: 444/501, loss: 0.3986400365829468\n",
      "test epoch: 1/11, round: 445/501, loss: 0.43840450048446655\n",
      "test epoch: 1/11, round: 446/501, loss: 0.4745407700538635\n",
      "test epoch: 1/11, round: 447/501, loss: 0.25430846214294434\n",
      "test epoch: 1/11, round: 448/501, loss: 0.34850600361824036\n",
      "test epoch: 1/11, round: 449/501, loss: 0.2069731056690216\n",
      "test epoch: 1/11, round: 450/501, loss: 0.6512244939804077\n",
      "test epoch: 1/11, round: 451/501, loss: 0.3271935284137726\n",
      "test epoch: 1/11, round: 452/501, loss: 0.3769833743572235\n",
      "test epoch: 1/11, round: 453/501, loss: 0.17789201438426971\n",
      "test epoch: 1/11, round: 454/501, loss: 0.20310422778129578\n",
      "test epoch: 1/11, round: 455/501, loss: 0.5615914463996887\n",
      "test epoch: 1/11, round: 456/501, loss: 0.2706812918186188\n",
      "test epoch: 1/11, round: 457/501, loss: 0.2557898461818695\n",
      "test epoch: 1/11, round: 458/501, loss: 0.21734558045864105\n",
      "test epoch: 1/11, round: 459/501, loss: 0.12763848900794983\n",
      "test epoch: 1/11, round: 460/501, loss: 0.13714811205863953\n",
      "test epoch: 1/11, round: 461/501, loss: 0.13707377016544342\n",
      "test epoch: 1/11, round: 462/501, loss: 0.1303194910287857\n",
      "test epoch: 1/11, round: 463/501, loss: 0.12392228096723557\n",
      "test epoch: 1/11, round: 464/501, loss: 0.1326325684785843\n",
      "test epoch: 1/11, round: 465/501, loss: 0.14183762669563293\n",
      "test epoch: 1/11, round: 466/501, loss: 0.1280098557472229\n",
      "test epoch: 1/11, round: 467/501, loss: 0.13360287249088287\n",
      "test epoch: 1/11, round: 468/501, loss: 0.12695476412773132\n",
      "test epoch: 1/11, round: 469/501, loss: 0.13914725184440613\n",
      "test epoch: 1/11, round: 470/501, loss: 0.13202795386314392\n",
      "test epoch: 1/11, round: 471/501, loss: 0.13690395653247833\n",
      "test epoch: 1/11, round: 472/501, loss: 0.1354394555091858\n",
      "test epoch: 1/11, round: 473/501, loss: 0.12878768146038055\n",
      "test epoch: 1/11, round: 474/501, loss: 0.14563249051570892\n",
      "test epoch: 1/11, round: 475/501, loss: 0.13956306874752045\n",
      "test epoch: 1/11, round: 476/501, loss: 0.12866146862506866\n",
      "test epoch: 1/11, round: 477/501, loss: 0.12778668105602264\n",
      "test epoch: 1/11, round: 478/501, loss: 0.12751559913158417\n",
      "test epoch: 1/11, round: 479/501, loss: 0.11265566945075989\n",
      "test epoch: 1/11, round: 480/501, loss: 0.13057062029838562\n",
      "test epoch: 1/11, round: 481/501, loss: 0.12205705791711807\n",
      "test epoch: 1/11, round: 482/501, loss: 0.1286490261554718\n",
      "test epoch: 1/11, round: 483/501, loss: 0.12006288021802902\n",
      "test epoch: 1/11, round: 484/501, loss: 0.12616418302059174\n",
      "test epoch: 1/11, round: 485/501, loss: 0.12151219695806503\n",
      "test epoch: 1/11, round: 486/501, loss: 0.13116715848445892\n",
      "test epoch: 1/11, round: 487/501, loss: 0.12879039347171783\n",
      "test epoch: 1/11, round: 488/501, loss: 0.1408550888299942\n",
      "test epoch: 1/11, round: 489/501, loss: 0.11750996857881546\n",
      "test epoch: 1/11, round: 490/501, loss: 0.1096818745136261\n",
      "test epoch: 1/11, round: 491/501, loss: 0.11701487749814987\n",
      "test epoch: 1/11, round: 492/501, loss: 0.13133272528648376\n",
      "test epoch: 1/11, round: 493/501, loss: 0.13273686170578003\n",
      "test epoch: 1/11, round: 494/501, loss: 0.13943172991275787\n",
      "test epoch: 1/11, round: 495/501, loss: 0.11890791356563568\n",
      "test epoch: 1/11, round: 496/501, loss: 0.13874326646327972\n",
      "test epoch: 1/11, round: 497/501, loss: 0.13238881528377533\n",
      "test epoch: 1/11, round: 498/501, loss: 0.11317943036556244\n",
      "test epoch: 1/11, round: 499/501, loss: 0.11428762972354889\n",
      "test epoch: 1/11, round: 500/501, loss: 0.34640565514564514\n",
      "test epoch: 1/11, round: 501/501, loss: 0.8527544140815735\n",
      "test epoch: 1/11, KS: 0.1477622471608091, ROC: 0.5991381627578791\n",
      "cost time: 1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sloop\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type MnasNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\sloop\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type InvertedResidual. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2/11, round: 1/532, loss: 0.4546927809715271\n",
      "train epoch: 2/11, round: 2/532, loss: 0.43667683005332947\n",
      "train epoch: 2/11, round: 3/532, loss: 0.39080721139907837\n",
      "train epoch: 2/11, round: 4/532, loss: 0.5133320093154907\n",
      "train epoch: 2/11, round: 5/532, loss: 0.4364377558231354\n",
      "train epoch: 2/11, round: 6/532, loss: 0.43450236320495605\n",
      "train epoch: 2/11, round: 7/532, loss: 0.4122926592826843\n",
      "train epoch: 2/11, round: 8/532, loss: 0.46564945578575134\n",
      "train epoch: 2/11, round: 9/532, loss: 0.43858522176742554\n",
      "train epoch: 2/11, round: 10/532, loss: 0.4033544659614563\n",
      "train epoch: 2/11, round: 11/532, loss: 0.39191684126853943\n",
      "train epoch: 2/11, round: 12/532, loss: 0.43580636382102966\n",
      "train epoch: 2/11, round: 13/532, loss: 0.5445637702941895\n",
      "train epoch: 2/11, round: 14/532, loss: 0.459016889333725\n",
      "train epoch: 2/11, round: 15/532, loss: 0.38217219710350037\n",
      "train epoch: 2/11, round: 16/532, loss: 0.39700227975845337\n",
      "train epoch: 2/11, round: 17/532, loss: 0.3649650514125824\n",
      "train epoch: 2/11, round: 18/532, loss: 0.46656888723373413\n",
      "train epoch: 2/11, round: 19/532, loss: 0.4643617570400238\n",
      "train epoch: 2/11, round: 20/532, loss: 0.43845924735069275\n",
      "train epoch: 2/11, round: 21/532, loss: 0.41731366515159607\n",
      "train epoch: 2/11, round: 22/532, loss: 0.41829314827919006\n",
      "train epoch: 2/11, round: 23/532, loss: 0.2980244755744934\n",
      "train epoch: 2/11, round: 24/532, loss: 0.5203224420547485\n",
      "train epoch: 2/11, round: 25/532, loss: 0.3890732228755951\n",
      "train epoch: 2/11, round: 26/532, loss: 0.44335755705833435\n",
      "train epoch: 2/11, round: 27/532, loss: 0.40307706594467163\n",
      "train epoch: 2/11, round: 28/532, loss: 0.5746555328369141\n",
      "train epoch: 2/11, round: 29/532, loss: 0.3612196445465088\n",
      "train epoch: 2/11, round: 30/532, loss: 0.4364183843135834\n",
      "train epoch: 2/11, round: 31/532, loss: 0.36152639985084534\n",
      "train epoch: 2/11, round: 32/532, loss: 0.35422009229660034\n",
      "train epoch: 2/11, round: 33/532, loss: 0.4561138153076172\n",
      "train epoch: 2/11, round: 34/532, loss: 0.46105068922042847\n",
      "train epoch: 2/11, round: 35/532, loss: 0.35734453797340393\n",
      "train epoch: 2/11, round: 36/532, loss: 0.4042724668979645\n",
      "train epoch: 2/11, round: 37/532, loss: 0.3798966407775879\n",
      "train epoch: 2/11, round: 38/532, loss: 0.35326099395751953\n",
      "train epoch: 2/11, round: 39/532, loss: 0.433424174785614\n",
      "train epoch: 2/11, round: 40/532, loss: 0.4989026188850403\n",
      "train epoch: 2/11, round: 41/532, loss: 0.3498339056968689\n",
      "train epoch: 2/11, round: 42/532, loss: 0.4247414469718933\n",
      "train epoch: 2/11, round: 43/532, loss: 0.3601723611354828\n",
      "train epoch: 2/11, round: 44/532, loss: 0.3252963125705719\n",
      "train epoch: 2/11, round: 45/532, loss: 0.3401713967323303\n",
      "train epoch: 2/11, round: 46/532, loss: 0.4378941059112549\n",
      "train epoch: 2/11, round: 47/532, loss: 0.3959729075431824\n",
      "train epoch: 2/11, round: 48/532, loss: 0.5419096946716309\n",
      "train epoch: 2/11, round: 49/532, loss: 0.35697999596595764\n",
      "train epoch: 2/11, round: 50/532, loss: 0.3978894352912903\n",
      "train epoch: 2/11, round: 51/532, loss: 0.413433313369751\n",
      "train epoch: 2/11, round: 52/532, loss: 0.3757548928260803\n",
      "train epoch: 2/11, round: 53/532, loss: 0.4103735089302063\n",
      "train epoch: 2/11, round: 54/532, loss: 0.5546045899391174\n",
      "train epoch: 2/11, round: 55/532, loss: 0.4509080946445465\n",
      "train epoch: 2/11, round: 56/532, loss: 0.38990873098373413\n",
      "train epoch: 2/11, round: 57/532, loss: 0.4328001141548157\n",
      "train epoch: 2/11, round: 58/532, loss: 0.43286022543907166\n",
      "train epoch: 2/11, round: 59/532, loss: 0.34657835960388184\n",
      "train epoch: 2/11, round: 60/532, loss: 0.44824257493019104\n",
      "train epoch: 2/11, round: 61/532, loss: 0.3981812596321106\n",
      "train epoch: 2/11, round: 62/532, loss: 0.4682862162590027\n",
      "train epoch: 2/11, round: 63/532, loss: 0.39201289415359497\n",
      "train epoch: 2/11, round: 64/532, loss: 0.3431227505207062\n",
      "train epoch: 2/11, round: 65/532, loss: 0.46623319387435913\n",
      "train epoch: 2/11, round: 66/532, loss: 0.5248008966445923\n",
      "train epoch: 2/11, round: 67/532, loss: 0.45459359884262085\n",
      "train epoch: 2/11, round: 68/532, loss: 0.42817267775535583\n",
      "train epoch: 2/11, round: 69/532, loss: 0.41609811782836914\n",
      "train epoch: 2/11, round: 70/532, loss: 0.4791816771030426\n",
      "train epoch: 2/11, round: 71/532, loss: 0.43938690423965454\n",
      "train epoch: 2/11, round: 72/532, loss: 0.39467257261276245\n",
      "train epoch: 2/11, round: 73/532, loss: 0.41952842473983765\n",
      "train epoch: 2/11, round: 74/532, loss: 0.43664923310279846\n",
      "train epoch: 2/11, round: 75/532, loss: 0.43996500968933105\n",
      "train epoch: 2/11, round: 76/532, loss: 0.46640124917030334\n",
      "train epoch: 2/11, round: 77/532, loss: 0.4293968081474304\n",
      "train epoch: 2/11, round: 78/532, loss: 0.33089613914489746\n",
      "train epoch: 2/11, round: 79/532, loss: 0.40238863229751587\n",
      "train epoch: 2/11, round: 80/532, loss: 0.3570263683795929\n",
      "train epoch: 2/11, round: 81/532, loss: 0.3963121473789215\n",
      "train epoch: 2/11, round: 82/532, loss: 0.47075024247169495\n",
      "train epoch: 2/11, round: 83/532, loss: 0.44094571471214294\n",
      "train epoch: 2/11, round: 84/532, loss: 0.3559974730014801\n",
      "train epoch: 2/11, round: 85/532, loss: 0.30321982502937317\n",
      "train epoch: 2/11, round: 86/532, loss: 0.44998082518577576\n",
      "train epoch: 2/11, round: 87/532, loss: 0.4133027493953705\n",
      "train epoch: 2/11, round: 88/532, loss: 0.48906049132347107\n",
      "train epoch: 2/11, round: 89/532, loss: 0.5123081207275391\n",
      "train epoch: 2/11, round: 90/532, loss: 0.4514501094818115\n",
      "train epoch: 2/11, round: 91/532, loss: 0.5211113095283508\n",
      "train epoch: 2/11, round: 92/532, loss: 0.345537006855011\n",
      "train epoch: 2/11, round: 93/532, loss: 0.43913474678993225\n",
      "train epoch: 2/11, round: 94/532, loss: 0.39644333720207214\n",
      "train epoch: 2/11, round: 95/532, loss: 0.40374645590782166\n",
      "train epoch: 2/11, round: 96/532, loss: 0.34521883726119995\n",
      "train epoch: 2/11, round: 97/532, loss: 0.3757699728012085\n",
      "train epoch: 2/11, round: 98/532, loss: 0.41232675313949585\n",
      "train epoch: 2/11, round: 99/532, loss: 0.47006431221961975\n",
      "train epoch: 2/11, round: 100/532, loss: 0.377625048160553\n",
      "train epoch: 2/11, round: 101/532, loss: 0.48801127076148987\n",
      "train epoch: 2/11, round: 102/532, loss: 0.43213310837745667\n",
      "train epoch: 2/11, round: 103/532, loss: 0.3527347445487976\n",
      "train epoch: 2/11, round: 104/532, loss: 0.43757694959640503\n",
      "train epoch: 2/11, round: 105/532, loss: 0.3909943699836731\n",
      "train epoch: 2/11, round: 106/532, loss: 0.5234590768814087\n",
      "train epoch: 2/11, round: 107/532, loss: 0.41693931818008423\n",
      "train epoch: 2/11, round: 108/532, loss: 0.39984458684921265\n",
      "train epoch: 2/11, round: 109/532, loss: 0.41269445419311523\n",
      "train epoch: 2/11, round: 110/532, loss: 0.4178069233894348\n",
      "train epoch: 2/11, round: 111/532, loss: 0.42031511664390564\n",
      "train epoch: 2/11, round: 112/532, loss: 0.43643155694007874\n",
      "train epoch: 2/11, round: 113/532, loss: 0.483071893453598\n",
      "train epoch: 2/11, round: 114/532, loss: 0.41289791464805603\n",
      "train epoch: 2/11, round: 115/532, loss: 0.3963053226470947\n",
      "train epoch: 2/11, round: 116/532, loss: 0.4684041440486908\n",
      "train epoch: 2/11, round: 117/532, loss: 0.48615211248397827\n",
      "train epoch: 2/11, round: 118/532, loss: 0.3849567770957947\n",
      "train epoch: 2/11, round: 119/532, loss: 0.4107699990272522\n",
      "train epoch: 2/11, round: 120/532, loss: 0.41902679204940796\n",
      "train epoch: 2/11, round: 121/532, loss: 0.32126742601394653\n",
      "train epoch: 2/11, round: 122/532, loss: 0.36189866065979004\n",
      "train epoch: 2/11, round: 123/532, loss: 0.3724697530269623\n",
      "train epoch: 2/11, round: 124/532, loss: 0.4891441762447357\n",
      "train epoch: 2/11, round: 125/532, loss: 0.445089191198349\n",
      "train epoch: 2/11, round: 126/532, loss: 0.479759156703949\n",
      "train epoch: 2/11, round: 127/532, loss: 0.5060229301452637\n",
      "train epoch: 2/11, round: 128/532, loss: 0.3451351523399353\n",
      "train epoch: 2/11, round: 129/532, loss: 0.41998490691185\n",
      "train epoch: 2/11, round: 130/532, loss: 0.384229838848114\n",
      "train epoch: 2/11, round: 131/532, loss: 0.3663327991962433\n",
      "train epoch: 2/11, round: 132/532, loss: 0.37863245606422424\n",
      "train epoch: 2/11, round: 133/532, loss: 0.41106778383255005\n",
      "train epoch: 2/11, round: 134/532, loss: 0.4767892360687256\n",
      "train epoch: 2/11, round: 135/532, loss: 0.4726801812648773\n",
      "train epoch: 2/11, round: 136/532, loss: 0.4390730857849121\n",
      "train epoch: 2/11, round: 137/532, loss: 0.38588929176330566\n",
      "train epoch: 2/11, round: 138/532, loss: 0.3820532262325287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2/11, round: 139/532, loss: 0.4467243254184723\n",
      "train epoch: 2/11, round: 140/532, loss: 0.3816487193107605\n",
      "train epoch: 2/11, round: 141/532, loss: 0.39025408029556274\n",
      "train epoch: 2/11, round: 142/532, loss: 0.4847906529903412\n",
      "train epoch: 2/11, round: 143/532, loss: 0.3432764410972595\n",
      "train epoch: 2/11, round: 144/532, loss: 0.3810485303401947\n",
      "train epoch: 2/11, round: 145/532, loss: 0.3759242296218872\n",
      "train epoch: 2/11, round: 146/532, loss: 0.41074293851852417\n",
      "train epoch: 2/11, round: 147/532, loss: 0.45174646377563477\n",
      "train epoch: 2/11, round: 148/532, loss: 0.43712592124938965\n",
      "train epoch: 2/11, round: 149/532, loss: 0.44667595624923706\n",
      "train epoch: 2/11, round: 150/532, loss: 0.4680926203727722\n",
      "train epoch: 2/11, round: 151/532, loss: 0.380097895860672\n",
      "train epoch: 2/11, round: 152/532, loss: 0.3442544639110565\n",
      "train epoch: 2/11, round: 153/532, loss: 0.359884649515152\n",
      "train epoch: 2/11, round: 154/532, loss: 0.3785719573497772\n",
      "train epoch: 2/11, round: 155/532, loss: 0.37588441371917725\n",
      "train epoch: 2/11, round: 156/532, loss: 0.35124772787094116\n",
      "train epoch: 2/11, round: 157/532, loss: 0.47667327523231506\n",
      "train epoch: 2/11, round: 158/532, loss: 0.3489557206630707\n",
      "train epoch: 2/11, round: 159/532, loss: 0.43982940912246704\n",
      "train epoch: 2/11, round: 160/532, loss: 0.4199209213256836\n",
      "train epoch: 2/11, round: 161/532, loss: 0.4484807550907135\n",
      "train epoch: 2/11, round: 162/532, loss: 0.3480234742164612\n",
      "train epoch: 2/11, round: 163/532, loss: 0.37148579955101013\n",
      "train epoch: 2/11, round: 164/532, loss: 0.4158249795436859\n",
      "train epoch: 2/11, round: 165/532, loss: 0.45222941040992737\n",
      "train epoch: 2/11, round: 166/532, loss: 0.3933411240577698\n",
      "train epoch: 2/11, round: 167/532, loss: 0.45480069518089294\n",
      "train epoch: 2/11, round: 168/532, loss: 0.41384077072143555\n",
      "train epoch: 2/11, round: 169/532, loss: 0.5195464491844177\n",
      "train epoch: 2/11, round: 170/532, loss: 0.3567122220993042\n",
      "train epoch: 2/11, round: 171/532, loss: 0.3654036223888397\n",
      "train epoch: 2/11, round: 172/532, loss: 0.4220256805419922\n",
      "train epoch: 2/11, round: 173/532, loss: 0.43118971586227417\n",
      "train epoch: 2/11, round: 174/532, loss: 0.3486289978027344\n",
      "train epoch: 2/11, round: 175/532, loss: 0.4431668221950531\n",
      "train epoch: 2/11, round: 176/532, loss: 0.4398588240146637\n",
      "train epoch: 2/11, round: 177/532, loss: 0.40683650970458984\n",
      "train epoch: 2/11, round: 178/532, loss: 0.4379505217075348\n",
      "train epoch: 2/11, round: 179/532, loss: 0.4112117290496826\n",
      "train epoch: 2/11, round: 180/532, loss: 0.3687542974948883\n",
      "train epoch: 2/11, round: 181/532, loss: 0.38471049070358276\n",
      "train epoch: 2/11, round: 182/532, loss: 0.4260789453983307\n",
      "train epoch: 2/11, round: 183/532, loss: 0.402834951877594\n",
      "train epoch: 2/11, round: 184/532, loss: 0.4415959417819977\n",
      "train epoch: 2/11, round: 185/532, loss: 0.447013795375824\n",
      "train epoch: 2/11, round: 186/532, loss: 0.4527709484100342\n",
      "train epoch: 2/11, round: 187/532, loss: 0.3668115735054016\n",
      "train epoch: 2/11, round: 188/532, loss: 0.46656161546707153\n",
      "train epoch: 2/11, round: 189/532, loss: 0.367464154958725\n",
      "train epoch: 2/11, round: 190/532, loss: 0.35310325026512146\n",
      "train epoch: 2/11, round: 191/532, loss: 0.41179513931274414\n",
      "train epoch: 2/11, round: 192/532, loss: 0.5683116316795349\n",
      "train epoch: 2/11, round: 193/532, loss: 0.4851638674736023\n",
      "train epoch: 2/11, round: 194/532, loss: 0.527478814125061\n",
      "train epoch: 2/11, round: 195/532, loss: 0.42191457748413086\n",
      "train epoch: 2/11, round: 196/532, loss: 0.45456647872924805\n",
      "train epoch: 2/11, round: 197/532, loss: 0.3948875963687897\n",
      "train epoch: 2/11, round: 198/532, loss: 0.40113702416419983\n",
      "train epoch: 2/11, round: 199/532, loss: 0.39983126521110535\n",
      "train epoch: 2/11, round: 200/532, loss: 0.4511743485927582\n",
      "train epoch: 2/11, round: 201/532, loss: 0.39425426721572876\n",
      "train epoch: 2/11, round: 202/532, loss: 0.46872201561927795\n",
      "train epoch: 2/11, round: 203/532, loss: 0.5256952047348022\n",
      "train epoch: 2/11, round: 204/532, loss: 0.46471351385116577\n",
      "train epoch: 2/11, round: 205/532, loss: 0.36428365111351013\n",
      "train epoch: 2/11, round: 206/532, loss: 0.4776218831539154\n",
      "train epoch: 2/11, round: 207/532, loss: 0.34088945388793945\n",
      "train epoch: 2/11, round: 208/532, loss: 0.3758665919303894\n",
      "train epoch: 2/11, round: 209/532, loss: 0.42570796608924866\n",
      "train epoch: 2/11, round: 210/532, loss: 0.5726783275604248\n",
      "train epoch: 2/11, round: 211/532, loss: 0.429379940032959\n",
      "train epoch: 2/11, round: 212/532, loss: 0.5316474437713623\n",
      "train epoch: 2/11, round: 213/532, loss: 0.45198696851730347\n",
      "train epoch: 2/11, round: 214/532, loss: 0.343572735786438\n",
      "train epoch: 2/11, round: 215/532, loss: 0.4134485125541687\n",
      "train epoch: 2/11, round: 216/532, loss: 0.4524311423301697\n",
      "train epoch: 2/11, round: 217/532, loss: 0.4033058285713196\n",
      "train epoch: 2/11, round: 218/532, loss: 0.39864581823349\n",
      "train epoch: 2/11, round: 219/532, loss: 0.3662361800670624\n",
      "train epoch: 2/11, round: 220/532, loss: 0.3645358085632324\n",
      "train epoch: 2/11, round: 221/532, loss: 0.3857678771018982\n",
      "train epoch: 2/11, round: 222/532, loss: 0.512631356716156\n",
      "train epoch: 2/11, round: 223/532, loss: 0.35181915760040283\n",
      "train epoch: 2/11, round: 224/532, loss: 0.4340396523475647\n",
      "train epoch: 2/11, round: 225/532, loss: 0.33477193117141724\n",
      "train epoch: 2/11, round: 226/532, loss: 0.4527057707309723\n",
      "train epoch: 2/11, round: 227/532, loss: 0.38083577156066895\n",
      "train epoch: 2/11, round: 228/532, loss: 0.3778792917728424\n",
      "train epoch: 2/11, round: 229/532, loss: 0.3636845350265503\n",
      "train epoch: 2/11, round: 230/532, loss: 0.4565247893333435\n",
      "train epoch: 2/11, round: 231/532, loss: 0.42025643587112427\n",
      "train epoch: 2/11, round: 232/532, loss: 0.3839262127876282\n",
      "train epoch: 2/11, round: 233/532, loss: 0.3967982232570648\n",
      "train epoch: 2/11, round: 234/532, loss: 0.4310992360115051\n",
      "train epoch: 2/11, round: 235/532, loss: 0.33134305477142334\n",
      "train epoch: 2/11, round: 236/532, loss: 0.4437590539455414\n",
      "train epoch: 2/11, round: 237/532, loss: 0.40936294198036194\n",
      "train epoch: 2/11, round: 238/532, loss: 0.41404756903648376\n",
      "train epoch: 2/11, round: 239/532, loss: 0.3887726962566376\n",
      "train epoch: 2/11, round: 240/532, loss: 0.4266781806945801\n",
      "train epoch: 2/11, round: 241/532, loss: 0.4178825318813324\n",
      "train epoch: 2/11, round: 242/532, loss: 0.38008826971054077\n",
      "train epoch: 2/11, round: 243/532, loss: 0.3230428099632263\n",
      "train epoch: 2/11, round: 244/532, loss: 0.432177871465683\n",
      "train epoch: 2/11, round: 245/532, loss: 0.42853468656539917\n",
      "train epoch: 2/11, round: 246/532, loss: 0.547800600528717\n",
      "train epoch: 2/11, round: 247/532, loss: 0.44149360060691833\n",
      "train epoch: 2/11, round: 248/532, loss: 0.4398981034755707\n",
      "train epoch: 2/11, round: 249/532, loss: 0.41438406705856323\n",
      "train epoch: 2/11, round: 250/532, loss: 0.3975622057914734\n",
      "train epoch: 2/11, round: 251/532, loss: 0.38376325368881226\n",
      "train epoch: 2/11, round: 252/532, loss: 0.455800861120224\n",
      "train epoch: 2/11, round: 253/532, loss: 0.4009164273738861\n",
      "train epoch: 2/11, round: 254/532, loss: 0.40729933977127075\n",
      "train epoch: 2/11, round: 255/532, loss: 0.38152876496315\n",
      "train epoch: 2/11, round: 256/532, loss: 0.4128574728965759\n",
      "train epoch: 2/11, round: 257/532, loss: 0.469533771276474\n",
      "train epoch: 2/11, round: 258/532, loss: 0.34773939847946167\n",
      "train epoch: 2/11, round: 259/532, loss: 0.36547282338142395\n",
      "train epoch: 2/11, round: 260/532, loss: 0.41955748200416565\n",
      "train epoch: 2/11, round: 261/532, loss: 0.4100441336631775\n",
      "train epoch: 2/11, round: 262/532, loss: 0.41588544845581055\n",
      "train epoch: 2/11, round: 263/532, loss: 0.477125346660614\n",
      "train epoch: 2/11, round: 264/532, loss: 0.425957053899765\n",
      "train epoch: 2/11, round: 265/532, loss: 0.4862843453884125\n",
      "train epoch: 2/11, round: 266/532, loss: 0.3885323405265808\n",
      "train epoch: 2/11, round: 267/532, loss: 0.37756237387657166\n",
      "train epoch: 2/11, round: 268/532, loss: 0.4285743832588196\n",
      "train epoch: 2/11, round: 269/532, loss: 0.34473246335983276\n",
      "train epoch: 2/11, round: 270/532, loss: 0.5041487216949463\n",
      "train epoch: 2/11, round: 271/532, loss: 0.32999351620674133\n",
      "train epoch: 2/11, round: 272/532, loss: 0.3746735453605652\n",
      "train epoch: 2/11, round: 273/532, loss: 0.35577890276908875\n",
      "train epoch: 2/11, round: 274/532, loss: 0.472729355096817\n",
      "train epoch: 2/11, round: 275/532, loss: 0.4364728033542633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2/11, round: 276/532, loss: 0.4188273847103119\n",
      "train epoch: 2/11, round: 277/532, loss: 0.4616360664367676\n",
      "train epoch: 2/11, round: 278/532, loss: 0.346924364566803\n",
      "train epoch: 2/11, round: 279/532, loss: 0.4303106665611267\n",
      "train epoch: 2/11, round: 280/532, loss: 0.4914000928401947\n",
      "train epoch: 2/11, round: 281/532, loss: 0.3404361605644226\n",
      "train epoch: 2/11, round: 282/532, loss: 0.3885767161846161\n",
      "train epoch: 2/11, round: 283/532, loss: 0.4312984347343445\n",
      "train epoch: 2/11, round: 284/532, loss: 0.4402603209018707\n",
      "train epoch: 2/11, round: 285/532, loss: 0.48225632309913635\n",
      "train epoch: 2/11, round: 286/532, loss: 0.493490606546402\n",
      "train epoch: 2/11, round: 287/532, loss: 0.43032246828079224\n",
      "train epoch: 2/11, round: 288/532, loss: 0.37474843859672546\n",
      "train epoch: 2/11, round: 289/532, loss: 0.41723284125328064\n",
      "train epoch: 2/11, round: 290/532, loss: 0.432564914226532\n",
      "train epoch: 2/11, round: 291/532, loss: 0.41252198815345764\n",
      "train epoch: 2/11, round: 292/532, loss: 0.39017483592033386\n",
      "train epoch: 2/11, round: 293/532, loss: 0.36959460377693176\n",
      "train epoch: 2/11, round: 294/532, loss: 0.36923399567604065\n",
      "train epoch: 2/11, round: 295/532, loss: 0.385739803314209\n",
      "train epoch: 2/11, round: 296/532, loss: 0.48530712723731995\n",
      "train epoch: 2/11, round: 297/532, loss: 0.4826469421386719\n",
      "train epoch: 2/11, round: 298/532, loss: 0.41152477264404297\n",
      "train epoch: 2/11, round: 299/532, loss: 0.39038851857185364\n",
      "train epoch: 2/11, round: 300/532, loss: 0.4469014108181\n",
      "train epoch: 2/11, round: 301/532, loss: 0.4620089530944824\n",
      "train epoch: 2/11, round: 302/532, loss: 0.46921253204345703\n",
      "train epoch: 2/11, round: 303/532, loss: 0.40337786078453064\n",
      "train epoch: 2/11, round: 304/532, loss: 0.3666556477546692\n",
      "train epoch: 2/11, round: 305/532, loss: 0.35180577635765076\n",
      "train epoch: 2/11, round: 306/532, loss: 0.36365705728530884\n",
      "train epoch: 2/11, round: 307/532, loss: 0.3346535563468933\n",
      "train epoch: 2/11, round: 308/532, loss: 0.37652987241744995\n",
      "train epoch: 2/11, round: 309/532, loss: 0.41182422637939453\n",
      "train epoch: 2/11, round: 310/532, loss: 0.4825405180454254\n",
      "train epoch: 2/11, round: 311/532, loss: 0.4627295434474945\n",
      "train epoch: 2/11, round: 312/532, loss: 0.4442848563194275\n",
      "train epoch: 2/11, round: 313/532, loss: 0.40643686056137085\n",
      "train epoch: 2/11, round: 314/532, loss: 0.3428635895252228\n",
      "train epoch: 2/11, round: 315/532, loss: 0.41395315527915955\n",
      "train epoch: 2/11, round: 316/532, loss: 0.4030507504940033\n",
      "train epoch: 2/11, round: 317/532, loss: 0.4380982518196106\n",
      "train epoch: 2/11, round: 318/532, loss: 0.4869097173213959\n",
      "train epoch: 2/11, round: 319/532, loss: 0.4179890751838684\n",
      "train epoch: 2/11, round: 320/532, loss: 0.43961063027381897\n",
      "train epoch: 2/11, round: 321/532, loss: 0.43377217650413513\n",
      "train epoch: 2/11, round: 322/532, loss: 0.4497932493686676\n",
      "train epoch: 2/11, round: 323/532, loss: 0.3952431082725525\n",
      "train epoch: 2/11, round: 324/532, loss: 0.3952573239803314\n",
      "train epoch: 2/11, round: 325/532, loss: 0.44510120153427124\n",
      "train epoch: 2/11, round: 326/532, loss: 0.41821032762527466\n",
      "train epoch: 2/11, round: 327/532, loss: 0.3711656928062439\n",
      "train epoch: 2/11, round: 328/532, loss: 0.40105074644088745\n",
      "train epoch: 2/11, round: 329/532, loss: 0.429068386554718\n",
      "train epoch: 2/11, round: 330/532, loss: 0.4750605523586273\n",
      "train epoch: 2/11, round: 331/532, loss: 0.46301230788230896\n",
      "train epoch: 2/11, round: 332/532, loss: 0.44821158051490784\n",
      "train epoch: 2/11, round: 333/532, loss: 0.36607691645622253\n",
      "train epoch: 2/11, round: 334/532, loss: 0.34233683347702026\n",
      "train epoch: 2/11, round: 335/532, loss: 0.41471290588378906\n",
      "train epoch: 2/11, round: 336/532, loss: 0.3010730743408203\n",
      "train epoch: 2/11, round: 337/532, loss: 0.3219420313835144\n",
      "train epoch: 2/11, round: 338/532, loss: 0.3426291048526764\n",
      "train epoch: 2/11, round: 339/532, loss: 0.4024694561958313\n",
      "train epoch: 2/11, round: 340/532, loss: 0.4240318238735199\n",
      "train epoch: 2/11, round: 341/532, loss: 0.4464237093925476\n",
      "train epoch: 2/11, round: 342/532, loss: 0.4572625756263733\n",
      "train epoch: 2/11, round: 343/532, loss: 0.4331207871437073\n",
      "train epoch: 2/11, round: 344/532, loss: 0.48774775862693787\n",
      "train epoch: 2/11, round: 345/532, loss: 0.3656618595123291\n",
      "train epoch: 2/11, round: 346/532, loss: 0.36744508147239685\n",
      "train epoch: 2/11, round: 347/532, loss: 0.4312517046928406\n",
      "train epoch: 2/11, round: 348/532, loss: 0.371651828289032\n",
      "train epoch: 2/11, round: 349/532, loss: 0.33090218901634216\n",
      "train epoch: 2/11, round: 350/532, loss: 0.3551848232746124\n",
      "train epoch: 2/11, round: 351/532, loss: 0.4226137101650238\n",
      "train epoch: 2/11, round: 352/532, loss: 0.3709739148616791\n",
      "train epoch: 2/11, round: 353/532, loss: 0.33035165071487427\n",
      "train epoch: 2/11, round: 354/532, loss: 0.4272077679634094\n",
      "train epoch: 2/11, round: 355/532, loss: 0.3729791045188904\n",
      "train epoch: 2/11, round: 356/532, loss: 0.35538962483406067\n",
      "train epoch: 2/11, round: 357/532, loss: 0.39991575479507446\n",
      "train epoch: 2/11, round: 358/532, loss: 0.4485047459602356\n",
      "train epoch: 2/11, round: 359/532, loss: 0.3537840247154236\n",
      "train epoch: 2/11, round: 360/532, loss: 0.3759384751319885\n",
      "train epoch: 2/11, round: 361/532, loss: 0.3697926700115204\n",
      "train epoch: 2/11, round: 362/532, loss: 0.3947981595993042\n",
      "train epoch: 2/11, round: 363/532, loss: 0.2965433895587921\n",
      "train epoch: 2/11, round: 364/532, loss: 0.4264267385005951\n",
      "train epoch: 2/11, round: 365/532, loss: 0.40263301134109497\n",
      "train epoch: 2/11, round: 366/532, loss: 0.4323102533817291\n",
      "train epoch: 2/11, round: 367/532, loss: 0.45851999521255493\n",
      "train epoch: 2/11, round: 368/532, loss: 0.44175347685813904\n",
      "train epoch: 2/11, round: 369/532, loss: 0.29146608710289\n",
      "train epoch: 2/11, round: 370/532, loss: 0.4403681755065918\n",
      "train epoch: 2/11, round: 371/532, loss: 0.3872978091239929\n",
      "train epoch: 2/11, round: 372/532, loss: 0.42503196001052856\n",
      "train epoch: 2/11, round: 373/532, loss: 0.4351188540458679\n",
      "train epoch: 2/11, round: 374/532, loss: 0.3926848769187927\n",
      "train epoch: 2/11, round: 375/532, loss: 0.3642710745334625\n",
      "train epoch: 2/11, round: 376/532, loss: 0.4263179302215576\n",
      "train epoch: 2/11, round: 377/532, loss: 0.36517101526260376\n",
      "train epoch: 2/11, round: 378/532, loss: 0.4274146556854248\n",
      "train epoch: 2/11, round: 379/532, loss: 0.33845892548561096\n",
      "train epoch: 2/11, round: 380/532, loss: 0.4072635769844055\n",
      "train epoch: 2/11, round: 381/532, loss: 0.45422011613845825\n",
      "train epoch: 2/11, round: 382/532, loss: 0.48271894454956055\n",
      "train epoch: 2/11, round: 383/532, loss: 0.421636164188385\n",
      "train epoch: 2/11, round: 384/532, loss: 0.4222021996974945\n",
      "train epoch: 2/11, round: 385/532, loss: 0.4533866047859192\n",
      "train epoch: 2/11, round: 386/532, loss: 0.4018022418022156\n",
      "train epoch: 2/11, round: 387/532, loss: 0.4504753053188324\n",
      "train epoch: 2/11, round: 388/532, loss: 0.3704826235771179\n",
      "train epoch: 2/11, round: 389/532, loss: 0.41280287504196167\n",
      "train epoch: 2/11, round: 390/532, loss: 0.383710116147995\n",
      "train epoch: 2/11, round: 391/532, loss: 0.4286426901817322\n",
      "train epoch: 2/11, round: 392/532, loss: 0.43541544675827026\n",
      "train epoch: 2/11, round: 393/532, loss: 0.37930136919021606\n",
      "train epoch: 2/11, round: 394/532, loss: 0.3785845637321472\n",
      "train epoch: 2/11, round: 395/532, loss: 0.3841169476509094\n",
      "train epoch: 2/11, round: 396/532, loss: 0.32480210065841675\n",
      "train epoch: 2/11, round: 397/532, loss: 0.4831356406211853\n",
      "train epoch: 2/11, round: 398/532, loss: 0.4207710325717926\n",
      "train epoch: 2/11, round: 399/532, loss: 0.4310080409049988\n",
      "train epoch: 2/11, round: 400/532, loss: 0.4070667624473572\n",
      "train epoch: 2/11, round: 401/532, loss: 0.4568610191345215\n",
      "train epoch: 2/11, round: 402/532, loss: 0.42444953322410583\n",
      "train epoch: 2/11, round: 403/532, loss: 0.3468576967716217\n",
      "train epoch: 2/11, round: 404/532, loss: 0.38561099767684937\n",
      "train epoch: 2/11, round: 405/532, loss: 0.3917297422885895\n",
      "train epoch: 2/11, round: 406/532, loss: 0.33231574296951294\n",
      "train epoch: 2/11, round: 407/532, loss: 0.37209972739219666\n",
      "train epoch: 2/11, round: 408/532, loss: 0.3848803639411926\n",
      "train epoch: 2/11, round: 409/532, loss: 0.3147702217102051\n",
      "train epoch: 2/11, round: 410/532, loss: 0.42875033617019653\n",
      "train epoch: 2/11, round: 411/532, loss: 0.4186323583126068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2/11, round: 412/532, loss: 0.3959428369998932\n",
      "train epoch: 2/11, round: 413/532, loss: 0.3655884265899658\n",
      "train epoch: 2/11, round: 414/532, loss: 0.4712674021720886\n",
      "train epoch: 2/11, round: 415/532, loss: 0.5349575281143188\n",
      "train epoch: 2/11, round: 416/532, loss: 0.39127448201179504\n",
      "train epoch: 2/11, round: 417/532, loss: 0.41355061531066895\n",
      "train epoch: 2/11, round: 418/532, loss: 0.4571212828159332\n",
      "train epoch: 2/11, round: 419/532, loss: 0.4306931495666504\n",
      "train epoch: 2/11, round: 420/532, loss: 0.4010200500488281\n",
      "train epoch: 2/11, round: 421/532, loss: 0.3513115644454956\n",
      "train epoch: 2/11, round: 422/532, loss: 0.400144100189209\n",
      "train epoch: 2/11, round: 423/532, loss: 0.4207688868045807\n",
      "train epoch: 2/11, round: 424/532, loss: 0.3734744191169739\n",
      "train epoch: 2/11, round: 425/532, loss: 0.4257137179374695\n",
      "train epoch: 2/11, round: 426/532, loss: 0.3599155843257904\n",
      "train epoch: 2/11, round: 427/532, loss: 0.44604045152664185\n",
      "train epoch: 2/11, round: 428/532, loss: 0.43987521529197693\n",
      "train epoch: 2/11, round: 429/532, loss: 0.42913442850112915\n",
      "train epoch: 2/11, round: 430/532, loss: 0.3847535252571106\n",
      "train epoch: 2/11, round: 431/532, loss: 0.3898558020591736\n",
      "train epoch: 2/11, round: 432/532, loss: 0.4799824655056\n",
      "train epoch: 2/11, round: 433/532, loss: 0.34720808267593384\n",
      "train epoch: 2/11, round: 434/532, loss: 0.5651007890701294\n",
      "train epoch: 2/11, round: 435/532, loss: 0.4542781710624695\n",
      "train epoch: 2/11, round: 436/532, loss: 0.3953081965446472\n",
      "train epoch: 2/11, round: 437/532, loss: 0.39086681604385376\n",
      "train epoch: 2/11, round: 438/532, loss: 0.4106578230857849\n",
      "train epoch: 2/11, round: 439/532, loss: 0.44993162155151367\n",
      "train epoch: 2/11, round: 440/532, loss: 0.3813634514808655\n",
      "train epoch: 2/11, round: 441/532, loss: 0.41015657782554626\n",
      "train epoch: 2/11, round: 442/532, loss: 0.5164486169815063\n",
      "train epoch: 2/11, round: 443/532, loss: 0.359186053276062\n",
      "train epoch: 2/11, round: 444/532, loss: 0.3685056269168854\n",
      "train epoch: 2/11, round: 445/532, loss: 0.4766860902309418\n",
      "train epoch: 2/11, round: 446/532, loss: 0.3871963620185852\n",
      "train epoch: 2/11, round: 447/532, loss: 0.497286319732666\n",
      "train epoch: 2/11, round: 448/532, loss: 0.4276367127895355\n",
      "train epoch: 2/11, round: 449/532, loss: 0.4546542763710022\n",
      "train epoch: 2/11, round: 450/532, loss: 0.4728425443172455\n",
      "train epoch: 2/11, round: 451/532, loss: 0.3507075905799866\n",
      "train epoch: 2/11, round: 452/532, loss: 0.4407057762145996\n",
      "train epoch: 2/11, round: 453/532, loss: 0.37816327810287476\n",
      "train epoch: 2/11, round: 454/532, loss: 0.3404980003833771\n",
      "train epoch: 2/11, round: 455/532, loss: 0.4054533541202545\n",
      "train epoch: 2/11, round: 456/532, loss: 0.364471435546875\n",
      "train epoch: 2/11, round: 457/532, loss: 0.4062069058418274\n",
      "train epoch: 2/11, round: 458/532, loss: 0.3554288446903229\n",
      "train epoch: 2/11, round: 459/532, loss: 0.38654768466949463\n",
      "train epoch: 2/11, round: 460/532, loss: 0.4246029853820801\n",
      "train epoch: 2/11, round: 461/532, loss: 0.4775594174861908\n",
      "train epoch: 2/11, round: 462/532, loss: 0.38500526547431946\n",
      "train epoch: 2/11, round: 463/532, loss: 0.37017250061035156\n",
      "train epoch: 2/11, round: 464/532, loss: 0.3685509264469147\n",
      "train epoch: 2/11, round: 465/532, loss: 0.42768198251724243\n",
      "train epoch: 2/11, round: 466/532, loss: 0.47381043434143066\n",
      "train epoch: 2/11, round: 467/532, loss: 0.44379276037216187\n",
      "train epoch: 2/11, round: 468/532, loss: 0.5754777193069458\n",
      "train epoch: 2/11, round: 469/532, loss: 0.3856174349784851\n",
      "train epoch: 2/11, round: 470/532, loss: 0.4837145209312439\n",
      "train epoch: 2/11, round: 471/532, loss: 0.39421170949935913\n",
      "train epoch: 2/11, round: 472/532, loss: 0.44497784972190857\n",
      "train epoch: 2/11, round: 473/532, loss: 0.3749600350856781\n",
      "train epoch: 2/11, round: 474/532, loss: 0.389818012714386\n",
      "train epoch: 2/11, round: 475/532, loss: 0.4537350535392761\n",
      "train epoch: 2/11, round: 476/532, loss: 0.39249348640441895\n",
      "train epoch: 2/11, round: 477/532, loss: 0.3727966248989105\n",
      "train epoch: 2/11, round: 478/532, loss: 0.48495522141456604\n",
      "train epoch: 2/11, round: 479/532, loss: 0.5153777599334717\n",
      "train epoch: 2/11, round: 480/532, loss: 0.5241380929946899\n",
      "train epoch: 2/11, round: 481/532, loss: 0.464222252368927\n",
      "train epoch: 2/11, round: 482/532, loss: 0.418836772441864\n",
      "train epoch: 2/11, round: 483/532, loss: 0.45667916536331177\n",
      "train epoch: 2/11, round: 484/532, loss: 0.4110335409641266\n",
      "train epoch: 2/11, round: 485/532, loss: 0.36023229360580444\n",
      "train epoch: 2/11, round: 486/532, loss: 0.3992401957511902\n",
      "train epoch: 2/11, round: 487/532, loss: 0.43881291151046753\n",
      "train epoch: 2/11, round: 488/532, loss: 0.413785845041275\n",
      "train epoch: 2/11, round: 489/532, loss: 0.4116709232330322\n",
      "train epoch: 2/11, round: 490/532, loss: 0.40291911363601685\n",
      "train epoch: 2/11, round: 491/532, loss: 0.43249350786209106\n",
      "train epoch: 2/11, round: 492/532, loss: 0.3949543535709381\n",
      "train epoch: 2/11, round: 493/532, loss: 0.3854322135448456\n",
      "train epoch: 2/11, round: 494/532, loss: 0.308917373418808\n",
      "train epoch: 2/11, round: 495/532, loss: 0.4152894914150238\n",
      "train epoch: 2/11, round: 496/532, loss: 0.3963260054588318\n",
      "train epoch: 2/11, round: 497/532, loss: 0.43160954117774963\n",
      "train epoch: 2/11, round: 498/532, loss: 0.45470160245895386\n",
      "train epoch: 2/11, round: 499/532, loss: 0.353263258934021\n",
      "train epoch: 2/11, round: 500/532, loss: 0.3998574912548065\n",
      "train epoch: 2/11, round: 501/532, loss: 0.344086229801178\n",
      "train epoch: 2/11, round: 502/532, loss: 0.5021107196807861\n",
      "train epoch: 2/11, round: 503/532, loss: 0.36171388626098633\n",
      "train epoch: 2/11, round: 504/532, loss: 0.4648955464363098\n",
      "train epoch: 2/11, round: 505/532, loss: 0.4463173747062683\n",
      "train epoch: 2/11, round: 506/532, loss: 0.3304571211338043\n",
      "train epoch: 2/11, round: 507/532, loss: 0.4528976082801819\n",
      "train epoch: 2/11, round: 508/532, loss: 0.39884650707244873\n",
      "train epoch: 2/11, round: 509/532, loss: 0.5368766784667969\n",
      "train epoch: 2/11, round: 510/532, loss: 0.3813968002796173\n",
      "train epoch: 2/11, round: 511/532, loss: 0.3783695101737976\n",
      "train epoch: 2/11, round: 512/532, loss: 0.37309423089027405\n",
      "train epoch: 2/11, round: 513/532, loss: 0.39436763525009155\n",
      "train epoch: 2/11, round: 514/532, loss: 0.4191504120826721\n",
      "train epoch: 2/11, round: 515/532, loss: 0.3151048719882965\n",
      "train epoch: 2/11, round: 516/532, loss: 0.40185266733169556\n",
      "train epoch: 2/11, round: 517/532, loss: 0.5018305778503418\n",
      "train epoch: 2/11, round: 518/532, loss: 0.41497594118118286\n",
      "train epoch: 2/11, round: 519/532, loss: 0.39759498834609985\n",
      "train epoch: 2/11, round: 520/532, loss: 0.3814166784286499\n",
      "train epoch: 2/11, round: 521/532, loss: 0.38611900806427\n",
      "train epoch: 2/11, round: 522/532, loss: 0.3914715349674225\n",
      "train epoch: 2/11, round: 523/532, loss: 0.3582342565059662\n",
      "train epoch: 2/11, round: 524/532, loss: 0.3507051169872284\n",
      "train epoch: 2/11, round: 525/532, loss: 0.3509801924228668\n",
      "train epoch: 2/11, round: 526/532, loss: 0.25761324167251587\n",
      "train epoch: 2/11, round: 527/532, loss: 0.3692944645881653\n",
      "train epoch: 2/11, round: 528/532, loss: 0.42313075065612793\n",
      "train epoch: 2/11, round: 529/532, loss: 0.2684291899204254\n",
      "train epoch: 2/11, round: 530/532, loss: 0.4147107005119324\n",
      "train epoch: 2/11, round: 531/532, loss: 0.33690115809440613\n",
      "train epoch: 2/11, round: 532/532, loss: 0.352232426404953\n",
      "train epoch: 2/11, KS: 0.1522103304117901, ROC: 0.6039102642563333\n",
      "test epoch: 2/11, round: 1/501, loss: 0.3667224943637848\n",
      "test epoch: 2/11, round: 2/501, loss: 0.3595145642757416\n",
      "test epoch: 2/11, round: 3/501, loss: 0.2603343725204468\n",
      "test epoch: 2/11, round: 4/501, loss: 0.3849489986896515\n",
      "test epoch: 2/11, round: 5/501, loss: 0.4280546307563782\n",
      "test epoch: 2/11, round: 6/501, loss: 0.3382050096988678\n",
      "test epoch: 2/11, round: 7/501, loss: 0.4381818175315857\n",
      "test epoch: 2/11, round: 8/501, loss: 0.38464611768722534\n",
      "test epoch: 2/11, round: 9/501, loss: 0.5271285176277161\n",
      "test epoch: 2/11, round: 10/501, loss: 0.6562621593475342\n",
      "test epoch: 2/11, round: 11/501, loss: 0.1986793875694275\n",
      "test epoch: 2/11, round: 12/501, loss: 0.3723386824131012\n",
      "test epoch: 2/11, round: 13/501, loss: 0.3027767241001129\n",
      "test epoch: 2/11, round: 14/501, loss: 0.38076505064964294\n",
      "test epoch: 2/11, round: 15/501, loss: 0.47271987795829773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 2/11, round: 16/501, loss: 0.4964045286178589\n",
      "test epoch: 2/11, round: 17/501, loss: 0.3745107054710388\n",
      "test epoch: 2/11, round: 18/501, loss: 0.5227418541908264\n",
      "test epoch: 2/11, round: 19/501, loss: 0.5620546936988831\n",
      "test epoch: 2/11, round: 20/501, loss: 0.7835149168968201\n",
      "test epoch: 2/11, round: 21/501, loss: 0.38884681463241577\n",
      "test epoch: 2/11, round: 22/501, loss: 0.5725539326667786\n",
      "test epoch: 2/11, round: 23/501, loss: 0.5630638003349304\n",
      "test epoch: 2/11, round: 24/501, loss: 0.40590813755989075\n",
      "test epoch: 2/11, round: 25/501, loss: 0.5926399230957031\n",
      "test epoch: 2/11, round: 26/501, loss: 0.6381487250328064\n",
      "test epoch: 2/11, round: 27/501, loss: 0.2440139204263687\n",
      "test epoch: 2/11, round: 28/501, loss: 0.4527463912963867\n",
      "test epoch: 2/11, round: 29/501, loss: 0.29971858859062195\n",
      "test epoch: 2/11, round: 30/501, loss: 0.5524464845657349\n",
      "test epoch: 2/11, round: 31/501, loss: 0.521106481552124\n",
      "test epoch: 2/11, round: 32/501, loss: 0.4449254870414734\n",
      "test epoch: 2/11, round: 33/501, loss: 0.6216431856155396\n",
      "test epoch: 2/11, round: 34/501, loss: 0.5093637108802795\n",
      "test epoch: 2/11, round: 35/501, loss: 0.19244107604026794\n",
      "test epoch: 2/11, round: 36/501, loss: 0.49785929918289185\n",
      "test epoch: 2/11, round: 37/501, loss: 0.44750887155532837\n",
      "test epoch: 2/11, round: 38/501, loss: 0.4448777437210083\n",
      "test epoch: 2/11, round: 39/501, loss: 0.656385064125061\n",
      "test epoch: 2/11, round: 40/501, loss: 0.5704489350318909\n",
      "test epoch: 2/11, round: 41/501, loss: 0.4182858169078827\n",
      "test epoch: 2/11, round: 42/501, loss: 0.39641767740249634\n",
      "test epoch: 2/11, round: 43/501, loss: 0.3862875699996948\n",
      "test epoch: 2/11, round: 44/501, loss: 0.5522888898849487\n",
      "test epoch: 2/11, round: 45/501, loss: 0.6247154474258423\n",
      "test epoch: 2/11, round: 46/501, loss: 0.502637505531311\n",
      "test epoch: 2/11, round: 47/501, loss: 0.2879522740840912\n",
      "test epoch: 2/11, round: 48/501, loss: 0.47686246037483215\n",
      "test epoch: 2/11, round: 49/501, loss: 0.31804925203323364\n",
      "test epoch: 2/11, round: 50/501, loss: 0.2575497627258301\n",
      "test epoch: 2/11, round: 51/501, loss: 0.4699934422969818\n",
      "test epoch: 2/11, round: 52/501, loss: 0.42230403423309326\n",
      "test epoch: 2/11, round: 53/501, loss: 0.5591093897819519\n",
      "test epoch: 2/11, round: 54/501, loss: 0.52216637134552\n",
      "test epoch: 2/11, round: 55/501, loss: 0.3331388533115387\n",
      "test epoch: 2/11, round: 56/501, loss: 0.4485979676246643\n",
      "test epoch: 2/11, round: 57/501, loss: 0.3203839957714081\n",
      "test epoch: 2/11, round: 58/501, loss: 0.46171337366104126\n",
      "test epoch: 2/11, round: 59/501, loss: 0.24341894686222076\n",
      "test epoch: 2/11, round: 60/501, loss: 0.455128014087677\n",
      "test epoch: 2/11, round: 61/501, loss: 0.4248351454734802\n",
      "test epoch: 2/11, round: 62/501, loss: 0.6633453369140625\n",
      "test epoch: 2/11, round: 63/501, loss: 0.7348124980926514\n",
      "test epoch: 2/11, round: 64/501, loss: 0.3110490143299103\n",
      "test epoch: 2/11, round: 65/501, loss: 0.5891266465187073\n",
      "test epoch: 2/11, round: 66/501, loss: 0.4556126296520233\n",
      "test epoch: 2/11, round: 67/501, loss: 0.520416259765625\n",
      "test epoch: 2/11, round: 68/501, loss: 0.7158710360527039\n",
      "test epoch: 2/11, round: 69/501, loss: 0.5106155276298523\n",
      "test epoch: 2/11, round: 70/501, loss: 0.4484614133834839\n",
      "test epoch: 2/11, round: 71/501, loss: 0.6016301512718201\n",
      "test epoch: 2/11, round: 72/501, loss: 0.5731865763664246\n",
      "test epoch: 2/11, round: 73/501, loss: 0.48895159363746643\n",
      "test epoch: 2/11, round: 74/501, loss: 0.5367082953453064\n",
      "test epoch: 2/11, round: 75/501, loss: 0.584222674369812\n",
      "test epoch: 2/11, round: 76/501, loss: 0.745775043964386\n",
      "test epoch: 2/11, round: 77/501, loss: 0.41578835248947144\n",
      "test epoch: 2/11, round: 78/501, loss: 0.5939229726791382\n",
      "test epoch: 2/11, round: 79/501, loss: 0.388494610786438\n",
      "test epoch: 2/11, round: 80/501, loss: 0.5920080542564392\n",
      "test epoch: 2/11, round: 81/501, loss: 0.8043404817581177\n",
      "test epoch: 2/11, round: 82/501, loss: 0.6791898012161255\n",
      "test epoch: 2/11, round: 83/501, loss: 0.4390641152858734\n",
      "test epoch: 2/11, round: 84/501, loss: 0.5986825823783875\n",
      "test epoch: 2/11, round: 85/501, loss: 0.5979260206222534\n",
      "test epoch: 2/11, round: 86/501, loss: 0.34737542271614075\n",
      "test epoch: 2/11, round: 87/501, loss: 0.44633910059928894\n",
      "test epoch: 2/11, round: 88/501, loss: 0.43412142992019653\n",
      "test epoch: 2/11, round: 89/501, loss: 0.29805511236190796\n",
      "test epoch: 2/11, round: 90/501, loss: 0.702642023563385\n",
      "test epoch: 2/11, round: 91/501, loss: 0.34076860547065735\n",
      "test epoch: 2/11, round: 92/501, loss: 0.5639327764511108\n",
      "test epoch: 2/11, round: 93/501, loss: 0.4577748477458954\n",
      "test epoch: 2/11, round: 94/501, loss: 0.5455387830734253\n",
      "test epoch: 2/11, round: 95/501, loss: 0.38205868005752563\n",
      "test epoch: 2/11, round: 96/501, loss: 0.3303259015083313\n",
      "test epoch: 2/11, round: 97/501, loss: 0.6565867066383362\n",
      "test epoch: 2/11, round: 98/501, loss: 0.434033066034317\n",
      "test epoch: 2/11, round: 99/501, loss: 0.5464311242103577\n",
      "test epoch: 2/11, round: 100/501, loss: 0.4811669588088989\n",
      "test epoch: 2/11, round: 101/501, loss: 0.5720086693763733\n",
      "test epoch: 2/11, round: 102/501, loss: 0.31740644574165344\n",
      "test epoch: 2/11, round: 103/501, loss: 0.4494057297706604\n",
      "test epoch: 2/11, round: 104/501, loss: 0.6702533960342407\n",
      "test epoch: 2/11, round: 105/501, loss: 0.39497655630111694\n",
      "test epoch: 2/11, round: 106/501, loss: 0.5403863191604614\n",
      "test epoch: 2/11, round: 107/501, loss: 0.3534981906414032\n",
      "test epoch: 2/11, round: 108/501, loss: 0.5755149722099304\n",
      "test epoch: 2/11, round: 109/501, loss: 0.3614393174648285\n",
      "test epoch: 2/11, round: 110/501, loss: 0.7933081388473511\n",
      "test epoch: 2/11, round: 111/501, loss: 0.2687285840511322\n",
      "test epoch: 2/11, round: 112/501, loss: 0.21654082834720612\n",
      "test epoch: 2/11, round: 113/501, loss: 0.42508524656295776\n",
      "test epoch: 2/11, round: 114/501, loss: 0.4119310975074768\n",
      "test epoch: 2/11, round: 115/501, loss: 0.25616195797920227\n",
      "test epoch: 2/11, round: 116/501, loss: 0.34741345047950745\n",
      "test epoch: 2/11, round: 117/501, loss: 0.3447428345680237\n",
      "test epoch: 2/11, round: 118/501, loss: 0.38489964604377747\n",
      "test epoch: 2/11, round: 119/501, loss: 0.3363143503665924\n",
      "test epoch: 2/11, round: 120/501, loss: 0.4039478898048401\n",
      "test epoch: 2/11, round: 121/501, loss: 0.4017520248889923\n",
      "test epoch: 2/11, round: 122/501, loss: 0.34751689434051514\n",
      "test epoch: 2/11, round: 123/501, loss: 0.3409896492958069\n",
      "test epoch: 2/11, round: 124/501, loss: 0.5559346675872803\n",
      "test epoch: 2/11, round: 125/501, loss: 0.4187420606613159\n",
      "test epoch: 2/11, round: 126/501, loss: 0.3453645408153534\n",
      "test epoch: 2/11, round: 127/501, loss: 0.39360684156417847\n",
      "test epoch: 2/11, round: 128/501, loss: 0.21542812883853912\n",
      "test epoch: 2/11, round: 129/501, loss: 0.4405149221420288\n",
      "test epoch: 2/11, round: 130/501, loss: 0.7392618656158447\n",
      "test epoch: 2/11, round: 131/501, loss: 0.6133409142494202\n",
      "test epoch: 2/11, round: 132/501, loss: 0.42418423295021057\n",
      "test epoch: 2/11, round: 133/501, loss: 0.7278620600700378\n",
      "test epoch: 2/11, round: 134/501, loss: 0.515925943851471\n",
      "test epoch: 2/11, round: 135/501, loss: 0.3096396327018738\n",
      "test epoch: 2/11, round: 136/501, loss: 0.3962261974811554\n",
      "test epoch: 2/11, round: 137/501, loss: 0.47144216299057007\n",
      "test epoch: 2/11, round: 138/501, loss: 0.455500990152359\n",
      "test epoch: 2/11, round: 139/501, loss: 0.5361221432685852\n",
      "test epoch: 2/11, round: 140/501, loss: 0.4183858036994934\n",
      "test epoch: 2/11, round: 141/501, loss: 0.3632277250289917\n",
      "test epoch: 2/11, round: 142/501, loss: 0.5875819325447083\n",
      "test epoch: 2/11, round: 143/501, loss: 0.3774251937866211\n",
      "test epoch: 2/11, round: 144/501, loss: 0.5077728033065796\n",
      "test epoch: 2/11, round: 145/501, loss: 0.33544090390205383\n",
      "test epoch: 2/11, round: 146/501, loss: 0.573782205581665\n",
      "test epoch: 2/11, round: 147/501, loss: 0.5212842226028442\n",
      "test epoch: 2/11, round: 148/501, loss: 0.514909565448761\n",
      "test epoch: 2/11, round: 149/501, loss: 0.34853485226631165\n",
      "test epoch: 2/11, round: 150/501, loss: 0.5493884682655334\n",
      "test epoch: 2/11, round: 151/501, loss: 0.4211392104625702\n",
      "test epoch: 2/11, round: 152/501, loss: 0.46896597743034363\n",
      "test epoch: 2/11, round: 153/501, loss: 0.5475543737411499\n",
      "test epoch: 2/11, round: 154/501, loss: 0.5477684140205383\n",
      "test epoch: 2/11, round: 155/501, loss: 0.37437140941619873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 2/11, round: 156/501, loss: 0.3273414671421051\n",
      "test epoch: 2/11, round: 157/501, loss: 0.28866782784461975\n",
      "test epoch: 2/11, round: 158/501, loss: 0.46828117966651917\n",
      "test epoch: 2/11, round: 159/501, loss: 0.38185611367225647\n",
      "test epoch: 2/11, round: 160/501, loss: 0.3824285566806793\n",
      "test epoch: 2/11, round: 161/501, loss: 0.3479229509830475\n",
      "test epoch: 2/11, round: 162/501, loss: 0.4900660812854767\n",
      "test epoch: 2/11, round: 163/501, loss: 0.4542330503463745\n",
      "test epoch: 2/11, round: 164/501, loss: 0.356707900762558\n",
      "test epoch: 2/11, round: 165/501, loss: 0.5440788269042969\n",
      "test epoch: 2/11, round: 166/501, loss: 0.2545025050640106\n",
      "test epoch: 2/11, round: 167/501, loss: 0.1614125519990921\n",
      "test epoch: 2/11, round: 168/501, loss: 0.12761366367340088\n",
      "test epoch: 2/11, round: 169/501, loss: 0.35932889580726624\n",
      "test epoch: 2/11, round: 170/501, loss: 0.3617006540298462\n",
      "test epoch: 2/11, round: 171/501, loss: 0.5278600454330444\n",
      "test epoch: 2/11, round: 172/501, loss: 0.5707996487617493\n",
      "test epoch: 2/11, round: 173/501, loss: 0.2581181824207306\n",
      "test epoch: 2/11, round: 174/501, loss: 0.6602323055267334\n",
      "test epoch: 2/11, round: 175/501, loss: 0.24351273477077484\n",
      "test epoch: 2/11, round: 176/501, loss: 0.5652739405632019\n",
      "test epoch: 2/11, round: 177/501, loss: 0.2688058316707611\n",
      "test epoch: 2/11, round: 178/501, loss: 0.18587814271450043\n",
      "test epoch: 2/11, round: 179/501, loss: 0.17461352050304413\n",
      "test epoch: 2/11, round: 180/501, loss: 0.2753666341304779\n",
      "test epoch: 2/11, round: 181/501, loss: 0.6230242252349854\n",
      "test epoch: 2/11, round: 182/501, loss: 0.6037613153457642\n",
      "test epoch: 2/11, round: 183/501, loss: 0.45631030201911926\n",
      "test epoch: 2/11, round: 184/501, loss: 0.6699845194816589\n",
      "test epoch: 2/11, round: 185/501, loss: 0.4834195375442505\n",
      "test epoch: 2/11, round: 186/501, loss: 0.7055655121803284\n",
      "test epoch: 2/11, round: 187/501, loss: 0.6385638117790222\n",
      "test epoch: 2/11, round: 188/501, loss: 0.5579609274864197\n",
      "test epoch: 2/11, round: 189/501, loss: 0.8004613518714905\n",
      "test epoch: 2/11, round: 190/501, loss: 0.4551384747028351\n",
      "test epoch: 2/11, round: 191/501, loss: 0.29598042368888855\n",
      "test epoch: 2/11, round: 192/501, loss: 0.6204116940498352\n",
      "test epoch: 2/11, round: 193/501, loss: 0.599770724773407\n",
      "test epoch: 2/11, round: 194/501, loss: 0.48445332050323486\n",
      "test epoch: 2/11, round: 195/501, loss: 0.485591858625412\n",
      "test epoch: 2/11, round: 196/501, loss: 0.29420506954193115\n",
      "test epoch: 2/11, round: 197/501, loss: 0.4612485468387604\n",
      "test epoch: 2/11, round: 198/501, loss: 0.5222324728965759\n",
      "test epoch: 2/11, round: 199/501, loss: 0.5044097900390625\n",
      "test epoch: 2/11, round: 200/501, loss: 0.7788220643997192\n",
      "test epoch: 2/11, round: 201/501, loss: 0.338401198387146\n",
      "test epoch: 2/11, round: 202/501, loss: 0.3419821560382843\n",
      "test epoch: 2/11, round: 203/501, loss: 0.4684838056564331\n",
      "test epoch: 2/11, round: 204/501, loss: 0.6909675598144531\n",
      "test epoch: 2/11, round: 205/501, loss: 0.3907260596752167\n",
      "test epoch: 2/11, round: 206/501, loss: 0.25192686915397644\n",
      "test epoch: 2/11, round: 207/501, loss: 0.46088725328445435\n",
      "test epoch: 2/11, round: 208/501, loss: 0.4827163815498352\n",
      "test epoch: 2/11, round: 209/501, loss: 0.3046526610851288\n",
      "test epoch: 2/11, round: 210/501, loss: 0.4451933801174164\n",
      "test epoch: 2/11, round: 211/501, loss: 0.24806709587574005\n",
      "test epoch: 2/11, round: 212/501, loss: 0.2686351239681244\n",
      "test epoch: 2/11, round: 213/501, loss: 0.2726232707500458\n",
      "test epoch: 2/11, round: 214/501, loss: 0.15410731732845306\n",
      "test epoch: 2/11, round: 215/501, loss: 0.10738086700439453\n",
      "test epoch: 2/11, round: 216/501, loss: 0.10924210399389267\n",
      "test epoch: 2/11, round: 217/501, loss: 0.09927307814359665\n",
      "test epoch: 2/11, round: 218/501, loss: 0.1594477742910385\n",
      "test epoch: 2/11, round: 219/501, loss: 0.19121834635734558\n",
      "test epoch: 2/11, round: 220/501, loss: 0.3905769884586334\n",
      "test epoch: 2/11, round: 221/501, loss: 0.3588862121105194\n",
      "test epoch: 2/11, round: 222/501, loss: 0.10259567946195602\n",
      "test epoch: 2/11, round: 223/501, loss: 0.11477448791265488\n",
      "test epoch: 2/11, round: 224/501, loss: 0.11342933028936386\n",
      "test epoch: 2/11, round: 225/501, loss: 0.11822988092899323\n",
      "test epoch: 2/11, round: 226/501, loss: 0.10687825083732605\n",
      "test epoch: 2/11, round: 227/501, loss: 0.16300655901432037\n",
      "test epoch: 2/11, round: 228/501, loss: 0.17853723466396332\n",
      "test epoch: 2/11, round: 229/501, loss: 0.4151354134082794\n",
      "test epoch: 2/11, round: 230/501, loss: 0.25002625584602356\n",
      "test epoch: 2/11, round: 231/501, loss: 0.30673593282699585\n",
      "test epoch: 2/11, round: 232/501, loss: 0.4326252043247223\n",
      "test epoch: 2/11, round: 233/501, loss: 0.5117703676223755\n",
      "test epoch: 2/11, round: 234/501, loss: 0.5036343336105347\n",
      "test epoch: 2/11, round: 235/501, loss: 0.27501168847084045\n",
      "test epoch: 2/11, round: 236/501, loss: 0.3089328110218048\n",
      "test epoch: 2/11, round: 237/501, loss: 0.35129866003990173\n",
      "test epoch: 2/11, round: 238/501, loss: 0.38397639989852905\n",
      "test epoch: 2/11, round: 239/501, loss: 0.4107445180416107\n",
      "test epoch: 2/11, round: 240/501, loss: 0.19077084958553314\n",
      "test epoch: 2/11, round: 241/501, loss: 0.38061511516571045\n",
      "test epoch: 2/11, round: 242/501, loss: 0.2948493957519531\n",
      "test epoch: 2/11, round: 243/501, loss: 0.2441098690032959\n",
      "test epoch: 2/11, round: 244/501, loss: 0.24967151880264282\n",
      "test epoch: 2/11, round: 245/501, loss: 0.3953806757926941\n",
      "test epoch: 2/11, round: 246/501, loss: 0.354475200176239\n",
      "test epoch: 2/11, round: 247/501, loss: 0.4797528386116028\n",
      "test epoch: 2/11, round: 248/501, loss: 0.15722443163394928\n",
      "test epoch: 2/11, round: 249/501, loss: 0.35370251536369324\n",
      "test epoch: 2/11, round: 250/501, loss: 0.26859137415885925\n",
      "test epoch: 2/11, round: 251/501, loss: 0.30817946791648865\n",
      "test epoch: 2/11, round: 252/501, loss: 0.3250422775745392\n",
      "test epoch: 2/11, round: 253/501, loss: 0.36398056149482727\n",
      "test epoch: 2/11, round: 254/501, loss: 0.28174421191215515\n",
      "test epoch: 2/11, round: 255/501, loss: 0.32908955216407776\n",
      "test epoch: 2/11, round: 256/501, loss: 0.4378660023212433\n",
      "test epoch: 2/11, round: 257/501, loss: 0.36534327268600464\n",
      "test epoch: 2/11, round: 258/501, loss: 0.3650793731212616\n",
      "test epoch: 2/11, round: 259/501, loss: 0.2206934243440628\n",
      "test epoch: 2/11, round: 260/501, loss: 0.5015290379524231\n",
      "test epoch: 2/11, round: 261/501, loss: 0.5967862010002136\n",
      "test epoch: 2/11, round: 262/501, loss: 0.5124792456626892\n",
      "test epoch: 2/11, round: 263/501, loss: 0.4248184263706207\n",
      "test epoch: 2/11, round: 264/501, loss: 0.45909884572029114\n",
      "test epoch: 2/11, round: 265/501, loss: 0.6600881814956665\n",
      "test epoch: 2/11, round: 266/501, loss: 0.401456356048584\n",
      "test epoch: 2/11, round: 267/501, loss: 0.3973984718322754\n",
      "test epoch: 2/11, round: 268/501, loss: 0.27441534399986267\n",
      "test epoch: 2/11, round: 269/501, loss: 0.5419052839279175\n",
      "test epoch: 2/11, round: 270/501, loss: 0.2646472156047821\n",
      "test epoch: 2/11, round: 271/501, loss: 0.5590605139732361\n",
      "test epoch: 2/11, round: 272/501, loss: 0.3911750912666321\n",
      "test epoch: 2/11, round: 273/501, loss: 0.3459342122077942\n",
      "test epoch: 2/11, round: 274/501, loss: 0.5180960297584534\n",
      "test epoch: 2/11, round: 275/501, loss: 0.3280481994152069\n",
      "test epoch: 2/11, round: 276/501, loss: 0.41300687193870544\n",
      "test epoch: 2/11, round: 277/501, loss: 0.3864164352416992\n",
      "test epoch: 2/11, round: 278/501, loss: 0.6768857836723328\n",
      "test epoch: 2/11, round: 279/501, loss: 0.3044334948062897\n",
      "test epoch: 2/11, round: 280/501, loss: 0.21850132942199707\n",
      "test epoch: 2/11, round: 281/501, loss: 0.16494379937648773\n",
      "test epoch: 2/11, round: 282/501, loss: 0.23954111337661743\n",
      "test epoch: 2/11, round: 283/501, loss: 0.21235717833042145\n",
      "test epoch: 2/11, round: 284/501, loss: 0.3184797167778015\n",
      "test epoch: 2/11, round: 285/501, loss: 0.528426468372345\n",
      "test epoch: 2/11, round: 286/501, loss: 0.3863386809825897\n",
      "test epoch: 2/11, round: 287/501, loss: 0.580969512462616\n",
      "test epoch: 2/11, round: 288/501, loss: 0.2173328995704651\n",
      "test epoch: 2/11, round: 289/501, loss: 0.32897186279296875\n",
      "test epoch: 2/11, round: 290/501, loss: 0.33124178647994995\n",
      "test epoch: 2/11, round: 291/501, loss: 0.5411821007728577\n",
      "test epoch: 2/11, round: 292/501, loss: 0.4606335759162903\n",
      "test epoch: 2/11, round: 293/501, loss: 0.5383004546165466\n",
      "test epoch: 2/11, round: 294/501, loss: 0.1887800544500351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 2/11, round: 295/501, loss: 0.33085882663726807\n",
      "test epoch: 2/11, round: 296/501, loss: 0.46920162439346313\n",
      "test epoch: 2/11, round: 297/501, loss: 0.35607343912124634\n",
      "test epoch: 2/11, round: 298/501, loss: 0.4671162962913513\n",
      "test epoch: 2/11, round: 299/501, loss: 0.4116092920303345\n",
      "test epoch: 2/11, round: 300/501, loss: 0.5483308434486389\n",
      "test epoch: 2/11, round: 301/501, loss: 0.42908546328544617\n",
      "test epoch: 2/11, round: 302/501, loss: 0.22088027000427246\n",
      "test epoch: 2/11, round: 303/501, loss: 0.6440171599388123\n",
      "test epoch: 2/11, round: 304/501, loss: 0.7037650942802429\n",
      "test epoch: 2/11, round: 305/501, loss: 0.1668497920036316\n",
      "test epoch: 2/11, round: 306/501, loss: 0.25024065375328064\n",
      "test epoch: 2/11, round: 307/501, loss: 0.49216774106025696\n",
      "test epoch: 2/11, round: 308/501, loss: 0.2505761384963989\n",
      "test epoch: 2/11, round: 309/501, loss: 0.4527917206287384\n",
      "test epoch: 2/11, round: 310/501, loss: 0.39478400349617004\n",
      "test epoch: 2/11, round: 311/501, loss: 0.5503709316253662\n",
      "test epoch: 2/11, round: 312/501, loss: 0.386281281709671\n",
      "test epoch: 2/11, round: 313/501, loss: 0.33439910411834717\n",
      "test epoch: 2/11, round: 314/501, loss: 0.3178507685661316\n",
      "test epoch: 2/11, round: 315/501, loss: 0.3033358156681061\n",
      "test epoch: 2/11, round: 316/501, loss: 0.30799171328544617\n",
      "test epoch: 2/11, round: 317/501, loss: 0.3579552471637726\n",
      "test epoch: 2/11, round: 318/501, loss: 0.37774521112442017\n",
      "test epoch: 2/11, round: 319/501, loss: 0.6461157202720642\n",
      "test epoch: 2/11, round: 320/501, loss: 0.3361791670322418\n",
      "test epoch: 2/11, round: 321/501, loss: 0.3104965090751648\n",
      "test epoch: 2/11, round: 322/501, loss: 0.3939804136753082\n",
      "test epoch: 2/11, round: 323/501, loss: 0.4506727159023285\n",
      "test epoch: 2/11, round: 324/501, loss: 0.3196394741535187\n",
      "test epoch: 2/11, round: 325/501, loss: 0.42703020572662354\n",
      "test epoch: 2/11, round: 326/501, loss: 0.45055440068244934\n",
      "test epoch: 2/11, round: 327/501, loss: 0.6700770258903503\n",
      "test epoch: 2/11, round: 328/501, loss: 0.18640075623989105\n",
      "test epoch: 2/11, round: 329/501, loss: 0.4509524703025818\n",
      "test epoch: 2/11, round: 330/501, loss: 0.4921204447746277\n",
      "test epoch: 2/11, round: 331/501, loss: 0.38210833072662354\n",
      "test epoch: 2/11, round: 332/501, loss: 0.36083558201789856\n",
      "test epoch: 2/11, round: 333/501, loss: 0.4153404235839844\n",
      "test epoch: 2/11, round: 334/501, loss: 0.2236003875732422\n",
      "test epoch: 2/11, round: 335/501, loss: 0.36390748620033264\n",
      "test epoch: 2/11, round: 336/501, loss: 0.38563042879104614\n",
      "test epoch: 2/11, round: 337/501, loss: 0.5770631432533264\n",
      "test epoch: 2/11, round: 338/501, loss: 0.3743935525417328\n",
      "test epoch: 2/11, round: 339/501, loss: 0.9303098320960999\n",
      "test epoch: 2/11, round: 340/501, loss: 0.4517878592014313\n",
      "test epoch: 2/11, round: 341/501, loss: 0.47544607520103455\n",
      "test epoch: 2/11, round: 342/501, loss: 0.35255149006843567\n",
      "test epoch: 2/11, round: 343/501, loss: 0.32035455107688904\n",
      "test epoch: 2/11, round: 344/501, loss: 0.2414080947637558\n",
      "test epoch: 2/11, round: 345/501, loss: 0.18786948919296265\n",
      "test epoch: 2/11, round: 346/501, loss: 0.3532499372959137\n",
      "test epoch: 2/11, round: 347/501, loss: 0.3285458981990814\n",
      "test epoch: 2/11, round: 348/501, loss: 0.3495078682899475\n",
      "test epoch: 2/11, round: 349/501, loss: 0.31022369861602783\n",
      "test epoch: 2/11, round: 350/501, loss: 0.4581923484802246\n",
      "test epoch: 2/11, round: 351/501, loss: 0.46434423327445984\n",
      "test epoch: 2/11, round: 352/501, loss: 0.4922846555709839\n",
      "test epoch: 2/11, round: 353/501, loss: 0.3797038495540619\n",
      "test epoch: 2/11, round: 354/501, loss: 0.5466667413711548\n",
      "test epoch: 2/11, round: 355/501, loss: 0.39427289366722107\n",
      "test epoch: 2/11, round: 356/501, loss: 0.6147729158401489\n",
      "test epoch: 2/11, round: 357/501, loss: 0.4553261995315552\n",
      "test epoch: 2/11, round: 358/501, loss: 0.38130664825439453\n",
      "test epoch: 2/11, round: 359/501, loss: 0.34669819474220276\n",
      "test epoch: 2/11, round: 360/501, loss: 0.6199296116828918\n",
      "test epoch: 2/11, round: 361/501, loss: 0.5909103155136108\n",
      "test epoch: 2/11, round: 362/501, loss: 0.41792622208595276\n",
      "test epoch: 2/11, round: 363/501, loss: 0.610736608505249\n",
      "test epoch: 2/11, round: 364/501, loss: 0.5344964265823364\n",
      "test epoch: 2/11, round: 365/501, loss: 0.4881683588027954\n",
      "test epoch: 2/11, round: 366/501, loss: 0.6208397150039673\n",
      "test epoch: 2/11, round: 367/501, loss: 0.7790177464485168\n",
      "test epoch: 2/11, round: 368/501, loss: 0.26654621958732605\n",
      "test epoch: 2/11, round: 369/501, loss: 0.3495539426803589\n",
      "test epoch: 2/11, round: 370/501, loss: 0.3677566647529602\n",
      "test epoch: 2/11, round: 371/501, loss: 0.41084110736846924\n",
      "test epoch: 2/11, round: 372/501, loss: 0.3478405773639679\n",
      "test epoch: 2/11, round: 373/501, loss: 0.4336720108985901\n",
      "test epoch: 2/11, round: 374/501, loss: 0.32685554027557373\n",
      "test epoch: 2/11, round: 375/501, loss: 0.431654155254364\n",
      "test epoch: 2/11, round: 376/501, loss: 0.5448827147483826\n",
      "test epoch: 2/11, round: 377/501, loss: 0.11858890950679779\n",
      "test epoch: 2/11, round: 378/501, loss: 0.12905928492546082\n",
      "test epoch: 2/11, round: 379/501, loss: 0.4464924931526184\n",
      "test epoch: 2/11, round: 380/501, loss: 0.2540636360645294\n",
      "test epoch: 2/11, round: 381/501, loss: 0.37955793738365173\n",
      "test epoch: 2/11, round: 382/501, loss: 0.25538623332977295\n",
      "test epoch: 2/11, round: 383/501, loss: 0.31060999631881714\n",
      "test epoch: 2/11, round: 384/501, loss: 0.2113223373889923\n",
      "test epoch: 2/11, round: 385/501, loss: 0.5552559494972229\n",
      "test epoch: 2/11, round: 386/501, loss: 0.6018142700195312\n",
      "test epoch: 2/11, round: 387/501, loss: 0.278383731842041\n",
      "test epoch: 2/11, round: 388/501, loss: 0.2628946900367737\n",
      "test epoch: 2/11, round: 389/501, loss: 0.30253398418426514\n",
      "test epoch: 2/11, round: 390/501, loss: 0.44238269329071045\n",
      "test epoch: 2/11, round: 391/501, loss: 0.35722124576568604\n",
      "test epoch: 2/11, round: 392/501, loss: 0.4237608015537262\n",
      "test epoch: 2/11, round: 393/501, loss: 0.36245742440223694\n",
      "test epoch: 2/11, round: 394/501, loss: 0.6565490365028381\n",
      "test epoch: 2/11, round: 395/501, loss: 0.24727250635623932\n",
      "test epoch: 2/11, round: 396/501, loss: 0.41744422912597656\n",
      "test epoch: 2/11, round: 397/501, loss: 0.46645036339759827\n",
      "test epoch: 2/11, round: 398/501, loss: 0.4892212450504303\n",
      "test epoch: 2/11, round: 399/501, loss: 0.3161746561527252\n",
      "test epoch: 2/11, round: 400/501, loss: 0.2947078049182892\n",
      "test epoch: 2/11, round: 401/501, loss: 0.6655951142311096\n",
      "test epoch: 2/11, round: 402/501, loss: 0.4428040087223053\n",
      "test epoch: 2/11, round: 403/501, loss: 0.2918378412723541\n",
      "test epoch: 2/11, round: 404/501, loss: 0.2022092044353485\n",
      "test epoch: 2/11, round: 405/501, loss: 0.7247701287269592\n",
      "test epoch: 2/11, round: 406/501, loss: 0.42214080691337585\n",
      "test epoch: 2/11, round: 407/501, loss: 0.4849201738834381\n",
      "test epoch: 2/11, round: 408/501, loss: 0.5637820959091187\n",
      "test epoch: 2/11, round: 409/501, loss: 0.6004056930541992\n",
      "test epoch: 2/11, round: 410/501, loss: 0.3719313442707062\n",
      "test epoch: 2/11, round: 411/501, loss: 0.3586936891078949\n",
      "test epoch: 2/11, round: 412/501, loss: 0.4474915862083435\n",
      "test epoch: 2/11, round: 413/501, loss: 0.5083850622177124\n",
      "test epoch: 2/11, round: 414/501, loss: 0.3305293023586273\n",
      "test epoch: 2/11, round: 415/501, loss: 0.3410355746746063\n",
      "test epoch: 2/11, round: 416/501, loss: 0.36726200580596924\n",
      "test epoch: 2/11, round: 417/501, loss: 0.2545965909957886\n",
      "test epoch: 2/11, round: 418/501, loss: 0.2928958833217621\n",
      "test epoch: 2/11, round: 419/501, loss: 0.408563494682312\n",
      "test epoch: 2/11, round: 420/501, loss: 0.31530970335006714\n",
      "test epoch: 2/11, round: 421/501, loss: 0.42002323269844055\n",
      "test epoch: 2/11, round: 422/501, loss: 0.3747499883174896\n",
      "test epoch: 2/11, round: 423/501, loss: 0.6890180110931396\n",
      "test epoch: 2/11, round: 424/501, loss: 0.4353863298892975\n",
      "test epoch: 2/11, round: 425/501, loss: 0.3193722367286682\n",
      "test epoch: 2/11, round: 426/501, loss: 0.5283413529396057\n",
      "test epoch: 2/11, round: 427/501, loss: 0.27615419030189514\n",
      "test epoch: 2/11, round: 428/501, loss: 0.5905085802078247\n",
      "test epoch: 2/11, round: 429/501, loss: 0.6713255047798157\n",
      "test epoch: 2/11, round: 430/501, loss: 0.6093981862068176\n",
      "test epoch: 2/11, round: 431/501, loss: 0.4018520414829254\n",
      "test epoch: 2/11, round: 432/501, loss: 0.32739898562431335\n",
      "test epoch: 2/11, round: 433/501, loss: 0.41691216826438904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 2/11, round: 434/501, loss: 0.3263002336025238\n",
      "test epoch: 2/11, round: 435/501, loss: 0.33633723855018616\n",
      "test epoch: 2/11, round: 436/501, loss: 0.31651416420936584\n",
      "test epoch: 2/11, round: 437/501, loss: 0.4604608416557312\n",
      "test epoch: 2/11, round: 438/501, loss: 0.5648539066314697\n",
      "test epoch: 2/11, round: 439/501, loss: 0.3574886620044708\n",
      "test epoch: 2/11, round: 440/501, loss: 0.5200533866882324\n",
      "test epoch: 2/11, round: 441/501, loss: 0.39553529024124146\n",
      "test epoch: 2/11, round: 442/501, loss: 0.3494589924812317\n",
      "test epoch: 2/11, round: 443/501, loss: 0.25056418776512146\n",
      "test epoch: 2/11, round: 444/501, loss: 0.4222268760204315\n",
      "test epoch: 2/11, round: 445/501, loss: 0.45658379793167114\n",
      "test epoch: 2/11, round: 446/501, loss: 0.4753369688987732\n",
      "test epoch: 2/11, round: 447/501, loss: 0.2497512847185135\n",
      "test epoch: 2/11, round: 448/501, loss: 0.3713124990463257\n",
      "test epoch: 2/11, round: 449/501, loss: 0.21203361451625824\n",
      "test epoch: 2/11, round: 450/501, loss: 0.6926359534263611\n",
      "test epoch: 2/11, round: 451/501, loss: 0.33940786123275757\n",
      "test epoch: 2/11, round: 452/501, loss: 0.38423821330070496\n",
      "test epoch: 2/11, round: 453/501, loss: 0.154580757021904\n",
      "test epoch: 2/11, round: 454/501, loss: 0.2208058089017868\n",
      "test epoch: 2/11, round: 455/501, loss: 0.5542137622833252\n",
      "test epoch: 2/11, round: 456/501, loss: 0.2686925232410431\n",
      "test epoch: 2/11, round: 457/501, loss: 0.21487754583358765\n",
      "test epoch: 2/11, round: 458/501, loss: 0.20637543499469757\n",
      "test epoch: 2/11, round: 459/501, loss: 0.1146080493927002\n",
      "test epoch: 2/11, round: 460/501, loss: 0.11000214517116547\n",
      "test epoch: 2/11, round: 461/501, loss: 0.1205354854464531\n",
      "test epoch: 2/11, round: 462/501, loss: 0.1045575961470604\n",
      "test epoch: 2/11, round: 463/501, loss: 0.11168014258146286\n",
      "test epoch: 2/11, round: 464/501, loss: 0.10142660140991211\n",
      "test epoch: 2/11, round: 465/501, loss: 0.12747256457805634\n",
      "test epoch: 2/11, round: 466/501, loss: 0.11425819993019104\n",
      "test epoch: 2/11, round: 467/501, loss: 0.12995503842830658\n",
      "test epoch: 2/11, round: 468/501, loss: 0.12012139707803726\n",
      "test epoch: 2/11, round: 469/501, loss: 0.11676473915576935\n",
      "test epoch: 2/11, round: 470/501, loss: 0.1256679892539978\n",
      "test epoch: 2/11, round: 471/501, loss: 0.12452532351016998\n",
      "test epoch: 2/11, round: 472/501, loss: 0.11439363658428192\n",
      "test epoch: 2/11, round: 473/501, loss: 0.11206270754337311\n",
      "test epoch: 2/11, round: 474/501, loss: 0.12648862600326538\n",
      "test epoch: 2/11, round: 475/501, loss: 0.11787231266498566\n",
      "test epoch: 2/11, round: 476/501, loss: 0.0950959175825119\n",
      "test epoch: 2/11, round: 477/501, loss: 0.10632969439029694\n",
      "test epoch: 2/11, round: 478/501, loss: 0.10874905437231064\n",
      "test epoch: 2/11, round: 479/501, loss: 0.08366195857524872\n",
      "test epoch: 2/11, round: 480/501, loss: 0.10598690062761307\n",
      "test epoch: 2/11, round: 481/501, loss: 0.10923382639884949\n",
      "test epoch: 2/11, round: 482/501, loss: 0.10187981277704239\n",
      "test epoch: 2/11, round: 483/501, loss: 0.10399293154478073\n",
      "test epoch: 2/11, round: 484/501, loss: 0.10954127460718155\n",
      "test epoch: 2/11, round: 485/501, loss: 0.09288036823272705\n",
      "test epoch: 2/11, round: 486/501, loss: 0.10517381131649017\n",
      "test epoch: 2/11, round: 487/501, loss: 0.10002435743808746\n",
      "test epoch: 2/11, round: 488/501, loss: 0.1253952980041504\n",
      "test epoch: 2/11, round: 489/501, loss: 0.10662107169628143\n",
      "test epoch: 2/11, round: 490/501, loss: 0.09951201826334\n",
      "test epoch: 2/11, round: 491/501, loss: 0.1084233745932579\n",
      "test epoch: 2/11, round: 492/501, loss: 0.124005988240242\n",
      "test epoch: 2/11, round: 493/501, loss: 0.13173305988311768\n",
      "test epoch: 2/11, round: 494/501, loss: 0.12003842741250992\n",
      "test epoch: 2/11, round: 495/501, loss: 0.10853800922632217\n",
      "test epoch: 2/11, round: 496/501, loss: 0.12187460064888\n",
      "test epoch: 2/11, round: 497/501, loss: 0.11176171153783798\n",
      "test epoch: 2/11, round: 498/501, loss: 0.09382756799459457\n",
      "test epoch: 2/11, round: 499/501, loss: 0.1035013422369957\n",
      "test epoch: 2/11, round: 500/501, loss: 0.3445761799812317\n",
      "test epoch: 2/11, round: 501/501, loss: 0.9259646534919739\n",
      "test epoch: 2/11, KS: 0.1637916358667652, ROC: 0.6124823600564477\n",
      "cost time: 1990\n",
      "train epoch: 3/11, round: 1/532, loss: 0.4094608426094055\n",
      "train epoch: 3/11, round: 2/532, loss: 0.41497403383255005\n",
      "train epoch: 3/11, round: 3/532, loss: 0.4633655548095703\n",
      "train epoch: 3/11, round: 4/532, loss: 0.38321182131767273\n",
      "train epoch: 3/11, round: 5/532, loss: 0.399496853351593\n",
      "train epoch: 3/11, round: 6/532, loss: 0.4015943109989166\n",
      "train epoch: 3/11, round: 7/532, loss: 0.33352431654930115\n",
      "train epoch: 3/11, round: 8/532, loss: 0.46255630254745483\n",
      "train epoch: 3/11, round: 9/532, loss: 0.42514991760253906\n",
      "train epoch: 3/11, round: 10/532, loss: 0.39770784974098206\n",
      "train epoch: 3/11, round: 11/532, loss: 0.426565557718277\n",
      "train epoch: 3/11, round: 12/532, loss: 0.38798433542251587\n",
      "train epoch: 3/11, round: 13/532, loss: 0.42682522535324097\n",
      "train epoch: 3/11, round: 14/532, loss: 0.3830614984035492\n",
      "train epoch: 3/11, round: 15/532, loss: 0.41096431016921997\n",
      "train epoch: 3/11, round: 16/532, loss: 0.5000005960464478\n",
      "train epoch: 3/11, round: 17/532, loss: 0.3959212601184845\n",
      "train epoch: 3/11, round: 18/532, loss: 0.4263443946838379\n",
      "train epoch: 3/11, round: 19/532, loss: 0.44598713517189026\n",
      "train epoch: 3/11, round: 20/532, loss: 0.5019806027412415\n",
      "train epoch: 3/11, round: 21/532, loss: 0.42017999291419983\n",
      "train epoch: 3/11, round: 22/532, loss: 0.43787679076194763\n",
      "train epoch: 3/11, round: 23/532, loss: 0.44947752356529236\n",
      "train epoch: 3/11, round: 24/532, loss: 0.4079670011997223\n",
      "train epoch: 3/11, round: 25/532, loss: 0.39653176069259644\n",
      "train epoch: 3/11, round: 26/532, loss: 0.4576376974582672\n",
      "train epoch: 3/11, round: 27/532, loss: 0.360901415348053\n",
      "train epoch: 3/11, round: 28/532, loss: 0.42714959383010864\n",
      "train epoch: 3/11, round: 29/532, loss: 0.3429473638534546\n",
      "train epoch: 3/11, round: 30/532, loss: 0.43958187103271484\n",
      "train epoch: 3/11, round: 31/532, loss: 0.4152924120426178\n",
      "train epoch: 3/11, round: 32/532, loss: 0.3035893440246582\n",
      "train epoch: 3/11, round: 33/532, loss: 0.38757920265197754\n",
      "train epoch: 3/11, round: 34/532, loss: 0.4034059941768646\n",
      "train epoch: 3/11, round: 35/532, loss: 0.43687525391578674\n",
      "train epoch: 3/11, round: 36/532, loss: 0.36811283230781555\n",
      "train epoch: 3/11, round: 37/532, loss: 0.48205655813217163\n",
      "train epoch: 3/11, round: 38/532, loss: 0.41286271810531616\n",
      "train epoch: 3/11, round: 39/532, loss: 0.300845205783844\n",
      "train epoch: 3/11, round: 40/532, loss: 0.5014306902885437\n",
      "train epoch: 3/11, round: 41/532, loss: 0.44038501381874084\n",
      "train epoch: 3/11, round: 42/532, loss: 0.46234217286109924\n",
      "train epoch: 3/11, round: 43/532, loss: 0.49977055191993713\n",
      "train epoch: 3/11, round: 44/532, loss: 0.42289671301841736\n",
      "train epoch: 3/11, round: 45/532, loss: 0.33084964752197266\n",
      "train epoch: 3/11, round: 46/532, loss: 0.39607229828834534\n",
      "train epoch: 3/11, round: 47/532, loss: 0.4505246579647064\n",
      "train epoch: 3/11, round: 48/532, loss: 0.42304831743240356\n",
      "train epoch: 3/11, round: 49/532, loss: 0.3526957333087921\n",
      "train epoch: 3/11, round: 50/532, loss: 0.41406354308128357\n",
      "train epoch: 3/11, round: 51/532, loss: 0.4316135346889496\n",
      "train epoch: 3/11, round: 52/532, loss: 0.4453807771205902\n",
      "train epoch: 3/11, round: 53/532, loss: 0.43184900283813477\n",
      "train epoch: 3/11, round: 54/532, loss: 0.33546215295791626\n",
      "train epoch: 3/11, round: 55/532, loss: 0.3943081498146057\n",
      "train epoch: 3/11, round: 56/532, loss: 0.3405747413635254\n",
      "train epoch: 3/11, round: 57/532, loss: 0.3751192092895508\n",
      "train epoch: 3/11, round: 58/532, loss: 0.3864808678627014\n",
      "train epoch: 3/11, round: 59/532, loss: 0.40838852524757385\n",
      "train epoch: 3/11, round: 60/532, loss: 0.4177912771701813\n",
      "train epoch: 3/11, round: 61/532, loss: 0.48719048500061035\n",
      "train epoch: 3/11, round: 62/532, loss: 0.4306701719760895\n",
      "train epoch: 3/11, round: 63/532, loss: 0.4536689817905426\n",
      "train epoch: 3/11, round: 64/532, loss: 0.3724002540111542\n",
      "train epoch: 3/11, round: 65/532, loss: 0.43735140562057495\n",
      "train epoch: 3/11, round: 66/532, loss: 0.4226744771003723\n",
      "train epoch: 3/11, round: 67/532, loss: 0.4137965738773346\n",
      "train epoch: 3/11, round: 68/532, loss: 0.39034682512283325\n",
      "train epoch: 3/11, round: 69/532, loss: 0.4156283736228943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3/11, round: 70/532, loss: 0.4101749360561371\n",
      "train epoch: 3/11, round: 71/532, loss: 0.40653085708618164\n",
      "train epoch: 3/11, round: 72/532, loss: 0.44230732321739197\n",
      "train epoch: 3/11, round: 73/532, loss: 0.41020363569259644\n",
      "train epoch: 3/11, round: 74/532, loss: 0.3741522431373596\n",
      "train epoch: 3/11, round: 75/532, loss: 0.44220131635665894\n",
      "train epoch: 3/11, round: 76/532, loss: 0.3653114438056946\n",
      "train epoch: 3/11, round: 77/532, loss: 0.3604726195335388\n",
      "train epoch: 3/11, round: 78/532, loss: 0.5142597556114197\n",
      "train epoch: 3/11, round: 79/532, loss: 0.40335482358932495\n",
      "train epoch: 3/11, round: 80/532, loss: 0.4771525263786316\n",
      "train epoch: 3/11, round: 81/532, loss: 0.48633426427841187\n",
      "train epoch: 3/11, round: 82/532, loss: 0.41733676195144653\n",
      "train epoch: 3/11, round: 83/532, loss: 0.32920339703559875\n",
      "train epoch: 3/11, round: 84/532, loss: 0.4311290681362152\n",
      "train epoch: 3/11, round: 85/532, loss: 0.3993819057941437\n",
      "train epoch: 3/11, round: 86/532, loss: 0.37478670477867126\n",
      "train epoch: 3/11, round: 87/532, loss: 0.3683532774448395\n",
      "train epoch: 3/11, round: 88/532, loss: 0.46165353059768677\n",
      "train epoch: 3/11, round: 89/532, loss: 0.4218483865261078\n",
      "train epoch: 3/11, round: 90/532, loss: 0.41121619939804077\n",
      "train epoch: 3/11, round: 91/532, loss: 0.4382048547267914\n",
      "train epoch: 3/11, round: 92/532, loss: 0.3783869743347168\n",
      "train epoch: 3/11, round: 93/532, loss: 0.3461610674858093\n",
      "train epoch: 3/11, round: 94/532, loss: 0.46496447920799255\n",
      "train epoch: 3/11, round: 95/532, loss: 0.5409528613090515\n",
      "train epoch: 3/11, round: 96/532, loss: 0.4360865652561188\n",
      "train epoch: 3/11, round: 97/532, loss: 0.3438575267791748\n",
      "train epoch: 3/11, round: 98/532, loss: 0.39022526144981384\n",
      "train epoch: 3/11, round: 99/532, loss: 0.40573519468307495\n",
      "train epoch: 3/11, round: 100/532, loss: 0.34995755553245544\n",
      "train epoch: 3/11, round: 101/532, loss: 0.3711182475090027\n",
      "train epoch: 3/11, round: 102/532, loss: 0.4023978114128113\n",
      "train epoch: 3/11, round: 103/532, loss: 0.4228743016719818\n",
      "train epoch: 3/11, round: 104/532, loss: 0.4424421191215515\n",
      "train epoch: 3/11, round: 105/532, loss: 0.42793703079223633\n",
      "train epoch: 3/11, round: 106/532, loss: 0.40224742889404297\n",
      "train epoch: 3/11, round: 107/532, loss: 0.40359073877334595\n",
      "train epoch: 3/11, round: 108/532, loss: 0.36694541573524475\n",
      "train epoch: 3/11, round: 109/532, loss: 0.4422597885131836\n",
      "train epoch: 3/11, round: 110/532, loss: 0.477067768573761\n",
      "train epoch: 3/11, round: 111/532, loss: 0.39237180352211\n",
      "train epoch: 3/11, round: 112/532, loss: 0.4841904640197754\n",
      "train epoch: 3/11, round: 113/532, loss: 0.41968002915382385\n",
      "train epoch: 3/11, round: 114/532, loss: 0.372086763381958\n",
      "train epoch: 3/11, round: 115/532, loss: 0.42528682947158813\n",
      "train epoch: 3/11, round: 116/532, loss: 0.3939811587333679\n",
      "train epoch: 3/11, round: 117/532, loss: 0.40795889496803284\n",
      "train epoch: 3/11, round: 118/532, loss: 0.37819981575012207\n",
      "train epoch: 3/11, round: 119/532, loss: 0.5069405436515808\n",
      "train epoch: 3/11, round: 120/532, loss: 0.475416362285614\n",
      "train epoch: 3/11, round: 121/532, loss: 0.4214302897453308\n",
      "train epoch: 3/11, round: 122/532, loss: 0.45622873306274414\n",
      "train epoch: 3/11, round: 123/532, loss: 0.4297960698604584\n",
      "train epoch: 3/11, round: 124/532, loss: 0.4083757996559143\n",
      "train epoch: 3/11, round: 125/532, loss: 0.33724245429039\n",
      "train epoch: 3/11, round: 126/532, loss: 0.42015570402145386\n",
      "train epoch: 3/11, round: 127/532, loss: 0.44924378395080566\n",
      "train epoch: 3/11, round: 128/532, loss: 0.42866963148117065\n",
      "train epoch: 3/11, round: 129/532, loss: 0.5177819132804871\n",
      "train epoch: 3/11, round: 130/532, loss: 0.39919739961624146\n",
      "train epoch: 3/11, round: 131/532, loss: 0.4086039662361145\n",
      "train epoch: 3/11, round: 132/532, loss: 0.42728695273399353\n",
      "train epoch: 3/11, round: 133/532, loss: 0.363436758518219\n",
      "train epoch: 3/11, round: 134/532, loss: 0.3871755003929138\n",
      "train epoch: 3/11, round: 135/532, loss: 0.3957230746746063\n",
      "train epoch: 3/11, round: 136/532, loss: 0.43084344267845154\n",
      "train epoch: 3/11, round: 137/532, loss: 0.3892954885959625\n",
      "train epoch: 3/11, round: 138/532, loss: 0.4327642321586609\n",
      "train epoch: 3/11, round: 139/532, loss: 0.4218668043613434\n",
      "train epoch: 3/11, round: 140/532, loss: 0.43353739380836487\n",
      "train epoch: 3/11, round: 141/532, loss: 0.4396609365940094\n",
      "train epoch: 3/11, round: 142/532, loss: 0.515105664730072\n",
      "train epoch: 3/11, round: 143/532, loss: 0.36078935861587524\n",
      "train epoch: 3/11, round: 144/532, loss: 0.446320116519928\n",
      "train epoch: 3/11, round: 145/532, loss: 0.41141581535339355\n",
      "train epoch: 3/11, round: 146/532, loss: 0.4997239112854004\n",
      "train epoch: 3/11, round: 147/532, loss: 0.3539934754371643\n",
      "train epoch: 3/11, round: 148/532, loss: 0.3656516969203949\n",
      "train epoch: 3/11, round: 149/532, loss: 0.3826112449169159\n",
      "train epoch: 3/11, round: 150/532, loss: 0.41683775186538696\n",
      "train epoch: 3/11, round: 151/532, loss: 0.4277999997138977\n",
      "train epoch: 3/11, round: 152/532, loss: 0.4184338450431824\n",
      "train epoch: 3/11, round: 153/532, loss: 0.35491421818733215\n",
      "train epoch: 3/11, round: 154/532, loss: 0.4400025010108948\n",
      "train epoch: 3/11, round: 155/532, loss: 0.462962806224823\n",
      "train epoch: 3/11, round: 156/532, loss: 0.3335222601890564\n",
      "train epoch: 3/11, round: 157/532, loss: 0.35892122983932495\n",
      "train epoch: 3/11, round: 158/532, loss: 0.3832392692565918\n",
      "train epoch: 3/11, round: 159/532, loss: 0.32101017236709595\n",
      "train epoch: 3/11, round: 160/532, loss: 0.374237596988678\n",
      "train epoch: 3/11, round: 161/532, loss: 0.41335010528564453\n",
      "train epoch: 3/11, round: 162/532, loss: 0.43115440011024475\n",
      "train epoch: 3/11, round: 163/532, loss: 0.38482946157455444\n",
      "train epoch: 3/11, round: 164/532, loss: 0.38301682472229004\n",
      "train epoch: 3/11, round: 165/532, loss: 0.36098629236221313\n",
      "train epoch: 3/11, round: 166/532, loss: 0.4327112138271332\n",
      "train epoch: 3/11, round: 167/532, loss: 0.4521011412143707\n",
      "train epoch: 3/11, round: 168/532, loss: 0.4148593842983246\n",
      "train epoch: 3/11, round: 169/532, loss: 0.40135878324508667\n",
      "train epoch: 3/11, round: 170/532, loss: 0.40656501054763794\n",
      "train epoch: 3/11, round: 171/532, loss: 0.3770270347595215\n",
      "train epoch: 3/11, round: 172/532, loss: 0.40025264024734497\n",
      "train epoch: 3/11, round: 173/532, loss: 0.5566166639328003\n",
      "train epoch: 3/11, round: 174/532, loss: 0.38109689950942993\n",
      "train epoch: 3/11, round: 175/532, loss: 0.44497138261795044\n",
      "train epoch: 3/11, round: 176/532, loss: 0.43008366227149963\n",
      "train epoch: 3/11, round: 177/532, loss: 0.3988816738128662\n",
      "train epoch: 3/11, round: 178/532, loss: 0.4375753402709961\n",
      "train epoch: 3/11, round: 179/532, loss: 0.41940444707870483\n",
      "train epoch: 3/11, round: 180/532, loss: 0.3879413604736328\n",
      "train epoch: 3/11, round: 181/532, loss: 0.44011592864990234\n",
      "train epoch: 3/11, round: 182/532, loss: 0.37933221459388733\n",
      "train epoch: 3/11, round: 183/532, loss: 0.37105172872543335\n",
      "train epoch: 3/11, round: 184/532, loss: 0.4479304850101471\n",
      "train epoch: 3/11, round: 185/532, loss: 0.3674315810203552\n",
      "train epoch: 3/11, round: 186/532, loss: 0.4107789099216461\n",
      "train epoch: 3/11, round: 187/532, loss: 0.4059605002403259\n",
      "train epoch: 3/11, round: 188/532, loss: 0.392745703458786\n",
      "train epoch: 3/11, round: 189/532, loss: 0.3936794698238373\n",
      "train epoch: 3/11, round: 190/532, loss: 0.3054586946964264\n",
      "train epoch: 3/11, round: 191/532, loss: 0.5334360003471375\n",
      "train epoch: 3/11, round: 192/532, loss: 0.3909265995025635\n",
      "train epoch: 3/11, round: 193/532, loss: 0.41788730025291443\n",
      "train epoch: 3/11, round: 194/532, loss: 0.41051363945007324\n",
      "train epoch: 3/11, round: 195/532, loss: 0.4680747389793396\n",
      "train epoch: 3/11, round: 196/532, loss: 0.43706703186035156\n",
      "train epoch: 3/11, round: 197/532, loss: 0.4655434191226959\n",
      "train epoch: 3/11, round: 198/532, loss: 0.5286422967910767\n",
      "train epoch: 3/11, round: 199/532, loss: 0.4125814437866211\n",
      "train epoch: 3/11, round: 200/532, loss: 0.36542654037475586\n",
      "train epoch: 3/11, round: 201/532, loss: 0.4084261357784271\n",
      "train epoch: 3/11, round: 202/532, loss: 0.42586761713027954\n",
      "train epoch: 3/11, round: 203/532, loss: 0.43405312299728394\n",
      "train epoch: 3/11, round: 204/532, loss: 0.37055307626724243\n",
      "train epoch: 3/11, round: 205/532, loss: 0.37040024995803833\n",
      "train epoch: 3/11, round: 206/532, loss: 0.45868557691574097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3/11, round: 207/532, loss: 0.4878709316253662\n",
      "train epoch: 3/11, round: 208/532, loss: 0.39462023973464966\n",
      "train epoch: 3/11, round: 209/532, loss: 0.40002521872520447\n",
      "train epoch: 3/11, round: 210/532, loss: 0.4496603012084961\n",
      "train epoch: 3/11, round: 211/532, loss: 0.4723953604698181\n",
      "train epoch: 3/11, round: 212/532, loss: 0.38460126519203186\n",
      "train epoch: 3/11, round: 213/532, loss: 0.41998133063316345\n",
      "train epoch: 3/11, round: 214/532, loss: 0.4199298322200775\n",
      "train epoch: 3/11, round: 215/532, loss: 0.4535375237464905\n",
      "train epoch: 3/11, round: 216/532, loss: 0.4319004416465759\n",
      "train epoch: 3/11, round: 217/532, loss: 0.438598096370697\n",
      "train epoch: 3/11, round: 218/532, loss: 0.4131197929382324\n",
      "train epoch: 3/11, round: 219/532, loss: 0.4308830797672272\n",
      "train epoch: 3/11, round: 220/532, loss: 0.4321250915527344\n",
      "train epoch: 3/11, round: 221/532, loss: 0.38605085015296936\n",
      "train epoch: 3/11, round: 222/532, loss: 0.41504350304603577\n",
      "train epoch: 3/11, round: 223/532, loss: 0.3253684937953949\n",
      "train epoch: 3/11, round: 224/532, loss: 0.42975226044654846\n",
      "train epoch: 3/11, round: 225/532, loss: 0.4202420115470886\n",
      "train epoch: 3/11, round: 226/532, loss: 0.3568243086338043\n",
      "train epoch: 3/11, round: 227/532, loss: 0.4210059642791748\n",
      "train epoch: 3/11, round: 228/532, loss: 0.42452898621559143\n",
      "train epoch: 3/11, round: 229/532, loss: 0.4058462977409363\n",
      "train epoch: 3/11, round: 230/532, loss: 0.40826234221458435\n",
      "train epoch: 3/11, round: 231/532, loss: 0.3844917416572571\n",
      "train epoch: 3/11, round: 232/532, loss: 0.3800863027572632\n",
      "train epoch: 3/11, round: 233/532, loss: 0.4748358726501465\n",
      "train epoch: 3/11, round: 234/532, loss: 0.34478887915611267\n",
      "train epoch: 3/11, round: 235/532, loss: 0.417219340801239\n",
      "train epoch: 3/11, round: 236/532, loss: 0.4004761278629303\n",
      "train epoch: 3/11, round: 237/532, loss: 0.4382072389125824\n",
      "train epoch: 3/11, round: 238/532, loss: 0.3629209101200104\n",
      "train epoch: 3/11, round: 239/532, loss: 0.5045371651649475\n",
      "train epoch: 3/11, round: 240/532, loss: 0.37568163871765137\n",
      "train epoch: 3/11, round: 241/532, loss: 0.477041631937027\n",
      "train epoch: 3/11, round: 242/532, loss: 0.40306010842323303\n",
      "train epoch: 3/11, round: 243/532, loss: 0.40005603432655334\n",
      "train epoch: 3/11, round: 244/532, loss: 0.3832201361656189\n",
      "train epoch: 3/11, round: 245/532, loss: 0.4144322872161865\n",
      "train epoch: 3/11, round: 246/532, loss: 0.39194995164871216\n",
      "train epoch: 3/11, round: 247/532, loss: 0.4015195369720459\n",
      "train epoch: 3/11, round: 248/532, loss: 0.48418623208999634\n",
      "train epoch: 3/11, round: 249/532, loss: 0.46882668137550354\n",
      "train epoch: 3/11, round: 250/532, loss: 0.41078081727027893\n",
      "train epoch: 3/11, round: 251/532, loss: 0.4198126196861267\n",
      "train epoch: 3/11, round: 252/532, loss: 0.39466431736946106\n",
      "train epoch: 3/11, round: 253/532, loss: 0.45460766553878784\n",
      "train epoch: 3/11, round: 254/532, loss: 0.3723606467247009\n",
      "train epoch: 3/11, round: 255/532, loss: 0.4031011164188385\n",
      "train epoch: 3/11, round: 256/532, loss: 0.3941192328929901\n",
      "train epoch: 3/11, round: 257/532, loss: 0.4363585114479065\n",
      "train epoch: 3/11, round: 258/532, loss: 0.3795146942138672\n",
      "train epoch: 3/11, round: 259/532, loss: 0.3432503640651703\n",
      "train epoch: 3/11, round: 260/532, loss: 0.4186228811740875\n",
      "train epoch: 3/11, round: 261/532, loss: 0.3893888294696808\n",
      "train epoch: 3/11, round: 262/532, loss: 0.40046581625938416\n",
      "train epoch: 3/11, round: 263/532, loss: 0.33823055028915405\n",
      "train epoch: 3/11, round: 264/532, loss: 0.33741024136543274\n",
      "train epoch: 3/11, round: 265/532, loss: 0.4023675322532654\n",
      "train epoch: 3/11, round: 266/532, loss: 0.4519883096218109\n",
      "train epoch: 3/11, round: 267/532, loss: 0.36229994893074036\n",
      "train epoch: 3/11, round: 268/532, loss: 0.3841840624809265\n",
      "train epoch: 3/11, round: 269/532, loss: 0.3973453640937805\n",
      "train epoch: 3/11, round: 270/532, loss: 0.3686831593513489\n",
      "train epoch: 3/11, round: 271/532, loss: 0.34766265749931335\n",
      "train epoch: 3/11, round: 272/532, loss: 0.45015066862106323\n",
      "train epoch: 3/11, round: 273/532, loss: 0.33323824405670166\n",
      "train epoch: 3/11, round: 274/532, loss: 0.41345396637916565\n",
      "train epoch: 3/11, round: 275/532, loss: 0.37215864658355713\n",
      "train epoch: 3/11, round: 276/532, loss: 0.39321792125701904\n",
      "train epoch: 3/11, round: 277/532, loss: 0.3732066750526428\n",
      "train epoch: 3/11, round: 278/532, loss: 0.41964760422706604\n",
      "train epoch: 3/11, round: 279/532, loss: 0.3945002555847168\n",
      "train epoch: 3/11, round: 280/532, loss: 0.4528472423553467\n",
      "train epoch: 3/11, round: 281/532, loss: 0.44781166315078735\n",
      "train epoch: 3/11, round: 282/532, loss: 0.38868117332458496\n",
      "train epoch: 3/11, round: 283/532, loss: 0.4076022207736969\n",
      "train epoch: 3/11, round: 284/532, loss: 0.3893890678882599\n",
      "train epoch: 3/11, round: 285/532, loss: 0.3775182366371155\n",
      "train epoch: 3/11, round: 286/532, loss: 0.43845224380493164\n",
      "train epoch: 3/11, round: 287/532, loss: 0.45746445655822754\n",
      "train epoch: 3/11, round: 288/532, loss: 0.35329118371009827\n",
      "train epoch: 3/11, round: 289/532, loss: 0.37684720754623413\n",
      "train epoch: 3/11, round: 290/532, loss: 0.43477755784988403\n",
      "train epoch: 3/11, round: 291/532, loss: 0.4347975254058838\n",
      "train epoch: 3/11, round: 292/532, loss: 0.483991801738739\n",
      "train epoch: 3/11, round: 293/532, loss: 0.4115839898586273\n",
      "train epoch: 3/11, round: 294/532, loss: 0.40946096181869507\n",
      "train epoch: 3/11, round: 295/532, loss: 0.3970242440700531\n",
      "train epoch: 3/11, round: 296/532, loss: 0.3766512870788574\n",
      "train epoch: 3/11, round: 297/532, loss: 0.4779861569404602\n",
      "train epoch: 3/11, round: 298/532, loss: 0.4612954258918762\n",
      "train epoch: 3/11, round: 299/532, loss: 0.4111330509185791\n",
      "train epoch: 3/11, round: 300/532, loss: 0.33500656485557556\n",
      "train epoch: 3/11, round: 301/532, loss: 0.37661370635032654\n",
      "train epoch: 3/11, round: 302/532, loss: 0.3594088554382324\n",
      "train epoch: 3/11, round: 303/532, loss: 0.4537838399410248\n",
      "train epoch: 3/11, round: 304/532, loss: 0.36793282628059387\n",
      "train epoch: 3/11, round: 305/532, loss: 0.4606860280036926\n",
      "train epoch: 3/11, round: 306/532, loss: 0.4069198668003082\n",
      "train epoch: 3/11, round: 307/532, loss: 0.47266238927841187\n",
      "train epoch: 3/11, round: 308/532, loss: 0.4633084833621979\n",
      "train epoch: 3/11, round: 309/532, loss: 0.3366962969303131\n",
      "train epoch: 3/11, round: 310/532, loss: 0.3468569219112396\n",
      "train epoch: 3/11, round: 311/532, loss: 0.49874067306518555\n",
      "train epoch: 3/11, round: 312/532, loss: 0.4449188709259033\n",
      "train epoch: 3/11, round: 313/532, loss: 0.4404345154762268\n",
      "train epoch: 3/11, round: 314/532, loss: 0.43454569578170776\n",
      "train epoch: 3/11, round: 315/532, loss: 0.3866475522518158\n",
      "train epoch: 3/11, round: 316/532, loss: 0.3799118399620056\n",
      "train epoch: 3/11, round: 317/532, loss: 0.3914795219898224\n",
      "train epoch: 3/11, round: 318/532, loss: 0.42836302518844604\n",
      "train epoch: 3/11, round: 319/532, loss: 0.4360172152519226\n",
      "train epoch: 3/11, round: 320/532, loss: 0.37124258279800415\n",
      "train epoch: 3/11, round: 321/532, loss: 0.4044385850429535\n",
      "train epoch: 3/11, round: 322/532, loss: 0.4737021327018738\n",
      "train epoch: 3/11, round: 323/532, loss: 0.31995296478271484\n",
      "train epoch: 3/11, round: 324/532, loss: 0.43374794721603394\n",
      "train epoch: 3/11, round: 325/532, loss: 0.46193623542785645\n",
      "train epoch: 3/11, round: 326/532, loss: 0.4989220201969147\n",
      "train epoch: 3/11, round: 327/532, loss: 0.37739869952201843\n",
      "train epoch: 3/11, round: 328/532, loss: 0.43931055068969727\n",
      "train epoch: 3/11, round: 329/532, loss: 0.3090457022190094\n",
      "train epoch: 3/11, round: 330/532, loss: 0.32049980759620667\n",
      "train epoch: 3/11, round: 331/532, loss: 0.44396406412124634\n",
      "train epoch: 3/11, round: 332/532, loss: 0.29608479142189026\n",
      "train epoch: 3/11, round: 333/532, loss: 0.3890311121940613\n",
      "train epoch: 3/11, round: 334/532, loss: 0.45399636030197144\n",
      "train epoch: 3/11, round: 335/532, loss: 0.4861159324645996\n",
      "train epoch: 3/11, round: 336/532, loss: 0.3818967342376709\n",
      "train epoch: 3/11, round: 337/532, loss: 0.40353697538375854\n",
      "train epoch: 3/11, round: 338/532, loss: 0.47981786727905273\n",
      "train epoch: 3/11, round: 339/532, loss: 0.3302687406539917\n",
      "train epoch: 3/11, round: 340/532, loss: 0.3510708510875702\n",
      "train epoch: 3/11, round: 341/532, loss: 0.2969570457935333\n",
      "train epoch: 3/11, round: 342/532, loss: 0.45413050055503845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3/11, round: 343/532, loss: 0.3705061972141266\n",
      "train epoch: 3/11, round: 344/532, loss: 0.44055691361427307\n",
      "train epoch: 3/11, round: 345/532, loss: 0.4865645468235016\n",
      "train epoch: 3/11, round: 346/532, loss: 0.37243279814720154\n",
      "train epoch: 3/11, round: 347/532, loss: 0.3645620048046112\n",
      "train epoch: 3/11, round: 348/532, loss: 0.2664608061313629\n",
      "train epoch: 3/11, round: 349/532, loss: 0.4107910096645355\n",
      "train epoch: 3/11, round: 350/532, loss: 0.3044883906841278\n",
      "train epoch: 3/11, round: 351/532, loss: 0.3932999074459076\n",
      "train epoch: 3/11, round: 352/532, loss: 0.35669511556625366\n",
      "train epoch: 3/11, round: 353/532, loss: 0.4494563639163971\n",
      "train epoch: 3/11, round: 354/532, loss: 0.4486466348171234\n",
      "train epoch: 3/11, round: 355/532, loss: 0.43775948882102966\n",
      "train epoch: 3/11, round: 356/532, loss: 0.3645102381706238\n",
      "train epoch: 3/11, round: 357/532, loss: 0.35485389828681946\n",
      "train epoch: 3/11, round: 358/532, loss: 0.40977054834365845\n",
      "train epoch: 3/11, round: 359/532, loss: 0.4096020758152008\n",
      "train epoch: 3/11, round: 360/532, loss: 0.49639686942100525\n",
      "train epoch: 3/11, round: 361/532, loss: 0.4354875683784485\n",
      "train epoch: 3/11, round: 362/532, loss: 0.3103475868701935\n",
      "train epoch: 3/11, round: 363/532, loss: 0.38938719034194946\n",
      "train epoch: 3/11, round: 364/532, loss: 0.4482668340206146\n",
      "train epoch: 3/11, round: 365/532, loss: 0.40801185369491577\n",
      "train epoch: 3/11, round: 366/532, loss: 0.4337213933467865\n",
      "train epoch: 3/11, round: 367/532, loss: 0.4818391799926758\n",
      "train epoch: 3/11, round: 368/532, loss: 0.3572489619255066\n",
      "train epoch: 3/11, round: 369/532, loss: 0.43947285413742065\n",
      "train epoch: 3/11, round: 370/532, loss: 0.4024812579154968\n",
      "train epoch: 3/11, round: 371/532, loss: 0.39772266149520874\n",
      "train epoch: 3/11, round: 372/532, loss: 0.40354710817337036\n",
      "train epoch: 3/11, round: 373/532, loss: 0.4332173466682434\n",
      "train epoch: 3/11, round: 374/532, loss: 0.3308115303516388\n",
      "train epoch: 3/11, round: 375/532, loss: 0.3961104154586792\n",
      "train epoch: 3/11, round: 376/532, loss: 0.4392443597316742\n",
      "train epoch: 3/11, round: 377/532, loss: 0.4094100594520569\n",
      "train epoch: 3/11, round: 378/532, loss: 0.3356149196624756\n",
      "train epoch: 3/11, round: 379/532, loss: 0.3716588616371155\n",
      "train epoch: 3/11, round: 380/532, loss: 0.4942247271537781\n",
      "train epoch: 3/11, round: 381/532, loss: 0.4131739139556885\n",
      "train epoch: 3/11, round: 382/532, loss: 0.4180695414543152\n",
      "train epoch: 3/11, round: 383/532, loss: 0.42361459136009216\n",
      "train epoch: 3/11, round: 384/532, loss: 0.40634655952453613\n",
      "train epoch: 3/11, round: 385/532, loss: 0.3966487646102905\n",
      "train epoch: 3/11, round: 386/532, loss: 0.4103471338748932\n",
      "train epoch: 3/11, round: 387/532, loss: 0.3520589768886566\n",
      "train epoch: 3/11, round: 388/532, loss: 0.3665633797645569\n",
      "train epoch: 3/11, round: 389/532, loss: 0.38714921474456787\n",
      "train epoch: 3/11, round: 390/532, loss: 0.47568875551223755\n",
      "train epoch: 3/11, round: 391/532, loss: 0.38581383228302\n",
      "train epoch: 3/11, round: 392/532, loss: 0.49931755661964417\n",
      "train epoch: 3/11, round: 393/532, loss: 0.384231299161911\n",
      "train epoch: 3/11, round: 394/532, loss: 0.31979385018348694\n",
      "train epoch: 3/11, round: 395/532, loss: 0.4554620385169983\n",
      "train epoch: 3/11, round: 396/532, loss: 0.3805761933326721\n",
      "train epoch: 3/11, round: 397/532, loss: 0.38385745882987976\n",
      "train epoch: 3/11, round: 398/532, loss: 0.38800257444381714\n",
      "train epoch: 3/11, round: 399/532, loss: 0.42860084772109985\n",
      "train epoch: 3/11, round: 400/532, loss: 0.39117658138275146\n",
      "train epoch: 3/11, round: 401/532, loss: 0.3669680655002594\n",
      "train epoch: 3/11, round: 402/532, loss: 0.38213762640953064\n",
      "train epoch: 3/11, round: 403/532, loss: 0.4013134837150574\n",
      "train epoch: 3/11, round: 404/532, loss: 0.47918692231178284\n",
      "train epoch: 3/11, round: 405/532, loss: 0.350612610578537\n",
      "train epoch: 3/11, round: 406/532, loss: 0.44671836495399475\n",
      "train epoch: 3/11, round: 407/532, loss: 0.4411846697330475\n",
      "train epoch: 3/11, round: 408/532, loss: 0.3853762149810791\n",
      "train epoch: 3/11, round: 409/532, loss: 0.472238689661026\n",
      "train epoch: 3/11, round: 410/532, loss: 0.48916298151016235\n",
      "train epoch: 3/11, round: 411/532, loss: 0.41789722442626953\n",
      "train epoch: 3/11, round: 412/532, loss: 0.4235171377658844\n",
      "train epoch: 3/11, round: 413/532, loss: 0.3740723431110382\n",
      "train epoch: 3/11, round: 414/532, loss: 0.37878769636154175\n",
      "train epoch: 3/11, round: 415/532, loss: 0.382168710231781\n",
      "train epoch: 3/11, round: 416/532, loss: 0.4342036247253418\n",
      "train epoch: 3/11, round: 417/532, loss: 0.5109338760375977\n",
      "train epoch: 3/11, round: 418/532, loss: 0.3550335466861725\n",
      "train epoch: 3/11, round: 419/532, loss: 0.357108473777771\n",
      "train epoch: 3/11, round: 420/532, loss: 0.3599725365638733\n",
      "train epoch: 3/11, round: 421/532, loss: 0.43077629804611206\n",
      "train epoch: 3/11, round: 422/532, loss: 0.3844006657600403\n",
      "train epoch: 3/11, round: 423/532, loss: 0.35030075907707214\n",
      "train epoch: 3/11, round: 424/532, loss: 0.3699207603931427\n",
      "train epoch: 3/11, round: 425/532, loss: 0.368565171957016\n",
      "train epoch: 3/11, round: 426/532, loss: 0.44723090529441833\n",
      "train epoch: 3/11, round: 427/532, loss: 0.36323946714401245\n",
      "train epoch: 3/11, round: 428/532, loss: 0.42953625321388245\n",
      "train epoch: 3/11, round: 429/532, loss: 0.43656325340270996\n",
      "train epoch: 3/11, round: 430/532, loss: 0.39765697717666626\n",
      "train epoch: 3/11, round: 431/532, loss: 0.4823424816131592\n",
      "train epoch: 3/11, round: 432/532, loss: 0.3492703139781952\n",
      "train epoch: 3/11, round: 433/532, loss: 0.35982128977775574\n",
      "train epoch: 3/11, round: 434/532, loss: 0.42468443512916565\n",
      "train epoch: 3/11, round: 435/532, loss: 0.4164097309112549\n",
      "train epoch: 3/11, round: 436/532, loss: 0.39544376730918884\n",
      "train epoch: 3/11, round: 437/532, loss: 0.34314000606536865\n",
      "train epoch: 3/11, round: 438/532, loss: 0.402689129114151\n",
      "train epoch: 3/11, round: 439/532, loss: 0.46086329221725464\n",
      "train epoch: 3/11, round: 440/532, loss: 0.4011666774749756\n",
      "train epoch: 3/11, round: 441/532, loss: 0.344865620136261\n",
      "train epoch: 3/11, round: 442/532, loss: 0.4388650059700012\n",
      "train epoch: 3/11, round: 443/532, loss: 0.3801814913749695\n",
      "train epoch: 3/11, round: 444/532, loss: 0.46562105417251587\n",
      "train epoch: 3/11, round: 445/532, loss: 0.45988208055496216\n",
      "train epoch: 3/11, round: 446/532, loss: 0.35778576135635376\n",
      "train epoch: 3/11, round: 447/532, loss: 0.443983256816864\n",
      "train epoch: 3/11, round: 448/532, loss: 0.3789359927177429\n",
      "train epoch: 3/11, round: 449/532, loss: 0.44930726289749146\n",
      "train epoch: 3/11, round: 450/532, loss: 0.43781977891921997\n",
      "train epoch: 3/11, round: 451/532, loss: 0.4383360743522644\n",
      "train epoch: 3/11, round: 452/532, loss: 0.3789409399032593\n",
      "train epoch: 3/11, round: 453/532, loss: 0.32165709137916565\n",
      "train epoch: 3/11, round: 454/532, loss: 0.3948825001716614\n",
      "train epoch: 3/11, round: 455/532, loss: 0.33684223890304565\n",
      "train epoch: 3/11, round: 456/532, loss: 0.39357560873031616\n",
      "train epoch: 3/11, round: 457/532, loss: 0.3733874261379242\n",
      "train epoch: 3/11, round: 458/532, loss: 0.3096219003200531\n",
      "train epoch: 3/11, round: 459/532, loss: 0.42837637662887573\n",
      "train epoch: 3/11, round: 460/532, loss: 0.3728262782096863\n",
      "train epoch: 3/11, round: 461/532, loss: 0.397399365901947\n",
      "train epoch: 3/11, round: 462/532, loss: 0.4324970245361328\n",
      "train epoch: 3/11, round: 463/532, loss: 0.4159226417541504\n",
      "train epoch: 3/11, round: 464/532, loss: 0.3927450180053711\n",
      "train epoch: 3/11, round: 465/532, loss: 0.47011297941207886\n",
      "train epoch: 3/11, round: 466/532, loss: 0.4620911180973053\n",
      "train epoch: 3/11, round: 467/532, loss: 0.3990139365196228\n",
      "train epoch: 3/11, round: 468/532, loss: 0.3760082721710205\n",
      "train epoch: 3/11, round: 469/532, loss: 0.3841991424560547\n",
      "train epoch: 3/11, round: 470/532, loss: 0.364594042301178\n",
      "train epoch: 3/11, round: 471/532, loss: 0.33325695991516113\n",
      "train epoch: 3/11, round: 472/532, loss: 0.4244730472564697\n",
      "train epoch: 3/11, round: 473/532, loss: 0.3665466904640198\n",
      "train epoch: 3/11, round: 474/532, loss: 0.36534610390663147\n",
      "train epoch: 3/11, round: 475/532, loss: 0.4061654210090637\n",
      "train epoch: 3/11, round: 476/532, loss: 0.43327468633651733\n",
      "train epoch: 3/11, round: 477/532, loss: 0.37988218665122986\n",
      "train epoch: 3/11, round: 478/532, loss: 0.30311304330825806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3/11, round: 479/532, loss: 0.5001393556594849\n",
      "train epoch: 3/11, round: 480/532, loss: 0.26265236735343933\n",
      "train epoch: 3/11, round: 481/532, loss: 0.30857372283935547\n",
      "train epoch: 3/11, round: 482/532, loss: 0.34346476197242737\n",
      "train epoch: 3/11, round: 483/532, loss: 0.3355109989643097\n",
      "train epoch: 3/11, round: 484/532, loss: 0.4077015519142151\n",
      "train epoch: 3/11, round: 485/532, loss: 0.38137057423591614\n",
      "train epoch: 3/11, round: 486/532, loss: 0.42526206374168396\n",
      "train epoch: 3/11, round: 487/532, loss: 0.5103408098220825\n",
      "train epoch: 3/11, round: 488/532, loss: 0.5609825253486633\n",
      "train epoch: 3/11, round: 489/532, loss: 0.37347573041915894\n",
      "train epoch: 3/11, round: 490/532, loss: 0.4016973078250885\n",
      "train epoch: 3/11, round: 491/532, loss: 0.41043052077293396\n",
      "train epoch: 3/11, round: 492/532, loss: 0.44317126274108887\n",
      "train epoch: 3/11, round: 493/532, loss: 0.4227820336818695\n",
      "train epoch: 3/11, round: 494/532, loss: 0.36774736642837524\n",
      "train epoch: 3/11, round: 495/532, loss: 0.3866109848022461\n",
      "train epoch: 3/11, round: 496/532, loss: 0.40359193086624146\n",
      "train epoch: 3/11, round: 497/532, loss: 0.4925510883331299\n",
      "train epoch: 3/11, round: 498/532, loss: 0.5342995524406433\n",
      "train epoch: 3/11, round: 499/532, loss: 0.39690104126930237\n",
      "train epoch: 3/11, round: 500/532, loss: 0.39570552110671997\n",
      "train epoch: 3/11, round: 501/532, loss: 0.36879628896713257\n",
      "train epoch: 3/11, round: 502/532, loss: 0.38149768114089966\n",
      "train epoch: 3/11, round: 503/532, loss: 0.4009493887424469\n",
      "train epoch: 3/11, round: 504/532, loss: 0.2673567235469818\n",
      "train epoch: 3/11, round: 505/532, loss: 0.4246462881565094\n",
      "train epoch: 3/11, round: 506/532, loss: 0.39228662848472595\n",
      "train epoch: 3/11, round: 507/532, loss: 0.3227109909057617\n",
      "train epoch: 3/11, round: 508/532, loss: 0.3716971278190613\n",
      "train epoch: 3/11, round: 509/532, loss: 0.366637647151947\n",
      "train epoch: 3/11, round: 510/532, loss: 0.3313462734222412\n",
      "train epoch: 3/11, round: 511/532, loss: 0.41391485929489136\n",
      "train epoch: 3/11, round: 512/532, loss: 0.4841206967830658\n",
      "train epoch: 3/11, round: 513/532, loss: 0.40272611379623413\n",
      "train epoch: 3/11, round: 514/532, loss: 0.49838703870773315\n",
      "train epoch: 3/11, round: 515/532, loss: 0.39794254302978516\n",
      "train epoch: 3/11, round: 516/532, loss: 0.417985737323761\n",
      "train epoch: 3/11, round: 517/532, loss: 0.44502314925193787\n",
      "train epoch: 3/11, round: 518/532, loss: 0.4311285614967346\n",
      "train epoch: 3/11, round: 519/532, loss: 0.40857934951782227\n",
      "train epoch: 3/11, round: 520/532, loss: 0.40459227561950684\n",
      "train epoch: 3/11, round: 521/532, loss: 0.4475231170654297\n",
      "train epoch: 3/11, round: 522/532, loss: 0.3857775330543518\n",
      "train epoch: 3/11, round: 523/532, loss: 0.42972689867019653\n",
      "train epoch: 3/11, round: 524/532, loss: 0.41469016671180725\n",
      "train epoch: 3/11, round: 525/532, loss: 0.37557798624038696\n",
      "train epoch: 3/11, round: 526/532, loss: 0.3634028434753418\n",
      "train epoch: 3/11, round: 527/532, loss: 0.4121526777744293\n",
      "train epoch: 3/11, round: 528/532, loss: 0.45219746232032776\n",
      "train epoch: 3/11, round: 529/532, loss: 0.4240185618400574\n",
      "train epoch: 3/11, round: 530/532, loss: 0.3608516752719879\n",
      "train epoch: 3/11, round: 531/532, loss: 0.3580704927444458\n",
      "train epoch: 3/11, round: 532/532, loss: 0.37041038274765015\n",
      "train epoch: 3/11, KS: 0.1867148349777205, ROC: 0.6292709337906224\n",
      "test epoch: 3/11, round: 1/501, loss: 0.3687306046485901\n",
      "test epoch: 3/11, round: 2/501, loss: 0.2972082793712616\n",
      "test epoch: 3/11, round: 3/501, loss: 0.22976048290729523\n",
      "test epoch: 3/11, round: 4/501, loss: 0.40691107511520386\n",
      "test epoch: 3/11, round: 5/501, loss: 0.3701741397380829\n",
      "test epoch: 3/11, round: 6/501, loss: 0.3366446793079376\n",
      "test epoch: 3/11, round: 7/501, loss: 0.4291895925998688\n",
      "test epoch: 3/11, round: 8/501, loss: 0.4385721981525421\n",
      "test epoch: 3/11, round: 9/501, loss: 0.5147190690040588\n",
      "test epoch: 3/11, round: 10/501, loss: 0.6063178777694702\n",
      "test epoch: 3/11, round: 11/501, loss: 0.202710822224617\n",
      "test epoch: 3/11, round: 12/501, loss: 0.3267368972301483\n",
      "test epoch: 3/11, round: 13/501, loss: 0.38056138157844543\n",
      "test epoch: 3/11, round: 14/501, loss: 0.3249366879463196\n",
      "test epoch: 3/11, round: 15/501, loss: 0.4621313810348511\n",
      "test epoch: 3/11, round: 16/501, loss: 0.47207164764404297\n",
      "test epoch: 3/11, round: 17/501, loss: 0.386985719203949\n",
      "test epoch: 3/11, round: 18/501, loss: 0.5057042241096497\n",
      "test epoch: 3/11, round: 19/501, loss: 0.5375293493270874\n",
      "test epoch: 3/11, round: 20/501, loss: 0.7643871903419495\n",
      "test epoch: 3/11, round: 21/501, loss: 0.3866448998451233\n",
      "test epoch: 3/11, round: 22/501, loss: 0.6248942613601685\n",
      "test epoch: 3/11, round: 23/501, loss: 0.5353599786758423\n",
      "test epoch: 3/11, round: 24/501, loss: 0.4254533648490906\n",
      "test epoch: 3/11, round: 25/501, loss: 0.6116011738777161\n",
      "test epoch: 3/11, round: 26/501, loss: 0.6093304753303528\n",
      "test epoch: 3/11, round: 27/501, loss: 0.2235441952943802\n",
      "test epoch: 3/11, round: 28/501, loss: 0.49237295985221863\n",
      "test epoch: 3/11, round: 29/501, loss: 0.3084494173526764\n",
      "test epoch: 3/11, round: 30/501, loss: 0.5311163067817688\n",
      "test epoch: 3/11, round: 31/501, loss: 0.4825432002544403\n",
      "test epoch: 3/11, round: 32/501, loss: 0.49987003207206726\n",
      "test epoch: 3/11, round: 33/501, loss: 0.5797475576400757\n",
      "test epoch: 3/11, round: 34/501, loss: 0.48235446214675903\n",
      "test epoch: 3/11, round: 35/501, loss: 0.17845599353313446\n",
      "test epoch: 3/11, round: 36/501, loss: 0.45787811279296875\n",
      "test epoch: 3/11, round: 37/501, loss: 0.43904152512550354\n",
      "test epoch: 3/11, round: 38/501, loss: 0.43496838212013245\n",
      "test epoch: 3/11, round: 39/501, loss: 0.6775779724121094\n",
      "test epoch: 3/11, round: 40/501, loss: 0.619292676448822\n",
      "test epoch: 3/11, round: 41/501, loss: 0.3918808102607727\n",
      "test epoch: 3/11, round: 42/501, loss: 0.4077097177505493\n",
      "test epoch: 3/11, round: 43/501, loss: 0.42850008606910706\n",
      "test epoch: 3/11, round: 44/501, loss: 0.5467243194580078\n",
      "test epoch: 3/11, round: 45/501, loss: 0.6424404978752136\n",
      "test epoch: 3/11, round: 46/501, loss: 0.4967847764492035\n",
      "test epoch: 3/11, round: 47/501, loss: 0.3023838400840759\n",
      "test epoch: 3/11, round: 48/501, loss: 0.4870051443576813\n",
      "test epoch: 3/11, round: 49/501, loss: 0.3301719129085541\n",
      "test epoch: 3/11, round: 50/501, loss: 0.20550760626792908\n",
      "test epoch: 3/11, round: 51/501, loss: 0.4663938581943512\n",
      "test epoch: 3/11, round: 52/501, loss: 0.417294979095459\n",
      "test epoch: 3/11, round: 53/501, loss: 0.5169022679328918\n",
      "test epoch: 3/11, round: 54/501, loss: 0.5279096961021423\n",
      "test epoch: 3/11, round: 55/501, loss: 0.3405938446521759\n",
      "test epoch: 3/11, round: 56/501, loss: 0.42509889602661133\n",
      "test epoch: 3/11, round: 57/501, loss: 0.39946672320365906\n",
      "test epoch: 3/11, round: 58/501, loss: 0.46742668747901917\n",
      "test epoch: 3/11, round: 59/501, loss: 0.2934356927871704\n",
      "test epoch: 3/11, round: 60/501, loss: 0.4311642646789551\n",
      "test epoch: 3/11, round: 61/501, loss: 0.37478700280189514\n",
      "test epoch: 3/11, round: 62/501, loss: 0.6133939623832703\n",
      "test epoch: 3/11, round: 63/501, loss: 0.7225598692893982\n",
      "test epoch: 3/11, round: 64/501, loss: 0.292611688375473\n",
      "test epoch: 3/11, round: 65/501, loss: 0.6221362948417664\n",
      "test epoch: 3/11, round: 66/501, loss: 0.42842403054237366\n",
      "test epoch: 3/11, round: 67/501, loss: 0.513325572013855\n",
      "test epoch: 3/11, round: 68/501, loss: 0.6803098917007446\n",
      "test epoch: 3/11, round: 69/501, loss: 0.45617735385894775\n",
      "test epoch: 3/11, round: 70/501, loss: 0.4697445034980774\n",
      "test epoch: 3/11, round: 71/501, loss: 0.5753033757209778\n",
      "test epoch: 3/11, round: 72/501, loss: 0.5718898773193359\n",
      "test epoch: 3/11, round: 73/501, loss: 0.49360236525535583\n",
      "test epoch: 3/11, round: 74/501, loss: 0.49216264486312866\n",
      "test epoch: 3/11, round: 75/501, loss: 0.5419241786003113\n",
      "test epoch: 3/11, round: 76/501, loss: 0.6819407343864441\n",
      "test epoch: 3/11, round: 77/501, loss: 0.3537687361240387\n",
      "test epoch: 3/11, round: 78/501, loss: 0.576890230178833\n",
      "test epoch: 3/11, round: 79/501, loss: 0.39973947405815125\n",
      "test epoch: 3/11, round: 80/501, loss: 0.5994390845298767\n",
      "test epoch: 3/11, round: 81/501, loss: 0.7952918410301208\n",
      "test epoch: 3/11, round: 82/501, loss: 0.6012459993362427\n",
      "test epoch: 3/11, round: 83/501, loss: 0.4011423885822296\n",
      "test epoch: 3/11, round: 84/501, loss: 0.6207183599472046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 3/11, round: 85/501, loss: 0.5807120203971863\n",
      "test epoch: 3/11, round: 86/501, loss: 0.347744882106781\n",
      "test epoch: 3/11, round: 87/501, loss: 0.45687371492385864\n",
      "test epoch: 3/11, round: 88/501, loss: 0.37988701462745667\n",
      "test epoch: 3/11, round: 89/501, loss: 0.32223251461982727\n",
      "test epoch: 3/11, round: 90/501, loss: 0.6963045597076416\n",
      "test epoch: 3/11, round: 91/501, loss: 0.3429814279079437\n",
      "test epoch: 3/11, round: 92/501, loss: 0.5317339301109314\n",
      "test epoch: 3/11, round: 93/501, loss: 0.45277291536331177\n",
      "test epoch: 3/11, round: 94/501, loss: 0.5778396129608154\n",
      "test epoch: 3/11, round: 95/501, loss: 0.4012688398361206\n",
      "test epoch: 3/11, round: 96/501, loss: 0.3758726119995117\n",
      "test epoch: 3/11, round: 97/501, loss: 0.5914574265480042\n",
      "test epoch: 3/11, round: 98/501, loss: 0.42240631580352783\n",
      "test epoch: 3/11, round: 99/501, loss: 0.5984362959861755\n",
      "test epoch: 3/11, round: 100/501, loss: 0.4995552599430084\n",
      "test epoch: 3/11, round: 101/501, loss: 0.5279890298843384\n",
      "test epoch: 3/11, round: 102/501, loss: 0.3214823305606842\n",
      "test epoch: 3/11, round: 103/501, loss: 0.4008577764034271\n",
      "test epoch: 3/11, round: 104/501, loss: 0.6620199680328369\n",
      "test epoch: 3/11, round: 105/501, loss: 0.4097123146057129\n",
      "test epoch: 3/11, round: 106/501, loss: 0.5747160315513611\n",
      "test epoch: 3/11, round: 107/501, loss: 0.34795716404914856\n",
      "test epoch: 3/11, round: 108/501, loss: 0.5266701579093933\n",
      "test epoch: 3/11, round: 109/501, loss: 0.37207064032554626\n",
      "test epoch: 3/11, round: 110/501, loss: 0.7306433320045471\n",
      "test epoch: 3/11, round: 111/501, loss: 0.24095337092876434\n",
      "test epoch: 3/11, round: 112/501, loss: 0.2341724932193756\n",
      "test epoch: 3/11, round: 113/501, loss: 0.3813956081867218\n",
      "test epoch: 3/11, round: 114/501, loss: 0.3815103769302368\n",
      "test epoch: 3/11, round: 115/501, loss: 0.29753175377845764\n",
      "test epoch: 3/11, round: 116/501, loss: 0.333333283662796\n",
      "test epoch: 3/11, round: 117/501, loss: 0.33900755643844604\n",
      "test epoch: 3/11, round: 118/501, loss: 0.3324333727359772\n",
      "test epoch: 3/11, round: 119/501, loss: 0.32543277740478516\n",
      "test epoch: 3/11, round: 120/501, loss: 0.3832013010978699\n",
      "test epoch: 3/11, round: 121/501, loss: 0.39725610613822937\n",
      "test epoch: 3/11, round: 122/501, loss: 0.37402769923210144\n",
      "test epoch: 3/11, round: 123/501, loss: 0.39546966552734375\n",
      "test epoch: 3/11, round: 124/501, loss: 0.5629896521568298\n",
      "test epoch: 3/11, round: 125/501, loss: 0.4361509084701538\n",
      "test epoch: 3/11, round: 126/501, loss: 0.3591936230659485\n",
      "test epoch: 3/11, round: 127/501, loss: 0.40669161081314087\n",
      "test epoch: 3/11, round: 128/501, loss: 0.2260860800743103\n",
      "test epoch: 3/11, round: 129/501, loss: 0.4685761630535126\n",
      "test epoch: 3/11, round: 130/501, loss: 0.7735647559165955\n",
      "test epoch: 3/11, round: 131/501, loss: 0.5833167433738708\n",
      "test epoch: 3/11, round: 132/501, loss: 0.45211994647979736\n",
      "test epoch: 3/11, round: 133/501, loss: 0.7345725297927856\n",
      "test epoch: 3/11, round: 134/501, loss: 0.49666061997413635\n",
      "test epoch: 3/11, round: 135/501, loss: 0.30023956298828125\n",
      "test epoch: 3/11, round: 136/501, loss: 0.45472070574760437\n",
      "test epoch: 3/11, round: 137/501, loss: 0.4134325087070465\n",
      "test epoch: 3/11, round: 138/501, loss: 0.3904157280921936\n",
      "test epoch: 3/11, round: 139/501, loss: 0.5389821529388428\n",
      "test epoch: 3/11, round: 140/501, loss: 0.461181640625\n",
      "test epoch: 3/11, round: 141/501, loss: 0.31363093852996826\n",
      "test epoch: 3/11, round: 142/501, loss: 0.5880553126335144\n",
      "test epoch: 3/11, round: 143/501, loss: 0.4020187258720398\n",
      "test epoch: 3/11, round: 144/501, loss: 0.4624052941799164\n",
      "test epoch: 3/11, round: 145/501, loss: 0.34420523047447205\n",
      "test epoch: 3/11, round: 146/501, loss: 0.581262469291687\n",
      "test epoch: 3/11, round: 147/501, loss: 0.5014588236808777\n",
      "test epoch: 3/11, round: 148/501, loss: 0.5138127207756042\n",
      "test epoch: 3/11, round: 149/501, loss: 0.38219889998435974\n",
      "test epoch: 3/11, round: 150/501, loss: 0.5542847514152527\n",
      "test epoch: 3/11, round: 151/501, loss: 0.40854206681251526\n",
      "test epoch: 3/11, round: 152/501, loss: 0.5115604400634766\n",
      "test epoch: 3/11, round: 153/501, loss: 0.5450928807258606\n",
      "test epoch: 3/11, round: 154/501, loss: 0.5631176233291626\n",
      "test epoch: 3/11, round: 155/501, loss: 0.38813355565071106\n",
      "test epoch: 3/11, round: 156/501, loss: 0.33117368817329407\n",
      "test epoch: 3/11, round: 157/501, loss: 0.36478814482688904\n",
      "test epoch: 3/11, round: 158/501, loss: 0.4600638747215271\n",
      "test epoch: 3/11, round: 159/501, loss: 0.3862173855304718\n",
      "test epoch: 3/11, round: 160/501, loss: 0.38455429673194885\n",
      "test epoch: 3/11, round: 161/501, loss: 0.39415493607521057\n",
      "test epoch: 3/11, round: 162/501, loss: 0.4540587067604065\n",
      "test epoch: 3/11, round: 163/501, loss: 0.42912575602531433\n",
      "test epoch: 3/11, round: 164/501, loss: 0.3670123517513275\n",
      "test epoch: 3/11, round: 165/501, loss: 0.5063478946685791\n",
      "test epoch: 3/11, round: 166/501, loss: 0.32926952838897705\n",
      "test epoch: 3/11, round: 167/501, loss: 0.2626756727695465\n",
      "test epoch: 3/11, round: 168/501, loss: 0.2157498002052307\n",
      "test epoch: 3/11, round: 169/501, loss: 0.3724220395088196\n",
      "test epoch: 3/11, round: 170/501, loss: 0.38993072509765625\n",
      "test epoch: 3/11, round: 171/501, loss: 0.4962259531021118\n",
      "test epoch: 3/11, round: 172/501, loss: 0.4743157625198364\n",
      "test epoch: 3/11, round: 173/501, loss: 0.32877224683761597\n",
      "test epoch: 3/11, round: 174/501, loss: 0.5444671511650085\n",
      "test epoch: 3/11, round: 175/501, loss: 0.3016277551651001\n",
      "test epoch: 3/11, round: 176/501, loss: 0.5194503664970398\n",
      "test epoch: 3/11, round: 177/501, loss: 0.3227141797542572\n",
      "test epoch: 3/11, round: 178/501, loss: 0.26008012890815735\n",
      "test epoch: 3/11, round: 179/501, loss: 0.2373804897069931\n",
      "test epoch: 3/11, round: 180/501, loss: 0.3455973267555237\n",
      "test epoch: 3/11, round: 181/501, loss: 0.5669298768043518\n",
      "test epoch: 3/11, round: 182/501, loss: 0.5270090699195862\n",
      "test epoch: 3/11, round: 183/501, loss: 0.4177909791469574\n",
      "test epoch: 3/11, round: 184/501, loss: 0.5322464108467102\n",
      "test epoch: 3/11, round: 185/501, loss: 0.46983522176742554\n",
      "test epoch: 3/11, round: 186/501, loss: 0.6030991673469543\n",
      "test epoch: 3/11, round: 187/501, loss: 0.5631520748138428\n",
      "test epoch: 3/11, round: 188/501, loss: 0.4935663938522339\n",
      "test epoch: 3/11, round: 189/501, loss: 0.6470001339912415\n",
      "test epoch: 3/11, round: 190/501, loss: 0.47029054164886475\n",
      "test epoch: 3/11, round: 191/501, loss: 0.34415900707244873\n",
      "test epoch: 3/11, round: 192/501, loss: 0.5514545440673828\n",
      "test epoch: 3/11, round: 193/501, loss: 0.5268568992614746\n",
      "test epoch: 3/11, round: 194/501, loss: 0.4823833405971527\n",
      "test epoch: 3/11, round: 195/501, loss: 0.4800054132938385\n",
      "test epoch: 3/11, round: 196/501, loss: 0.31780439615249634\n",
      "test epoch: 3/11, round: 197/501, loss: 0.3987937271595001\n",
      "test epoch: 3/11, round: 198/501, loss: 0.46171337366104126\n",
      "test epoch: 3/11, round: 199/501, loss: 0.47275814414024353\n",
      "test epoch: 3/11, round: 200/501, loss: 0.6473382115364075\n",
      "test epoch: 3/11, round: 201/501, loss: 0.3277713358402252\n",
      "test epoch: 3/11, round: 202/501, loss: 0.3183143734931946\n",
      "test epoch: 3/11, round: 203/501, loss: 0.39901912212371826\n",
      "test epoch: 3/11, round: 204/501, loss: 0.5573569536209106\n",
      "test epoch: 3/11, round: 205/501, loss: 0.4337761700153351\n",
      "test epoch: 3/11, round: 206/501, loss: 0.2539982795715332\n",
      "test epoch: 3/11, round: 207/501, loss: 0.39300790429115295\n",
      "test epoch: 3/11, round: 208/501, loss: 0.48253133893013\n",
      "test epoch: 3/11, round: 209/501, loss: 0.32243672013282776\n",
      "test epoch: 3/11, round: 210/501, loss: 0.4668220579624176\n",
      "test epoch: 3/11, round: 211/501, loss: 0.2801991105079651\n",
      "test epoch: 3/11, round: 212/501, loss: 0.3158426582813263\n",
      "test epoch: 3/11, round: 213/501, loss: 0.2981349229812622\n",
      "test epoch: 3/11, round: 214/501, loss: 0.2012486755847931\n",
      "test epoch: 3/11, round: 215/501, loss: 0.18721017241477966\n",
      "test epoch: 3/11, round: 216/501, loss: 0.19433380663394928\n",
      "test epoch: 3/11, round: 217/501, loss: 0.1681266576051712\n",
      "test epoch: 3/11, round: 218/501, loss: 0.17952117323875427\n",
      "test epoch: 3/11, round: 219/501, loss: 0.23554515838623047\n",
      "test epoch: 3/11, round: 220/501, loss: 0.4259980618953705\n",
      "test epoch: 3/11, round: 221/501, loss: 0.3452400863170624\n",
      "test epoch: 3/11, round: 222/501, loss: 0.16086047887802124\n",
      "test epoch: 3/11, round: 223/501, loss: 0.18160857260227203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 3/11, round: 224/501, loss: 0.19930510222911835\n",
      "test epoch: 3/11, round: 225/501, loss: 0.17804470658302307\n",
      "test epoch: 3/11, round: 226/501, loss: 0.1754685789346695\n",
      "test epoch: 3/11, round: 227/501, loss: 0.21753039956092834\n",
      "test epoch: 3/11, round: 228/501, loss: 0.2435351461172104\n",
      "test epoch: 3/11, round: 229/501, loss: 0.41008472442626953\n",
      "test epoch: 3/11, round: 230/501, loss: 0.29341235756874084\n",
      "test epoch: 3/11, round: 231/501, loss: 0.33576133847236633\n",
      "test epoch: 3/11, round: 232/501, loss: 0.4254373610019684\n",
      "test epoch: 3/11, round: 233/501, loss: 0.43900078535079956\n",
      "test epoch: 3/11, round: 234/501, loss: 0.4584459960460663\n",
      "test epoch: 3/11, round: 235/501, loss: 0.3138592541217804\n",
      "test epoch: 3/11, round: 236/501, loss: 0.3360801041126251\n",
      "test epoch: 3/11, round: 237/501, loss: 0.3341974914073944\n",
      "test epoch: 3/11, round: 238/501, loss: 0.32918626070022583\n",
      "test epoch: 3/11, round: 239/501, loss: 0.39762407541275024\n",
      "test epoch: 3/11, round: 240/501, loss: 0.23205333948135376\n",
      "test epoch: 3/11, round: 241/501, loss: 0.3850349187850952\n",
      "test epoch: 3/11, round: 242/501, loss: 0.2638188600540161\n",
      "test epoch: 3/11, round: 243/501, loss: 0.27410343289375305\n",
      "test epoch: 3/11, round: 244/501, loss: 0.275057852268219\n",
      "test epoch: 3/11, round: 245/501, loss: 0.3689616620540619\n",
      "test epoch: 3/11, round: 246/501, loss: 0.37975189089775085\n",
      "test epoch: 3/11, round: 247/501, loss: 0.4472872018814087\n",
      "test epoch: 3/11, round: 248/501, loss: 0.1931767463684082\n",
      "test epoch: 3/11, round: 249/501, loss: 0.34287023544311523\n",
      "test epoch: 3/11, round: 250/501, loss: 0.3193696439266205\n",
      "test epoch: 3/11, round: 251/501, loss: 0.3268831670284271\n",
      "test epoch: 3/11, round: 252/501, loss: 0.27616193890571594\n",
      "test epoch: 3/11, round: 253/501, loss: 0.3317825198173523\n",
      "test epoch: 3/11, round: 254/501, loss: 0.2972431778907776\n",
      "test epoch: 3/11, round: 255/501, loss: 0.3144756555557251\n",
      "test epoch: 3/11, round: 256/501, loss: 0.43994924426078796\n",
      "test epoch: 3/11, round: 257/501, loss: 0.3668712377548218\n",
      "test epoch: 3/11, round: 258/501, loss: 0.3922639787197113\n",
      "test epoch: 3/11, round: 259/501, loss: 0.23708447813987732\n",
      "test epoch: 3/11, round: 260/501, loss: 0.4768168032169342\n",
      "test epoch: 3/11, round: 261/501, loss: 0.5550900101661682\n",
      "test epoch: 3/11, round: 262/501, loss: 0.49267005920410156\n",
      "test epoch: 3/11, round: 263/501, loss: 0.43707558512687683\n",
      "test epoch: 3/11, round: 264/501, loss: 0.46152541041374207\n",
      "test epoch: 3/11, round: 265/501, loss: 0.638262152671814\n",
      "test epoch: 3/11, round: 266/501, loss: 0.3946285545825958\n",
      "test epoch: 3/11, round: 267/501, loss: 0.39974167943000793\n",
      "test epoch: 3/11, round: 268/501, loss: 0.27231520414352417\n",
      "test epoch: 3/11, round: 269/501, loss: 0.49211737513542175\n",
      "test epoch: 3/11, round: 270/501, loss: 0.25564584136009216\n",
      "test epoch: 3/11, round: 271/501, loss: 0.507715106010437\n",
      "test epoch: 3/11, round: 272/501, loss: 0.4065508544445038\n",
      "test epoch: 3/11, round: 273/501, loss: 0.3602200150489807\n",
      "test epoch: 3/11, round: 274/501, loss: 0.5152167677879333\n",
      "test epoch: 3/11, round: 275/501, loss: 0.3273707330226898\n",
      "test epoch: 3/11, round: 276/501, loss: 0.3802945017814636\n",
      "test epoch: 3/11, round: 277/501, loss: 0.35805264115333557\n",
      "test epoch: 3/11, round: 278/501, loss: 0.6379872560501099\n",
      "test epoch: 3/11, round: 279/501, loss: 0.3083533048629761\n",
      "test epoch: 3/11, round: 280/501, loss: 0.19060280919075012\n",
      "test epoch: 3/11, round: 281/501, loss: 0.16056302189826965\n",
      "test epoch: 3/11, round: 282/501, loss: 0.25300753116607666\n",
      "test epoch: 3/11, round: 283/501, loss: 0.23499734699726105\n",
      "test epoch: 3/11, round: 284/501, loss: 0.34791314601898193\n",
      "test epoch: 3/11, round: 285/501, loss: 0.49600785970687866\n",
      "test epoch: 3/11, round: 286/501, loss: 0.360321968793869\n",
      "test epoch: 3/11, round: 287/501, loss: 0.5555603504180908\n",
      "test epoch: 3/11, round: 288/501, loss: 0.2241998016834259\n",
      "test epoch: 3/11, round: 289/501, loss: 0.35926544666290283\n",
      "test epoch: 3/11, round: 290/501, loss: 0.3339557647705078\n",
      "test epoch: 3/11, round: 291/501, loss: 0.5514643788337708\n",
      "test epoch: 3/11, round: 292/501, loss: 0.5064043402671814\n",
      "test epoch: 3/11, round: 293/501, loss: 0.5494580864906311\n",
      "test epoch: 3/11, round: 294/501, loss: 0.21016547083854675\n",
      "test epoch: 3/11, round: 295/501, loss: 0.3353264629840851\n",
      "test epoch: 3/11, round: 296/501, loss: 0.438749223947525\n",
      "test epoch: 3/11, round: 297/501, loss: 0.3275039792060852\n",
      "test epoch: 3/11, round: 298/501, loss: 0.4066367745399475\n",
      "test epoch: 3/11, round: 299/501, loss: 0.393777459859848\n",
      "test epoch: 3/11, round: 300/501, loss: 0.5829845070838928\n",
      "test epoch: 3/11, round: 301/501, loss: 0.37575531005859375\n",
      "test epoch: 3/11, round: 302/501, loss: 0.21999362111091614\n",
      "test epoch: 3/11, round: 303/501, loss: 0.6234785914421082\n",
      "test epoch: 3/11, round: 304/501, loss: 0.6387441158294678\n",
      "test epoch: 3/11, round: 305/501, loss: 0.18238182365894318\n",
      "test epoch: 3/11, round: 306/501, loss: 0.24289493262767792\n",
      "test epoch: 3/11, round: 307/501, loss: 0.4376591444015503\n",
      "test epoch: 3/11, round: 308/501, loss: 0.2554693818092346\n",
      "test epoch: 3/11, round: 309/501, loss: 0.4484516680240631\n",
      "test epoch: 3/11, round: 310/501, loss: 0.3856840133666992\n",
      "test epoch: 3/11, round: 311/501, loss: 0.5867021083831787\n",
      "test epoch: 3/11, round: 312/501, loss: 0.36423519253730774\n",
      "test epoch: 3/11, round: 313/501, loss: 0.3205980360507965\n",
      "test epoch: 3/11, round: 314/501, loss: 0.32723620533943176\n",
      "test epoch: 3/11, round: 315/501, loss: 0.3151671588420868\n",
      "test epoch: 3/11, round: 316/501, loss: 0.3311816453933716\n",
      "test epoch: 3/11, round: 317/501, loss: 0.36291804909706116\n",
      "test epoch: 3/11, round: 318/501, loss: 0.3759446442127228\n",
      "test epoch: 3/11, round: 319/501, loss: 0.6246516704559326\n",
      "test epoch: 3/11, round: 320/501, loss: 0.379232257604599\n",
      "test epoch: 3/11, round: 321/501, loss: 0.31762924790382385\n",
      "test epoch: 3/11, round: 322/501, loss: 0.3893875181674957\n",
      "test epoch: 3/11, round: 323/501, loss: 0.44864124059677124\n",
      "test epoch: 3/11, round: 324/501, loss: 0.3319918215274811\n",
      "test epoch: 3/11, round: 325/501, loss: 0.39142200350761414\n",
      "test epoch: 3/11, round: 326/501, loss: 0.42671218514442444\n",
      "test epoch: 3/11, round: 327/501, loss: 0.6194039583206177\n",
      "test epoch: 3/11, round: 328/501, loss: 0.19713503122329712\n",
      "test epoch: 3/11, round: 329/501, loss: 0.44837820529937744\n",
      "test epoch: 3/11, round: 330/501, loss: 0.46860554814338684\n",
      "test epoch: 3/11, round: 331/501, loss: 0.4189053177833557\n",
      "test epoch: 3/11, round: 332/501, loss: 0.3567645251750946\n",
      "test epoch: 3/11, round: 333/501, loss: 0.4052361845970154\n",
      "test epoch: 3/11, round: 334/501, loss: 0.25858670473098755\n",
      "test epoch: 3/11, round: 335/501, loss: 0.37569254636764526\n",
      "test epoch: 3/11, round: 336/501, loss: 0.37606143951416016\n",
      "test epoch: 3/11, round: 337/501, loss: 0.6113145351409912\n",
      "test epoch: 3/11, round: 338/501, loss: 0.39501330256462097\n",
      "test epoch: 3/11, round: 339/501, loss: 0.9053806662559509\n",
      "test epoch: 3/11, round: 340/501, loss: 0.461677223443985\n",
      "test epoch: 3/11, round: 341/501, loss: 0.45469704270362854\n",
      "test epoch: 3/11, round: 342/501, loss: 0.37575143575668335\n",
      "test epoch: 3/11, round: 343/501, loss: 0.34146741032600403\n",
      "test epoch: 3/11, round: 344/501, loss: 0.25047266483306885\n",
      "test epoch: 3/11, round: 345/501, loss: 0.21487314999103546\n",
      "test epoch: 3/11, round: 346/501, loss: 0.31827929615974426\n",
      "test epoch: 3/11, round: 347/501, loss: 0.3303337097167969\n",
      "test epoch: 3/11, round: 348/501, loss: 0.41018903255462646\n",
      "test epoch: 3/11, round: 349/501, loss: 0.32347169518470764\n",
      "test epoch: 3/11, round: 350/501, loss: 0.456830233335495\n",
      "test epoch: 3/11, round: 351/501, loss: 0.3984314501285553\n",
      "test epoch: 3/11, round: 352/501, loss: 0.4610818922519684\n",
      "test epoch: 3/11, round: 353/501, loss: 0.38727569580078125\n",
      "test epoch: 3/11, round: 354/501, loss: 0.5441173911094666\n",
      "test epoch: 3/11, round: 355/501, loss: 0.3786318600177765\n",
      "test epoch: 3/11, round: 356/501, loss: 0.5786982178688049\n",
      "test epoch: 3/11, round: 357/501, loss: 0.4512294828891754\n",
      "test epoch: 3/11, round: 358/501, loss: 0.41045376658439636\n",
      "test epoch: 3/11, round: 359/501, loss: 0.41148319840431213\n",
      "test epoch: 3/11, round: 360/501, loss: 0.6091204285621643\n",
      "test epoch: 3/11, round: 361/501, loss: 0.5740342736244202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 3/11, round: 362/501, loss: 0.4066477417945862\n",
      "test epoch: 3/11, round: 363/501, loss: 0.5479529500007629\n",
      "test epoch: 3/11, round: 364/501, loss: 0.5032430291175842\n",
      "test epoch: 3/11, round: 365/501, loss: 0.4191252887248993\n",
      "test epoch: 3/11, round: 366/501, loss: 0.6076929569244385\n",
      "test epoch: 3/11, round: 367/501, loss: 0.7016517519950867\n",
      "test epoch: 3/11, round: 368/501, loss: 0.2812274396419525\n",
      "test epoch: 3/11, round: 369/501, loss: 0.35039299726486206\n",
      "test epoch: 3/11, round: 370/501, loss: 0.37082639336586\n",
      "test epoch: 3/11, round: 371/501, loss: 0.4008919894695282\n",
      "test epoch: 3/11, round: 372/501, loss: 0.352402001619339\n",
      "test epoch: 3/11, round: 373/501, loss: 0.4352388381958008\n",
      "test epoch: 3/11, round: 374/501, loss: 0.33873140811920166\n",
      "test epoch: 3/11, round: 375/501, loss: 0.4361112415790558\n",
      "test epoch: 3/11, round: 376/501, loss: 0.5535980463027954\n",
      "test epoch: 3/11, round: 377/501, loss: 0.15769408643245697\n",
      "test epoch: 3/11, round: 378/501, loss: 0.15838070213794708\n",
      "test epoch: 3/11, round: 379/501, loss: 0.44317007064819336\n",
      "test epoch: 3/11, round: 380/501, loss: 0.2731129229068756\n",
      "test epoch: 3/11, round: 381/501, loss: 0.4099314510822296\n",
      "test epoch: 3/11, round: 382/501, loss: 0.27713629603385925\n",
      "test epoch: 3/11, round: 383/501, loss: 0.31851476430892944\n",
      "test epoch: 3/11, round: 384/501, loss: 0.2604493498802185\n",
      "test epoch: 3/11, round: 385/501, loss: 0.48220929503440857\n",
      "test epoch: 3/11, round: 386/501, loss: 0.5675545930862427\n",
      "test epoch: 3/11, round: 387/501, loss: 0.28429505228996277\n",
      "test epoch: 3/11, round: 388/501, loss: 0.27535825967788696\n",
      "test epoch: 3/11, round: 389/501, loss: 0.32332807779312134\n",
      "test epoch: 3/11, round: 390/501, loss: 0.40770289301872253\n",
      "test epoch: 3/11, round: 391/501, loss: 0.365267276763916\n",
      "test epoch: 3/11, round: 392/501, loss: 0.44525623321533203\n",
      "test epoch: 3/11, round: 393/501, loss: 0.3701534867286682\n",
      "test epoch: 3/11, round: 394/501, loss: 0.6588877439498901\n",
      "test epoch: 3/11, round: 395/501, loss: 0.26198676228523254\n",
      "test epoch: 3/11, round: 396/501, loss: 0.4311695396900177\n",
      "test epoch: 3/11, round: 397/501, loss: 0.48720583319664\n",
      "test epoch: 3/11, round: 398/501, loss: 0.544786810874939\n",
      "test epoch: 3/11, round: 399/501, loss: 0.3127526044845581\n",
      "test epoch: 3/11, round: 400/501, loss: 0.32502028346061707\n",
      "test epoch: 3/11, round: 401/501, loss: 0.6656767725944519\n",
      "test epoch: 3/11, round: 402/501, loss: 0.4594615399837494\n",
      "test epoch: 3/11, round: 403/501, loss: 0.2746177017688751\n",
      "test epoch: 3/11, round: 404/501, loss: 0.2230280488729477\n",
      "test epoch: 3/11, round: 405/501, loss: 0.7506982088088989\n",
      "test epoch: 3/11, round: 406/501, loss: 0.39956462383270264\n",
      "test epoch: 3/11, round: 407/501, loss: 0.4723239243030548\n",
      "test epoch: 3/11, round: 408/501, loss: 0.5180574059486389\n",
      "test epoch: 3/11, round: 409/501, loss: 0.5372369289398193\n",
      "test epoch: 3/11, round: 410/501, loss: 0.3835791349411011\n",
      "test epoch: 3/11, round: 411/501, loss: 0.3966732621192932\n",
      "test epoch: 3/11, round: 412/501, loss: 0.4248618483543396\n",
      "test epoch: 3/11, round: 413/501, loss: 0.48003053665161133\n",
      "test epoch: 3/11, round: 414/501, loss: 0.3486665189266205\n",
      "test epoch: 3/11, round: 415/501, loss: 0.3515491187572479\n",
      "test epoch: 3/11, round: 416/501, loss: 0.4102887809276581\n",
      "test epoch: 3/11, round: 417/501, loss: 0.2980785369873047\n",
      "test epoch: 3/11, round: 418/501, loss: 0.34290823340415955\n",
      "test epoch: 3/11, round: 419/501, loss: 0.4150222837924957\n",
      "test epoch: 3/11, round: 420/501, loss: 0.3269783556461334\n",
      "test epoch: 3/11, round: 421/501, loss: 0.45701682567596436\n",
      "test epoch: 3/11, round: 422/501, loss: 0.42751747369766235\n",
      "test epoch: 3/11, round: 423/501, loss: 0.6025581359863281\n",
      "test epoch: 3/11, round: 424/501, loss: 0.4267931580543518\n",
      "test epoch: 3/11, round: 425/501, loss: 0.36461979150772095\n",
      "test epoch: 3/11, round: 426/501, loss: 0.4615907073020935\n",
      "test epoch: 3/11, round: 427/501, loss: 0.3123496174812317\n",
      "test epoch: 3/11, round: 428/501, loss: 0.5308366417884827\n",
      "test epoch: 3/11, round: 429/501, loss: 0.5819348692893982\n",
      "test epoch: 3/11, round: 430/501, loss: 0.5513932704925537\n",
      "test epoch: 3/11, round: 431/501, loss: 0.384060263633728\n",
      "test epoch: 3/11, round: 432/501, loss: 0.3497233986854553\n",
      "test epoch: 3/11, round: 433/501, loss: 0.4428474009037018\n",
      "test epoch: 3/11, round: 434/501, loss: 0.33473291993141174\n",
      "test epoch: 3/11, round: 435/501, loss: 0.35960978269577026\n",
      "test epoch: 3/11, round: 436/501, loss: 0.35161522030830383\n",
      "test epoch: 3/11, round: 437/501, loss: 0.4681457579135895\n",
      "test epoch: 3/11, round: 438/501, loss: 0.532076895236969\n",
      "test epoch: 3/11, round: 439/501, loss: 0.3748440742492676\n",
      "test epoch: 3/11, round: 440/501, loss: 0.4968733787536621\n",
      "test epoch: 3/11, round: 441/501, loss: 0.4103843569755554\n",
      "test epoch: 3/11, round: 442/501, loss: 0.3633495271205902\n",
      "test epoch: 3/11, round: 443/501, loss: 0.27510520815849304\n",
      "test epoch: 3/11, round: 444/501, loss: 0.4177702069282532\n",
      "test epoch: 3/11, round: 445/501, loss: 0.4106145203113556\n",
      "test epoch: 3/11, round: 446/501, loss: 0.49741479754447937\n",
      "test epoch: 3/11, round: 447/501, loss: 0.26599961519241333\n",
      "test epoch: 3/11, round: 448/501, loss: 0.35758355259895325\n",
      "test epoch: 3/11, round: 449/501, loss: 0.2643774449825287\n",
      "test epoch: 3/11, round: 450/501, loss: 0.6021797060966492\n",
      "test epoch: 3/11, round: 451/501, loss: 0.3659050166606903\n",
      "test epoch: 3/11, round: 452/501, loss: 0.4127654433250427\n",
      "test epoch: 3/11, round: 453/501, loss: 0.1737925261259079\n",
      "test epoch: 3/11, round: 454/501, loss: 0.2644806206226349\n",
      "test epoch: 3/11, round: 455/501, loss: 0.5122491121292114\n",
      "test epoch: 3/11, round: 456/501, loss: 0.32059717178344727\n",
      "test epoch: 3/11, round: 457/501, loss: 0.24717862904071808\n",
      "test epoch: 3/11, round: 458/501, loss: 0.252520889043808\n",
      "test epoch: 3/11, round: 459/501, loss: 0.18591372668743134\n",
      "test epoch: 3/11, round: 460/501, loss: 0.1548243910074234\n",
      "test epoch: 3/11, round: 461/501, loss: 0.16726990044116974\n",
      "test epoch: 3/11, round: 462/501, loss: 0.1530262529850006\n",
      "test epoch: 3/11, round: 463/501, loss: 0.16299279034137726\n",
      "test epoch: 3/11, round: 464/501, loss: 0.1537638008594513\n",
      "test epoch: 3/11, round: 465/501, loss: 0.19297027587890625\n",
      "test epoch: 3/11, round: 466/501, loss: 0.15289385616779327\n",
      "test epoch: 3/11, round: 467/501, loss: 0.1880638152360916\n",
      "test epoch: 3/11, round: 468/501, loss: 0.15476587414741516\n",
      "test epoch: 3/11, round: 469/501, loss: 0.18572302162647247\n",
      "test epoch: 3/11, round: 470/501, loss: 0.1750868409872055\n",
      "test epoch: 3/11, round: 471/501, loss: 0.22395911812782288\n",
      "test epoch: 3/11, round: 472/501, loss: 0.18144263327121735\n",
      "test epoch: 3/11, round: 473/501, loss: 0.1438589245080948\n",
      "test epoch: 3/11, round: 474/501, loss: 0.1724233627319336\n",
      "test epoch: 3/11, round: 475/501, loss: 0.15201041102409363\n",
      "test epoch: 3/11, round: 476/501, loss: 0.13871408998966217\n",
      "test epoch: 3/11, round: 477/501, loss: 0.14024196565151215\n",
      "test epoch: 3/11, round: 478/501, loss: 0.15270869433879852\n",
      "test epoch: 3/11, round: 479/501, loss: 0.11669135093688965\n",
      "test epoch: 3/11, round: 480/501, loss: 0.1521424949169159\n",
      "test epoch: 3/11, round: 481/501, loss: 0.14508746564388275\n",
      "test epoch: 3/11, round: 482/501, loss: 0.1518663465976715\n",
      "test epoch: 3/11, round: 483/501, loss: 0.1568482220172882\n",
      "test epoch: 3/11, round: 484/501, loss: 0.1633143275976181\n",
      "test epoch: 3/11, round: 485/501, loss: 0.1410624086856842\n",
      "test epoch: 3/11, round: 486/501, loss: 0.1357375681400299\n",
      "test epoch: 3/11, round: 487/501, loss: 0.13146166503429413\n",
      "test epoch: 3/11, round: 488/501, loss: 0.17705699801445007\n",
      "test epoch: 3/11, round: 489/501, loss: 0.12795038521289825\n",
      "test epoch: 3/11, round: 490/501, loss: 0.11322705447673798\n",
      "test epoch: 3/11, round: 491/501, loss: 0.1400621086359024\n",
      "test epoch: 3/11, round: 492/501, loss: 0.14885391294956207\n",
      "test epoch: 3/11, round: 493/501, loss: 0.14285477995872498\n",
      "test epoch: 3/11, round: 494/501, loss: 0.15253809094429016\n",
      "test epoch: 3/11, round: 495/501, loss: 0.12046296894550323\n",
      "test epoch: 3/11, round: 496/501, loss: 0.157380610704422\n",
      "test epoch: 3/11, round: 497/501, loss: 0.1343155801296234\n",
      "test epoch: 3/11, round: 498/501, loss: 0.11222334206104279\n",
      "test epoch: 3/11, round: 499/501, loss: 0.10236185044050217\n",
      "test epoch: 3/11, round: 500/501, loss: 0.3421119749546051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 3/11, round: 501/501, loss: 0.9197991490364075\n",
      "test epoch: 3/11, KS: 0.1731648858723652, ROC: 0.615419251991727\n",
      "cost time: 1998\n",
      "train epoch: 4/11, round: 1/532, loss: 0.4520593285560608\n",
      "train epoch: 4/11, round: 2/532, loss: 0.4006194472312927\n",
      "train epoch: 4/11, round: 3/532, loss: 0.45793208479881287\n",
      "train epoch: 4/11, round: 4/532, loss: 0.4166138172149658\n",
      "train epoch: 4/11, round: 5/532, loss: 0.412183940410614\n",
      "train epoch: 4/11, round: 6/532, loss: 0.37752363085746765\n",
      "train epoch: 4/11, round: 7/532, loss: 0.39617419242858887\n",
      "train epoch: 4/11, round: 8/532, loss: 0.38828420639038086\n",
      "train epoch: 4/11, round: 9/532, loss: 0.35808315873146057\n",
      "train epoch: 4/11, round: 10/532, loss: 0.45338478684425354\n",
      "train epoch: 4/11, round: 11/532, loss: 0.36293524503707886\n",
      "train epoch: 4/11, round: 12/532, loss: 0.5113881826400757\n",
      "train epoch: 4/11, round: 13/532, loss: 0.42126068472862244\n",
      "train epoch: 4/11, round: 14/532, loss: 0.39148837327957153\n",
      "train epoch: 4/11, round: 15/532, loss: 0.4842853546142578\n",
      "train epoch: 4/11, round: 16/532, loss: 0.47591280937194824\n",
      "train epoch: 4/11, round: 17/532, loss: 0.4525385797023773\n",
      "train epoch: 4/11, round: 18/532, loss: 0.4267978072166443\n",
      "train epoch: 4/11, round: 19/532, loss: 0.4438531994819641\n",
      "train epoch: 4/11, round: 20/532, loss: 0.4156777262687683\n",
      "train epoch: 4/11, round: 21/532, loss: 0.44082561135292053\n",
      "train epoch: 4/11, round: 22/532, loss: 0.3412778377532959\n",
      "train epoch: 4/11, round: 23/532, loss: 0.4310310482978821\n",
      "train epoch: 4/11, round: 24/532, loss: 0.3434954285621643\n",
      "train epoch: 4/11, round: 25/532, loss: 0.3840382993221283\n",
      "train epoch: 4/11, round: 26/532, loss: 0.361276775598526\n",
      "train epoch: 4/11, round: 27/532, loss: 0.38590207695961\n",
      "train epoch: 4/11, round: 28/532, loss: 0.36930549144744873\n",
      "train epoch: 4/11, round: 29/532, loss: 0.313634991645813\n",
      "train epoch: 4/11, round: 30/532, loss: 0.3757902979850769\n",
      "train epoch: 4/11, round: 31/532, loss: 0.45023947954177856\n",
      "train epoch: 4/11, round: 32/532, loss: 0.4038720726966858\n",
      "train epoch: 4/11, round: 33/532, loss: 0.4201686978340149\n",
      "train epoch: 4/11, round: 34/532, loss: 0.3360406756401062\n",
      "train epoch: 4/11, round: 35/532, loss: 0.45437973737716675\n",
      "train epoch: 4/11, round: 36/532, loss: 0.32809966802597046\n",
      "train epoch: 4/11, round: 37/532, loss: 0.41414937376976013\n",
      "train epoch: 4/11, round: 38/532, loss: 0.44856899976730347\n",
      "train epoch: 4/11, round: 39/532, loss: 0.38069164752960205\n",
      "train epoch: 4/11, round: 40/532, loss: 0.38193655014038086\n",
      "train epoch: 4/11, round: 41/532, loss: 0.43662768602371216\n",
      "train epoch: 4/11, round: 42/532, loss: 0.3464739918708801\n",
      "train epoch: 4/11, round: 43/532, loss: 0.3997741639614105\n",
      "train epoch: 4/11, round: 44/532, loss: 0.41729217767715454\n",
      "train epoch: 4/11, round: 45/532, loss: 0.39663073420524597\n",
      "train epoch: 4/11, round: 46/532, loss: 0.36280563473701477\n",
      "train epoch: 4/11, round: 47/532, loss: 0.3478320240974426\n",
      "train epoch: 4/11, round: 48/532, loss: 0.43153828382492065\n",
      "train epoch: 4/11, round: 49/532, loss: 0.4461698532104492\n",
      "train epoch: 4/11, round: 50/532, loss: 0.38803109526634216\n",
      "train epoch: 4/11, round: 51/532, loss: 0.42587289214134216\n",
      "train epoch: 4/11, round: 52/532, loss: 0.4187662601470947\n",
      "train epoch: 4/11, round: 53/532, loss: 0.4385108947753906\n",
      "train epoch: 4/11, round: 54/532, loss: 0.37821170687675476\n",
      "train epoch: 4/11, round: 55/532, loss: 0.33902889490127563\n",
      "train epoch: 4/11, round: 56/532, loss: 0.40954217314720154\n",
      "train epoch: 4/11, round: 57/532, loss: 0.4562968611717224\n",
      "train epoch: 4/11, round: 58/532, loss: 0.42496997117996216\n",
      "train epoch: 4/11, round: 59/532, loss: 0.4203493595123291\n",
      "train epoch: 4/11, round: 60/532, loss: 0.31274062395095825\n",
      "train epoch: 4/11, round: 61/532, loss: 0.43785858154296875\n",
      "train epoch: 4/11, round: 62/532, loss: 0.41493529081344604\n",
      "train epoch: 4/11, round: 63/532, loss: 0.44506916403770447\n",
      "train epoch: 4/11, round: 64/532, loss: 0.37018394470214844\n",
      "train epoch: 4/11, round: 65/532, loss: 0.39174002408981323\n",
      "train epoch: 4/11, round: 66/532, loss: 0.3219943344593048\n",
      "train epoch: 4/11, round: 67/532, loss: 0.3352063298225403\n",
      "train epoch: 4/11, round: 68/532, loss: 0.41309529542922974\n",
      "train epoch: 4/11, round: 69/532, loss: 0.3846447467803955\n",
      "train epoch: 4/11, round: 70/532, loss: 0.4067015051841736\n",
      "train epoch: 4/11, round: 71/532, loss: 0.4801432192325592\n",
      "train epoch: 4/11, round: 72/532, loss: 0.5421408414840698\n",
      "train epoch: 4/11, round: 73/532, loss: 0.44017845392227173\n",
      "train epoch: 4/11, round: 74/532, loss: 0.33700019121170044\n",
      "train epoch: 4/11, round: 75/532, loss: 0.502172589302063\n",
      "train epoch: 4/11, round: 76/532, loss: 0.3631680905818939\n",
      "train epoch: 4/11, round: 77/532, loss: 0.34915679693222046\n",
      "train epoch: 4/11, round: 78/532, loss: 0.3371613621711731\n",
      "train epoch: 4/11, round: 79/532, loss: 0.4736262857913971\n",
      "train epoch: 4/11, round: 80/532, loss: 0.3964473605155945\n",
      "train epoch: 4/11, round: 81/532, loss: 0.36546534299850464\n",
      "train epoch: 4/11, round: 82/532, loss: 0.38864046335220337\n",
      "train epoch: 4/11, round: 83/532, loss: 0.45181718468666077\n",
      "train epoch: 4/11, round: 84/532, loss: 0.4689105153083801\n",
      "train epoch: 4/11, round: 85/532, loss: 0.42257529497146606\n",
      "train epoch: 4/11, round: 86/532, loss: 0.4307226240634918\n",
      "train epoch: 4/11, round: 87/532, loss: 0.3943852484226227\n",
      "train epoch: 4/11, round: 88/532, loss: 0.34086355566978455\n",
      "train epoch: 4/11, round: 89/532, loss: 0.3939952850341797\n",
      "train epoch: 4/11, round: 90/532, loss: 0.4682164788246155\n",
      "train epoch: 4/11, round: 91/532, loss: 0.3483954071998596\n",
      "train epoch: 4/11, round: 92/532, loss: 0.39694806933403015\n",
      "train epoch: 4/11, round: 93/532, loss: 0.4181556701660156\n",
      "train epoch: 4/11, round: 94/532, loss: 0.4045259356498718\n",
      "train epoch: 4/11, round: 95/532, loss: 0.39766764640808105\n",
      "train epoch: 4/11, round: 96/532, loss: 0.4295405447483063\n",
      "train epoch: 4/11, round: 97/532, loss: 0.3484373688697815\n",
      "train epoch: 4/11, round: 98/532, loss: 0.34178227186203003\n",
      "train epoch: 4/11, round: 99/532, loss: 0.4389025568962097\n",
      "train epoch: 4/11, round: 100/532, loss: 0.322166383266449\n",
      "train epoch: 4/11, round: 101/532, loss: 0.45673155784606934\n",
      "train epoch: 4/11, round: 102/532, loss: 0.42401131987571716\n",
      "train epoch: 4/11, round: 103/532, loss: 0.4035405218601227\n",
      "train epoch: 4/11, round: 104/532, loss: 0.4998762607574463\n",
      "train epoch: 4/11, round: 105/532, loss: 0.3474622368812561\n",
      "train epoch: 4/11, round: 106/532, loss: 0.45711392164230347\n",
      "train epoch: 4/11, round: 107/532, loss: 0.4414547085762024\n",
      "train epoch: 4/11, round: 108/532, loss: 0.27048230171203613\n",
      "train epoch: 4/11, round: 109/532, loss: 0.33063241839408875\n",
      "train epoch: 4/11, round: 110/532, loss: 0.4537752568721771\n",
      "train epoch: 4/11, round: 111/532, loss: 0.4248918890953064\n",
      "train epoch: 4/11, round: 112/532, loss: 0.3372550904750824\n",
      "train epoch: 4/11, round: 113/532, loss: 0.3957403600215912\n",
      "train epoch: 4/11, round: 114/532, loss: 0.3984665870666504\n",
      "train epoch: 4/11, round: 115/532, loss: 0.39662161469459534\n",
      "train epoch: 4/11, round: 116/532, loss: 0.35212844610214233\n",
      "train epoch: 4/11, round: 117/532, loss: 0.46326714754104614\n",
      "train epoch: 4/11, round: 118/532, loss: 0.35757502913475037\n",
      "train epoch: 4/11, round: 119/532, loss: 0.3810945451259613\n",
      "train epoch: 4/11, round: 120/532, loss: 0.5418837666511536\n",
      "train epoch: 4/11, round: 121/532, loss: 0.3439719080924988\n",
      "train epoch: 4/11, round: 122/532, loss: 0.3551884591579437\n",
      "train epoch: 4/11, round: 123/532, loss: 0.42823362350463867\n",
      "train epoch: 4/11, round: 124/532, loss: 0.43021726608276367\n",
      "train epoch: 4/11, round: 125/532, loss: 0.3626895248889923\n",
      "train epoch: 4/11, round: 126/532, loss: 0.3759642243385315\n",
      "train epoch: 4/11, round: 127/532, loss: 0.3842625021934509\n",
      "train epoch: 4/11, round: 128/532, loss: 0.457203209400177\n",
      "train epoch: 4/11, round: 129/532, loss: 0.3903443217277527\n",
      "train epoch: 4/11, round: 130/532, loss: 0.47406983375549316\n",
      "train epoch: 4/11, round: 131/532, loss: 0.34970903396606445\n",
      "train epoch: 4/11, round: 132/532, loss: 0.4273549020290375\n",
      "train epoch: 4/11, round: 133/532, loss: 0.4254423677921295\n",
      "train epoch: 4/11, round: 134/532, loss: 0.4277464747428894\n",
      "train epoch: 4/11, round: 135/532, loss: 0.4249815344810486\n",
      "train epoch: 4/11, round: 136/532, loss: 0.36055609583854675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4/11, round: 137/532, loss: 0.4872194230556488\n",
      "train epoch: 4/11, round: 138/532, loss: 0.44499993324279785\n",
      "train epoch: 4/11, round: 139/532, loss: 0.40575695037841797\n",
      "train epoch: 4/11, round: 140/532, loss: 0.46713605523109436\n",
      "train epoch: 4/11, round: 141/532, loss: 0.40571966767311096\n",
      "train epoch: 4/11, round: 142/532, loss: 0.40900182723999023\n",
      "train epoch: 4/11, round: 143/532, loss: 0.36284005641937256\n",
      "train epoch: 4/11, round: 144/532, loss: 0.39597728848457336\n",
      "train epoch: 4/11, round: 145/532, loss: 0.45069822669029236\n",
      "train epoch: 4/11, round: 146/532, loss: 0.35765522718429565\n",
      "train epoch: 4/11, round: 147/532, loss: 0.36679425835609436\n",
      "train epoch: 4/11, round: 148/532, loss: 0.36400315165519714\n",
      "train epoch: 4/11, round: 149/532, loss: 0.40868085622787476\n",
      "train epoch: 4/11, round: 150/532, loss: 0.3879438042640686\n",
      "train epoch: 4/11, round: 151/532, loss: 0.4044685363769531\n",
      "train epoch: 4/11, round: 152/532, loss: 0.4743001461029053\n",
      "train epoch: 4/11, round: 153/532, loss: 0.39467358589172363\n",
      "train epoch: 4/11, round: 154/532, loss: 0.4235139489173889\n",
      "train epoch: 4/11, round: 155/532, loss: 0.4496241509914398\n",
      "train epoch: 4/11, round: 156/532, loss: 0.3349589407444\n",
      "train epoch: 4/11, round: 157/532, loss: 0.5020145177841187\n",
      "train epoch: 4/11, round: 158/532, loss: 0.4633147716522217\n",
      "train epoch: 4/11, round: 159/532, loss: 0.5553973317146301\n",
      "train epoch: 4/11, round: 160/532, loss: 0.4964989721775055\n",
      "train epoch: 4/11, round: 161/532, loss: 0.4103025794029236\n",
      "train epoch: 4/11, round: 162/532, loss: 0.44394445419311523\n",
      "train epoch: 4/11, round: 163/532, loss: 0.3798266649246216\n",
      "train epoch: 4/11, round: 164/532, loss: 0.4180496335029602\n",
      "train epoch: 4/11, round: 165/532, loss: 0.34227660298347473\n",
      "train epoch: 4/11, round: 166/532, loss: 0.40849319100379944\n",
      "train epoch: 4/11, round: 167/532, loss: 0.4141428470611572\n",
      "train epoch: 4/11, round: 168/532, loss: 0.39616474509239197\n",
      "train epoch: 4/11, round: 169/532, loss: 0.3906455934047699\n",
      "train epoch: 4/11, round: 170/532, loss: 0.43484264612197876\n",
      "train epoch: 4/11, round: 171/532, loss: 0.39229124784469604\n",
      "train epoch: 4/11, round: 172/532, loss: 0.45443081855773926\n",
      "train epoch: 4/11, round: 173/532, loss: 0.31868547201156616\n",
      "train epoch: 4/11, round: 174/532, loss: 0.3416493833065033\n",
      "train epoch: 4/11, round: 175/532, loss: 0.35011792182922363\n",
      "train epoch: 4/11, round: 176/532, loss: 0.37221235036849976\n",
      "train epoch: 4/11, round: 177/532, loss: 0.37395331263542175\n",
      "train epoch: 4/11, round: 178/532, loss: 0.43331390619277954\n",
      "train epoch: 4/11, round: 179/532, loss: 0.4159580171108246\n",
      "train epoch: 4/11, round: 180/532, loss: 0.3132782578468323\n",
      "train epoch: 4/11, round: 181/532, loss: 0.3222814202308655\n",
      "train epoch: 4/11, round: 182/532, loss: 0.4081903100013733\n",
      "train epoch: 4/11, round: 183/532, loss: 0.43851765990257263\n",
      "train epoch: 4/11, round: 184/532, loss: 0.4850893020629883\n",
      "train epoch: 4/11, round: 185/532, loss: 0.3681480288505554\n",
      "train epoch: 4/11, round: 186/532, loss: 0.3887794017791748\n",
      "train epoch: 4/11, round: 187/532, loss: 0.43724679946899414\n",
      "train epoch: 4/11, round: 188/532, loss: 0.34803348779678345\n",
      "train epoch: 4/11, round: 189/532, loss: 0.3651260435581207\n",
      "train epoch: 4/11, round: 190/532, loss: 0.3885127305984497\n",
      "train epoch: 4/11, round: 191/532, loss: 0.3112022578716278\n",
      "train epoch: 4/11, round: 192/532, loss: 0.3375067710876465\n",
      "train epoch: 4/11, round: 193/532, loss: 0.4263536036014557\n",
      "train epoch: 4/11, round: 194/532, loss: 0.37866973876953125\n",
      "train epoch: 4/11, round: 195/532, loss: 0.4065268635749817\n",
      "train epoch: 4/11, round: 196/532, loss: 0.39387091994285583\n",
      "train epoch: 4/11, round: 197/532, loss: 0.3893924653530121\n",
      "train epoch: 4/11, round: 198/532, loss: 0.5084711313247681\n",
      "train epoch: 4/11, round: 199/532, loss: 0.2819697856903076\n",
      "train epoch: 4/11, round: 200/532, loss: 0.5586003065109253\n",
      "train epoch: 4/11, round: 201/532, loss: 0.34044063091278076\n",
      "train epoch: 4/11, round: 202/532, loss: 0.374211847782135\n",
      "train epoch: 4/11, round: 203/532, loss: 0.38433533906936646\n",
      "train epoch: 4/11, round: 204/532, loss: 0.37353771924972534\n",
      "train epoch: 4/11, round: 205/532, loss: 0.42076268792152405\n",
      "train epoch: 4/11, round: 206/532, loss: 0.4148222506046295\n",
      "train epoch: 4/11, round: 207/532, loss: 0.3738899827003479\n",
      "train epoch: 4/11, round: 208/532, loss: 0.33114656805992126\n",
      "train epoch: 4/11, round: 209/532, loss: 0.42103785276412964\n",
      "train epoch: 4/11, round: 210/532, loss: 0.3741810917854309\n",
      "train epoch: 4/11, round: 211/532, loss: 0.4707435071468353\n",
      "train epoch: 4/11, round: 212/532, loss: 0.44706231355667114\n",
      "train epoch: 4/11, round: 213/532, loss: 0.4381847381591797\n",
      "train epoch: 4/11, round: 214/532, loss: 0.43041688203811646\n",
      "train epoch: 4/11, round: 215/532, loss: 0.40279707312583923\n",
      "train epoch: 4/11, round: 216/532, loss: 0.47610488533973694\n",
      "train epoch: 4/11, round: 217/532, loss: 0.3438481092453003\n",
      "train epoch: 4/11, round: 218/532, loss: 0.3517369329929352\n",
      "train epoch: 4/11, round: 219/532, loss: 0.4042436182498932\n",
      "train epoch: 4/11, round: 220/532, loss: 0.3694630265235901\n",
      "train epoch: 4/11, round: 221/532, loss: 0.36874258518218994\n",
      "train epoch: 4/11, round: 222/532, loss: 0.40890470147132874\n",
      "train epoch: 4/11, round: 223/532, loss: 0.42315149307250977\n",
      "train epoch: 4/11, round: 224/532, loss: 0.4673137068748474\n",
      "train epoch: 4/11, round: 225/532, loss: 0.36621010303497314\n",
      "train epoch: 4/11, round: 226/532, loss: 0.2520376741886139\n",
      "train epoch: 4/11, round: 227/532, loss: 0.4811154007911682\n",
      "train epoch: 4/11, round: 228/532, loss: 0.3982904553413391\n",
      "train epoch: 4/11, round: 229/532, loss: 0.44160112738609314\n",
      "train epoch: 4/11, round: 230/532, loss: 0.41504350304603577\n",
      "train epoch: 4/11, round: 231/532, loss: 0.4040272831916809\n",
      "train epoch: 4/11, round: 232/532, loss: 0.4173363149166107\n",
      "train epoch: 4/11, round: 233/532, loss: 0.41966143250465393\n",
      "train epoch: 4/11, round: 234/532, loss: 0.3813041150569916\n",
      "train epoch: 4/11, round: 235/532, loss: 0.3770643174648285\n",
      "train epoch: 4/11, round: 236/532, loss: 0.38852831721305847\n",
      "train epoch: 4/11, round: 237/532, loss: 0.35502657294273376\n",
      "train epoch: 4/11, round: 238/532, loss: 0.5041132569313049\n",
      "train epoch: 4/11, round: 239/532, loss: 0.40391913056373596\n",
      "train epoch: 4/11, round: 240/532, loss: 0.4061830937862396\n",
      "train epoch: 4/11, round: 241/532, loss: 0.46009889245033264\n",
      "train epoch: 4/11, round: 242/532, loss: 0.5153511166572571\n",
      "train epoch: 4/11, round: 243/532, loss: 0.3483332693576813\n",
      "train epoch: 4/11, round: 244/532, loss: 0.39031389355659485\n",
      "train epoch: 4/11, round: 245/532, loss: 0.35647037625312805\n",
      "train epoch: 4/11, round: 246/532, loss: 0.5252889394760132\n",
      "train epoch: 4/11, round: 247/532, loss: 0.37009936571121216\n",
      "train epoch: 4/11, round: 248/532, loss: 0.3886590600013733\n",
      "train epoch: 4/11, round: 249/532, loss: 0.42152947187423706\n",
      "train epoch: 4/11, round: 250/532, loss: 0.4749521315097809\n",
      "train epoch: 4/11, round: 251/532, loss: 0.42495840787887573\n",
      "train epoch: 4/11, round: 252/532, loss: 0.40657320618629456\n",
      "train epoch: 4/11, round: 253/532, loss: 0.3151416480541229\n",
      "train epoch: 4/11, round: 254/532, loss: 0.33271169662475586\n",
      "train epoch: 4/11, round: 255/532, loss: 0.4030311703681946\n",
      "train epoch: 4/11, round: 256/532, loss: 0.4387515187263489\n",
      "train epoch: 4/11, round: 257/532, loss: 0.35180747509002686\n",
      "train epoch: 4/11, round: 258/532, loss: 0.42662033438682556\n",
      "train epoch: 4/11, round: 259/532, loss: 0.3679635524749756\n",
      "train epoch: 4/11, round: 260/532, loss: 0.454885333776474\n",
      "train epoch: 4/11, round: 261/532, loss: 0.35260501503944397\n",
      "train epoch: 4/11, round: 262/532, loss: 0.3268807530403137\n",
      "train epoch: 4/11, round: 263/532, loss: 0.40246182680130005\n",
      "train epoch: 4/11, round: 264/532, loss: 0.4528343677520752\n",
      "train epoch: 4/11, round: 265/532, loss: 0.48326271772384644\n",
      "train epoch: 4/11, round: 266/532, loss: 0.3867908716201782\n",
      "train epoch: 4/11, round: 267/532, loss: 0.4906412959098816\n",
      "train epoch: 4/11, round: 268/532, loss: 0.4316198229789734\n",
      "train epoch: 4/11, round: 269/532, loss: 0.38566046953201294\n",
      "train epoch: 4/11, round: 270/532, loss: 0.4039744436740875\n",
      "train epoch: 4/11, round: 271/532, loss: 0.4057576060295105\n",
      "train epoch: 4/11, round: 272/532, loss: 0.3409363925457001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4/11, round: 273/532, loss: 0.3433849811553955\n",
      "train epoch: 4/11, round: 274/532, loss: 0.34892910718917847\n",
      "train epoch: 4/11, round: 275/532, loss: 0.4763273298740387\n",
      "train epoch: 4/11, round: 276/532, loss: 0.3394927382469177\n",
      "train epoch: 4/11, round: 277/532, loss: 0.426959365606308\n",
      "train epoch: 4/11, round: 278/532, loss: 0.38713088631629944\n",
      "train epoch: 4/11, round: 279/532, loss: 0.35379236936569214\n",
      "train epoch: 4/11, round: 280/532, loss: 0.42117175459861755\n",
      "train epoch: 4/11, round: 281/532, loss: 0.4804554879665375\n",
      "train epoch: 4/11, round: 282/532, loss: 0.36232104897499084\n",
      "train epoch: 4/11, round: 283/532, loss: 0.43369579315185547\n",
      "train epoch: 4/11, round: 284/532, loss: 0.3774029612541199\n",
      "train epoch: 4/11, round: 285/532, loss: 0.48040398955345154\n",
      "train epoch: 4/11, round: 286/532, loss: 0.3633897006511688\n",
      "train epoch: 4/11, round: 287/532, loss: 0.4332153797149658\n",
      "train epoch: 4/11, round: 288/532, loss: 0.34039634466171265\n",
      "train epoch: 4/11, round: 289/532, loss: 0.4734863340854645\n",
      "train epoch: 4/11, round: 290/532, loss: 0.3654199242591858\n",
      "train epoch: 4/11, round: 291/532, loss: 0.3951462507247925\n",
      "train epoch: 4/11, round: 292/532, loss: 0.43335890769958496\n",
      "train epoch: 4/11, round: 293/532, loss: 0.5624721050262451\n",
      "train epoch: 4/11, round: 294/532, loss: 0.48103469610214233\n",
      "train epoch: 4/11, round: 295/532, loss: 0.3984905481338501\n",
      "train epoch: 4/11, round: 296/532, loss: 0.48075446486473083\n",
      "train epoch: 4/11, round: 297/532, loss: 0.394330769777298\n",
      "train epoch: 4/11, round: 298/532, loss: 0.3494091033935547\n",
      "train epoch: 4/11, round: 299/532, loss: 0.40205296874046326\n",
      "train epoch: 4/11, round: 300/532, loss: 0.3832833170890808\n",
      "train epoch: 4/11, round: 301/532, loss: 0.4171154499053955\n",
      "train epoch: 4/11, round: 302/532, loss: 0.3156163990497589\n",
      "train epoch: 4/11, round: 303/532, loss: 0.40821805596351624\n",
      "train epoch: 4/11, round: 304/532, loss: 0.5062341094017029\n",
      "train epoch: 4/11, round: 305/532, loss: 0.34067612886428833\n",
      "train epoch: 4/11, round: 306/532, loss: 0.44668713212013245\n",
      "train epoch: 4/11, round: 307/532, loss: 0.47193461656570435\n",
      "train epoch: 4/11, round: 308/532, loss: 0.3747558891773224\n",
      "train epoch: 4/11, round: 309/532, loss: 0.3752903640270233\n",
      "train epoch: 4/11, round: 310/532, loss: 0.364820659160614\n",
      "train epoch: 4/11, round: 311/532, loss: 0.4930242598056793\n",
      "train epoch: 4/11, round: 312/532, loss: 0.45438551902770996\n",
      "train epoch: 4/11, round: 313/532, loss: 0.33043617010116577\n",
      "train epoch: 4/11, round: 314/532, loss: 0.3154599070549011\n",
      "train epoch: 4/11, round: 315/532, loss: 0.4335833191871643\n",
      "train epoch: 4/11, round: 316/532, loss: 0.484712690114975\n",
      "train epoch: 4/11, round: 317/532, loss: 0.42812538146972656\n",
      "train epoch: 4/11, round: 318/532, loss: 0.44878309965133667\n",
      "train epoch: 4/11, round: 319/532, loss: 0.41459426283836365\n",
      "train epoch: 4/11, round: 320/532, loss: 0.358303427696228\n",
      "train epoch: 4/11, round: 321/532, loss: 0.31375303864479065\n",
      "train epoch: 4/11, round: 322/532, loss: 0.3520425856113434\n",
      "train epoch: 4/11, round: 323/532, loss: 0.41906577348709106\n",
      "train epoch: 4/11, round: 324/532, loss: 0.4207999110221863\n",
      "train epoch: 4/11, round: 325/532, loss: 0.35022568702697754\n",
      "train epoch: 4/11, round: 326/532, loss: 0.39016684889793396\n",
      "train epoch: 4/11, round: 327/532, loss: 0.4714202880859375\n",
      "train epoch: 4/11, round: 328/532, loss: 0.3240724205970764\n",
      "train epoch: 4/11, round: 329/532, loss: 0.37441593408584595\n",
      "train epoch: 4/11, round: 330/532, loss: 0.3681483864784241\n",
      "train epoch: 4/11, round: 331/532, loss: 0.36213943362236023\n",
      "train epoch: 4/11, round: 332/532, loss: 0.5181315541267395\n",
      "train epoch: 4/11, round: 333/532, loss: 0.40745997428894043\n",
      "train epoch: 4/11, round: 334/532, loss: 0.45029282569885254\n",
      "train epoch: 4/11, round: 335/532, loss: 0.43924862146377563\n",
      "train epoch: 4/11, round: 336/532, loss: 0.4630734920501709\n",
      "train epoch: 4/11, round: 337/532, loss: 0.38532555103302\n",
      "train epoch: 4/11, round: 338/532, loss: 0.388599157333374\n",
      "train epoch: 4/11, round: 339/532, loss: 0.4570314288139343\n",
      "train epoch: 4/11, round: 340/532, loss: 0.42406851053237915\n",
      "train epoch: 4/11, round: 341/532, loss: 0.354642778635025\n",
      "train epoch: 4/11, round: 342/532, loss: 0.40284499526023865\n",
      "train epoch: 4/11, round: 343/532, loss: 0.3971954882144928\n",
      "train epoch: 4/11, round: 344/532, loss: 0.49060314893722534\n",
      "train epoch: 4/11, round: 345/532, loss: 0.4472460150718689\n",
      "train epoch: 4/11, round: 346/532, loss: 0.3997906744480133\n",
      "train epoch: 4/11, round: 347/532, loss: 0.37207692861557007\n",
      "train epoch: 4/11, round: 348/532, loss: 0.2722383737564087\n",
      "train epoch: 4/11, round: 349/532, loss: 0.4935905337333679\n",
      "train epoch: 4/11, round: 350/532, loss: 0.42104583978652954\n",
      "train epoch: 4/11, round: 351/532, loss: 0.29987940192222595\n",
      "train epoch: 4/11, round: 352/532, loss: 0.38802433013916016\n",
      "train epoch: 4/11, round: 353/532, loss: 0.4476616382598877\n",
      "train epoch: 4/11, round: 354/532, loss: 0.4397704601287842\n",
      "train epoch: 4/11, round: 355/532, loss: 0.43764370679855347\n",
      "train epoch: 4/11, round: 356/532, loss: 0.35698747634887695\n",
      "train epoch: 4/11, round: 357/532, loss: 0.49373579025268555\n",
      "train epoch: 4/11, round: 358/532, loss: 0.38386186957359314\n",
      "train epoch: 4/11, round: 359/532, loss: 0.3190487325191498\n",
      "train epoch: 4/11, round: 360/532, loss: 0.4261421263217926\n",
      "train epoch: 4/11, round: 361/532, loss: 0.30431053042411804\n",
      "train epoch: 4/11, round: 362/532, loss: 0.4684346318244934\n",
      "train epoch: 4/11, round: 363/532, loss: 0.4130721986293793\n",
      "train epoch: 4/11, round: 364/532, loss: 0.4013253152370453\n",
      "train epoch: 4/11, round: 365/532, loss: 0.38975512981414795\n",
      "train epoch: 4/11, round: 366/532, loss: 0.41553354263305664\n",
      "train epoch: 4/11, round: 367/532, loss: 0.2876195013523102\n",
      "train epoch: 4/11, round: 368/532, loss: 0.4289683401584625\n",
      "train epoch: 4/11, round: 369/532, loss: 0.38198232650756836\n",
      "train epoch: 4/11, round: 370/532, loss: 0.40193790197372437\n",
      "train epoch: 4/11, round: 371/532, loss: 0.316366583108902\n",
      "train epoch: 4/11, round: 372/532, loss: 0.34387677907943726\n",
      "train epoch: 4/11, round: 373/532, loss: 0.46758928894996643\n",
      "train epoch: 4/11, round: 374/532, loss: 0.5341795086860657\n",
      "train epoch: 4/11, round: 375/532, loss: 0.40747323632240295\n",
      "train epoch: 4/11, round: 376/532, loss: 0.35931795835494995\n",
      "train epoch: 4/11, round: 377/532, loss: 0.40834569931030273\n",
      "train epoch: 4/11, round: 378/532, loss: 0.451941579580307\n",
      "train epoch: 4/11, round: 379/532, loss: 0.35897472500801086\n",
      "train epoch: 4/11, round: 380/532, loss: 0.47152695059776306\n",
      "train epoch: 4/11, round: 381/532, loss: 0.32806506752967834\n",
      "train epoch: 4/11, round: 382/532, loss: 0.3596457540988922\n",
      "train epoch: 4/11, round: 383/532, loss: 0.2899525761604309\n",
      "train epoch: 4/11, round: 384/532, loss: 0.337859570980072\n",
      "train epoch: 4/11, round: 385/532, loss: 0.32157522439956665\n",
      "train epoch: 4/11, round: 386/532, loss: 0.45580562949180603\n",
      "train epoch: 4/11, round: 387/532, loss: 0.4023898243904114\n",
      "train epoch: 4/11, round: 388/532, loss: 0.38465046882629395\n",
      "train epoch: 4/11, round: 389/532, loss: 0.35444799065589905\n",
      "train epoch: 4/11, round: 390/532, loss: 0.489579975605011\n",
      "train epoch: 4/11, round: 391/532, loss: 0.45163726806640625\n",
      "train epoch: 4/11, round: 392/532, loss: 0.3950749933719635\n",
      "train epoch: 4/11, round: 393/532, loss: 0.5182114839553833\n",
      "train epoch: 4/11, round: 394/532, loss: 0.41062116622924805\n",
      "train epoch: 4/11, round: 395/532, loss: 0.5145906209945679\n",
      "train epoch: 4/11, round: 396/532, loss: 0.3781687915325165\n",
      "train epoch: 4/11, round: 397/532, loss: 0.35299021005630493\n",
      "train epoch: 4/11, round: 398/532, loss: 0.43774309754371643\n",
      "train epoch: 4/11, round: 399/532, loss: 0.42912617325782776\n",
      "train epoch: 4/11, round: 400/532, loss: 0.43790531158447266\n",
      "train epoch: 4/11, round: 401/532, loss: 0.4095725119113922\n",
      "train epoch: 4/11, round: 402/532, loss: 0.4229012429714203\n",
      "train epoch: 4/11, round: 403/532, loss: 0.4172991216182709\n",
      "train epoch: 4/11, round: 404/532, loss: 0.4374106526374817\n",
      "train epoch: 4/11, round: 405/532, loss: 0.3504025936126709\n",
      "train epoch: 4/11, round: 406/532, loss: 0.44470053911209106\n",
      "train epoch: 4/11, round: 407/532, loss: 0.3958949148654938\n",
      "train epoch: 4/11, round: 408/532, loss: 0.37537360191345215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4/11, round: 409/532, loss: 0.48608866333961487\n",
      "train epoch: 4/11, round: 410/532, loss: 0.37827691435813904\n",
      "train epoch: 4/11, round: 411/532, loss: 0.3940989375114441\n",
      "train epoch: 4/11, round: 412/532, loss: 0.4745634198188782\n",
      "train epoch: 4/11, round: 413/532, loss: 0.41233840584754944\n",
      "train epoch: 4/11, round: 414/532, loss: 0.40054816007614136\n",
      "train epoch: 4/11, round: 415/532, loss: 0.44317102432250977\n",
      "train epoch: 4/11, round: 416/532, loss: 0.39957475662231445\n",
      "train epoch: 4/11, round: 417/532, loss: 0.45929551124572754\n",
      "train epoch: 4/11, round: 418/532, loss: 0.3404902517795563\n",
      "train epoch: 4/11, round: 419/532, loss: 0.3731553554534912\n",
      "train epoch: 4/11, round: 420/532, loss: 0.4448227286338806\n",
      "train epoch: 4/11, round: 421/532, loss: 0.4027930200099945\n",
      "train epoch: 4/11, round: 422/532, loss: 0.4847429692745209\n",
      "train epoch: 4/11, round: 423/532, loss: 0.41670170426368713\n",
      "train epoch: 4/11, round: 424/532, loss: 0.37286868691444397\n",
      "train epoch: 4/11, round: 425/532, loss: 0.4662175178527832\n",
      "train epoch: 4/11, round: 426/532, loss: 0.4027220606803894\n",
      "train epoch: 4/11, round: 427/532, loss: 0.34044167399406433\n",
      "train epoch: 4/11, round: 428/532, loss: 0.5053101778030396\n",
      "train epoch: 4/11, round: 429/532, loss: 0.3329102396965027\n",
      "train epoch: 4/11, round: 430/532, loss: 0.3793678283691406\n",
      "train epoch: 4/11, round: 431/532, loss: 0.46881476044654846\n",
      "train epoch: 4/11, round: 432/532, loss: 0.5248141288757324\n",
      "train epoch: 4/11, round: 433/532, loss: 0.31504812836647034\n",
      "train epoch: 4/11, round: 434/532, loss: 0.41177019476890564\n",
      "train epoch: 4/11, round: 435/532, loss: 0.4378952383995056\n",
      "train epoch: 4/11, round: 436/532, loss: 0.3447973132133484\n",
      "train epoch: 4/11, round: 437/532, loss: 0.4710226058959961\n",
      "train epoch: 4/11, round: 438/532, loss: 0.41543903946876526\n",
      "train epoch: 4/11, round: 439/532, loss: 0.30865249037742615\n",
      "train epoch: 4/11, round: 440/532, loss: 0.47551265358924866\n",
      "train epoch: 4/11, round: 441/532, loss: 0.4035249650478363\n",
      "train epoch: 4/11, round: 442/532, loss: 0.39172738790512085\n",
      "train epoch: 4/11, round: 443/532, loss: 0.4089962840080261\n",
      "train epoch: 4/11, round: 444/532, loss: 0.4119264483451843\n",
      "train epoch: 4/11, round: 445/532, loss: 0.3952309489250183\n",
      "train epoch: 4/11, round: 446/532, loss: 0.4683317542076111\n",
      "train epoch: 4/11, round: 447/532, loss: 0.38638490438461304\n",
      "train epoch: 4/11, round: 448/532, loss: 0.38567453622817993\n",
      "train epoch: 4/11, round: 449/532, loss: 0.40951070189476013\n",
      "train epoch: 4/11, round: 450/532, loss: 0.38072994351387024\n",
      "train epoch: 4/11, round: 451/532, loss: 0.33327630162239075\n",
      "train epoch: 4/11, round: 452/532, loss: 0.41172662377357483\n",
      "train epoch: 4/11, round: 453/532, loss: 0.3920672833919525\n",
      "train epoch: 4/11, round: 454/532, loss: 0.5098050832748413\n",
      "train epoch: 4/11, round: 455/532, loss: 0.3858082890510559\n",
      "train epoch: 4/11, round: 456/532, loss: 0.4430460035800934\n",
      "train epoch: 4/11, round: 457/532, loss: 0.4003599286079407\n",
      "train epoch: 4/11, round: 458/532, loss: 0.38359081745147705\n",
      "train epoch: 4/11, round: 459/532, loss: 0.44754886627197266\n",
      "train epoch: 4/11, round: 460/532, loss: 0.3940158486366272\n",
      "train epoch: 4/11, round: 461/532, loss: 0.28348222374916077\n",
      "train epoch: 4/11, round: 462/532, loss: 0.3932654857635498\n",
      "train epoch: 4/11, round: 463/532, loss: 0.44154125452041626\n",
      "train epoch: 4/11, round: 464/532, loss: 0.3450709283351898\n",
      "train epoch: 4/11, round: 465/532, loss: 0.4437224268913269\n",
      "train epoch: 4/11, round: 466/532, loss: 0.42234158515930176\n",
      "train epoch: 4/11, round: 467/532, loss: 0.35237306356430054\n",
      "train epoch: 4/11, round: 468/532, loss: 0.4841545522212982\n",
      "train epoch: 4/11, round: 469/532, loss: 0.44722944498062134\n",
      "train epoch: 4/11, round: 470/532, loss: 0.3813292384147644\n",
      "train epoch: 4/11, round: 471/532, loss: 0.3153316080570221\n",
      "train epoch: 4/11, round: 472/532, loss: 0.44269198179244995\n",
      "train epoch: 4/11, round: 473/532, loss: 0.40229088068008423\n",
      "train epoch: 4/11, round: 474/532, loss: 0.3364354074001312\n",
      "train epoch: 4/11, round: 475/532, loss: 0.43868571519851685\n",
      "train epoch: 4/11, round: 476/532, loss: 0.4063143730163574\n",
      "train epoch: 4/11, round: 477/532, loss: 0.40879154205322266\n",
      "train epoch: 4/11, round: 478/532, loss: 0.40504416823387146\n",
      "train epoch: 4/11, round: 479/532, loss: 0.3311120569705963\n",
      "train epoch: 4/11, round: 480/532, loss: 0.3400016725063324\n",
      "train epoch: 4/11, round: 481/532, loss: 0.375997394323349\n",
      "train epoch: 4/11, round: 482/532, loss: 0.39700764417648315\n",
      "train epoch: 4/11, round: 483/532, loss: 0.3383149206638336\n",
      "train epoch: 4/11, round: 484/532, loss: 0.49221014976501465\n",
      "train epoch: 4/11, round: 485/532, loss: 0.37169530987739563\n",
      "train epoch: 4/11, round: 486/532, loss: 0.3875264525413513\n",
      "train epoch: 4/11, round: 487/532, loss: 0.3557125926017761\n",
      "train epoch: 4/11, round: 488/532, loss: 0.41293564438819885\n",
      "train epoch: 4/11, round: 489/532, loss: 0.4764600396156311\n",
      "train epoch: 4/11, round: 490/532, loss: 0.40041932463645935\n",
      "train epoch: 4/11, round: 491/532, loss: 0.34892192482948303\n",
      "train epoch: 4/11, round: 492/532, loss: 0.4287407398223877\n",
      "train epoch: 4/11, round: 493/532, loss: 0.43233615159988403\n",
      "train epoch: 4/11, round: 494/532, loss: 0.3187560439109802\n",
      "train epoch: 4/11, round: 495/532, loss: 0.44421058893203735\n",
      "train epoch: 4/11, round: 496/532, loss: 0.35581308603286743\n",
      "train epoch: 4/11, round: 497/532, loss: 0.3867892622947693\n",
      "train epoch: 4/11, round: 498/532, loss: 0.4334891736507416\n",
      "train epoch: 4/11, round: 499/532, loss: 0.3397393226623535\n",
      "train epoch: 4/11, round: 500/532, loss: 0.39932575821876526\n",
      "train epoch: 4/11, round: 501/532, loss: 0.25452423095703125\n",
      "train epoch: 4/11, round: 502/532, loss: 0.36331963539123535\n",
      "train epoch: 4/11, round: 503/532, loss: 0.39810389280319214\n",
      "train epoch: 4/11, round: 504/532, loss: 0.40753626823425293\n",
      "train epoch: 4/11, round: 505/532, loss: 0.37150901556015015\n",
      "train epoch: 4/11, round: 506/532, loss: 0.39303842186927795\n",
      "train epoch: 4/11, round: 507/532, loss: 0.5108228921890259\n",
      "train epoch: 4/11, round: 508/532, loss: 0.3410273492336273\n",
      "train epoch: 4/11, round: 509/532, loss: 0.458055317401886\n",
      "train epoch: 4/11, round: 510/532, loss: 0.48972591757774353\n",
      "train epoch: 4/11, round: 511/532, loss: 0.32068997621536255\n",
      "train epoch: 4/11, round: 512/532, loss: 0.4379733204841614\n",
      "train epoch: 4/11, round: 513/532, loss: 0.3388150632381439\n",
      "train epoch: 4/11, round: 514/532, loss: 0.38624897599220276\n",
      "train epoch: 4/11, round: 515/532, loss: 0.4294397830963135\n",
      "train epoch: 4/11, round: 516/532, loss: 0.43862438201904297\n",
      "train epoch: 4/11, round: 517/532, loss: 0.5028935670852661\n",
      "train epoch: 4/11, round: 518/532, loss: 0.3422776162624359\n",
      "train epoch: 4/11, round: 519/532, loss: 0.3525485396385193\n",
      "train epoch: 4/11, round: 520/532, loss: 0.385509729385376\n",
      "train epoch: 4/11, round: 521/532, loss: 0.4324948787689209\n",
      "train epoch: 4/11, round: 522/532, loss: 0.30480045080184937\n",
      "train epoch: 4/11, round: 523/532, loss: 0.39971065521240234\n",
      "train epoch: 4/11, round: 524/532, loss: 0.4320642352104187\n",
      "train epoch: 4/11, round: 525/532, loss: 0.2589971423149109\n",
      "train epoch: 4/11, round: 526/532, loss: 0.36014237999916077\n",
      "train epoch: 4/11, round: 527/532, loss: 0.4475111961364746\n",
      "train epoch: 4/11, round: 528/532, loss: 0.30889472365379333\n",
      "train epoch: 4/11, round: 529/532, loss: 0.40823817253112793\n",
      "train epoch: 4/11, round: 530/532, loss: 0.41257888078689575\n",
      "train epoch: 4/11, round: 531/532, loss: 0.3669833540916443\n",
      "train epoch: 4/11, round: 532/532, loss: 0.4406365752220154\n",
      "train epoch: 4/11, KS: 0.21775628929364527, ROC: 0.6472454921856201\n",
      "test epoch: 4/11, round: 1/501, loss: 0.3973984122276306\n",
      "test epoch: 4/11, round: 2/501, loss: 0.2994649112224579\n",
      "test epoch: 4/11, round: 3/501, loss: 0.2328028827905655\n",
      "test epoch: 4/11, round: 4/501, loss: 0.3724810779094696\n",
      "test epoch: 4/11, round: 5/501, loss: 0.39677804708480835\n",
      "test epoch: 4/11, round: 6/501, loss: 0.3484899401664734\n",
      "test epoch: 4/11, round: 7/501, loss: 0.4631138741970062\n",
      "test epoch: 4/11, round: 8/501, loss: 0.4428720474243164\n",
      "test epoch: 4/11, round: 9/501, loss: 0.5974291563034058\n",
      "test epoch: 4/11, round: 10/501, loss: 0.6457154154777527\n",
      "test epoch: 4/11, round: 11/501, loss: 0.216862291097641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 4/11, round: 12/501, loss: 0.35410892963409424\n",
      "test epoch: 4/11, round: 13/501, loss: 0.32568931579589844\n",
      "test epoch: 4/11, round: 14/501, loss: 0.31599894165992737\n",
      "test epoch: 4/11, round: 15/501, loss: 0.4862963855266571\n",
      "test epoch: 4/11, round: 16/501, loss: 0.47851887345314026\n",
      "test epoch: 4/11, round: 17/501, loss: 0.4092242419719696\n",
      "test epoch: 4/11, round: 18/501, loss: 0.49393174052238464\n",
      "test epoch: 4/11, round: 19/501, loss: 0.5475783944129944\n",
      "test epoch: 4/11, round: 20/501, loss: 0.7610218524932861\n",
      "test epoch: 4/11, round: 21/501, loss: 0.4350907504558563\n",
      "test epoch: 4/11, round: 22/501, loss: 0.6147230863571167\n",
      "test epoch: 4/11, round: 23/501, loss: 0.5059613585472107\n",
      "test epoch: 4/11, round: 24/501, loss: 0.4467758536338806\n",
      "test epoch: 4/11, round: 25/501, loss: 0.6334646344184875\n",
      "test epoch: 4/11, round: 26/501, loss: 0.638595700263977\n",
      "test epoch: 4/11, round: 27/501, loss: 0.23205681145191193\n",
      "test epoch: 4/11, round: 28/501, loss: 0.4914127290248871\n",
      "test epoch: 4/11, round: 29/501, loss: 0.27121537923812866\n",
      "test epoch: 4/11, round: 30/501, loss: 0.5269864797592163\n",
      "test epoch: 4/11, round: 31/501, loss: 0.498418927192688\n",
      "test epoch: 4/11, round: 32/501, loss: 0.5744979977607727\n",
      "test epoch: 4/11, round: 33/501, loss: 0.586923360824585\n",
      "test epoch: 4/11, round: 34/501, loss: 0.5017133355140686\n",
      "test epoch: 4/11, round: 35/501, loss: 0.14709140360355377\n",
      "test epoch: 4/11, round: 36/501, loss: 0.4510159194469452\n",
      "test epoch: 4/11, round: 37/501, loss: 0.4231177866458893\n",
      "test epoch: 4/11, round: 38/501, loss: 0.4165264070034027\n",
      "test epoch: 4/11, round: 39/501, loss: 0.6923336386680603\n",
      "test epoch: 4/11, round: 40/501, loss: 0.6186440587043762\n",
      "test epoch: 4/11, round: 41/501, loss: 0.42225825786590576\n",
      "test epoch: 4/11, round: 42/501, loss: 0.39470118284225464\n",
      "test epoch: 4/11, round: 43/501, loss: 0.36591750383377075\n",
      "test epoch: 4/11, round: 44/501, loss: 0.5999024510383606\n",
      "test epoch: 4/11, round: 45/501, loss: 0.6653236150741577\n",
      "test epoch: 4/11, round: 46/501, loss: 0.49653181433677673\n",
      "test epoch: 4/11, round: 47/501, loss: 0.24543753266334534\n",
      "test epoch: 4/11, round: 48/501, loss: 0.5353514552116394\n",
      "test epoch: 4/11, round: 49/501, loss: 0.3153420388698578\n",
      "test epoch: 4/11, round: 50/501, loss: 0.19596093893051147\n",
      "test epoch: 4/11, round: 51/501, loss: 0.4662984311580658\n",
      "test epoch: 4/11, round: 52/501, loss: 0.433624267578125\n",
      "test epoch: 4/11, round: 53/501, loss: 0.5066332221031189\n",
      "test epoch: 4/11, round: 54/501, loss: 0.5698769688606262\n",
      "test epoch: 4/11, round: 55/501, loss: 0.33398640155792236\n",
      "test epoch: 4/11, round: 56/501, loss: 0.46238547563552856\n",
      "test epoch: 4/11, round: 57/501, loss: 0.36760321259498596\n",
      "test epoch: 4/11, round: 58/501, loss: 0.47249355912208557\n",
      "test epoch: 4/11, round: 59/501, loss: 0.2420012503862381\n",
      "test epoch: 4/11, round: 60/501, loss: 0.4981260895729065\n",
      "test epoch: 4/11, round: 61/501, loss: 0.40096911787986755\n",
      "test epoch: 4/11, round: 62/501, loss: 0.6928775310516357\n",
      "test epoch: 4/11, round: 63/501, loss: 0.8264448046684265\n",
      "test epoch: 4/11, round: 64/501, loss: 0.2404932677745819\n",
      "test epoch: 4/11, round: 65/501, loss: 0.6337708830833435\n",
      "test epoch: 4/11, round: 66/501, loss: 0.42042145133018494\n",
      "test epoch: 4/11, round: 67/501, loss: 0.5420656800270081\n",
      "test epoch: 4/11, round: 68/501, loss: 0.6703869104385376\n",
      "test epoch: 4/11, round: 69/501, loss: 0.45197805762290955\n",
      "test epoch: 4/11, round: 70/501, loss: 0.44117873907089233\n",
      "test epoch: 4/11, round: 71/501, loss: 0.5951530933380127\n",
      "test epoch: 4/11, round: 72/501, loss: 0.5464362502098083\n",
      "test epoch: 4/11, round: 73/501, loss: 0.46959051489830017\n",
      "test epoch: 4/11, round: 74/501, loss: 0.48390260338783264\n",
      "test epoch: 4/11, round: 75/501, loss: 0.5587493181228638\n",
      "test epoch: 4/11, round: 76/501, loss: 0.7612679600715637\n",
      "test epoch: 4/11, round: 77/501, loss: 0.3491141200065613\n",
      "test epoch: 4/11, round: 78/501, loss: 0.6459518074989319\n",
      "test epoch: 4/11, round: 79/501, loss: 0.39549192786216736\n",
      "test epoch: 4/11, round: 80/501, loss: 0.5838662981987\n",
      "test epoch: 4/11, round: 81/501, loss: 0.8025224208831787\n",
      "test epoch: 4/11, round: 82/501, loss: 0.6234763860702515\n",
      "test epoch: 4/11, round: 83/501, loss: 0.4249509274959564\n",
      "test epoch: 4/11, round: 84/501, loss: 0.6638756394386292\n",
      "test epoch: 4/11, round: 85/501, loss: 0.5793635845184326\n",
      "test epoch: 4/11, round: 86/501, loss: 0.3166861832141876\n",
      "test epoch: 4/11, round: 87/501, loss: 0.46434077620506287\n",
      "test epoch: 4/11, round: 88/501, loss: 0.3360541760921478\n",
      "test epoch: 4/11, round: 89/501, loss: 0.3332323431968689\n",
      "test epoch: 4/11, round: 90/501, loss: 0.7186608910560608\n",
      "test epoch: 4/11, round: 91/501, loss: 0.3238728940486908\n",
      "test epoch: 4/11, round: 92/501, loss: 0.5939744710922241\n",
      "test epoch: 4/11, round: 93/501, loss: 0.4470893144607544\n",
      "test epoch: 4/11, round: 94/501, loss: 0.6454970836639404\n",
      "test epoch: 4/11, round: 95/501, loss: 0.37637683749198914\n",
      "test epoch: 4/11, round: 96/501, loss: 0.3622906506061554\n",
      "test epoch: 4/11, round: 97/501, loss: 0.6480622887611389\n",
      "test epoch: 4/11, round: 98/501, loss: 0.4021892547607422\n",
      "test epoch: 4/11, round: 99/501, loss: 0.5696058869361877\n",
      "test epoch: 4/11, round: 100/501, loss: 0.5263256430625916\n",
      "test epoch: 4/11, round: 101/501, loss: 0.5533052086830139\n",
      "test epoch: 4/11, round: 102/501, loss: 0.30589327216148376\n",
      "test epoch: 4/11, round: 103/501, loss: 0.4311569929122925\n",
      "test epoch: 4/11, round: 104/501, loss: 0.7069753408432007\n",
      "test epoch: 4/11, round: 105/501, loss: 0.34993693232536316\n",
      "test epoch: 4/11, round: 106/501, loss: 0.6007834076881409\n",
      "test epoch: 4/11, round: 107/501, loss: 0.2885860800743103\n",
      "test epoch: 4/11, round: 108/501, loss: 0.5518075227737427\n",
      "test epoch: 4/11, round: 109/501, loss: 0.3580299913883209\n",
      "test epoch: 4/11, round: 110/501, loss: 0.8180914521217346\n",
      "test epoch: 4/11, round: 111/501, loss: 0.2085927277803421\n",
      "test epoch: 4/11, round: 112/501, loss: 0.20506611466407776\n",
      "test epoch: 4/11, round: 113/501, loss: 0.37791183590888977\n",
      "test epoch: 4/11, round: 114/501, loss: 0.3603496551513672\n",
      "test epoch: 4/11, round: 115/501, loss: 0.28338465094566345\n",
      "test epoch: 4/11, round: 116/501, loss: 0.33147621154785156\n",
      "test epoch: 4/11, round: 117/501, loss: 0.32563626766204834\n",
      "test epoch: 4/11, round: 118/501, loss: 0.29401636123657227\n",
      "test epoch: 4/11, round: 119/501, loss: 0.3112010657787323\n",
      "test epoch: 4/11, round: 120/501, loss: 0.4201526641845703\n",
      "test epoch: 4/11, round: 121/501, loss: 0.40738731622695923\n",
      "test epoch: 4/11, round: 122/501, loss: 0.39633262157440186\n",
      "test epoch: 4/11, round: 123/501, loss: 0.39263781905174255\n",
      "test epoch: 4/11, round: 124/501, loss: 0.6172899603843689\n",
      "test epoch: 4/11, round: 125/501, loss: 0.4166378974914551\n",
      "test epoch: 4/11, round: 126/501, loss: 0.35327452421188354\n",
      "test epoch: 4/11, round: 127/501, loss: 0.41529661417007446\n",
      "test epoch: 4/11, round: 128/501, loss: 0.18085524439811707\n",
      "test epoch: 4/11, round: 129/501, loss: 0.4697292447090149\n",
      "test epoch: 4/11, round: 130/501, loss: 0.795265257358551\n",
      "test epoch: 4/11, round: 131/501, loss: 0.6760513186454773\n",
      "test epoch: 4/11, round: 132/501, loss: 0.4382387399673462\n",
      "test epoch: 4/11, round: 133/501, loss: 0.7768587470054626\n",
      "test epoch: 4/11, round: 134/501, loss: 0.49979811906814575\n",
      "test epoch: 4/11, round: 135/501, loss: 0.29311439394950867\n",
      "test epoch: 4/11, round: 136/501, loss: 0.44709861278533936\n",
      "test epoch: 4/11, round: 137/501, loss: 0.37162160873413086\n",
      "test epoch: 4/11, round: 138/501, loss: 0.4166053831577301\n",
      "test epoch: 4/11, round: 139/501, loss: 0.5683423280715942\n",
      "test epoch: 4/11, round: 140/501, loss: 0.441366970539093\n",
      "test epoch: 4/11, round: 141/501, loss: 0.2920878827571869\n",
      "test epoch: 4/11, round: 142/501, loss: 0.6085051894187927\n",
      "test epoch: 4/11, round: 143/501, loss: 0.3984758257865906\n",
      "test epoch: 4/11, round: 144/501, loss: 0.43620580434799194\n",
      "test epoch: 4/11, round: 145/501, loss: 0.33844202756881714\n",
      "test epoch: 4/11, round: 146/501, loss: 0.6454355716705322\n",
      "test epoch: 4/11, round: 147/501, loss: 0.46240293979644775\n",
      "test epoch: 4/11, round: 148/501, loss: 0.5067057013511658\n",
      "test epoch: 4/11, round: 149/501, loss: 0.37359854578971863\n",
      "test epoch: 4/11, round: 150/501, loss: 0.6029193997383118\n",
      "test epoch: 4/11, round: 151/501, loss: 0.4489237368106842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 4/11, round: 152/501, loss: 0.5084524154663086\n",
      "test epoch: 4/11, round: 153/501, loss: 0.6027807593345642\n",
      "test epoch: 4/11, round: 154/501, loss: 0.58971107006073\n",
      "test epoch: 4/11, round: 155/501, loss: 0.39416390657424927\n",
      "test epoch: 4/11, round: 156/501, loss: 0.23563390970230103\n",
      "test epoch: 4/11, round: 157/501, loss: 0.2988570034503937\n",
      "test epoch: 4/11, round: 158/501, loss: 0.4017665982246399\n",
      "test epoch: 4/11, round: 159/501, loss: 0.3772217333316803\n",
      "test epoch: 4/11, round: 160/501, loss: 0.32751426100730896\n",
      "test epoch: 4/11, round: 161/501, loss: 0.3399585783481598\n",
      "test epoch: 4/11, round: 162/501, loss: 0.483158141374588\n",
      "test epoch: 4/11, round: 163/501, loss: 0.4562821090221405\n",
      "test epoch: 4/11, round: 164/501, loss: 0.33012261986732483\n",
      "test epoch: 4/11, round: 165/501, loss: 0.47138386964797974\n",
      "test epoch: 4/11, round: 166/501, loss: 0.2619079053401947\n",
      "test epoch: 4/11, round: 167/501, loss: 0.16733840107917786\n",
      "test epoch: 4/11, round: 168/501, loss: 0.12219800800085068\n",
      "test epoch: 4/11, round: 169/501, loss: 0.3415948748588562\n",
      "test epoch: 4/11, round: 170/501, loss: 0.3603549897670746\n",
      "test epoch: 4/11, round: 171/501, loss: 0.4750900864601135\n",
      "test epoch: 4/11, round: 172/501, loss: 0.5429742336273193\n",
      "test epoch: 4/11, round: 173/501, loss: 0.28859370946884155\n",
      "test epoch: 4/11, round: 174/501, loss: 0.6313574910163879\n",
      "test epoch: 4/11, round: 175/501, loss: 0.22883263230323792\n",
      "test epoch: 4/11, round: 176/501, loss: 0.5677383542060852\n",
      "test epoch: 4/11, round: 177/501, loss: 0.2599204182624817\n",
      "test epoch: 4/11, round: 178/501, loss: 0.17565830051898956\n",
      "test epoch: 4/11, round: 179/501, loss: 0.1686840057373047\n",
      "test epoch: 4/11, round: 180/501, loss: 0.25344741344451904\n",
      "test epoch: 4/11, round: 181/501, loss: 0.5817206501960754\n",
      "test epoch: 4/11, round: 182/501, loss: 0.5674065947532654\n",
      "test epoch: 4/11, round: 183/501, loss: 0.4415903687477112\n",
      "test epoch: 4/11, round: 184/501, loss: 0.5158030986785889\n",
      "test epoch: 4/11, round: 185/501, loss: 0.4659596383571625\n",
      "test epoch: 4/11, round: 186/501, loss: 0.6572971343994141\n",
      "test epoch: 4/11, round: 187/501, loss: 0.5038334727287292\n",
      "test epoch: 4/11, round: 188/501, loss: 0.47300633788108826\n",
      "test epoch: 4/11, round: 189/501, loss: 0.6907145977020264\n",
      "test epoch: 4/11, round: 190/501, loss: 0.4738820791244507\n",
      "test epoch: 4/11, round: 191/501, loss: 0.31033262610435486\n",
      "test epoch: 4/11, round: 192/501, loss: 0.5980460047721863\n",
      "test epoch: 4/11, round: 193/501, loss: 0.48799437284469604\n",
      "test epoch: 4/11, round: 194/501, loss: 0.4825458824634552\n",
      "test epoch: 4/11, round: 195/501, loss: 0.5528191924095154\n",
      "test epoch: 4/11, round: 196/501, loss: 0.2863622307777405\n",
      "test epoch: 4/11, round: 197/501, loss: 0.4063400328159332\n",
      "test epoch: 4/11, round: 198/501, loss: 0.48817339539527893\n",
      "test epoch: 4/11, round: 199/501, loss: 0.5280593037605286\n",
      "test epoch: 4/11, round: 200/501, loss: 0.654388964176178\n",
      "test epoch: 4/11, round: 201/501, loss: 0.31582218408584595\n",
      "test epoch: 4/11, round: 202/501, loss: 0.3340816795825958\n",
      "test epoch: 4/11, round: 203/501, loss: 0.46292632818222046\n",
      "test epoch: 4/11, round: 204/501, loss: 0.6103731393814087\n",
      "test epoch: 4/11, round: 205/501, loss: 0.4123135507106781\n",
      "test epoch: 4/11, round: 206/501, loss: 0.22724966704845428\n",
      "test epoch: 4/11, round: 207/501, loss: 0.38922253251075745\n",
      "test epoch: 4/11, round: 208/501, loss: 0.4926968216896057\n",
      "test epoch: 4/11, round: 209/501, loss: 0.29498279094696045\n",
      "test epoch: 4/11, round: 210/501, loss: 0.49450168013572693\n",
      "test epoch: 4/11, round: 211/501, loss: 0.2398291677236557\n",
      "test epoch: 4/11, round: 212/501, loss: 0.292143315076828\n",
      "test epoch: 4/11, round: 213/501, loss: 0.26163944602012634\n",
      "test epoch: 4/11, round: 214/501, loss: 0.15516676008701324\n",
      "test epoch: 4/11, round: 215/501, loss: 0.11245763301849365\n",
      "test epoch: 4/11, round: 216/501, loss: 0.12132929265499115\n",
      "test epoch: 4/11, round: 217/501, loss: 0.1047251969575882\n",
      "test epoch: 4/11, round: 218/501, loss: 0.13686780631542206\n",
      "test epoch: 4/11, round: 219/501, loss: 0.18342804908752441\n",
      "test epoch: 4/11, round: 220/501, loss: 0.38292211294174194\n",
      "test epoch: 4/11, round: 221/501, loss: 0.3533901572227478\n",
      "test epoch: 4/11, round: 222/501, loss: 0.10066213458776474\n",
      "test epoch: 4/11, round: 223/501, loss: 0.12781701982021332\n",
      "test epoch: 4/11, round: 224/501, loss: 0.11898894608020782\n",
      "test epoch: 4/11, round: 225/501, loss: 0.10795257240533829\n",
      "test epoch: 4/11, round: 226/501, loss: 0.1038801446557045\n",
      "test epoch: 4/11, round: 227/501, loss: 0.15497885644435883\n",
      "test epoch: 4/11, round: 228/501, loss: 0.18794196844100952\n",
      "test epoch: 4/11, round: 229/501, loss: 0.41906148195266724\n",
      "test epoch: 4/11, round: 230/501, loss: 0.2562861442565918\n",
      "test epoch: 4/11, round: 231/501, loss: 0.30367061495780945\n",
      "test epoch: 4/11, round: 232/501, loss: 0.41628584265708923\n",
      "test epoch: 4/11, round: 233/501, loss: 0.5098476409912109\n",
      "test epoch: 4/11, round: 234/501, loss: 0.4823351800441742\n",
      "test epoch: 4/11, round: 235/501, loss: 0.25256994366645813\n",
      "test epoch: 4/11, round: 236/501, loss: 0.3212457001209259\n",
      "test epoch: 4/11, round: 237/501, loss: 0.3244727551937103\n",
      "test epoch: 4/11, round: 238/501, loss: 0.3277931213378906\n",
      "test epoch: 4/11, round: 239/501, loss: 0.4323461651802063\n",
      "test epoch: 4/11, round: 240/501, loss: 0.20567919313907623\n",
      "test epoch: 4/11, round: 241/501, loss: 0.39142316579818726\n",
      "test epoch: 4/11, round: 242/501, loss: 0.24130943417549133\n",
      "test epoch: 4/11, round: 243/501, loss: 0.26660192012786865\n",
      "test epoch: 4/11, round: 244/501, loss: 0.2790144681930542\n",
      "test epoch: 4/11, round: 245/501, loss: 0.3855668902397156\n",
      "test epoch: 4/11, round: 246/501, loss: 0.384326308965683\n",
      "test epoch: 4/11, round: 247/501, loss: 0.46525007486343384\n",
      "test epoch: 4/11, round: 248/501, loss: 0.19454005360603333\n",
      "test epoch: 4/11, round: 249/501, loss: 0.3210345506668091\n",
      "test epoch: 4/11, round: 250/501, loss: 0.2875886857509613\n",
      "test epoch: 4/11, round: 251/501, loss: 0.3442096710205078\n",
      "test epoch: 4/11, round: 252/501, loss: 0.28728580474853516\n",
      "test epoch: 4/11, round: 253/501, loss: 0.330303817987442\n",
      "test epoch: 4/11, round: 254/501, loss: 0.2708373963832855\n",
      "test epoch: 4/11, round: 255/501, loss: 0.33365240693092346\n",
      "test epoch: 4/11, round: 256/501, loss: 0.4411452114582062\n",
      "test epoch: 4/11, round: 257/501, loss: 0.3584538400173187\n",
      "test epoch: 4/11, round: 258/501, loss: 0.39194777607917786\n",
      "test epoch: 4/11, round: 259/501, loss: 0.23317572474479675\n",
      "test epoch: 4/11, round: 260/501, loss: 0.4702794849872589\n",
      "test epoch: 4/11, round: 261/501, loss: 0.5457204580307007\n",
      "test epoch: 4/11, round: 262/501, loss: 0.45789462327957153\n",
      "test epoch: 4/11, round: 263/501, loss: 0.3912122845649719\n",
      "test epoch: 4/11, round: 264/501, loss: 0.47049781680107117\n",
      "test epoch: 4/11, round: 265/501, loss: 0.6374430060386658\n",
      "test epoch: 4/11, round: 266/501, loss: 0.38110026717185974\n",
      "test epoch: 4/11, round: 267/501, loss: 0.3703441321849823\n",
      "test epoch: 4/11, round: 268/501, loss: 0.2659761905670166\n",
      "test epoch: 4/11, round: 269/501, loss: 0.4689141511917114\n",
      "test epoch: 4/11, round: 270/501, loss: 0.26063042879104614\n",
      "test epoch: 4/11, round: 271/501, loss: 0.5477166771888733\n",
      "test epoch: 4/11, round: 272/501, loss: 0.4306362271308899\n",
      "test epoch: 4/11, round: 273/501, loss: 0.3596489727497101\n",
      "test epoch: 4/11, round: 274/501, loss: 0.5095797777175903\n",
      "test epoch: 4/11, round: 275/501, loss: 0.30187708139419556\n",
      "test epoch: 4/11, round: 276/501, loss: 0.3446420133113861\n",
      "test epoch: 4/11, round: 277/501, loss: 0.3874594271183014\n",
      "test epoch: 4/11, round: 278/501, loss: 0.6420825123786926\n",
      "test epoch: 4/11, round: 279/501, loss: 0.31419387459754944\n",
      "test epoch: 4/11, round: 280/501, loss: 0.1672978699207306\n",
      "test epoch: 4/11, round: 281/501, loss: 0.14619861543178558\n",
      "test epoch: 4/11, round: 282/501, loss: 0.23954330384731293\n",
      "test epoch: 4/11, round: 283/501, loss: 0.24017122387886047\n",
      "test epoch: 4/11, round: 284/501, loss: 0.3733217120170593\n",
      "test epoch: 4/11, round: 285/501, loss: 0.4870239198207855\n",
      "test epoch: 4/11, round: 286/501, loss: 0.33702611923217773\n",
      "test epoch: 4/11, round: 287/501, loss: 0.5459907650947571\n",
      "test epoch: 4/11, round: 288/501, loss: 0.21611028909683228\n",
      "test epoch: 4/11, round: 289/501, loss: 0.3393224775791168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 4/11, round: 290/501, loss: 0.3367862105369568\n",
      "test epoch: 4/11, round: 291/501, loss: 0.5786649584770203\n",
      "test epoch: 4/11, round: 292/501, loss: 0.5021764636039734\n",
      "test epoch: 4/11, round: 293/501, loss: 0.578682005405426\n",
      "test epoch: 4/11, round: 294/501, loss: 0.21421022713184357\n",
      "test epoch: 4/11, round: 295/501, loss: 0.31165754795074463\n",
      "test epoch: 4/11, round: 296/501, loss: 0.45211726427078247\n",
      "test epoch: 4/11, round: 297/501, loss: 0.3625123202800751\n",
      "test epoch: 4/11, round: 298/501, loss: 0.3884645402431488\n",
      "test epoch: 4/11, round: 299/501, loss: 0.4356403052806854\n",
      "test epoch: 4/11, round: 300/501, loss: 0.5998476147651672\n",
      "test epoch: 4/11, round: 301/501, loss: 0.3565923571586609\n",
      "test epoch: 4/11, round: 302/501, loss: 0.1935875564813614\n",
      "test epoch: 4/11, round: 303/501, loss: 0.658591628074646\n",
      "test epoch: 4/11, round: 304/501, loss: 0.6509389877319336\n",
      "test epoch: 4/11, round: 305/501, loss: 0.14427782595157623\n",
      "test epoch: 4/11, round: 306/501, loss: 0.22973795235157013\n",
      "test epoch: 4/11, round: 307/501, loss: 0.4479157328605652\n",
      "test epoch: 4/11, round: 308/501, loss: 0.25626593828201294\n",
      "test epoch: 4/11, round: 309/501, loss: 0.4724408984184265\n",
      "test epoch: 4/11, round: 310/501, loss: 0.3999205231666565\n",
      "test epoch: 4/11, round: 311/501, loss: 0.6177424192428589\n",
      "test epoch: 4/11, round: 312/501, loss: 0.34759265184402466\n",
      "test epoch: 4/11, round: 313/501, loss: 0.3287791907787323\n",
      "test epoch: 4/11, round: 314/501, loss: 0.3084939122200012\n",
      "test epoch: 4/11, round: 315/501, loss: 0.28335195779800415\n",
      "test epoch: 4/11, round: 316/501, loss: 0.32305005192756653\n",
      "test epoch: 4/11, round: 317/501, loss: 0.3699798882007599\n",
      "test epoch: 4/11, round: 318/501, loss: 0.38260719180107117\n",
      "test epoch: 4/11, round: 319/501, loss: 0.5950702428817749\n",
      "test epoch: 4/11, round: 320/501, loss: 0.39660879969596863\n",
      "test epoch: 4/11, round: 321/501, loss: 0.300021767616272\n",
      "test epoch: 4/11, round: 322/501, loss: 0.4673559069633484\n",
      "test epoch: 4/11, round: 323/501, loss: 0.48139041662216187\n",
      "test epoch: 4/11, round: 324/501, loss: 0.3022502064704895\n",
      "test epoch: 4/11, round: 325/501, loss: 0.45026957988739014\n",
      "test epoch: 4/11, round: 326/501, loss: 0.44851094484329224\n",
      "test epoch: 4/11, round: 327/501, loss: 0.6447716355323792\n",
      "test epoch: 4/11, round: 328/501, loss: 0.1741635501384735\n",
      "test epoch: 4/11, round: 329/501, loss: 0.4567471444606781\n",
      "test epoch: 4/11, round: 330/501, loss: 0.5331871509552002\n",
      "test epoch: 4/11, round: 331/501, loss: 0.4289373457431793\n",
      "test epoch: 4/11, round: 332/501, loss: 0.35276931524276733\n",
      "test epoch: 4/11, round: 333/501, loss: 0.3740958869457245\n",
      "test epoch: 4/11, round: 334/501, loss: 0.25516775250434875\n",
      "test epoch: 4/11, round: 335/501, loss: 0.37231704592704773\n",
      "test epoch: 4/11, round: 336/501, loss: 0.35989513993263245\n",
      "test epoch: 4/11, round: 337/501, loss: 0.6346757411956787\n",
      "test epoch: 4/11, round: 338/501, loss: 0.4003179371356964\n",
      "test epoch: 4/11, round: 339/501, loss: 0.9894537329673767\n",
      "test epoch: 4/11, round: 340/501, loss: 0.49460774660110474\n",
      "test epoch: 4/11, round: 341/501, loss: 0.43494364619255066\n",
      "test epoch: 4/11, round: 342/501, loss: 0.36716416478157043\n",
      "test epoch: 4/11, round: 343/501, loss: 0.35921892523765564\n",
      "test epoch: 4/11, round: 344/501, loss: 0.23229926824569702\n",
      "test epoch: 4/11, round: 345/501, loss: 0.20287984609603882\n",
      "test epoch: 4/11, round: 346/501, loss: 0.30450159311294556\n",
      "test epoch: 4/11, round: 347/501, loss: 0.3363039195537567\n",
      "test epoch: 4/11, round: 348/501, loss: 0.4070102572441101\n",
      "test epoch: 4/11, round: 349/501, loss: 0.34792986512184143\n",
      "test epoch: 4/11, round: 350/501, loss: 0.4969251751899719\n",
      "test epoch: 4/11, round: 351/501, loss: 0.3860844671726227\n",
      "test epoch: 4/11, round: 352/501, loss: 0.46727341413497925\n",
      "test epoch: 4/11, round: 353/501, loss: 0.38531601428985596\n",
      "test epoch: 4/11, round: 354/501, loss: 0.5508154034614563\n",
      "test epoch: 4/11, round: 355/501, loss: 0.3618941009044647\n",
      "test epoch: 4/11, round: 356/501, loss: 0.6140856146812439\n",
      "test epoch: 4/11, round: 357/501, loss: 0.4510502517223358\n",
      "test epoch: 4/11, round: 358/501, loss: 0.4477505385875702\n",
      "test epoch: 4/11, round: 359/501, loss: 0.3916839063167572\n",
      "test epoch: 4/11, round: 360/501, loss: 0.5919421911239624\n",
      "test epoch: 4/11, round: 361/501, loss: 0.5867023468017578\n",
      "test epoch: 4/11, round: 362/501, loss: 0.39866480231285095\n",
      "test epoch: 4/11, round: 363/501, loss: 0.5365254878997803\n",
      "test epoch: 4/11, round: 364/501, loss: 0.5635319948196411\n",
      "test epoch: 4/11, round: 365/501, loss: 0.39864635467529297\n",
      "test epoch: 4/11, round: 366/501, loss: 0.6591619253158569\n",
      "test epoch: 4/11, round: 367/501, loss: 0.7026675939559937\n",
      "test epoch: 4/11, round: 368/501, loss: 0.2601025402545929\n",
      "test epoch: 4/11, round: 369/501, loss: 0.31450405716896057\n",
      "test epoch: 4/11, round: 370/501, loss: 0.44062504172325134\n",
      "test epoch: 4/11, round: 371/501, loss: 0.42179134488105774\n",
      "test epoch: 4/11, round: 372/501, loss: 0.35869741439819336\n",
      "test epoch: 4/11, round: 373/501, loss: 0.4496869444847107\n",
      "test epoch: 4/11, round: 374/501, loss: 0.33853858709335327\n",
      "test epoch: 4/11, round: 375/501, loss: 0.48376062512397766\n",
      "test epoch: 4/11, round: 376/501, loss: 0.6037737727165222\n",
      "test epoch: 4/11, round: 377/501, loss: 0.10303617268800735\n",
      "test epoch: 4/11, round: 378/501, loss: 0.11743629723787308\n",
      "test epoch: 4/11, round: 379/501, loss: 0.46284469962120056\n",
      "test epoch: 4/11, round: 380/501, loss: 0.26708489656448364\n",
      "test epoch: 4/11, round: 381/501, loss: 0.46458521485328674\n",
      "test epoch: 4/11, round: 382/501, loss: 0.23529648780822754\n",
      "test epoch: 4/11, round: 383/501, loss: 0.33401644229888916\n",
      "test epoch: 4/11, round: 384/501, loss: 0.21137575805187225\n",
      "test epoch: 4/11, round: 385/501, loss: 0.5045430660247803\n",
      "test epoch: 4/11, round: 386/501, loss: 0.5980921387672424\n",
      "test epoch: 4/11, round: 387/501, loss: 0.26061350107192993\n",
      "test epoch: 4/11, round: 388/501, loss: 0.25824272632598877\n",
      "test epoch: 4/11, round: 389/501, loss: 0.2918958067893982\n",
      "test epoch: 4/11, round: 390/501, loss: 0.4120313823223114\n",
      "test epoch: 4/11, round: 391/501, loss: 0.36738836765289307\n",
      "test epoch: 4/11, round: 392/501, loss: 0.44928133487701416\n",
      "test epoch: 4/11, round: 393/501, loss: 0.40571674704551697\n",
      "test epoch: 4/11, round: 394/501, loss: 0.6975677013397217\n",
      "test epoch: 4/11, round: 395/501, loss: 0.21865420043468475\n",
      "test epoch: 4/11, round: 396/501, loss: 0.4197811484336853\n",
      "test epoch: 4/11, round: 397/501, loss: 0.527549147605896\n",
      "test epoch: 4/11, round: 398/501, loss: 0.49990272521972656\n",
      "test epoch: 4/11, round: 399/501, loss: 0.31995028257369995\n",
      "test epoch: 4/11, round: 400/501, loss: 0.2865872383117676\n",
      "test epoch: 4/11, round: 401/501, loss: 0.6917074918746948\n",
      "test epoch: 4/11, round: 402/501, loss: 0.47760385274887085\n",
      "test epoch: 4/11, round: 403/501, loss: 0.2743185758590698\n",
      "test epoch: 4/11, round: 404/501, loss: 0.20920512080192566\n",
      "test epoch: 4/11, round: 405/501, loss: 0.8566337823867798\n",
      "test epoch: 4/11, round: 406/501, loss: 0.46644723415374756\n",
      "test epoch: 4/11, round: 407/501, loss: 0.543067991733551\n",
      "test epoch: 4/11, round: 408/501, loss: 0.5862447023391724\n",
      "test epoch: 4/11, round: 409/501, loss: 0.6133424043655396\n",
      "test epoch: 4/11, round: 410/501, loss: 0.351066917181015\n",
      "test epoch: 4/11, round: 411/501, loss: 0.42277559638023376\n",
      "test epoch: 4/11, round: 412/501, loss: 0.4124056398868561\n",
      "test epoch: 4/11, round: 413/501, loss: 0.5048304796218872\n",
      "test epoch: 4/11, round: 414/501, loss: 0.34697067737579346\n",
      "test epoch: 4/11, round: 415/501, loss: 0.3871397078037262\n",
      "test epoch: 4/11, round: 416/501, loss: 0.4115300476551056\n",
      "test epoch: 4/11, round: 417/501, loss: 0.23815512657165527\n",
      "test epoch: 4/11, round: 418/501, loss: 0.29875048995018005\n",
      "test epoch: 4/11, round: 419/501, loss: 0.3703180253505707\n",
      "test epoch: 4/11, round: 420/501, loss: 0.3106139004230499\n",
      "test epoch: 4/11, round: 421/501, loss: 0.3943749666213989\n",
      "test epoch: 4/11, round: 422/501, loss: 0.47324231266975403\n",
      "test epoch: 4/11, round: 423/501, loss: 0.6822034120559692\n",
      "test epoch: 4/11, round: 424/501, loss: 0.4543965756893158\n",
      "test epoch: 4/11, round: 425/501, loss: 0.32222387194633484\n",
      "test epoch: 4/11, round: 426/501, loss: 0.5167838335037231\n",
      "test epoch: 4/11, round: 427/501, loss: 0.3039768934249878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 4/11, round: 428/501, loss: 0.5259690880775452\n",
      "test epoch: 4/11, round: 429/501, loss: 0.616436779499054\n",
      "test epoch: 4/11, round: 430/501, loss: 0.6572915315628052\n",
      "test epoch: 4/11, round: 431/501, loss: 0.3971811532974243\n",
      "test epoch: 4/11, round: 432/501, loss: 0.35297998785972595\n",
      "test epoch: 4/11, round: 433/501, loss: 0.45099762082099915\n",
      "test epoch: 4/11, round: 434/501, loss: 0.31054675579071045\n",
      "test epoch: 4/11, round: 435/501, loss: 0.3129884600639343\n",
      "test epoch: 4/11, round: 436/501, loss: 0.36637720465660095\n",
      "test epoch: 4/11, round: 437/501, loss: 0.49549242854118347\n",
      "test epoch: 4/11, round: 438/501, loss: 0.5966746211051941\n",
      "test epoch: 4/11, round: 439/501, loss: 0.3657732605934143\n",
      "test epoch: 4/11, round: 440/501, loss: 0.5002790093421936\n",
      "test epoch: 4/11, round: 441/501, loss: 0.39867985248565674\n",
      "test epoch: 4/11, round: 442/501, loss: 0.34933948516845703\n",
      "test epoch: 4/11, round: 443/501, loss: 0.24082094430923462\n",
      "test epoch: 4/11, round: 444/501, loss: 0.40997403860092163\n",
      "test epoch: 4/11, round: 445/501, loss: 0.44136765599250793\n",
      "test epoch: 4/11, round: 446/501, loss: 0.5486850738525391\n",
      "test epoch: 4/11, round: 447/501, loss: 0.22137035429477692\n",
      "test epoch: 4/11, round: 448/501, loss: 0.315606951713562\n",
      "test epoch: 4/11, round: 449/501, loss: 0.20602545142173767\n",
      "test epoch: 4/11, round: 450/501, loss: 0.7302305102348328\n",
      "test epoch: 4/11, round: 451/501, loss: 0.35017603635787964\n",
      "test epoch: 4/11, round: 452/501, loss: 0.43485021591186523\n",
      "test epoch: 4/11, round: 453/501, loss: 0.12011706084012985\n",
      "test epoch: 4/11, round: 454/501, loss: 0.21309417486190796\n",
      "test epoch: 4/11, round: 455/501, loss: 0.5448792576789856\n",
      "test epoch: 4/11, round: 456/501, loss: 0.28885725140571594\n",
      "test epoch: 4/11, round: 457/501, loss: 0.190487802028656\n",
      "test epoch: 4/11, round: 458/501, loss: 0.23521389067173004\n",
      "test epoch: 4/11, round: 459/501, loss: 0.12862664461135864\n",
      "test epoch: 4/11, round: 460/501, loss: 0.12576760351657867\n",
      "test epoch: 4/11, round: 461/501, loss: 0.11528463661670685\n",
      "test epoch: 4/11, round: 462/501, loss: 0.11076890677213669\n",
      "test epoch: 4/11, round: 463/501, loss: 0.11405747383832932\n",
      "test epoch: 4/11, round: 464/501, loss: 0.11755544692277908\n",
      "test epoch: 4/11, round: 465/501, loss: 0.1490742415189743\n",
      "test epoch: 4/11, round: 466/501, loss: 0.12313392758369446\n",
      "test epoch: 4/11, round: 467/501, loss: 0.15099000930786133\n",
      "test epoch: 4/11, round: 468/501, loss: 0.12443602830171585\n",
      "test epoch: 4/11, round: 469/501, loss: 0.1325816661119461\n",
      "test epoch: 4/11, round: 470/501, loss: 0.11759787052869797\n",
      "test epoch: 4/11, round: 471/501, loss: 0.15596376359462738\n",
      "test epoch: 4/11, round: 472/501, loss: 0.13055215775966644\n",
      "test epoch: 4/11, round: 473/501, loss: 0.10708889365196228\n",
      "test epoch: 4/11, round: 474/501, loss: 0.1292990893125534\n",
      "test epoch: 4/11, round: 475/501, loss: 0.12617385387420654\n",
      "test epoch: 4/11, round: 476/501, loss: 0.0977008119225502\n",
      "test epoch: 4/11, round: 477/501, loss: 0.10768216103315353\n",
      "test epoch: 4/11, round: 478/501, loss: 0.10789290815591812\n",
      "test epoch: 4/11, round: 479/501, loss: 0.07987166196107864\n",
      "test epoch: 4/11, round: 480/501, loss: 0.09608820080757141\n",
      "test epoch: 4/11, round: 481/501, loss: 0.09937524050474167\n",
      "test epoch: 4/11, round: 482/501, loss: 0.09889639168977737\n",
      "test epoch: 4/11, round: 483/501, loss: 0.10855193436145782\n",
      "test epoch: 4/11, round: 484/501, loss: 0.1345711052417755\n",
      "test epoch: 4/11, round: 485/501, loss: 0.08736928552389145\n",
      "test epoch: 4/11, round: 486/501, loss: 0.09244231134653091\n",
      "test epoch: 4/11, round: 487/501, loss: 0.09073392301797867\n",
      "test epoch: 4/11, round: 488/501, loss: 0.13369394838809967\n",
      "test epoch: 4/11, round: 489/501, loss: 0.10038426518440247\n",
      "test epoch: 4/11, round: 490/501, loss: 0.07643251121044159\n",
      "test epoch: 4/11, round: 491/501, loss: 0.11370695382356644\n",
      "test epoch: 4/11, round: 492/501, loss: 0.10916389524936676\n",
      "test epoch: 4/11, round: 493/501, loss: 0.1223403587937355\n",
      "test epoch: 4/11, round: 494/501, loss: 0.13587337732315063\n",
      "test epoch: 4/11, round: 495/501, loss: 0.08341493457555771\n",
      "test epoch: 4/11, round: 496/501, loss: 0.11257065087556839\n",
      "test epoch: 4/11, round: 497/501, loss: 0.09069838374853134\n",
      "test epoch: 4/11, round: 498/501, loss: 0.08377072960138321\n",
      "test epoch: 4/11, round: 499/501, loss: 0.0775960236787796\n",
      "test epoch: 4/11, round: 500/501, loss: 0.3362387418746948\n",
      "test epoch: 4/11, round: 501/501, loss: 1.046407699584961\n",
      "test epoch: 4/11, KS: 0.2096319691776986, ROC: 0.6302221886223297\n",
      "cost time: 1992\n",
      "train epoch: 5/11, round: 1/532, loss: 0.3485106825828552\n",
      "train epoch: 5/11, round: 2/532, loss: 0.34657230973243713\n",
      "train epoch: 5/11, round: 3/532, loss: 0.36876970529556274\n",
      "train epoch: 5/11, round: 4/532, loss: 0.3387390077114105\n",
      "train epoch: 5/11, round: 5/532, loss: 0.2992861866950989\n",
      "train epoch: 5/11, round: 6/532, loss: 0.45197415351867676\n",
      "train epoch: 5/11, round: 7/532, loss: 0.414376437664032\n",
      "train epoch: 5/11, round: 8/532, loss: 0.45281872153282166\n",
      "train epoch: 5/11, round: 9/532, loss: 0.396352082490921\n",
      "train epoch: 5/11, round: 10/532, loss: 0.4278198778629303\n",
      "train epoch: 5/11, round: 11/532, loss: 0.40810173749923706\n",
      "train epoch: 5/11, round: 12/532, loss: 0.4005565643310547\n",
      "train epoch: 5/11, round: 13/532, loss: 0.3645936846733093\n",
      "train epoch: 5/11, round: 14/532, loss: 0.32752150297164917\n",
      "train epoch: 5/11, round: 15/532, loss: 0.33457809686660767\n",
      "train epoch: 5/11, round: 16/532, loss: 0.41303911805152893\n",
      "train epoch: 5/11, round: 17/532, loss: 0.4056550860404968\n",
      "train epoch: 5/11, round: 18/532, loss: 0.3646816611289978\n",
      "train epoch: 5/11, round: 19/532, loss: 0.3626346290111542\n",
      "train epoch: 5/11, round: 20/532, loss: 0.4261820912361145\n",
      "train epoch: 5/11, round: 21/532, loss: 0.41557708382606506\n",
      "train epoch: 5/11, round: 22/532, loss: 0.33862391114234924\n",
      "train epoch: 5/11, round: 23/532, loss: 0.4411148428916931\n",
      "train epoch: 5/11, round: 24/532, loss: 0.33569616079330444\n",
      "train epoch: 5/11, round: 25/532, loss: 0.3393712043762207\n",
      "train epoch: 5/11, round: 26/532, loss: 0.4836184084415436\n",
      "train epoch: 5/11, round: 27/532, loss: 0.41085973381996155\n",
      "train epoch: 5/11, round: 28/532, loss: 0.42607003450393677\n",
      "train epoch: 5/11, round: 29/532, loss: 0.41406407952308655\n",
      "train epoch: 5/11, round: 30/532, loss: 0.3970555365085602\n",
      "train epoch: 5/11, round: 31/532, loss: 0.3830886781215668\n",
      "train epoch: 5/11, round: 32/532, loss: 0.40865474939346313\n",
      "train epoch: 5/11, round: 33/532, loss: 0.384744793176651\n",
      "train epoch: 5/11, round: 34/532, loss: 0.4505404829978943\n",
      "train epoch: 5/11, round: 35/532, loss: 0.4410635828971863\n",
      "train epoch: 5/11, round: 36/532, loss: 0.44055575132369995\n",
      "train epoch: 5/11, round: 37/532, loss: 0.3981899321079254\n",
      "train epoch: 5/11, round: 38/532, loss: 0.3673204779624939\n",
      "train epoch: 5/11, round: 39/532, loss: 0.44671303033828735\n",
      "train epoch: 5/11, round: 40/532, loss: 0.3902915120124817\n",
      "train epoch: 5/11, round: 41/532, loss: 0.41331347823143005\n",
      "train epoch: 5/11, round: 42/532, loss: 0.39104071259498596\n",
      "train epoch: 5/11, round: 43/532, loss: 0.3802263140678406\n",
      "train epoch: 5/11, round: 44/532, loss: 0.3769519627094269\n",
      "train epoch: 5/11, round: 45/532, loss: 0.47966235876083374\n",
      "train epoch: 5/11, round: 46/532, loss: 0.3893709182739258\n",
      "train epoch: 5/11, round: 47/532, loss: 0.34693020582199097\n",
      "train epoch: 5/11, round: 48/532, loss: 0.3596220910549164\n",
      "train epoch: 5/11, round: 49/532, loss: 0.4319349229335785\n",
      "train epoch: 5/11, round: 50/532, loss: 0.28419071435928345\n",
      "train epoch: 5/11, round: 51/532, loss: 0.3507649600505829\n",
      "train epoch: 5/11, round: 52/532, loss: 0.37757426500320435\n",
      "train epoch: 5/11, round: 53/532, loss: 0.3884236216545105\n",
      "train epoch: 5/11, round: 54/532, loss: 0.4219951033592224\n",
      "train epoch: 5/11, round: 55/532, loss: 0.3989773690700531\n",
      "train epoch: 5/11, round: 56/532, loss: 0.36561647057533264\n",
      "train epoch: 5/11, round: 57/532, loss: 0.31735485792160034\n",
      "train epoch: 5/11, round: 58/532, loss: 0.25679340958595276\n",
      "train epoch: 5/11, round: 59/532, loss: 0.43284744024276733\n",
      "train epoch: 5/11, round: 60/532, loss: 0.48080316185951233\n",
      "train epoch: 5/11, round: 61/532, loss: 0.37569913268089294\n",
      "train epoch: 5/11, round: 62/532, loss: 0.4317612648010254\n",
      "train epoch: 5/11, round: 63/532, loss: 0.2527102828025818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5/11, round: 64/532, loss: 0.3921963572502136\n",
      "train epoch: 5/11, round: 65/532, loss: 0.4908682703971863\n",
      "train epoch: 5/11, round: 66/532, loss: 0.3707468509674072\n",
      "train epoch: 5/11, round: 67/532, loss: 0.3392913341522217\n",
      "train epoch: 5/11, round: 68/532, loss: 0.325267493724823\n",
      "train epoch: 5/11, round: 69/532, loss: 0.35398656129837036\n",
      "train epoch: 5/11, round: 70/532, loss: 0.42768508195877075\n",
      "train epoch: 5/11, round: 71/532, loss: 0.4022718369960785\n",
      "train epoch: 5/11, round: 72/532, loss: 0.3379944860935211\n",
      "train epoch: 5/11, round: 73/532, loss: 0.45218801498413086\n",
      "train epoch: 5/11, round: 74/532, loss: 0.45492464303970337\n",
      "train epoch: 5/11, round: 75/532, loss: 0.4493705630302429\n",
      "train epoch: 5/11, round: 76/532, loss: 0.37257450819015503\n",
      "train epoch: 5/11, round: 77/532, loss: 0.3281424343585968\n",
      "train epoch: 5/11, round: 78/532, loss: 0.3784148097038269\n",
      "train epoch: 5/11, round: 79/532, loss: 0.40099096298217773\n",
      "train epoch: 5/11, round: 80/532, loss: 0.3900935649871826\n",
      "train epoch: 5/11, round: 81/532, loss: 0.4828747808933258\n",
      "train epoch: 5/11, round: 82/532, loss: 0.39364150166511536\n",
      "train epoch: 5/11, round: 83/532, loss: 0.3704202473163605\n",
      "train epoch: 5/11, round: 84/532, loss: 0.5244797468185425\n",
      "train epoch: 5/11, round: 85/532, loss: 0.4004981517791748\n",
      "train epoch: 5/11, round: 86/532, loss: 0.37452512979507446\n",
      "train epoch: 5/11, round: 87/532, loss: 0.33724817633628845\n",
      "train epoch: 5/11, round: 88/532, loss: 0.41469311714172363\n",
      "train epoch: 5/11, round: 89/532, loss: 0.40266767144203186\n",
      "train epoch: 5/11, round: 90/532, loss: 0.41189223527908325\n",
      "train epoch: 5/11, round: 91/532, loss: 0.39538517594337463\n",
      "train epoch: 5/11, round: 92/532, loss: 0.4058491587638855\n",
      "train epoch: 5/11, round: 93/532, loss: 0.3533957898616791\n",
      "train epoch: 5/11, round: 94/532, loss: 0.3929291367530823\n",
      "train epoch: 5/11, round: 95/532, loss: 0.28569304943084717\n",
      "train epoch: 5/11, round: 96/532, loss: 0.5083795189857483\n",
      "train epoch: 5/11, round: 97/532, loss: 0.4120517671108246\n",
      "train epoch: 5/11, round: 98/532, loss: 0.3999546766281128\n",
      "train epoch: 5/11, round: 99/532, loss: 0.3293948769569397\n",
      "train epoch: 5/11, round: 100/532, loss: 0.47640037536621094\n",
      "train epoch: 5/11, round: 101/532, loss: 0.3927268981933594\n",
      "train epoch: 5/11, round: 102/532, loss: 0.3845629096031189\n",
      "train epoch: 5/11, round: 103/532, loss: 0.3770669102668762\n",
      "train epoch: 5/11, round: 104/532, loss: 0.3481614291667938\n",
      "train epoch: 5/11, round: 105/532, loss: 0.32601198554039\n",
      "train epoch: 5/11, round: 106/532, loss: 0.3532255291938782\n",
      "train epoch: 5/11, round: 107/532, loss: 0.4288908839225769\n",
      "train epoch: 5/11, round: 108/532, loss: 0.43672895431518555\n",
      "train epoch: 5/11, round: 109/532, loss: 0.4201325476169586\n",
      "train epoch: 5/11, round: 110/532, loss: 0.42400914430618286\n",
      "train epoch: 5/11, round: 111/532, loss: 0.3014402389526367\n",
      "train epoch: 5/11, round: 112/532, loss: 0.36502623558044434\n",
      "train epoch: 5/11, round: 113/532, loss: 0.4567622244358063\n",
      "train epoch: 5/11, round: 114/532, loss: 0.4351445138454437\n",
      "train epoch: 5/11, round: 115/532, loss: 0.3923301100730896\n",
      "train epoch: 5/11, round: 116/532, loss: 0.40804415941238403\n",
      "train epoch: 5/11, round: 117/532, loss: 0.36118394136428833\n",
      "train epoch: 5/11, round: 118/532, loss: 0.4321442246437073\n",
      "train epoch: 5/11, round: 119/532, loss: 0.3947197496891022\n",
      "train epoch: 5/11, round: 120/532, loss: 0.401008278131485\n",
      "train epoch: 5/11, round: 121/532, loss: 0.5012996792793274\n",
      "train epoch: 5/11, round: 122/532, loss: 0.3535703420639038\n",
      "train epoch: 5/11, round: 123/532, loss: 0.419130802154541\n",
      "train epoch: 5/11, round: 124/532, loss: 0.3857334852218628\n",
      "train epoch: 5/11, round: 125/532, loss: 0.3740687966346741\n",
      "train epoch: 5/11, round: 126/532, loss: 0.4973243176937103\n",
      "train epoch: 5/11, round: 127/532, loss: 0.39724063873291016\n",
      "train epoch: 5/11, round: 128/532, loss: 0.3887649178504944\n",
      "train epoch: 5/11, round: 129/532, loss: 0.3380710184574127\n",
      "train epoch: 5/11, round: 130/532, loss: 0.44552794098854065\n",
      "train epoch: 5/11, round: 131/532, loss: 0.3046613335609436\n",
      "train epoch: 5/11, round: 132/532, loss: 0.4259822964668274\n",
      "train epoch: 5/11, round: 133/532, loss: 0.4254593253135681\n",
      "train epoch: 5/11, round: 134/532, loss: 0.4938485026359558\n",
      "train epoch: 5/11, round: 135/532, loss: 0.3433694839477539\n",
      "train epoch: 5/11, round: 136/532, loss: 0.44441676139831543\n",
      "train epoch: 5/11, round: 137/532, loss: 0.40181565284729004\n",
      "train epoch: 5/11, round: 138/532, loss: 0.46103447675704956\n",
      "train epoch: 5/11, round: 139/532, loss: 0.34967494010925293\n",
      "train epoch: 5/11, round: 140/532, loss: 0.4428179860115051\n",
      "train epoch: 5/11, round: 141/532, loss: 0.39894744753837585\n",
      "train epoch: 5/11, round: 142/532, loss: 0.3941536545753479\n",
      "train epoch: 5/11, round: 143/532, loss: 0.36970943212509155\n",
      "train epoch: 5/11, round: 144/532, loss: 0.4159800112247467\n",
      "train epoch: 5/11, round: 145/532, loss: 0.3838661313056946\n",
      "train epoch: 5/11, round: 146/532, loss: 0.34883543848991394\n",
      "train epoch: 5/11, round: 147/532, loss: 0.4303562045097351\n",
      "train epoch: 5/11, round: 148/532, loss: 0.38854530453681946\n",
      "train epoch: 5/11, round: 149/532, loss: 0.4449586272239685\n",
      "train epoch: 5/11, round: 150/532, loss: 0.4229004979133606\n",
      "train epoch: 5/11, round: 151/532, loss: 0.3961089551448822\n",
      "train epoch: 5/11, round: 152/532, loss: 0.38436242938041687\n",
      "train epoch: 5/11, round: 153/532, loss: 0.4473925530910492\n",
      "train epoch: 5/11, round: 154/532, loss: 0.3621954321861267\n",
      "train epoch: 5/11, round: 155/532, loss: 0.36913004517555237\n",
      "train epoch: 5/11, round: 156/532, loss: 0.40945130586624146\n",
      "train epoch: 5/11, round: 157/532, loss: 0.4269837439060211\n",
      "train epoch: 5/11, round: 158/532, loss: 0.3625282049179077\n",
      "train epoch: 5/11, round: 159/532, loss: 0.43177086114883423\n",
      "train epoch: 5/11, round: 160/532, loss: 0.44697800278663635\n",
      "train epoch: 5/11, round: 161/532, loss: 0.36339589953422546\n",
      "train epoch: 5/11, round: 162/532, loss: 0.3936116099357605\n",
      "train epoch: 5/11, round: 163/532, loss: 0.3293153941631317\n",
      "train epoch: 5/11, round: 164/532, loss: 0.39725953340530396\n",
      "train epoch: 5/11, round: 165/532, loss: 0.33744412660598755\n",
      "train epoch: 5/11, round: 166/532, loss: 0.34580978751182556\n",
      "train epoch: 5/11, round: 167/532, loss: 0.33873292803764343\n",
      "train epoch: 5/11, round: 168/532, loss: 0.4869965612888336\n",
      "train epoch: 5/11, round: 169/532, loss: 0.3695302903652191\n",
      "train epoch: 5/11, round: 170/532, loss: 0.4630785584449768\n",
      "train epoch: 5/11, round: 171/532, loss: 0.345292866230011\n",
      "train epoch: 5/11, round: 172/532, loss: 0.3532160520553589\n",
      "train epoch: 5/11, round: 173/532, loss: 0.3472304940223694\n",
      "train epoch: 5/11, round: 174/532, loss: 0.3059740960597992\n",
      "train epoch: 5/11, round: 175/532, loss: 0.5053658485412598\n",
      "train epoch: 5/11, round: 176/532, loss: 0.3687154948711395\n",
      "train epoch: 5/11, round: 177/532, loss: 0.3986284136772156\n",
      "train epoch: 5/11, round: 178/532, loss: 0.37167128920555115\n",
      "train epoch: 5/11, round: 179/532, loss: 0.40393510460853577\n",
      "train epoch: 5/11, round: 180/532, loss: 0.36660075187683105\n",
      "train epoch: 5/11, round: 181/532, loss: 0.4402180314064026\n",
      "train epoch: 5/11, round: 182/532, loss: 0.37424904108047485\n",
      "train epoch: 5/11, round: 183/532, loss: 0.40142226219177246\n",
      "train epoch: 5/11, round: 184/532, loss: 0.376358300447464\n",
      "train epoch: 5/11, round: 185/532, loss: 0.4653305411338806\n",
      "train epoch: 5/11, round: 186/532, loss: 0.4043256342411041\n",
      "train epoch: 5/11, round: 187/532, loss: 0.3940271735191345\n",
      "train epoch: 5/11, round: 188/532, loss: 0.4190060496330261\n",
      "train epoch: 5/11, round: 189/532, loss: 0.40233534574508667\n",
      "train epoch: 5/11, round: 190/532, loss: 0.3438906669616699\n",
      "train epoch: 5/11, round: 191/532, loss: 0.3561265170574188\n",
      "train epoch: 5/11, round: 192/532, loss: 0.33689507842063904\n",
      "train epoch: 5/11, round: 193/532, loss: 0.4978044629096985\n",
      "train epoch: 5/11, round: 194/532, loss: 0.3714168667793274\n",
      "train epoch: 5/11, round: 195/532, loss: 0.401177316904068\n",
      "train epoch: 5/11, round: 196/532, loss: 0.3394721448421478\n",
      "train epoch: 5/11, round: 197/532, loss: 0.45400094985961914\n",
      "train epoch: 5/11, round: 198/532, loss: 0.4079299569129944\n",
      "train epoch: 5/11, round: 199/532, loss: 0.36284372210502625\n",
      "train epoch: 5/11, round: 200/532, loss: 0.37130293250083923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5/11, round: 201/532, loss: 0.3557085692882538\n",
      "train epoch: 5/11, round: 202/532, loss: 0.5229292511940002\n",
      "train epoch: 5/11, round: 203/532, loss: 0.40373897552490234\n",
      "train epoch: 5/11, round: 204/532, loss: 0.4451192319393158\n",
      "train epoch: 5/11, round: 205/532, loss: 0.4699345529079437\n",
      "train epoch: 5/11, round: 206/532, loss: 0.35797470808029175\n",
      "train epoch: 5/11, round: 207/532, loss: 0.37538760900497437\n",
      "train epoch: 5/11, round: 208/532, loss: 0.3680832087993622\n",
      "train epoch: 5/11, round: 209/532, loss: 0.39075222611427307\n",
      "train epoch: 5/11, round: 210/532, loss: 0.38719233870506287\n",
      "train epoch: 5/11, round: 211/532, loss: 0.3991670608520508\n",
      "train epoch: 5/11, round: 212/532, loss: 0.39708179235458374\n",
      "train epoch: 5/11, round: 213/532, loss: 0.33284053206443787\n",
      "train epoch: 5/11, round: 214/532, loss: 0.4719957709312439\n",
      "train epoch: 5/11, round: 215/532, loss: 0.39069169759750366\n",
      "train epoch: 5/11, round: 216/532, loss: 0.3304423391819\n",
      "train epoch: 5/11, round: 217/532, loss: 0.39209282398223877\n",
      "train epoch: 5/11, round: 218/532, loss: 0.3811259865760803\n",
      "train epoch: 5/11, round: 219/532, loss: 0.36161333322525024\n",
      "train epoch: 5/11, round: 220/532, loss: 0.35763972997665405\n",
      "train epoch: 5/11, round: 221/532, loss: 0.30284929275512695\n",
      "train epoch: 5/11, round: 222/532, loss: 0.42770442366600037\n",
      "train epoch: 5/11, round: 223/532, loss: 0.3714749813079834\n",
      "train epoch: 5/11, round: 224/532, loss: 0.34299641847610474\n",
      "train epoch: 5/11, round: 225/532, loss: 0.3487164080142975\n",
      "train epoch: 5/11, round: 226/532, loss: 0.5458170175552368\n",
      "train epoch: 5/11, round: 227/532, loss: 0.39779043197631836\n",
      "train epoch: 5/11, round: 228/532, loss: 0.34294742345809937\n",
      "train epoch: 5/11, round: 229/532, loss: 0.3950052857398987\n",
      "train epoch: 5/11, round: 230/532, loss: 0.3321496546268463\n",
      "train epoch: 5/11, round: 231/532, loss: 0.35517656803131104\n",
      "train epoch: 5/11, round: 232/532, loss: 0.3638734221458435\n",
      "train epoch: 5/11, round: 233/532, loss: 0.37801676988601685\n",
      "train epoch: 5/11, round: 234/532, loss: 0.38144737482070923\n",
      "train epoch: 5/11, round: 235/532, loss: 0.47607898712158203\n",
      "train epoch: 5/11, round: 236/532, loss: 0.3338050842285156\n",
      "train epoch: 5/11, round: 237/532, loss: 0.3653429448604584\n",
      "train epoch: 5/11, round: 238/532, loss: 0.4899721145629883\n",
      "train epoch: 5/11, round: 239/532, loss: 0.35838019847869873\n",
      "train epoch: 5/11, round: 240/532, loss: 0.3559788763523102\n",
      "train epoch: 5/11, round: 241/532, loss: 0.3635052740573883\n",
      "train epoch: 5/11, round: 242/532, loss: 0.37981659173965454\n",
      "train epoch: 5/11, round: 243/532, loss: 0.3448735177516937\n",
      "train epoch: 5/11, round: 244/532, loss: 0.582717776298523\n",
      "train epoch: 5/11, round: 245/532, loss: 0.4347410798072815\n",
      "train epoch: 5/11, round: 246/532, loss: 0.364096462726593\n",
      "train epoch: 5/11, round: 247/532, loss: 0.29489344358444214\n",
      "train epoch: 5/11, round: 248/532, loss: 0.43227091431617737\n",
      "train epoch: 5/11, round: 249/532, loss: 0.45299381017684937\n",
      "train epoch: 5/11, round: 250/532, loss: 0.3696262836456299\n",
      "train epoch: 5/11, round: 251/532, loss: 0.403857558965683\n",
      "train epoch: 5/11, round: 252/532, loss: 0.3583832383155823\n",
      "train epoch: 5/11, round: 253/532, loss: 0.44484156370162964\n",
      "train epoch: 5/11, round: 254/532, loss: 0.37025895714759827\n",
      "train epoch: 5/11, round: 255/532, loss: 0.4083813726902008\n",
      "train epoch: 5/11, round: 256/532, loss: 0.3716431260108948\n",
      "train epoch: 5/11, round: 257/532, loss: 0.3630656599998474\n",
      "train epoch: 5/11, round: 258/532, loss: 0.36156320571899414\n",
      "train epoch: 5/11, round: 259/532, loss: 0.4307924807071686\n",
      "train epoch: 5/11, round: 260/532, loss: 0.4234461784362793\n",
      "train epoch: 5/11, round: 261/532, loss: 0.4639096260070801\n",
      "train epoch: 5/11, round: 262/532, loss: 0.3133717179298401\n",
      "train epoch: 5/11, round: 263/532, loss: 0.3775961101055145\n",
      "train epoch: 5/11, round: 264/532, loss: 0.2973650097846985\n",
      "train epoch: 5/11, round: 265/532, loss: 0.3694596588611603\n",
      "train epoch: 5/11, round: 266/532, loss: 0.4275260865688324\n",
      "train epoch: 5/11, round: 267/532, loss: 0.371177613735199\n",
      "train epoch: 5/11, round: 268/532, loss: 0.513354480266571\n",
      "train epoch: 5/11, round: 269/532, loss: 0.4006079137325287\n",
      "train epoch: 5/11, round: 270/532, loss: 0.3436788022518158\n",
      "train epoch: 5/11, round: 271/532, loss: 0.2846687436103821\n",
      "train epoch: 5/11, round: 272/532, loss: 0.410269558429718\n",
      "train epoch: 5/11, round: 273/532, loss: 0.3687329888343811\n",
      "train epoch: 5/11, round: 274/532, loss: 0.38344112038612366\n",
      "train epoch: 5/11, round: 275/532, loss: 0.4105307459831238\n",
      "train epoch: 5/11, round: 276/532, loss: 0.3855080008506775\n",
      "train epoch: 5/11, round: 277/532, loss: 0.3192373812198639\n",
      "train epoch: 5/11, round: 278/532, loss: 0.3948518931865692\n",
      "train epoch: 5/11, round: 279/532, loss: 0.49771013855934143\n",
      "train epoch: 5/11, round: 280/532, loss: 0.412476122379303\n",
      "train epoch: 5/11, round: 281/532, loss: 0.411154568195343\n",
      "train epoch: 5/11, round: 282/532, loss: 0.3654288947582245\n",
      "train epoch: 5/11, round: 283/532, loss: 0.3586121201515198\n",
      "train epoch: 5/11, round: 284/532, loss: 0.4531373977661133\n",
      "train epoch: 5/11, round: 285/532, loss: 0.38835299015045166\n",
      "train epoch: 5/11, round: 286/532, loss: 0.4242466986179352\n",
      "train epoch: 5/11, round: 287/532, loss: 0.39028486609458923\n",
      "train epoch: 5/11, round: 288/532, loss: 0.3716517984867096\n",
      "train epoch: 5/11, round: 289/532, loss: 0.3321837782859802\n",
      "train epoch: 5/11, round: 290/532, loss: 0.3828875720500946\n",
      "train epoch: 5/11, round: 291/532, loss: 0.3526526987552643\n",
      "train epoch: 5/11, round: 292/532, loss: 0.3512815535068512\n",
      "train epoch: 5/11, round: 293/532, loss: 0.4567924439907074\n",
      "train epoch: 5/11, round: 294/532, loss: 0.4171134829521179\n",
      "train epoch: 5/11, round: 295/532, loss: 0.34868791699409485\n",
      "train epoch: 5/11, round: 296/532, loss: 0.48712506890296936\n",
      "train epoch: 5/11, round: 297/532, loss: 0.36890938878059387\n",
      "train epoch: 5/11, round: 298/532, loss: 0.36421075463294983\n",
      "train epoch: 5/11, round: 299/532, loss: 0.4221431612968445\n",
      "train epoch: 5/11, round: 300/532, loss: 0.42917221784591675\n",
      "train epoch: 5/11, round: 301/532, loss: 0.4193277955055237\n",
      "train epoch: 5/11, round: 302/532, loss: 0.38250815868377686\n",
      "train epoch: 5/11, round: 303/532, loss: 0.4387066960334778\n",
      "train epoch: 5/11, round: 304/532, loss: 0.4327657222747803\n",
      "train epoch: 5/11, round: 305/532, loss: 0.4091024398803711\n",
      "train epoch: 5/11, round: 306/532, loss: 0.33625203371047974\n",
      "train epoch: 5/11, round: 307/532, loss: 0.3503667712211609\n",
      "train epoch: 5/11, round: 308/532, loss: 0.425426721572876\n",
      "train epoch: 5/11, round: 309/532, loss: 0.3602493703365326\n",
      "train epoch: 5/11, round: 310/532, loss: 0.5102730989456177\n",
      "train epoch: 5/11, round: 311/532, loss: 0.36210232973098755\n",
      "train epoch: 5/11, round: 312/532, loss: 0.33870622515678406\n",
      "train epoch: 5/11, round: 313/532, loss: 0.39337682723999023\n",
      "train epoch: 5/11, round: 314/532, loss: 0.37872642278671265\n",
      "train epoch: 5/11, round: 315/532, loss: 0.38368645310401917\n",
      "train epoch: 5/11, round: 316/532, loss: 0.5070093274116516\n",
      "train epoch: 5/11, round: 317/532, loss: 0.3012768626213074\n",
      "train epoch: 5/11, round: 318/532, loss: 0.4191511571407318\n",
      "train epoch: 5/11, round: 319/532, loss: 0.3514247536659241\n",
      "train epoch: 5/11, round: 320/532, loss: 0.41409000754356384\n",
      "train epoch: 5/11, round: 321/532, loss: 0.444876104593277\n",
      "train epoch: 5/11, round: 322/532, loss: 0.3712855875492096\n",
      "train epoch: 5/11, round: 323/532, loss: 0.40059176087379456\n",
      "train epoch: 5/11, round: 324/532, loss: 0.3246007561683655\n",
      "train epoch: 5/11, round: 325/532, loss: 0.38513556122779846\n",
      "train epoch: 5/11, round: 326/532, loss: 0.40498167276382446\n",
      "train epoch: 5/11, round: 327/532, loss: 0.3857728838920593\n",
      "train epoch: 5/11, round: 328/532, loss: 0.43227845430374146\n",
      "train epoch: 5/11, round: 329/532, loss: 0.3734149932861328\n",
      "train epoch: 5/11, round: 330/532, loss: 0.4022575914859772\n",
      "train epoch: 5/11, round: 331/532, loss: 0.4383317828178406\n",
      "train epoch: 5/11, round: 332/532, loss: 0.45007091760635376\n",
      "train epoch: 5/11, round: 333/532, loss: 0.41492265462875366\n",
      "train epoch: 5/11, round: 334/532, loss: 0.4488641321659088\n",
      "train epoch: 5/11, round: 335/532, loss: 0.3375360369682312\n",
      "train epoch: 5/11, round: 336/532, loss: 0.4088803231716156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5/11, round: 337/532, loss: 0.4470058083534241\n",
      "train epoch: 5/11, round: 338/532, loss: 0.41753825545310974\n",
      "train epoch: 5/11, round: 339/532, loss: 0.5313130021095276\n",
      "train epoch: 5/11, round: 340/532, loss: 0.3753918707370758\n",
      "train epoch: 5/11, round: 341/532, loss: 0.40376606583595276\n",
      "train epoch: 5/11, round: 342/532, loss: 0.41703957319259644\n",
      "train epoch: 5/11, round: 343/532, loss: 0.38671210408210754\n",
      "train epoch: 5/11, round: 344/532, loss: 0.44022518396377563\n",
      "train epoch: 5/11, round: 345/532, loss: 0.39399078488349915\n",
      "train epoch: 5/11, round: 346/532, loss: 0.43093395233154297\n",
      "train epoch: 5/11, round: 347/532, loss: 0.3639603555202484\n",
      "train epoch: 5/11, round: 348/532, loss: 0.39184123277664185\n",
      "train epoch: 5/11, round: 349/532, loss: 0.3979392647743225\n",
      "train epoch: 5/11, round: 350/532, loss: 0.41589516401290894\n",
      "train epoch: 5/11, round: 351/532, loss: 0.4325655996799469\n",
      "train epoch: 5/11, round: 352/532, loss: 0.38871246576309204\n",
      "train epoch: 5/11, round: 353/532, loss: 0.32127290964126587\n",
      "train epoch: 5/11, round: 354/532, loss: 0.4493892788887024\n",
      "train epoch: 5/11, round: 355/532, loss: 0.42532557249069214\n",
      "train epoch: 5/11, round: 356/532, loss: 0.40259963274002075\n",
      "train epoch: 5/11, round: 357/532, loss: 0.35606852173805237\n",
      "train epoch: 5/11, round: 358/532, loss: 0.3479374647140503\n",
      "train epoch: 5/11, round: 359/532, loss: 0.4048157334327698\n",
      "train epoch: 5/11, round: 360/532, loss: 0.48830676078796387\n",
      "train epoch: 5/11, round: 361/532, loss: 0.3763854503631592\n",
      "train epoch: 5/11, round: 362/532, loss: 0.42482417821884155\n",
      "train epoch: 5/11, round: 363/532, loss: 0.3416094481945038\n",
      "train epoch: 5/11, round: 364/532, loss: 0.4429605007171631\n",
      "train epoch: 5/11, round: 365/532, loss: 0.42871493101119995\n",
      "train epoch: 5/11, round: 366/532, loss: 0.3983944058418274\n",
      "train epoch: 5/11, round: 367/532, loss: 0.3545518219470978\n",
      "train epoch: 5/11, round: 368/532, loss: 0.392429918050766\n",
      "train epoch: 5/11, round: 369/532, loss: 0.439859539270401\n",
      "train epoch: 5/11, round: 370/532, loss: 0.38661178946495056\n",
      "train epoch: 5/11, round: 371/532, loss: 0.3842618465423584\n",
      "train epoch: 5/11, round: 372/532, loss: 0.3685072958469391\n",
      "train epoch: 5/11, round: 373/532, loss: 0.3311218023300171\n",
      "train epoch: 5/11, round: 374/532, loss: 0.4055708944797516\n",
      "train epoch: 5/11, round: 375/532, loss: 0.35999807715415955\n",
      "train epoch: 5/11, round: 376/532, loss: 0.4301127791404724\n",
      "train epoch: 5/11, round: 377/532, loss: 0.4434366822242737\n",
      "train epoch: 5/11, round: 378/532, loss: 0.46244344115257263\n",
      "train epoch: 5/11, round: 379/532, loss: 0.4331188201904297\n",
      "train epoch: 5/11, round: 380/532, loss: 0.4376174509525299\n",
      "train epoch: 5/11, round: 381/532, loss: 0.31030571460723877\n",
      "train epoch: 5/11, round: 382/532, loss: 0.4488254189491272\n",
      "train epoch: 5/11, round: 383/532, loss: 0.46840277314186096\n",
      "train epoch: 5/11, round: 384/532, loss: 0.39506128430366516\n",
      "train epoch: 5/11, round: 385/532, loss: 0.35558846592903137\n",
      "train epoch: 5/11, round: 386/532, loss: 0.4444800913333893\n",
      "train epoch: 5/11, round: 387/532, loss: 0.41147032380104065\n",
      "train epoch: 5/11, round: 388/532, loss: 0.3929080367088318\n",
      "train epoch: 5/11, round: 389/532, loss: 0.37255415320396423\n",
      "train epoch: 5/11, round: 390/532, loss: 0.3759539723396301\n",
      "train epoch: 5/11, round: 391/532, loss: 0.3727026581764221\n",
      "train epoch: 5/11, round: 392/532, loss: 0.397392213344574\n",
      "train epoch: 5/11, round: 393/532, loss: 0.3466247618198395\n",
      "train epoch: 5/11, round: 394/532, loss: 0.34675830602645874\n",
      "train epoch: 5/11, round: 395/532, loss: 0.38258323073387146\n",
      "train epoch: 5/11, round: 396/532, loss: 0.45446714758872986\n",
      "train epoch: 5/11, round: 397/532, loss: 0.3797949254512787\n",
      "train epoch: 5/11, round: 398/532, loss: 0.36207014322280884\n",
      "train epoch: 5/11, round: 399/532, loss: 0.4439376890659332\n",
      "train epoch: 5/11, round: 400/532, loss: 0.4776063561439514\n",
      "train epoch: 5/11, round: 401/532, loss: 0.33074644207954407\n",
      "train epoch: 5/11, round: 402/532, loss: 0.3552129864692688\n",
      "train epoch: 5/11, round: 403/532, loss: 0.4604727625846863\n",
      "train epoch: 5/11, round: 404/532, loss: 0.38821959495544434\n",
      "train epoch: 5/11, round: 405/532, loss: 0.3624298870563507\n",
      "train epoch: 5/11, round: 406/532, loss: 0.3735598921775818\n",
      "train epoch: 5/11, round: 407/532, loss: 0.3713899254798889\n",
      "train epoch: 5/11, round: 408/532, loss: 0.4578879475593567\n",
      "train epoch: 5/11, round: 409/532, loss: 0.39125174283981323\n",
      "train epoch: 5/11, round: 410/532, loss: 0.31822165846824646\n",
      "train epoch: 5/11, round: 411/532, loss: 0.37078142166137695\n",
      "train epoch: 5/11, round: 412/532, loss: 0.36085671186447144\n",
      "train epoch: 5/11, round: 413/532, loss: 0.4542761743068695\n",
      "train epoch: 5/11, round: 414/532, loss: 0.43674078583717346\n",
      "train epoch: 5/11, round: 415/532, loss: 0.4297587275505066\n",
      "train epoch: 5/11, round: 416/532, loss: 0.4411246180534363\n",
      "train epoch: 5/11, round: 417/532, loss: 0.38729342818260193\n",
      "train epoch: 5/11, round: 418/532, loss: 0.41356897354125977\n",
      "train epoch: 5/11, round: 419/532, loss: 0.4104388356208801\n",
      "train epoch: 5/11, round: 420/532, loss: 0.36745044589042664\n",
      "train epoch: 5/11, round: 421/532, loss: 0.4030906558036804\n",
      "train epoch: 5/11, round: 422/532, loss: 0.4741595387458801\n",
      "train epoch: 5/11, round: 423/532, loss: 0.3815702497959137\n",
      "train epoch: 5/11, round: 424/532, loss: 0.32888802886009216\n",
      "train epoch: 5/11, round: 425/532, loss: 0.39518603682518005\n",
      "train epoch: 5/11, round: 426/532, loss: 0.33973410725593567\n",
      "train epoch: 5/11, round: 427/532, loss: 0.43741899728775024\n",
      "train epoch: 5/11, round: 428/532, loss: 0.4590773582458496\n",
      "train epoch: 5/11, round: 429/532, loss: 0.4263399541378021\n",
      "train epoch: 5/11, round: 430/532, loss: 0.4555002748966217\n",
      "train epoch: 5/11, round: 431/532, loss: 0.4181836247444153\n",
      "train epoch: 5/11, round: 432/532, loss: 0.39890235662460327\n",
      "train epoch: 5/11, round: 433/532, loss: 0.34510427713394165\n",
      "train epoch: 5/11, round: 434/532, loss: 0.40842771530151367\n",
      "train epoch: 5/11, round: 435/532, loss: 0.47361642122268677\n",
      "train epoch: 5/11, round: 436/532, loss: 0.4913308024406433\n",
      "train epoch: 5/11, round: 437/532, loss: 0.5010002255439758\n",
      "train epoch: 5/11, round: 438/532, loss: 0.35995784401893616\n",
      "train epoch: 5/11, round: 439/532, loss: 0.4201829433441162\n",
      "train epoch: 5/11, round: 440/532, loss: 0.3364217281341553\n",
      "train epoch: 5/11, round: 441/532, loss: 0.357658326625824\n",
      "train epoch: 5/11, round: 442/532, loss: 0.43628042936325073\n",
      "train epoch: 5/11, round: 443/532, loss: 0.43618956208229065\n",
      "train epoch: 5/11, round: 444/532, loss: 0.4980907440185547\n",
      "train epoch: 5/11, round: 445/532, loss: 0.348502516746521\n",
      "train epoch: 5/11, round: 446/532, loss: 0.378040611743927\n",
      "train epoch: 5/11, round: 447/532, loss: 0.43478864431381226\n",
      "train epoch: 5/11, round: 448/532, loss: 0.3284253478050232\n",
      "train epoch: 5/11, round: 449/532, loss: 0.44209879636764526\n",
      "train epoch: 5/11, round: 450/532, loss: 0.3856303095817566\n",
      "train epoch: 5/11, round: 451/532, loss: 0.42742055654525757\n",
      "train epoch: 5/11, round: 452/532, loss: 0.44884198904037476\n",
      "train epoch: 5/11, round: 453/532, loss: 0.4847783148288727\n",
      "train epoch: 5/11, round: 454/532, loss: 0.3511649966239929\n",
      "train epoch: 5/11, round: 455/532, loss: 0.42466965317726135\n",
      "train epoch: 5/11, round: 456/532, loss: 0.45947232842445374\n",
      "train epoch: 5/11, round: 457/532, loss: 0.3792341351509094\n",
      "train epoch: 5/11, round: 458/532, loss: 0.49741291999816895\n",
      "train epoch: 5/11, round: 459/532, loss: 0.4279839098453522\n",
      "train epoch: 5/11, round: 460/532, loss: 0.42321890592575073\n",
      "train epoch: 5/11, round: 461/532, loss: 0.41111698746681213\n",
      "train epoch: 5/11, round: 462/532, loss: 0.4155687391757965\n",
      "train epoch: 5/11, round: 463/532, loss: 0.36378762125968933\n",
      "train epoch: 5/11, round: 464/532, loss: 0.42655301094055176\n",
      "train epoch: 5/11, round: 465/532, loss: 0.42646104097366333\n",
      "train epoch: 5/11, round: 466/532, loss: 0.3563322424888611\n",
      "train epoch: 5/11, round: 467/532, loss: 0.41379842162132263\n",
      "train epoch: 5/11, round: 468/532, loss: 0.5256522297859192\n",
      "train epoch: 5/11, round: 469/532, loss: 0.3958686292171478\n",
      "train epoch: 5/11, round: 470/532, loss: 0.3794190585613251\n",
      "train epoch: 5/11, round: 471/532, loss: 0.42027410864830017\n",
      "train epoch: 5/11, round: 472/532, loss: 0.37315112352371216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5/11, round: 473/532, loss: 0.5159635543823242\n",
      "train epoch: 5/11, round: 474/532, loss: 0.3453567624092102\n",
      "train epoch: 5/11, round: 475/532, loss: 0.38629022240638733\n",
      "train epoch: 5/11, round: 476/532, loss: 0.3137369751930237\n",
      "train epoch: 5/11, round: 477/532, loss: 0.39089274406433105\n",
      "train epoch: 5/11, round: 478/532, loss: 0.39073967933654785\n",
      "train epoch: 5/11, round: 479/532, loss: 0.4118530750274658\n",
      "train epoch: 5/11, round: 480/532, loss: 0.42527151107788086\n",
      "train epoch: 5/11, round: 481/532, loss: 0.3576655983924866\n",
      "train epoch: 5/11, round: 482/532, loss: 0.41658419370651245\n",
      "train epoch: 5/11, round: 483/532, loss: 0.4623015522956848\n",
      "train epoch: 5/11, round: 484/532, loss: 0.3462654650211334\n",
      "train epoch: 5/11, round: 485/532, loss: 0.3549960255622864\n",
      "train epoch: 5/11, round: 486/532, loss: 0.4443328380584717\n",
      "train epoch: 5/11, round: 487/532, loss: 0.4313737750053406\n",
      "train epoch: 5/11, round: 488/532, loss: 0.29194533824920654\n",
      "train epoch: 5/11, round: 489/532, loss: 0.49313241243362427\n",
      "train epoch: 5/11, round: 490/532, loss: 0.4439598023891449\n",
      "train epoch: 5/11, round: 491/532, loss: 0.3969549834728241\n",
      "train epoch: 5/11, round: 492/532, loss: 0.38117027282714844\n",
      "train epoch: 5/11, round: 493/532, loss: 0.3305211365222931\n",
      "train epoch: 5/11, round: 494/532, loss: 0.3783566951751709\n",
      "train epoch: 5/11, round: 495/532, loss: 0.3995063304901123\n",
      "train epoch: 5/11, round: 496/532, loss: 0.49762868881225586\n",
      "train epoch: 5/11, round: 497/532, loss: 0.4410070776939392\n",
      "train epoch: 5/11, round: 498/532, loss: 0.40492910146713257\n",
      "train epoch: 5/11, round: 499/532, loss: 0.40063443779945374\n",
      "train epoch: 5/11, round: 500/532, loss: 0.4302647113800049\n",
      "train epoch: 5/11, round: 501/532, loss: 0.3384391665458679\n",
      "train epoch: 5/11, round: 502/532, loss: 0.4682701528072357\n",
      "train epoch: 5/11, round: 503/532, loss: 0.4097580909729004\n",
      "train epoch: 5/11, round: 504/532, loss: 0.39721226692199707\n",
      "train epoch: 5/11, round: 505/532, loss: 0.36914485692977905\n",
      "train epoch: 5/11, round: 506/532, loss: 0.3657051622867584\n",
      "train epoch: 5/11, round: 507/532, loss: 0.4965879023075104\n",
      "train epoch: 5/11, round: 508/532, loss: 0.3421846628189087\n",
      "train epoch: 5/11, round: 509/532, loss: 0.40332549810409546\n",
      "train epoch: 5/11, round: 510/532, loss: 0.3480757176876068\n",
      "train epoch: 5/11, round: 511/532, loss: 0.509544849395752\n",
      "train epoch: 5/11, round: 512/532, loss: 0.37297019362449646\n",
      "train epoch: 5/11, round: 513/532, loss: 0.4071696400642395\n",
      "train epoch: 5/11, round: 514/532, loss: 0.43838754296302795\n",
      "train epoch: 5/11, round: 515/532, loss: 0.4068896174430847\n",
      "train epoch: 5/11, round: 516/532, loss: 0.43651407957077026\n",
      "train epoch: 5/11, round: 517/532, loss: 0.3561837673187256\n",
      "train epoch: 5/11, round: 518/532, loss: 0.4455881118774414\n",
      "train epoch: 5/11, round: 519/532, loss: 0.37260374426841736\n",
      "train epoch: 5/11, round: 520/532, loss: 0.42362260818481445\n",
      "train epoch: 5/11, round: 521/532, loss: 0.33563822507858276\n",
      "train epoch: 5/11, round: 522/532, loss: 0.42707133293151855\n",
      "train epoch: 5/11, round: 523/532, loss: 0.44640588760375977\n",
      "train epoch: 5/11, round: 524/532, loss: 0.3865671455860138\n",
      "train epoch: 5/11, round: 525/532, loss: 0.41603270173072815\n",
      "train epoch: 5/11, round: 526/532, loss: 0.3426246643066406\n",
      "train epoch: 5/11, round: 527/532, loss: 0.32366234064102173\n",
      "train epoch: 5/11, round: 528/532, loss: 0.4230218827724457\n",
      "train epoch: 5/11, round: 529/532, loss: 0.4078596234321594\n",
      "train epoch: 5/11, round: 530/532, loss: 0.4725785255432129\n",
      "train epoch: 5/11, round: 531/532, loss: 0.5291309952735901\n",
      "train epoch: 5/11, round: 532/532, loss: 0.3357875943183899\n",
      "train epoch: 5/11, KS: 0.24149392399225633, ROC: 0.6668909403330345\n",
      "test epoch: 5/11, round: 1/501, loss: 0.3835744559764862\n",
      "test epoch: 5/11, round: 2/501, loss: 0.3029308319091797\n",
      "test epoch: 5/11, round: 3/501, loss: 0.22415560483932495\n",
      "test epoch: 5/11, round: 4/501, loss: 0.3591567873954773\n",
      "test epoch: 5/11, round: 5/501, loss: 0.3433320224285126\n",
      "test epoch: 5/11, round: 6/501, loss: 0.34076645970344543\n",
      "test epoch: 5/11, round: 7/501, loss: 0.41923338174819946\n",
      "test epoch: 5/11, round: 8/501, loss: 0.4062677323818207\n",
      "test epoch: 5/11, round: 9/501, loss: 0.6074369549751282\n",
      "test epoch: 5/11, round: 10/501, loss: 0.6311966776847839\n",
      "test epoch: 5/11, round: 11/501, loss: 0.24686279892921448\n",
      "test epoch: 5/11, round: 12/501, loss: 0.347907692193985\n",
      "test epoch: 5/11, round: 13/501, loss: 0.32791897654533386\n",
      "test epoch: 5/11, round: 14/501, loss: 0.3649020493030548\n",
      "test epoch: 5/11, round: 15/501, loss: 0.48805931210517883\n",
      "test epoch: 5/11, round: 16/501, loss: 0.4710111618041992\n",
      "test epoch: 5/11, round: 17/501, loss: 0.3657366931438446\n",
      "test epoch: 5/11, round: 18/501, loss: 0.4763345420360565\n",
      "test epoch: 5/11, round: 19/501, loss: 0.5018010139465332\n",
      "test epoch: 5/11, round: 20/501, loss: 0.7740269303321838\n",
      "test epoch: 5/11, round: 21/501, loss: 0.3993527591228485\n",
      "test epoch: 5/11, round: 22/501, loss: 0.5664829611778259\n",
      "test epoch: 5/11, round: 23/501, loss: 0.5023010969161987\n",
      "test epoch: 5/11, round: 24/501, loss: 0.46467527747154236\n",
      "test epoch: 5/11, round: 25/501, loss: 0.5805219411849976\n",
      "test epoch: 5/11, round: 26/501, loss: 0.6430105566978455\n",
      "test epoch: 5/11, round: 27/501, loss: 0.23903433978557587\n",
      "test epoch: 5/11, round: 28/501, loss: 0.4757709205150604\n",
      "test epoch: 5/11, round: 29/501, loss: 0.29127952456474304\n",
      "test epoch: 5/11, round: 30/501, loss: 0.5332655310630798\n",
      "test epoch: 5/11, round: 31/501, loss: 0.5568509697914124\n",
      "test epoch: 5/11, round: 32/501, loss: 0.4809889495372772\n",
      "test epoch: 5/11, round: 33/501, loss: 0.6476783752441406\n",
      "test epoch: 5/11, round: 34/501, loss: 0.46998435258865356\n",
      "test epoch: 5/11, round: 35/501, loss: 0.1795448362827301\n",
      "test epoch: 5/11, round: 36/501, loss: 0.44288429617881775\n",
      "test epoch: 5/11, round: 37/501, loss: 0.40406566858291626\n",
      "test epoch: 5/11, round: 38/501, loss: 0.4436734616756439\n",
      "test epoch: 5/11, round: 39/501, loss: 0.6743606328964233\n",
      "test epoch: 5/11, round: 40/501, loss: 0.5528575778007507\n",
      "test epoch: 5/11, round: 41/501, loss: 0.45940881967544556\n",
      "test epoch: 5/11, round: 42/501, loss: 0.41594573855400085\n",
      "test epoch: 5/11, round: 43/501, loss: 0.3667846918106079\n",
      "test epoch: 5/11, round: 44/501, loss: 0.5887329578399658\n",
      "test epoch: 5/11, round: 45/501, loss: 0.6344925761222839\n",
      "test epoch: 5/11, round: 46/501, loss: 0.4920038878917694\n",
      "test epoch: 5/11, round: 47/501, loss: 0.2968786358833313\n",
      "test epoch: 5/11, round: 48/501, loss: 0.5303950905799866\n",
      "test epoch: 5/11, round: 49/501, loss: 0.3403968811035156\n",
      "test epoch: 5/11, round: 50/501, loss: 0.26510754227638245\n",
      "test epoch: 5/11, round: 51/501, loss: 0.46310460567474365\n",
      "test epoch: 5/11, round: 52/501, loss: 0.4214925765991211\n",
      "test epoch: 5/11, round: 53/501, loss: 0.4887256920337677\n",
      "test epoch: 5/11, round: 54/501, loss: 0.4937184453010559\n",
      "test epoch: 5/11, round: 55/501, loss: 0.3388420343399048\n",
      "test epoch: 5/11, round: 56/501, loss: 0.3827669322490692\n",
      "test epoch: 5/11, round: 57/501, loss: 0.38781842589378357\n",
      "test epoch: 5/11, round: 58/501, loss: 0.4592047929763794\n",
      "test epoch: 5/11, round: 59/501, loss: 0.2553410828113556\n",
      "test epoch: 5/11, round: 60/501, loss: 0.45196643471717834\n",
      "test epoch: 5/11, round: 61/501, loss: 0.37571844458580017\n",
      "test epoch: 5/11, round: 62/501, loss: 0.6544361114501953\n",
      "test epoch: 5/11, round: 63/501, loss: 0.7948288321495056\n",
      "test epoch: 5/11, round: 64/501, loss: 0.26691368222236633\n",
      "test epoch: 5/11, round: 65/501, loss: 0.6562777757644653\n",
      "test epoch: 5/11, round: 66/501, loss: 0.3954009413719177\n",
      "test epoch: 5/11, round: 67/501, loss: 0.5116923451423645\n",
      "test epoch: 5/11, round: 68/501, loss: 0.591515839099884\n",
      "test epoch: 5/11, round: 69/501, loss: 0.45019546151161194\n",
      "test epoch: 5/11, round: 70/501, loss: 0.4541011154651642\n",
      "test epoch: 5/11, round: 71/501, loss: 0.5866327881813049\n",
      "test epoch: 5/11, round: 72/501, loss: 0.5069381594657898\n",
      "test epoch: 5/11, round: 73/501, loss: 0.4562496840953827\n",
      "test epoch: 5/11, round: 74/501, loss: 0.5108338594436646\n",
      "test epoch: 5/11, round: 75/501, loss: 0.5336939096450806\n",
      "test epoch: 5/11, round: 76/501, loss: 0.6542921662330627\n",
      "test epoch: 5/11, round: 77/501, loss: 0.3543553650379181\n",
      "test epoch: 5/11, round: 78/501, loss: 0.6572169065475464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 5/11, round: 79/501, loss: 0.4001546800136566\n",
      "test epoch: 5/11, round: 80/501, loss: 0.5775161981582642\n",
      "test epoch: 5/11, round: 81/501, loss: 0.8315473198890686\n",
      "test epoch: 5/11, round: 82/501, loss: 0.527990460395813\n",
      "test epoch: 5/11, round: 83/501, loss: 0.41728973388671875\n",
      "test epoch: 5/11, round: 84/501, loss: 0.6290770173072815\n",
      "test epoch: 5/11, round: 85/501, loss: 0.5963409543037415\n",
      "test epoch: 5/11, round: 86/501, loss: 0.35800763964653015\n",
      "test epoch: 5/11, round: 87/501, loss: 0.47206977009773254\n",
      "test epoch: 5/11, round: 88/501, loss: 0.3483017683029175\n",
      "test epoch: 5/11, round: 89/501, loss: 0.3380941152572632\n",
      "test epoch: 5/11, round: 90/501, loss: 0.6402677893638611\n",
      "test epoch: 5/11, round: 91/501, loss: 0.33153825998306274\n",
      "test epoch: 5/11, round: 92/501, loss: 0.5940321087837219\n",
      "test epoch: 5/11, round: 93/501, loss: 0.5018512606620789\n",
      "test epoch: 5/11, round: 94/501, loss: 0.5930861830711365\n",
      "test epoch: 5/11, round: 95/501, loss: 0.38461577892303467\n",
      "test epoch: 5/11, round: 96/501, loss: 0.3651226758956909\n",
      "test epoch: 5/11, round: 97/501, loss: 0.5882393717765808\n",
      "test epoch: 5/11, round: 98/501, loss: 0.4148475229740143\n",
      "test epoch: 5/11, round: 99/501, loss: 0.6167972087860107\n",
      "test epoch: 5/11, round: 100/501, loss: 0.5672009587287903\n",
      "test epoch: 5/11, round: 101/501, loss: 0.544326663017273\n",
      "test epoch: 5/11, round: 102/501, loss: 0.3424743413925171\n",
      "test epoch: 5/11, round: 103/501, loss: 0.46961089968681335\n",
      "test epoch: 5/11, round: 104/501, loss: 0.6911405324935913\n",
      "test epoch: 5/11, round: 105/501, loss: 0.4051506817340851\n",
      "test epoch: 5/11, round: 106/501, loss: 0.571912407875061\n",
      "test epoch: 5/11, round: 107/501, loss: 0.32616981863975525\n",
      "test epoch: 5/11, round: 108/501, loss: 0.5341781377792358\n",
      "test epoch: 5/11, round: 109/501, loss: 0.36783427000045776\n",
      "test epoch: 5/11, round: 110/501, loss: 0.8174254298210144\n",
      "test epoch: 5/11, round: 111/501, loss: 0.23523105680942535\n",
      "test epoch: 5/11, round: 112/501, loss: 0.19790521264076233\n",
      "test epoch: 5/11, round: 113/501, loss: 0.3777369260787964\n",
      "test epoch: 5/11, round: 114/501, loss: 0.350539892911911\n",
      "test epoch: 5/11, round: 115/501, loss: 0.27954021096229553\n",
      "test epoch: 5/11, round: 116/501, loss: 0.3503606915473938\n",
      "test epoch: 5/11, round: 117/501, loss: 0.36615803837776184\n",
      "test epoch: 5/11, round: 118/501, loss: 0.3324238955974579\n",
      "test epoch: 5/11, round: 119/501, loss: 0.2874227464199066\n",
      "test epoch: 5/11, round: 120/501, loss: 0.376928448677063\n",
      "test epoch: 5/11, round: 121/501, loss: 0.4160143733024597\n",
      "test epoch: 5/11, round: 122/501, loss: 0.4104076325893402\n",
      "test epoch: 5/11, round: 123/501, loss: 0.39901310205459595\n",
      "test epoch: 5/11, round: 124/501, loss: 0.5575424432754517\n",
      "test epoch: 5/11, round: 125/501, loss: 0.44124603271484375\n",
      "test epoch: 5/11, round: 126/501, loss: 0.38349252939224243\n",
      "test epoch: 5/11, round: 127/501, loss: 0.4367607533931732\n",
      "test epoch: 5/11, round: 128/501, loss: 0.21926727890968323\n",
      "test epoch: 5/11, round: 129/501, loss: 0.4545662999153137\n",
      "test epoch: 5/11, round: 130/501, loss: 0.7619613409042358\n",
      "test epoch: 5/11, round: 131/501, loss: 0.6116199493408203\n",
      "test epoch: 5/11, round: 132/501, loss: 0.4946083128452301\n",
      "test epoch: 5/11, round: 133/501, loss: 0.7598282694816589\n",
      "test epoch: 5/11, round: 134/501, loss: 0.5320615172386169\n",
      "test epoch: 5/11, round: 135/501, loss: 0.2659345269203186\n",
      "test epoch: 5/11, round: 136/501, loss: 0.42628610134124756\n",
      "test epoch: 5/11, round: 137/501, loss: 0.4417702555656433\n",
      "test epoch: 5/11, round: 138/501, loss: 0.35519737005233765\n",
      "test epoch: 5/11, round: 139/501, loss: 0.574763298034668\n",
      "test epoch: 5/11, round: 140/501, loss: 0.4506658613681793\n",
      "test epoch: 5/11, round: 141/501, loss: 0.3214530348777771\n",
      "test epoch: 5/11, round: 142/501, loss: 0.5632370114326477\n",
      "test epoch: 5/11, round: 143/501, loss: 0.38085687160491943\n",
      "test epoch: 5/11, round: 144/501, loss: 0.4294860064983368\n",
      "test epoch: 5/11, round: 145/501, loss: 0.36409568786621094\n",
      "test epoch: 5/11, round: 146/501, loss: 0.5800909399986267\n",
      "test epoch: 5/11, round: 147/501, loss: 0.5365482568740845\n",
      "test epoch: 5/11, round: 148/501, loss: 0.5591935515403748\n",
      "test epoch: 5/11, round: 149/501, loss: 0.3181810975074768\n",
      "test epoch: 5/11, round: 150/501, loss: 0.6408153772354126\n",
      "test epoch: 5/11, round: 151/501, loss: 0.4690989553928375\n",
      "test epoch: 5/11, round: 152/501, loss: 0.5131855607032776\n",
      "test epoch: 5/11, round: 153/501, loss: 0.560880720615387\n",
      "test epoch: 5/11, round: 154/501, loss: 0.5201746821403503\n",
      "test epoch: 5/11, round: 155/501, loss: 0.3821360170841217\n",
      "test epoch: 5/11, round: 156/501, loss: 0.28899142146110535\n",
      "test epoch: 5/11, round: 157/501, loss: 0.32018834352493286\n",
      "test epoch: 5/11, round: 158/501, loss: 0.3465590178966522\n",
      "test epoch: 5/11, round: 159/501, loss: 0.3693287670612335\n",
      "test epoch: 5/11, round: 160/501, loss: 0.3702823221683502\n",
      "test epoch: 5/11, round: 161/501, loss: 0.33285945653915405\n",
      "test epoch: 5/11, round: 162/501, loss: 0.45511817932128906\n",
      "test epoch: 5/11, round: 163/501, loss: 0.44279876351356506\n",
      "test epoch: 5/11, round: 164/501, loss: 0.3561992943286896\n",
      "test epoch: 5/11, round: 165/501, loss: 0.544970691204071\n",
      "test epoch: 5/11, round: 166/501, loss: 0.3282003700733185\n",
      "test epoch: 5/11, round: 167/501, loss: 0.24850943684577942\n",
      "test epoch: 5/11, round: 168/501, loss: 0.18932414054870605\n",
      "test epoch: 5/11, round: 169/501, loss: 0.3726930022239685\n",
      "test epoch: 5/11, round: 170/501, loss: 0.3491697311401367\n",
      "test epoch: 5/11, round: 171/501, loss: 0.4247226119041443\n",
      "test epoch: 5/11, round: 172/501, loss: 0.5219678282737732\n",
      "test epoch: 5/11, round: 173/501, loss: 0.2986239194869995\n",
      "test epoch: 5/11, round: 174/501, loss: 0.6088182926177979\n",
      "test epoch: 5/11, round: 175/501, loss: 0.2586996257305145\n",
      "test epoch: 5/11, round: 176/501, loss: 0.531267523765564\n",
      "test epoch: 5/11, round: 177/501, loss: 0.3262121081352234\n",
      "test epoch: 5/11, round: 178/501, loss: 0.24202851951122284\n",
      "test epoch: 5/11, round: 179/501, loss: 0.23416519165039062\n",
      "test epoch: 5/11, round: 180/501, loss: 0.3389347791671753\n",
      "test epoch: 5/11, round: 181/501, loss: 0.5692183375358582\n",
      "test epoch: 5/11, round: 182/501, loss: 0.5506227016448975\n",
      "test epoch: 5/11, round: 183/501, loss: 0.4304924011230469\n",
      "test epoch: 5/11, round: 184/501, loss: 0.5148147940635681\n",
      "test epoch: 5/11, round: 185/501, loss: 0.44096100330352783\n",
      "test epoch: 5/11, round: 186/501, loss: 0.5965968370437622\n",
      "test epoch: 5/11, round: 187/501, loss: 0.53570556640625\n",
      "test epoch: 5/11, round: 188/501, loss: 0.5526435375213623\n",
      "test epoch: 5/11, round: 189/501, loss: 0.6218260526657104\n",
      "test epoch: 5/11, round: 190/501, loss: 0.4552479386329651\n",
      "test epoch: 5/11, round: 191/501, loss: 0.32116326689720154\n",
      "test epoch: 5/11, round: 192/501, loss: 0.5858782529830933\n",
      "test epoch: 5/11, round: 193/501, loss: 0.5352684259414673\n",
      "test epoch: 5/11, round: 194/501, loss: 0.4723735451698303\n",
      "test epoch: 5/11, round: 195/501, loss: 0.5560280084609985\n",
      "test epoch: 5/11, round: 196/501, loss: 0.34671255946159363\n",
      "test epoch: 5/11, round: 197/501, loss: 0.3633951246738434\n",
      "test epoch: 5/11, round: 198/501, loss: 0.49730604887008667\n",
      "test epoch: 5/11, round: 199/501, loss: 0.43722400069236755\n",
      "test epoch: 5/11, round: 200/501, loss: 0.6277579665184021\n",
      "test epoch: 5/11, round: 201/501, loss: 0.3497394025325775\n",
      "test epoch: 5/11, round: 202/501, loss: 0.36087971925735474\n",
      "test epoch: 5/11, round: 203/501, loss: 0.4626675248146057\n",
      "test epoch: 5/11, round: 204/501, loss: 0.5663880109786987\n",
      "test epoch: 5/11, round: 205/501, loss: 0.40723082423210144\n",
      "test epoch: 5/11, round: 206/501, loss: 0.26846837997436523\n",
      "test epoch: 5/11, round: 207/501, loss: 0.365164190530777\n",
      "test epoch: 5/11, round: 208/501, loss: 0.48208752274513245\n",
      "test epoch: 5/11, round: 209/501, loss: 0.30888259410858154\n",
      "test epoch: 5/11, round: 210/501, loss: 0.46611231565475464\n",
      "test epoch: 5/11, round: 211/501, loss: 0.2644858658313751\n",
      "test epoch: 5/11, round: 212/501, loss: 0.31252580881118774\n",
      "test epoch: 5/11, round: 213/501, loss: 0.30133628845214844\n",
      "test epoch: 5/11, round: 214/501, loss: 0.23932942748069763\n",
      "test epoch: 5/11, round: 215/501, loss: 0.20198243856430054\n",
      "test epoch: 5/11, round: 216/501, loss: 0.2188432365655899\n",
      "test epoch: 5/11, round: 217/501, loss: 0.17809568345546722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 5/11, round: 218/501, loss: 0.19758614897727966\n",
      "test epoch: 5/11, round: 219/501, loss: 0.22204948961734772\n",
      "test epoch: 5/11, round: 220/501, loss: 0.39830055832862854\n",
      "test epoch: 5/11, round: 221/501, loss: 0.33665406703948975\n",
      "test epoch: 5/11, round: 222/501, loss: 0.19061002135276794\n",
      "test epoch: 5/11, round: 223/501, loss: 0.19522742927074432\n",
      "test epoch: 5/11, round: 224/501, loss: 0.22355452179908752\n",
      "test epoch: 5/11, round: 225/501, loss: 0.19668127596378326\n",
      "test epoch: 5/11, round: 226/501, loss: 0.18350079655647278\n",
      "test epoch: 5/11, round: 227/501, loss: 0.2344159334897995\n",
      "test epoch: 5/11, round: 228/501, loss: 0.2365477830171585\n",
      "test epoch: 5/11, round: 229/501, loss: 0.45484277606010437\n",
      "test epoch: 5/11, round: 230/501, loss: 0.30327656865119934\n",
      "test epoch: 5/11, round: 231/501, loss: 0.28492844104766846\n",
      "test epoch: 5/11, round: 232/501, loss: 0.4273417294025421\n",
      "test epoch: 5/11, round: 233/501, loss: 0.5179092884063721\n",
      "test epoch: 5/11, round: 234/501, loss: 0.45303839445114136\n",
      "test epoch: 5/11, round: 235/501, loss: 0.3149927854537964\n",
      "test epoch: 5/11, round: 236/501, loss: 0.3390565812587738\n",
      "test epoch: 5/11, round: 237/501, loss: 0.35936933755874634\n",
      "test epoch: 5/11, round: 238/501, loss: 0.3582901656627655\n",
      "test epoch: 5/11, round: 239/501, loss: 0.4043899476528168\n",
      "test epoch: 5/11, round: 240/501, loss: 0.2322719693183899\n",
      "test epoch: 5/11, round: 241/501, loss: 0.36430054903030396\n",
      "test epoch: 5/11, round: 242/501, loss: 0.29316195845603943\n",
      "test epoch: 5/11, round: 243/501, loss: 0.28039106726646423\n",
      "test epoch: 5/11, round: 244/501, loss: 0.31977421045303345\n",
      "test epoch: 5/11, round: 245/501, loss: 0.38567107915878296\n",
      "test epoch: 5/11, round: 246/501, loss: 0.43909093737602234\n",
      "test epoch: 5/11, round: 247/501, loss: 0.4087352156639099\n",
      "test epoch: 5/11, round: 248/501, loss: 0.19316314160823822\n",
      "test epoch: 5/11, round: 249/501, loss: 0.3361351788043976\n",
      "test epoch: 5/11, round: 250/501, loss: 0.3091993033885956\n",
      "test epoch: 5/11, round: 251/501, loss: 0.34864065051078796\n",
      "test epoch: 5/11, round: 252/501, loss: 0.33576443791389465\n",
      "test epoch: 5/11, round: 253/501, loss: 0.3326758146286011\n",
      "test epoch: 5/11, round: 254/501, loss: 0.31042423844337463\n",
      "test epoch: 5/11, round: 255/501, loss: 0.3226606249809265\n",
      "test epoch: 5/11, round: 256/501, loss: 0.39479535818099976\n",
      "test epoch: 5/11, round: 257/501, loss: 0.38490670919418335\n",
      "test epoch: 5/11, round: 258/501, loss: 0.4141092300415039\n",
      "test epoch: 5/11, round: 259/501, loss: 0.25146085023880005\n",
      "test epoch: 5/11, round: 260/501, loss: 0.5012426376342773\n",
      "test epoch: 5/11, round: 261/501, loss: 0.5986518263816833\n",
      "test epoch: 5/11, round: 262/501, loss: 0.4615332782268524\n",
      "test epoch: 5/11, round: 263/501, loss: 0.39309197664260864\n",
      "test epoch: 5/11, round: 264/501, loss: 0.4300425350666046\n",
      "test epoch: 5/11, round: 265/501, loss: 0.6058350801467896\n",
      "test epoch: 5/11, round: 266/501, loss: 0.3740162253379822\n",
      "test epoch: 5/11, round: 267/501, loss: 0.3482435345649719\n",
      "test epoch: 5/11, round: 268/501, loss: 0.28294163942337036\n",
      "test epoch: 5/11, round: 269/501, loss: 0.4956822693347931\n",
      "test epoch: 5/11, round: 270/501, loss: 0.2885492742061615\n",
      "test epoch: 5/11, round: 271/501, loss: 0.5714943408966064\n",
      "test epoch: 5/11, round: 272/501, loss: 0.39968231320381165\n",
      "test epoch: 5/11, round: 273/501, loss: 0.3939650356769562\n",
      "test epoch: 5/11, round: 274/501, loss: 0.5232717394828796\n",
      "test epoch: 5/11, round: 275/501, loss: 0.2807742953300476\n",
      "test epoch: 5/11, round: 276/501, loss: 0.40169137716293335\n",
      "test epoch: 5/11, round: 277/501, loss: 0.3680081367492676\n",
      "test epoch: 5/11, round: 278/501, loss: 0.5661262273788452\n",
      "test epoch: 5/11, round: 279/501, loss: 0.33381423354148865\n",
      "test epoch: 5/11, round: 280/501, loss: 0.2494015246629715\n",
      "test epoch: 5/11, round: 281/501, loss: 0.21111787855625153\n",
      "test epoch: 5/11, round: 282/501, loss: 0.29512277245521545\n",
      "test epoch: 5/11, round: 283/501, loss: 0.2862957715988159\n",
      "test epoch: 5/11, round: 284/501, loss: 0.36424097418785095\n",
      "test epoch: 5/11, round: 285/501, loss: 0.4306313693523407\n",
      "test epoch: 5/11, round: 286/501, loss: 0.4014049768447876\n",
      "test epoch: 5/11, round: 287/501, loss: 0.5640819072723389\n",
      "test epoch: 5/11, round: 288/501, loss: 0.2432994693517685\n",
      "test epoch: 5/11, round: 289/501, loss: 0.3047719895839691\n",
      "test epoch: 5/11, round: 290/501, loss: 0.3308061361312866\n",
      "test epoch: 5/11, round: 291/501, loss: 0.5221189856529236\n",
      "test epoch: 5/11, round: 292/501, loss: 0.49364718794822693\n",
      "test epoch: 5/11, round: 293/501, loss: 0.5815244317054749\n",
      "test epoch: 5/11, round: 294/501, loss: 0.2210288643836975\n",
      "test epoch: 5/11, round: 295/501, loss: 0.35586777329444885\n",
      "test epoch: 5/11, round: 296/501, loss: 0.42820289731025696\n",
      "test epoch: 5/11, round: 297/501, loss: 0.36768341064453125\n",
      "test epoch: 5/11, round: 298/501, loss: 0.4535900056362152\n",
      "test epoch: 5/11, round: 299/501, loss: 0.4321349561214447\n",
      "test epoch: 5/11, round: 300/501, loss: 0.5378631353378296\n",
      "test epoch: 5/11, round: 301/501, loss: 0.3902200162410736\n",
      "test epoch: 5/11, round: 302/501, loss: 0.23387162387371063\n",
      "test epoch: 5/11, round: 303/501, loss: 0.530181884765625\n",
      "test epoch: 5/11, round: 304/501, loss: 0.6254488825798035\n",
      "test epoch: 5/11, round: 305/501, loss: 0.17682941257953644\n",
      "test epoch: 5/11, round: 306/501, loss: 0.27088019251823425\n",
      "test epoch: 5/11, round: 307/501, loss: 0.4307920038700104\n",
      "test epoch: 5/11, round: 308/501, loss: 0.2763504087924957\n",
      "test epoch: 5/11, round: 309/501, loss: 0.44327083230018616\n",
      "test epoch: 5/11, round: 310/501, loss: 0.3830409348011017\n",
      "test epoch: 5/11, round: 311/501, loss: 0.5494323372840881\n",
      "test epoch: 5/11, round: 312/501, loss: 0.3870004117488861\n",
      "test epoch: 5/11, round: 313/501, loss: 0.3194986879825592\n",
      "test epoch: 5/11, round: 314/501, loss: 0.3267568051815033\n",
      "test epoch: 5/11, round: 315/501, loss: 0.35019174218177795\n",
      "test epoch: 5/11, round: 316/501, loss: 0.31201571226119995\n",
      "test epoch: 5/11, round: 317/501, loss: 0.340080201625824\n",
      "test epoch: 5/11, round: 318/501, loss: 0.36751118302345276\n",
      "test epoch: 5/11, round: 319/501, loss: 0.5726454257965088\n",
      "test epoch: 5/11, round: 320/501, loss: 0.4392639398574829\n",
      "test epoch: 5/11, round: 321/501, loss: 0.35477331280708313\n",
      "test epoch: 5/11, round: 322/501, loss: 0.4270409345626831\n",
      "test epoch: 5/11, round: 323/501, loss: 0.42571648955345154\n",
      "test epoch: 5/11, round: 324/501, loss: 0.30098846554756165\n",
      "test epoch: 5/11, round: 325/501, loss: 0.44654926657676697\n",
      "test epoch: 5/11, round: 326/501, loss: 0.4525716006755829\n",
      "test epoch: 5/11, round: 327/501, loss: 0.6130344271659851\n",
      "test epoch: 5/11, round: 328/501, loss: 0.19487294554710388\n",
      "test epoch: 5/11, round: 329/501, loss: 0.4610074758529663\n",
      "test epoch: 5/11, round: 330/501, loss: 0.4668005108833313\n",
      "test epoch: 5/11, round: 331/501, loss: 0.41681796312332153\n",
      "test epoch: 5/11, round: 332/501, loss: 0.36152875423431396\n",
      "test epoch: 5/11, round: 333/501, loss: 0.410176545381546\n",
      "test epoch: 5/11, round: 334/501, loss: 0.2730540335178375\n",
      "test epoch: 5/11, round: 335/501, loss: 0.359758198261261\n",
      "test epoch: 5/11, round: 336/501, loss: 0.34140077233314514\n",
      "test epoch: 5/11, round: 337/501, loss: 0.5761579275131226\n",
      "test epoch: 5/11, round: 338/501, loss: 0.3664957284927368\n",
      "test epoch: 5/11, round: 339/501, loss: 0.8228434324264526\n",
      "test epoch: 5/11, round: 340/501, loss: 0.41907399892807007\n",
      "test epoch: 5/11, round: 341/501, loss: 0.40913379192352295\n",
      "test epoch: 5/11, round: 342/501, loss: 0.3556024730205536\n",
      "test epoch: 5/11, round: 343/501, loss: 0.34153786301612854\n",
      "test epoch: 5/11, round: 344/501, loss: 0.24425284564495087\n",
      "test epoch: 5/11, round: 345/501, loss: 0.20785780251026154\n",
      "test epoch: 5/11, round: 346/501, loss: 0.30961811542510986\n",
      "test epoch: 5/11, round: 347/501, loss: 0.3299854099750519\n",
      "test epoch: 5/11, round: 348/501, loss: 0.43568024039268494\n",
      "test epoch: 5/11, round: 349/501, loss: 0.3479253649711609\n",
      "test epoch: 5/11, round: 350/501, loss: 0.4626367688179016\n",
      "test epoch: 5/11, round: 351/501, loss: 0.39758312702178955\n",
      "test epoch: 5/11, round: 352/501, loss: 0.4360213577747345\n",
      "test epoch: 5/11, round: 353/501, loss: 0.3693525493144989\n",
      "test epoch: 5/11, round: 354/501, loss: 0.4924885332584381\n",
      "test epoch: 5/11, round: 355/501, loss: 0.3940032720565796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 5/11, round: 356/501, loss: 0.5491772890090942\n",
      "test epoch: 5/11, round: 357/501, loss: 0.4291137158870697\n",
      "test epoch: 5/11, round: 358/501, loss: 0.38363710045814514\n",
      "test epoch: 5/11, round: 359/501, loss: 0.3467053771018982\n",
      "test epoch: 5/11, round: 360/501, loss: 0.5705813765525818\n",
      "test epoch: 5/11, round: 361/501, loss: 0.5523061752319336\n",
      "test epoch: 5/11, round: 362/501, loss: 0.3934955596923828\n",
      "test epoch: 5/11, round: 363/501, loss: 0.4747774004936218\n",
      "test epoch: 5/11, round: 364/501, loss: 0.4830836057662964\n",
      "test epoch: 5/11, round: 365/501, loss: 0.3833363950252533\n",
      "test epoch: 5/11, round: 366/501, loss: 0.5800714492797852\n",
      "test epoch: 5/11, round: 367/501, loss: 0.6776303052902222\n",
      "test epoch: 5/11, round: 368/501, loss: 0.32097333669662476\n",
      "test epoch: 5/11, round: 369/501, loss: 0.32438865303993225\n",
      "test epoch: 5/11, round: 370/501, loss: 0.3985643982887268\n",
      "test epoch: 5/11, round: 371/501, loss: 0.41535669565200806\n",
      "test epoch: 5/11, round: 372/501, loss: 0.3424451947212219\n",
      "test epoch: 5/11, round: 373/501, loss: 0.4570704698562622\n",
      "test epoch: 5/11, round: 374/501, loss: 0.328281968832016\n",
      "test epoch: 5/11, round: 375/501, loss: 0.5039711594581604\n",
      "test epoch: 5/11, round: 376/501, loss: 0.5599175691604614\n",
      "test epoch: 5/11, round: 377/501, loss: 0.15243996679782867\n",
      "test epoch: 5/11, round: 378/501, loss: 0.17629720270633698\n",
      "test epoch: 5/11, round: 379/501, loss: 0.44630926847457886\n",
      "test epoch: 5/11, round: 380/501, loss: 0.2710161507129669\n",
      "test epoch: 5/11, round: 381/501, loss: 0.4295080602169037\n",
      "test epoch: 5/11, round: 382/501, loss: 0.31624895334243774\n",
      "test epoch: 5/11, round: 383/501, loss: 0.3183283507823944\n",
      "test epoch: 5/11, round: 384/501, loss: 0.273798406124115\n",
      "test epoch: 5/11, round: 385/501, loss: 0.4774635434150696\n",
      "test epoch: 5/11, round: 386/501, loss: 0.5344359874725342\n",
      "test epoch: 5/11, round: 387/501, loss: 0.2519904375076294\n",
      "test epoch: 5/11, round: 388/501, loss: 0.2542726397514343\n",
      "test epoch: 5/11, round: 389/501, loss: 0.32422491908073425\n",
      "test epoch: 5/11, round: 390/501, loss: 0.4732667803764343\n",
      "test epoch: 5/11, round: 391/501, loss: 0.3433302342891693\n",
      "test epoch: 5/11, round: 392/501, loss: 0.4659067690372467\n",
      "test epoch: 5/11, round: 393/501, loss: 0.3929438292980194\n",
      "test epoch: 5/11, round: 394/501, loss: 0.6899493932723999\n",
      "test epoch: 5/11, round: 395/501, loss: 0.23631061613559723\n",
      "test epoch: 5/11, round: 396/501, loss: 0.4543101489543915\n",
      "test epoch: 5/11, round: 397/501, loss: 0.470291405916214\n",
      "test epoch: 5/11, round: 398/501, loss: 0.505985677242279\n",
      "test epoch: 5/11, round: 399/501, loss: 0.34931081533432007\n",
      "test epoch: 5/11, round: 400/501, loss: 0.33470872044563293\n",
      "test epoch: 5/11, round: 401/501, loss: 0.6237264275550842\n",
      "test epoch: 5/11, round: 402/501, loss: 0.41790565848350525\n",
      "test epoch: 5/11, round: 403/501, loss: 0.3671033978462219\n",
      "test epoch: 5/11, round: 404/501, loss: 0.2481934279203415\n",
      "test epoch: 5/11, round: 405/501, loss: 0.8163765072822571\n",
      "test epoch: 5/11, round: 406/501, loss: 0.40230637788772583\n",
      "test epoch: 5/11, round: 407/501, loss: 0.49282020330429077\n",
      "test epoch: 5/11, round: 408/501, loss: 0.4840070605278015\n",
      "test epoch: 5/11, round: 409/501, loss: 0.5889450311660767\n",
      "test epoch: 5/11, round: 410/501, loss: 0.4085725247859955\n",
      "test epoch: 5/11, round: 411/501, loss: 0.4466579556465149\n",
      "test epoch: 5/11, round: 412/501, loss: 0.4239265024662018\n",
      "test epoch: 5/11, round: 413/501, loss: 0.5163117051124573\n",
      "test epoch: 5/11, round: 414/501, loss: 0.3628780245780945\n",
      "test epoch: 5/11, round: 415/501, loss: 0.378987580537796\n",
      "test epoch: 5/11, round: 416/501, loss: 0.4162139296531677\n",
      "test epoch: 5/11, round: 417/501, loss: 0.25516337156295776\n",
      "test epoch: 5/11, round: 418/501, loss: 0.34118473529815674\n",
      "test epoch: 5/11, round: 419/501, loss: 0.37629586458206177\n",
      "test epoch: 5/11, round: 420/501, loss: 0.3288375735282898\n",
      "test epoch: 5/11, round: 421/501, loss: 0.4357168972492218\n",
      "test epoch: 5/11, round: 422/501, loss: 0.39475297927856445\n",
      "test epoch: 5/11, round: 423/501, loss: 0.659561812877655\n",
      "test epoch: 5/11, round: 424/501, loss: 0.4584598243236542\n",
      "test epoch: 5/11, round: 425/501, loss: 0.32924142479896545\n",
      "test epoch: 5/11, round: 426/501, loss: 0.4199509918689728\n",
      "test epoch: 5/11, round: 427/501, loss: 0.3067000210285187\n",
      "test epoch: 5/11, round: 428/501, loss: 0.5020886659622192\n",
      "test epoch: 5/11, round: 429/501, loss: 0.5415650010108948\n",
      "test epoch: 5/11, round: 430/501, loss: 0.5736135840415955\n",
      "test epoch: 5/11, round: 431/501, loss: 0.4224105179309845\n",
      "test epoch: 5/11, round: 432/501, loss: 0.3192669451236725\n",
      "test epoch: 5/11, round: 433/501, loss: 0.4156034588813782\n",
      "test epoch: 5/11, round: 434/501, loss: 0.31137654185295105\n",
      "test epoch: 5/11, round: 435/501, loss: 0.3134274482727051\n",
      "test epoch: 5/11, round: 436/501, loss: 0.3702392578125\n",
      "test epoch: 5/11, round: 437/501, loss: 0.5115705728530884\n",
      "test epoch: 5/11, round: 438/501, loss: 0.5213581919670105\n",
      "test epoch: 5/11, round: 439/501, loss: 0.365390419960022\n",
      "test epoch: 5/11, round: 440/501, loss: 0.44396212697029114\n",
      "test epoch: 5/11, round: 441/501, loss: 0.4220011830329895\n",
      "test epoch: 5/11, round: 442/501, loss: 0.34590256214141846\n",
      "test epoch: 5/11, round: 443/501, loss: 0.24814100563526154\n",
      "test epoch: 5/11, round: 444/501, loss: 0.4197072684764862\n",
      "test epoch: 5/11, round: 445/501, loss: 0.4153338670730591\n",
      "test epoch: 5/11, round: 446/501, loss: 0.4760279357433319\n",
      "test epoch: 5/11, round: 447/501, loss: 0.25102928280830383\n",
      "test epoch: 5/11, round: 448/501, loss: 0.3523627519607544\n",
      "test epoch: 5/11, round: 449/501, loss: 0.2544688880443573\n",
      "test epoch: 5/11, round: 450/501, loss: 0.7286518216133118\n",
      "test epoch: 5/11, round: 451/501, loss: 0.35615140199661255\n",
      "test epoch: 5/11, round: 452/501, loss: 0.40360844135284424\n",
      "test epoch: 5/11, round: 453/501, loss: 0.18165765702724457\n",
      "test epoch: 5/11, round: 454/501, loss: 0.26659825444221497\n",
      "test epoch: 5/11, round: 455/501, loss: 0.5111837387084961\n",
      "test epoch: 5/11, round: 456/501, loss: 0.34652814269065857\n",
      "test epoch: 5/11, round: 457/501, loss: 0.23109835386276245\n",
      "test epoch: 5/11, round: 458/501, loss: 0.29181772470474243\n",
      "test epoch: 5/11, round: 459/501, loss: 0.1824776977300644\n",
      "test epoch: 5/11, round: 460/501, loss: 0.16871656477451324\n",
      "test epoch: 5/11, round: 461/501, loss: 0.13764764368534088\n",
      "test epoch: 5/11, round: 462/501, loss: 0.13337208330631256\n",
      "test epoch: 5/11, round: 463/501, loss: 0.13690991699695587\n",
      "test epoch: 5/11, round: 464/501, loss: 0.1374242752790451\n",
      "test epoch: 5/11, round: 465/501, loss: 0.17061519622802734\n",
      "test epoch: 5/11, round: 466/501, loss: 0.14028744399547577\n",
      "test epoch: 5/11, round: 467/501, loss: 0.21023836731910706\n",
      "test epoch: 5/11, round: 468/501, loss: 0.1593264639377594\n",
      "test epoch: 5/11, round: 469/501, loss: 0.16713885962963104\n",
      "test epoch: 5/11, round: 470/501, loss: 0.14087533950805664\n",
      "test epoch: 5/11, round: 471/501, loss: 0.19060446321964264\n",
      "test epoch: 5/11, round: 472/501, loss: 0.16339024901390076\n",
      "test epoch: 5/11, round: 473/501, loss: 0.14906196296215057\n",
      "test epoch: 5/11, round: 474/501, loss: 0.1781671941280365\n",
      "test epoch: 5/11, round: 475/501, loss: 0.15618810057640076\n",
      "test epoch: 5/11, round: 476/501, loss: 0.127870574593544\n",
      "test epoch: 5/11, round: 477/501, loss: 0.11477484554052353\n",
      "test epoch: 5/11, round: 478/501, loss: 0.14442405104637146\n",
      "test epoch: 5/11, round: 479/501, loss: 0.11245915293693542\n",
      "test epoch: 5/11, round: 480/501, loss: 0.13410697877407074\n",
      "test epoch: 5/11, round: 481/501, loss: 0.14160044491291046\n",
      "test epoch: 5/11, round: 482/501, loss: 0.13306699693202972\n",
      "test epoch: 5/11, round: 483/501, loss: 0.1446276158094406\n",
      "test epoch: 5/11, round: 484/501, loss: 0.14387811720371246\n",
      "test epoch: 5/11, round: 485/501, loss: 0.12756936252117157\n",
      "test epoch: 5/11, round: 486/501, loss: 0.13373534381389618\n",
      "test epoch: 5/11, round: 487/501, loss: 0.1377144753932953\n",
      "test epoch: 5/11, round: 488/501, loss: 0.1682611107826233\n",
      "test epoch: 5/11, round: 489/501, loss: 0.1260044425725937\n",
      "test epoch: 5/11, round: 490/501, loss: 0.11572282016277313\n",
      "test epoch: 5/11, round: 491/501, loss: 0.14962495863437653\n",
      "test epoch: 5/11, round: 492/501, loss: 0.1638374626636505\n",
      "test epoch: 5/11, round: 493/501, loss: 0.15849696099758148\n",
      "test epoch: 5/11, round: 494/501, loss: 0.1401578038930893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 5/11, round: 495/501, loss: 0.10614439845085144\n",
      "test epoch: 5/11, round: 496/501, loss: 0.16646070778369904\n",
      "test epoch: 5/11, round: 497/501, loss: 0.13200490176677704\n",
      "test epoch: 5/11, round: 498/501, loss: 0.09007953107357025\n",
      "test epoch: 5/11, round: 499/501, loss: 0.11031933128833771\n",
      "test epoch: 5/11, round: 500/501, loss: 0.32419881224632263\n",
      "test epoch: 5/11, round: 501/501, loss: 0.792849600315094\n",
      "test epoch: 5/11, KS: 0.19467516370614282, ROC: 0.629840773842857\n",
      "cost time: 2002\n",
      "train epoch: 6/11, round: 1/532, loss: 0.3813697397708893\n",
      "train epoch: 6/11, round: 2/532, loss: 0.3897859752178192\n",
      "train epoch: 6/11, round: 3/532, loss: 0.3935609757900238\n",
      "train epoch: 6/11, round: 4/532, loss: 0.3579942286014557\n",
      "train epoch: 6/11, round: 5/532, loss: 0.3597416877746582\n",
      "train epoch: 6/11, round: 6/532, loss: 0.3525776267051697\n",
      "train epoch: 6/11, round: 7/532, loss: 0.3570094704627991\n",
      "train epoch: 6/11, round: 8/532, loss: 0.42358264327049255\n",
      "train epoch: 6/11, round: 9/532, loss: 0.33200520277023315\n",
      "train epoch: 6/11, round: 10/532, loss: 0.44484901428222656\n",
      "train epoch: 6/11, round: 11/532, loss: 0.43330565094947815\n",
      "train epoch: 6/11, round: 12/532, loss: 0.3517863154411316\n",
      "train epoch: 6/11, round: 13/532, loss: 0.38505834341049194\n",
      "train epoch: 6/11, round: 14/532, loss: 0.41631969809532166\n",
      "train epoch: 6/11, round: 15/532, loss: 0.40907207131385803\n",
      "train epoch: 6/11, round: 16/532, loss: 0.3475356698036194\n",
      "train epoch: 6/11, round: 17/532, loss: 0.3578658103942871\n",
      "train epoch: 6/11, round: 18/532, loss: 0.33035820722579956\n",
      "train epoch: 6/11, round: 19/532, loss: 0.3525257110595703\n",
      "train epoch: 6/11, round: 20/532, loss: 0.4118975102901459\n",
      "train epoch: 6/11, round: 21/532, loss: 0.33529144525527954\n",
      "train epoch: 6/11, round: 22/532, loss: 0.44375520944595337\n",
      "train epoch: 6/11, round: 23/532, loss: 0.3744242191314697\n",
      "train epoch: 6/11, round: 24/532, loss: 0.4499039053916931\n",
      "train epoch: 6/11, round: 25/532, loss: 0.3032629191875458\n",
      "train epoch: 6/11, round: 26/532, loss: 0.42061933875083923\n",
      "train epoch: 6/11, round: 27/532, loss: 0.4635235667228699\n",
      "train epoch: 6/11, round: 28/532, loss: 0.3700680136680603\n",
      "train epoch: 6/11, round: 29/532, loss: 0.36970415711402893\n",
      "train epoch: 6/11, round: 30/532, loss: 0.31092900037765503\n",
      "train epoch: 6/11, round: 31/532, loss: 0.4028305411338806\n",
      "train epoch: 6/11, round: 32/532, loss: 0.4171009659767151\n",
      "train epoch: 6/11, round: 33/532, loss: 0.40126433968544006\n",
      "train epoch: 6/11, round: 34/532, loss: 0.39118510484695435\n",
      "train epoch: 6/11, round: 35/532, loss: 0.3603780269622803\n",
      "train epoch: 6/11, round: 36/532, loss: 0.42532357573509216\n",
      "train epoch: 6/11, round: 37/532, loss: 0.37529298663139343\n",
      "train epoch: 6/11, round: 38/532, loss: 0.4100969731807709\n",
      "train epoch: 6/11, round: 39/532, loss: 0.3517252206802368\n",
      "train epoch: 6/11, round: 40/532, loss: 0.4104278087615967\n",
      "train epoch: 6/11, round: 41/532, loss: 0.3859935402870178\n",
      "train epoch: 6/11, round: 42/532, loss: 0.41818976402282715\n",
      "train epoch: 6/11, round: 43/532, loss: 0.479741632938385\n",
      "train epoch: 6/11, round: 44/532, loss: 0.3536228835582733\n",
      "train epoch: 6/11, round: 45/532, loss: 0.436937153339386\n",
      "train epoch: 6/11, round: 46/532, loss: 0.4078279137611389\n",
      "train epoch: 6/11, round: 47/532, loss: 0.3886018693447113\n",
      "train epoch: 6/11, round: 48/532, loss: 0.4705635607242584\n",
      "train epoch: 6/11, round: 49/532, loss: 0.48719269037246704\n",
      "train epoch: 6/11, round: 50/532, loss: 0.3650370240211487\n",
      "train epoch: 6/11, round: 51/532, loss: 0.4512566030025482\n",
      "train epoch: 6/11, round: 52/532, loss: 0.30559009313583374\n",
      "train epoch: 6/11, round: 53/532, loss: 0.3338521122932434\n",
      "train epoch: 6/11, round: 54/532, loss: 0.373269259929657\n",
      "train epoch: 6/11, round: 55/532, loss: 0.4425685405731201\n",
      "train epoch: 6/11, round: 56/532, loss: 0.4602648615837097\n",
      "train epoch: 6/11, round: 57/532, loss: 0.35641342401504517\n",
      "train epoch: 6/11, round: 58/532, loss: 0.35199183225631714\n",
      "train epoch: 6/11, round: 59/532, loss: 0.27818939089775085\n",
      "train epoch: 6/11, round: 60/532, loss: 0.41298627853393555\n",
      "train epoch: 6/11, round: 61/532, loss: 0.36024942994117737\n",
      "train epoch: 6/11, round: 62/532, loss: 0.4483083188533783\n",
      "train epoch: 6/11, round: 63/532, loss: 0.30296048521995544\n",
      "train epoch: 6/11, round: 64/532, loss: 0.4202679693698883\n",
      "train epoch: 6/11, round: 65/532, loss: 0.49519529938697815\n",
      "train epoch: 6/11, round: 66/532, loss: 0.39066100120544434\n",
      "train epoch: 6/11, round: 67/532, loss: 0.3080022931098938\n",
      "train epoch: 6/11, round: 68/532, loss: 0.4228861331939697\n",
      "train epoch: 6/11, round: 69/532, loss: 0.36986055970191956\n",
      "train epoch: 6/11, round: 70/532, loss: 0.4644508361816406\n",
      "train epoch: 6/11, round: 71/532, loss: 0.5271176099777222\n",
      "train epoch: 6/11, round: 72/532, loss: 0.3519541919231415\n",
      "train epoch: 6/11, round: 73/532, loss: 0.41829290986061096\n",
      "train epoch: 6/11, round: 74/532, loss: 0.40203413367271423\n",
      "train epoch: 6/11, round: 75/532, loss: 0.4793829917907715\n",
      "train epoch: 6/11, round: 76/532, loss: 0.3850128650665283\n",
      "train epoch: 6/11, round: 77/532, loss: 0.36714377999305725\n",
      "train epoch: 6/11, round: 78/532, loss: 0.3687073588371277\n",
      "train epoch: 6/11, round: 79/532, loss: 0.34214305877685547\n",
      "train epoch: 6/11, round: 80/532, loss: 0.3705993592739105\n",
      "train epoch: 6/11, round: 81/532, loss: 0.33940058946609497\n",
      "train epoch: 6/11, round: 82/532, loss: 0.3614942729473114\n",
      "train epoch: 6/11, round: 83/532, loss: 0.42846840620040894\n",
      "train epoch: 6/11, round: 84/532, loss: 0.44221481680870056\n",
      "train epoch: 6/11, round: 85/532, loss: 0.42154139280319214\n",
      "train epoch: 6/11, round: 86/532, loss: 0.35415536165237427\n",
      "train epoch: 6/11, round: 87/532, loss: 0.42157793045043945\n",
      "train epoch: 6/11, round: 88/532, loss: 0.2994617819786072\n",
      "train epoch: 6/11, round: 89/532, loss: 0.4859854280948639\n",
      "train epoch: 6/11, round: 90/532, loss: 0.38325896859169006\n",
      "train epoch: 6/11, round: 91/532, loss: 0.36755818128585815\n",
      "train epoch: 6/11, round: 92/532, loss: 0.39654430747032166\n",
      "train epoch: 6/11, round: 93/532, loss: 0.43021446466445923\n",
      "train epoch: 6/11, round: 94/532, loss: 0.5109518766403198\n",
      "train epoch: 6/11, round: 95/532, loss: 0.39503371715545654\n",
      "train epoch: 6/11, round: 96/532, loss: 0.436647891998291\n",
      "train epoch: 6/11, round: 97/532, loss: 0.40074700117111206\n",
      "train epoch: 6/11, round: 98/532, loss: 0.35594186186790466\n",
      "train epoch: 6/11, round: 99/532, loss: 0.37101131677627563\n",
      "train epoch: 6/11, round: 100/532, loss: 0.3434385657310486\n",
      "train epoch: 6/11, round: 101/532, loss: 0.37925228476524353\n",
      "train epoch: 6/11, round: 102/532, loss: 0.35085529088974\n",
      "train epoch: 6/11, round: 103/532, loss: 0.4723709523677826\n",
      "train epoch: 6/11, round: 104/532, loss: 0.48452258110046387\n",
      "train epoch: 6/11, round: 105/532, loss: 0.37948107719421387\n",
      "train epoch: 6/11, round: 106/532, loss: 0.4152560234069824\n",
      "train epoch: 6/11, round: 107/532, loss: 0.3273394703865051\n",
      "train epoch: 6/11, round: 108/532, loss: 0.3493212163448334\n",
      "train epoch: 6/11, round: 109/532, loss: 0.4042584300041199\n",
      "train epoch: 6/11, round: 110/532, loss: 0.48529958724975586\n",
      "train epoch: 6/11, round: 111/532, loss: 0.4207441806793213\n",
      "train epoch: 6/11, round: 112/532, loss: 0.3041054606437683\n",
      "train epoch: 6/11, round: 113/532, loss: 0.3943400979042053\n",
      "train epoch: 6/11, round: 114/532, loss: 0.38923418521881104\n",
      "train epoch: 6/11, round: 115/532, loss: 0.3918326497077942\n",
      "train epoch: 6/11, round: 116/532, loss: 0.4109589457511902\n",
      "train epoch: 6/11, round: 117/532, loss: 0.4647769033908844\n",
      "train epoch: 6/11, round: 118/532, loss: 0.3629184663295746\n",
      "train epoch: 6/11, round: 119/532, loss: 0.38449975848197937\n",
      "train epoch: 6/11, round: 120/532, loss: 0.4348739981651306\n",
      "train epoch: 6/11, round: 121/532, loss: 0.36326879262924194\n",
      "train epoch: 6/11, round: 122/532, loss: 0.3642820417881012\n",
      "train epoch: 6/11, round: 123/532, loss: 0.4026699960231781\n",
      "train epoch: 6/11, round: 124/532, loss: 0.44397011399269104\n",
      "train epoch: 6/11, round: 125/532, loss: 0.2873660922050476\n",
      "train epoch: 6/11, round: 126/532, loss: 0.4451327323913574\n",
      "train epoch: 6/11, round: 127/532, loss: 0.41031521558761597\n",
      "train epoch: 6/11, round: 128/532, loss: 0.38914984464645386\n",
      "train epoch: 6/11, round: 129/532, loss: 0.32131272554397583\n",
      "train epoch: 6/11, round: 130/532, loss: 0.3551991581916809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6/11, round: 131/532, loss: 0.37380892038345337\n",
      "train epoch: 6/11, round: 132/532, loss: 0.3463480472564697\n",
      "train epoch: 6/11, round: 133/532, loss: 0.5054783225059509\n",
      "train epoch: 6/11, round: 134/532, loss: 0.4289385676383972\n",
      "train epoch: 6/11, round: 135/532, loss: 0.4686766564846039\n",
      "train epoch: 6/11, round: 136/532, loss: 0.40603384375572205\n",
      "train epoch: 6/11, round: 137/532, loss: 0.4230666756629944\n",
      "train epoch: 6/11, round: 138/532, loss: 0.35212022066116333\n",
      "train epoch: 6/11, round: 139/532, loss: 0.3818172514438629\n",
      "train epoch: 6/11, round: 140/532, loss: 0.3017704486846924\n",
      "train epoch: 6/11, round: 141/532, loss: 0.3598242700099945\n",
      "train epoch: 6/11, round: 142/532, loss: 0.39099013805389404\n",
      "train epoch: 6/11, round: 143/532, loss: 0.461143434047699\n",
      "train epoch: 6/11, round: 144/532, loss: 0.3925595283508301\n",
      "train epoch: 6/11, round: 145/532, loss: 0.42155224084854126\n",
      "train epoch: 6/11, round: 146/532, loss: 0.44571390748023987\n",
      "train epoch: 6/11, round: 147/532, loss: 0.4114243984222412\n",
      "train epoch: 6/11, round: 148/532, loss: 0.42158421874046326\n",
      "train epoch: 6/11, round: 149/532, loss: 0.4490688741207123\n",
      "train epoch: 6/11, round: 150/532, loss: 0.35392603278160095\n",
      "train epoch: 6/11, round: 151/532, loss: 0.4543212950229645\n",
      "train epoch: 6/11, round: 152/532, loss: 0.34628069400787354\n",
      "train epoch: 6/11, round: 153/532, loss: 0.4413619935512543\n",
      "train epoch: 6/11, round: 154/532, loss: 0.3298476040363312\n",
      "train epoch: 6/11, round: 155/532, loss: 0.4553568959236145\n",
      "train epoch: 6/11, round: 156/532, loss: 0.41169506311416626\n",
      "train epoch: 6/11, round: 157/532, loss: 0.3637271523475647\n",
      "train epoch: 6/11, round: 158/532, loss: 0.4719020426273346\n",
      "train epoch: 6/11, round: 159/532, loss: 0.45408374071121216\n",
      "train epoch: 6/11, round: 160/532, loss: 0.29118210077285767\n",
      "train epoch: 6/11, round: 161/532, loss: 0.4008214473724365\n",
      "train epoch: 6/11, round: 162/532, loss: 0.3772069811820984\n",
      "train epoch: 6/11, round: 163/532, loss: 0.3424603343009949\n",
      "train epoch: 6/11, round: 164/532, loss: 0.3511369526386261\n",
      "train epoch: 6/11, round: 165/532, loss: 0.4723806381225586\n",
      "train epoch: 6/11, round: 166/532, loss: 0.38800621032714844\n",
      "train epoch: 6/11, round: 167/532, loss: 0.3609180450439453\n",
      "train epoch: 6/11, round: 168/532, loss: 0.33709901571273804\n",
      "train epoch: 6/11, round: 169/532, loss: 0.31145811080932617\n",
      "train epoch: 6/11, round: 170/532, loss: 0.42382559180259705\n",
      "train epoch: 6/11, round: 171/532, loss: 0.45603570342063904\n",
      "train epoch: 6/11, round: 172/532, loss: 0.3578973412513733\n",
      "train epoch: 6/11, round: 173/532, loss: 0.33310458064079285\n",
      "train epoch: 6/11, round: 174/532, loss: 0.2981756627559662\n",
      "train epoch: 6/11, round: 175/532, loss: 0.4204637110233307\n",
      "train epoch: 6/11, round: 176/532, loss: 0.34310629963874817\n",
      "train epoch: 6/11, round: 177/532, loss: 0.3709842562675476\n",
      "train epoch: 6/11, round: 178/532, loss: 0.5000823140144348\n",
      "train epoch: 6/11, round: 179/532, loss: 0.3938063085079193\n",
      "train epoch: 6/11, round: 180/532, loss: 0.37394002079963684\n",
      "train epoch: 6/11, round: 181/532, loss: 0.3705715537071228\n",
      "train epoch: 6/11, round: 182/532, loss: 0.3168521225452423\n",
      "train epoch: 6/11, round: 183/532, loss: 0.35080891847610474\n",
      "train epoch: 6/11, round: 184/532, loss: 0.3381335139274597\n",
      "train epoch: 6/11, round: 185/532, loss: 0.4933459162712097\n",
      "train epoch: 6/11, round: 186/532, loss: 0.29687896370887756\n",
      "train epoch: 6/11, round: 187/532, loss: 0.4312615394592285\n",
      "train epoch: 6/11, round: 188/532, loss: 0.4363652765750885\n",
      "train epoch: 6/11, round: 189/532, loss: 0.4225849211215973\n",
      "train epoch: 6/11, round: 190/532, loss: 0.4677044451236725\n",
      "train epoch: 6/11, round: 191/532, loss: 0.3065248429775238\n",
      "train epoch: 6/11, round: 192/532, loss: 0.4089817404747009\n",
      "train epoch: 6/11, round: 193/532, loss: 0.42489808797836304\n",
      "train epoch: 6/11, round: 194/532, loss: 0.4657183587551117\n",
      "train epoch: 6/11, round: 195/532, loss: 0.41709470748901367\n",
      "train epoch: 6/11, round: 196/532, loss: 0.3884262442588806\n",
      "train epoch: 6/11, round: 197/532, loss: 0.3690887987613678\n",
      "train epoch: 6/11, round: 198/532, loss: 0.3568735718727112\n",
      "train epoch: 6/11, round: 199/532, loss: 0.49945539236068726\n",
      "train epoch: 6/11, round: 200/532, loss: 0.33938559889793396\n",
      "train epoch: 6/11, round: 201/532, loss: 0.4199041426181793\n",
      "train epoch: 6/11, round: 202/532, loss: 0.46360301971435547\n",
      "train epoch: 6/11, round: 203/532, loss: 0.4734371602535248\n",
      "train epoch: 6/11, round: 204/532, loss: 0.4183233678340912\n",
      "train epoch: 6/11, round: 205/532, loss: 0.4220375418663025\n",
      "train epoch: 6/11, round: 206/532, loss: 0.38579410314559937\n",
      "train epoch: 6/11, round: 207/532, loss: 0.4094180166721344\n",
      "train epoch: 6/11, round: 208/532, loss: 0.43417268991470337\n",
      "train epoch: 6/11, round: 209/532, loss: 0.4125804305076599\n",
      "train epoch: 6/11, round: 210/532, loss: 0.37848153710365295\n",
      "train epoch: 6/11, round: 211/532, loss: 0.36775216460227966\n",
      "train epoch: 6/11, round: 212/532, loss: 0.42097654938697815\n",
      "train epoch: 6/11, round: 213/532, loss: 0.462485134601593\n",
      "train epoch: 6/11, round: 214/532, loss: 0.36808282136917114\n",
      "train epoch: 6/11, round: 215/532, loss: 0.3313513398170471\n",
      "train epoch: 6/11, round: 216/532, loss: 0.30471473932266235\n",
      "train epoch: 6/11, round: 217/532, loss: 0.479181706905365\n",
      "train epoch: 6/11, round: 218/532, loss: 0.38262003660202026\n",
      "train epoch: 6/11, round: 219/532, loss: 0.40807586908340454\n",
      "train epoch: 6/11, round: 220/532, loss: 0.32415640354156494\n",
      "train epoch: 6/11, round: 221/532, loss: 0.401742160320282\n",
      "train epoch: 6/11, round: 222/532, loss: 0.4997135102748871\n",
      "train epoch: 6/11, round: 223/532, loss: 0.34907737374305725\n",
      "train epoch: 6/11, round: 224/532, loss: 0.41847673058509827\n",
      "train epoch: 6/11, round: 225/532, loss: 0.3406202793121338\n",
      "train epoch: 6/11, round: 226/532, loss: 0.3679841160774231\n",
      "train epoch: 6/11, round: 227/532, loss: 0.3101418614387512\n",
      "train epoch: 6/11, round: 228/532, loss: 0.4390694200992584\n",
      "train epoch: 6/11, round: 229/532, loss: 0.3987359404563904\n",
      "train epoch: 6/11, round: 230/532, loss: 0.34919896721839905\n",
      "train epoch: 6/11, round: 231/532, loss: 0.4202192723751068\n",
      "train epoch: 6/11, round: 232/532, loss: 0.29262176156044006\n",
      "train epoch: 6/11, round: 233/532, loss: 0.47143012285232544\n",
      "train epoch: 6/11, round: 234/532, loss: 0.3772711455821991\n",
      "train epoch: 6/11, round: 235/532, loss: 0.4322839677333832\n",
      "train epoch: 6/11, round: 236/532, loss: 0.3698352873325348\n",
      "train epoch: 6/11, round: 237/532, loss: 0.3229902982711792\n",
      "train epoch: 6/11, round: 238/532, loss: 0.3123360276222229\n",
      "train epoch: 6/11, round: 239/532, loss: 0.4319888949394226\n",
      "train epoch: 6/11, round: 240/532, loss: 0.40348130464553833\n",
      "train epoch: 6/11, round: 241/532, loss: 0.35382044315338135\n",
      "train epoch: 6/11, round: 242/532, loss: 0.3930802047252655\n",
      "train epoch: 6/11, round: 243/532, loss: 0.33317846059799194\n",
      "train epoch: 6/11, round: 244/532, loss: 0.4594983458518982\n",
      "train epoch: 6/11, round: 245/532, loss: 0.3946684002876282\n",
      "train epoch: 6/11, round: 246/532, loss: 0.3575654625892639\n",
      "train epoch: 6/11, round: 247/532, loss: 0.39690810441970825\n",
      "train epoch: 6/11, round: 248/532, loss: 0.36146992444992065\n",
      "train epoch: 6/11, round: 249/532, loss: 0.2968667447566986\n",
      "train epoch: 6/11, round: 250/532, loss: 0.38264673948287964\n",
      "train epoch: 6/11, round: 251/532, loss: 0.42628270387649536\n",
      "train epoch: 6/11, round: 252/532, loss: 0.4682162404060364\n",
      "train epoch: 6/11, round: 253/532, loss: 0.38272926211357117\n",
      "train epoch: 6/11, round: 254/532, loss: 0.2925020158290863\n",
      "train epoch: 6/11, round: 255/532, loss: 0.4580293595790863\n",
      "train epoch: 6/11, round: 256/532, loss: 0.304842084646225\n",
      "train epoch: 6/11, round: 257/532, loss: 0.3342950940132141\n",
      "train epoch: 6/11, round: 258/532, loss: 0.3497997224330902\n",
      "train epoch: 6/11, round: 259/532, loss: 0.4546462595462799\n",
      "train epoch: 6/11, round: 260/532, loss: 0.3566572666168213\n",
      "train epoch: 6/11, round: 261/532, loss: 0.37552475929260254\n",
      "train epoch: 6/11, round: 262/532, loss: 0.4351135194301605\n",
      "train epoch: 6/11, round: 263/532, loss: 0.39714205265045166\n",
      "train epoch: 6/11, round: 264/532, loss: 0.3937194347381592\n",
      "train epoch: 6/11, round: 265/532, loss: 0.48280319571495056\n",
      "train epoch: 6/11, round: 266/532, loss: 0.47471266984939575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6/11, round: 267/532, loss: 0.3899487555027008\n",
      "train epoch: 6/11, round: 268/532, loss: 0.31530407071113586\n",
      "train epoch: 6/11, round: 269/532, loss: 0.3811596930027008\n",
      "train epoch: 6/11, round: 270/532, loss: 0.39301151037216187\n",
      "train epoch: 6/11, round: 271/532, loss: 0.36889055371284485\n",
      "train epoch: 6/11, round: 272/532, loss: 0.4374209940433502\n",
      "train epoch: 6/11, round: 273/532, loss: 0.36047011613845825\n",
      "train epoch: 6/11, round: 274/532, loss: 0.3085835576057434\n",
      "train epoch: 6/11, round: 275/532, loss: 0.3855562210083008\n",
      "train epoch: 6/11, round: 276/532, loss: 0.4496808648109436\n",
      "train epoch: 6/11, round: 277/532, loss: 0.4488741457462311\n",
      "train epoch: 6/11, round: 278/532, loss: 0.3924838900566101\n",
      "train epoch: 6/11, round: 279/532, loss: 0.3796149790287018\n",
      "train epoch: 6/11, round: 280/532, loss: 0.414252907037735\n",
      "train epoch: 6/11, round: 281/532, loss: 0.3008158802986145\n",
      "train epoch: 6/11, round: 282/532, loss: 0.30677878856658936\n",
      "train epoch: 6/11, round: 283/532, loss: 0.44325336813926697\n",
      "train epoch: 6/11, round: 284/532, loss: 0.41016340255737305\n",
      "train epoch: 6/11, round: 285/532, loss: 0.4727281928062439\n",
      "train epoch: 6/11, round: 286/532, loss: 0.40956911444664\n",
      "train epoch: 6/11, round: 287/532, loss: 0.277694433927536\n",
      "train epoch: 6/11, round: 288/532, loss: 0.3784191608428955\n",
      "train epoch: 6/11, round: 289/532, loss: 0.405665785074234\n",
      "train epoch: 6/11, round: 290/532, loss: 0.3837360739707947\n",
      "train epoch: 6/11, round: 291/532, loss: 0.41044512391090393\n",
      "train epoch: 6/11, round: 292/532, loss: 0.37643083930015564\n",
      "train epoch: 6/11, round: 293/532, loss: 0.38179296255111694\n",
      "train epoch: 6/11, round: 294/532, loss: 0.39734798669815063\n",
      "train epoch: 6/11, round: 295/532, loss: 0.3955848515033722\n",
      "train epoch: 6/11, round: 296/532, loss: 0.4626239240169525\n",
      "train epoch: 6/11, round: 297/532, loss: 0.3384801745414734\n",
      "train epoch: 6/11, round: 298/532, loss: 0.39169925451278687\n",
      "train epoch: 6/11, round: 299/532, loss: 0.41093072295188904\n",
      "train epoch: 6/11, round: 300/532, loss: 0.4579842984676361\n",
      "train epoch: 6/11, round: 301/532, loss: 0.41427335143089294\n",
      "train epoch: 6/11, round: 302/532, loss: 0.40350884199142456\n",
      "train epoch: 6/11, round: 303/532, loss: 0.43799543380737305\n",
      "train epoch: 6/11, round: 304/532, loss: 0.4852854609489441\n",
      "train epoch: 6/11, round: 305/532, loss: 0.3299294710159302\n",
      "train epoch: 6/11, round: 306/532, loss: 0.4209024906158447\n",
      "train epoch: 6/11, round: 307/532, loss: 0.4071127474308014\n",
      "train epoch: 6/11, round: 308/532, loss: 0.43164530396461487\n",
      "train epoch: 6/11, round: 309/532, loss: 0.39424657821655273\n",
      "train epoch: 6/11, round: 310/532, loss: 0.38250160217285156\n",
      "train epoch: 6/11, round: 311/532, loss: 0.39590349793434143\n",
      "train epoch: 6/11, round: 312/532, loss: 0.445594847202301\n",
      "train epoch: 6/11, round: 313/532, loss: 0.3284188508987427\n",
      "train epoch: 6/11, round: 314/532, loss: 0.4261079728603363\n",
      "train epoch: 6/11, round: 315/532, loss: 0.3673882484436035\n",
      "train epoch: 6/11, round: 316/532, loss: 0.4072968363761902\n",
      "train epoch: 6/11, round: 317/532, loss: 0.40738028287887573\n",
      "train epoch: 6/11, round: 318/532, loss: 0.3511815667152405\n",
      "train epoch: 6/11, round: 319/532, loss: 0.3925195336341858\n",
      "train epoch: 6/11, round: 320/532, loss: 0.36946815252304077\n",
      "train epoch: 6/11, round: 321/532, loss: 0.42553481459617615\n",
      "train epoch: 6/11, round: 322/532, loss: 0.41607004404067993\n",
      "train epoch: 6/11, round: 323/532, loss: 0.42990875244140625\n",
      "train epoch: 6/11, round: 324/532, loss: 0.374648779630661\n",
      "train epoch: 6/11, round: 325/532, loss: 0.3619435429573059\n",
      "train epoch: 6/11, round: 326/532, loss: 0.41399940848350525\n",
      "train epoch: 6/11, round: 327/532, loss: 0.363947331905365\n",
      "train epoch: 6/11, round: 328/532, loss: 0.4312078058719635\n",
      "train epoch: 6/11, round: 329/532, loss: 0.3933899998664856\n",
      "train epoch: 6/11, round: 330/532, loss: 0.3259546756744385\n",
      "train epoch: 6/11, round: 331/532, loss: 0.4953795075416565\n",
      "train epoch: 6/11, round: 332/532, loss: 0.39281272888183594\n",
      "train epoch: 6/11, round: 333/532, loss: 0.3278469145298004\n",
      "train epoch: 6/11, round: 334/532, loss: 0.44650325179100037\n",
      "train epoch: 6/11, round: 335/532, loss: 0.3569977581501007\n",
      "train epoch: 6/11, round: 336/532, loss: 0.417825311422348\n",
      "train epoch: 6/11, round: 337/532, loss: 0.29204195737838745\n",
      "train epoch: 6/11, round: 338/532, loss: 0.474313348531723\n",
      "train epoch: 6/11, round: 339/532, loss: 0.42726239562034607\n",
      "train epoch: 6/11, round: 340/532, loss: 0.37901949882507324\n",
      "train epoch: 6/11, round: 341/532, loss: 0.2653929591178894\n",
      "train epoch: 6/11, round: 342/532, loss: 0.4350535273551941\n",
      "train epoch: 6/11, round: 343/532, loss: 0.449558824300766\n",
      "train epoch: 6/11, round: 344/532, loss: 0.5177476406097412\n",
      "train epoch: 6/11, round: 345/532, loss: 0.38339269161224365\n",
      "train epoch: 6/11, round: 346/532, loss: 0.4248407781124115\n",
      "train epoch: 6/11, round: 347/532, loss: 0.3366601765155792\n",
      "train epoch: 6/11, round: 348/532, loss: 0.37151139974594116\n",
      "train epoch: 6/11, round: 349/532, loss: 0.368111252784729\n",
      "train epoch: 6/11, round: 350/532, loss: 0.3608531951904297\n",
      "train epoch: 6/11, round: 351/532, loss: 0.44209131598472595\n",
      "train epoch: 6/11, round: 352/532, loss: 0.43629106879234314\n",
      "train epoch: 6/11, round: 353/532, loss: 0.48939400911331177\n",
      "train epoch: 6/11, round: 354/532, loss: 0.4031898081302643\n",
      "train epoch: 6/11, round: 355/532, loss: 0.454232782125473\n",
      "train epoch: 6/11, round: 356/532, loss: 0.4234447479248047\n",
      "train epoch: 6/11, round: 357/532, loss: 0.37371090054512024\n",
      "train epoch: 6/11, round: 358/532, loss: 0.39429837465286255\n",
      "train epoch: 6/11, round: 359/532, loss: 0.38350892066955566\n",
      "train epoch: 6/11, round: 360/532, loss: 0.40943390130996704\n",
      "train epoch: 6/11, round: 361/532, loss: 0.30683305859565735\n",
      "train epoch: 6/11, round: 362/532, loss: 0.4510285258293152\n",
      "train epoch: 6/11, round: 363/532, loss: 0.41825881600379944\n",
      "train epoch: 6/11, round: 364/532, loss: 0.48490414023399353\n",
      "train epoch: 6/11, round: 365/532, loss: 0.44521936774253845\n",
      "train epoch: 6/11, round: 366/532, loss: 0.4494689404964447\n",
      "train epoch: 6/11, round: 367/532, loss: 0.3487014174461365\n",
      "train epoch: 6/11, round: 368/532, loss: 0.3776509165763855\n",
      "train epoch: 6/11, round: 369/532, loss: 0.378898561000824\n",
      "train epoch: 6/11, round: 370/532, loss: 0.43678897619247437\n",
      "train epoch: 6/11, round: 371/532, loss: 0.3804972767829895\n",
      "train epoch: 6/11, round: 372/532, loss: 0.3919529318809509\n",
      "train epoch: 6/11, round: 373/532, loss: 0.3661409020423889\n",
      "train epoch: 6/11, round: 374/532, loss: 0.3150749206542969\n",
      "train epoch: 6/11, round: 375/532, loss: 0.45317769050598145\n",
      "train epoch: 6/11, round: 376/532, loss: 0.3908156454563141\n",
      "train epoch: 6/11, round: 377/532, loss: 0.42832231521606445\n",
      "train epoch: 6/11, round: 378/532, loss: 0.4504217505455017\n",
      "train epoch: 6/11, round: 379/532, loss: 0.38314712047576904\n",
      "train epoch: 6/11, round: 380/532, loss: 0.29361486434936523\n",
      "train epoch: 6/11, round: 381/532, loss: 0.35086503624916077\n",
      "train epoch: 6/11, round: 382/532, loss: 0.3559221625328064\n",
      "train epoch: 6/11, round: 383/532, loss: 0.3914361596107483\n",
      "train epoch: 6/11, round: 384/532, loss: 0.46907275915145874\n",
      "train epoch: 6/11, round: 385/532, loss: 0.3802279829978943\n",
      "train epoch: 6/11, round: 386/532, loss: 0.39527255296707153\n",
      "train epoch: 6/11, round: 387/532, loss: 0.38747602701187134\n",
      "train epoch: 6/11, round: 388/532, loss: 0.39704465866088867\n",
      "train epoch: 6/11, round: 389/532, loss: 0.3839316964149475\n",
      "train epoch: 6/11, round: 390/532, loss: 0.36459869146347046\n",
      "train epoch: 6/11, round: 391/532, loss: 0.40504956245422363\n",
      "train epoch: 6/11, round: 392/532, loss: 0.30707499384880066\n",
      "train epoch: 6/11, round: 393/532, loss: 0.37551426887512207\n",
      "train epoch: 6/11, round: 394/532, loss: 0.3160387873649597\n",
      "train epoch: 6/11, round: 395/532, loss: 0.4003029763698578\n",
      "train epoch: 6/11, round: 396/532, loss: 0.41508030891418457\n",
      "train epoch: 6/11, round: 397/532, loss: 0.31225934624671936\n",
      "train epoch: 6/11, round: 398/532, loss: 0.3416275382041931\n",
      "train epoch: 6/11, round: 399/532, loss: 0.39901968836784363\n",
      "train epoch: 6/11, round: 400/532, loss: 0.3361499309539795\n",
      "train epoch: 6/11, round: 401/532, loss: 0.35681551694869995\n",
      "train epoch: 6/11, round: 402/532, loss: 0.3207576870918274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6/11, round: 403/532, loss: 0.4484683871269226\n",
      "train epoch: 6/11, round: 404/532, loss: 0.33714714646339417\n",
      "train epoch: 6/11, round: 405/532, loss: 0.3272044062614441\n",
      "train epoch: 6/11, round: 406/532, loss: 0.3581560254096985\n",
      "train epoch: 6/11, round: 407/532, loss: 0.32832446694374084\n",
      "train epoch: 6/11, round: 408/532, loss: 0.41683608293533325\n",
      "train epoch: 6/11, round: 409/532, loss: 0.4125320017337799\n",
      "train epoch: 6/11, round: 410/532, loss: 0.3819204866886139\n",
      "train epoch: 6/11, round: 411/532, loss: 0.42080169916152954\n",
      "train epoch: 6/11, round: 412/532, loss: 0.4832746088504791\n",
      "train epoch: 6/11, round: 413/532, loss: 0.33268463611602783\n",
      "train epoch: 6/11, round: 414/532, loss: 0.3988110423088074\n",
      "train epoch: 6/11, round: 415/532, loss: 0.4581066966056824\n",
      "train epoch: 6/11, round: 416/532, loss: 0.38926810026168823\n",
      "train epoch: 6/11, round: 417/532, loss: 0.36625564098358154\n",
      "train epoch: 6/11, round: 418/532, loss: 0.3944306969642639\n",
      "train epoch: 6/11, round: 419/532, loss: 0.3926030993461609\n",
      "train epoch: 6/11, round: 420/532, loss: 0.406062513589859\n",
      "train epoch: 6/11, round: 421/532, loss: 0.39078202843666077\n",
      "train epoch: 6/11, round: 422/532, loss: 0.4222833514213562\n",
      "train epoch: 6/11, round: 423/532, loss: 0.3759993612766266\n",
      "train epoch: 6/11, round: 424/532, loss: 0.34314805269241333\n",
      "train epoch: 6/11, round: 425/532, loss: 0.30690836906433105\n",
      "train epoch: 6/11, round: 426/532, loss: 0.4265534281730652\n",
      "train epoch: 6/11, round: 427/532, loss: 0.3598657548427582\n",
      "train epoch: 6/11, round: 428/532, loss: 0.39690786600112915\n",
      "train epoch: 6/11, round: 429/532, loss: 0.40848588943481445\n",
      "train epoch: 6/11, round: 430/532, loss: 0.4745520055294037\n",
      "train epoch: 6/11, round: 431/532, loss: 0.35452553629875183\n",
      "train epoch: 6/11, round: 432/532, loss: 0.33378687500953674\n",
      "train epoch: 6/11, round: 433/532, loss: 0.3274310231208801\n",
      "train epoch: 6/11, round: 434/532, loss: 0.42609405517578125\n",
      "train epoch: 6/11, round: 435/532, loss: 0.381327360868454\n",
      "train epoch: 6/11, round: 436/532, loss: 0.4562360644340515\n",
      "train epoch: 6/11, round: 437/532, loss: 0.43127888441085815\n",
      "train epoch: 6/11, round: 438/532, loss: 0.48823848366737366\n",
      "train epoch: 6/11, round: 439/532, loss: 0.3613138794898987\n",
      "train epoch: 6/11, round: 440/532, loss: 0.43103551864624023\n",
      "train epoch: 6/11, round: 441/532, loss: 0.2990800738334656\n",
      "train epoch: 6/11, round: 442/532, loss: 0.33644533157348633\n",
      "train epoch: 6/11, round: 443/532, loss: 0.3523328900337219\n",
      "train epoch: 6/11, round: 444/532, loss: 0.34366264939308167\n",
      "train epoch: 6/11, round: 445/532, loss: 0.39190107583999634\n",
      "train epoch: 6/11, round: 446/532, loss: 0.3970683515071869\n",
      "train epoch: 6/11, round: 447/532, loss: 0.43917471170425415\n",
      "train epoch: 6/11, round: 448/532, loss: 0.4196208417415619\n",
      "train epoch: 6/11, round: 449/532, loss: 0.3487856984138489\n",
      "train epoch: 6/11, round: 450/532, loss: 0.36879390478134155\n",
      "train epoch: 6/11, round: 451/532, loss: 0.31956544518470764\n",
      "train epoch: 6/11, round: 452/532, loss: 0.45244163274765015\n",
      "train epoch: 6/11, round: 453/532, loss: 0.4076753258705139\n",
      "train epoch: 6/11, round: 454/532, loss: 0.5318374037742615\n",
      "train epoch: 6/11, round: 455/532, loss: 0.43556681275367737\n",
      "train epoch: 6/11, round: 456/532, loss: 0.34171706438064575\n",
      "train epoch: 6/11, round: 457/532, loss: 0.3670850992202759\n",
      "train epoch: 6/11, round: 458/532, loss: 0.36893486976623535\n",
      "train epoch: 6/11, round: 459/532, loss: 0.36953917145729065\n",
      "train epoch: 6/11, round: 460/532, loss: 0.37367767095565796\n",
      "train epoch: 6/11, round: 461/532, loss: 0.3642615079879761\n",
      "train epoch: 6/11, round: 462/532, loss: 0.4435470998287201\n",
      "train epoch: 6/11, round: 463/532, loss: 0.32853102684020996\n",
      "train epoch: 6/11, round: 464/532, loss: 0.4236975610256195\n",
      "train epoch: 6/11, round: 465/532, loss: 0.44202202558517456\n",
      "train epoch: 6/11, round: 466/532, loss: 0.4062482714653015\n",
      "train epoch: 6/11, round: 467/532, loss: 0.35302773118019104\n",
      "train epoch: 6/11, round: 468/532, loss: 0.33802324533462524\n",
      "train epoch: 6/11, round: 469/532, loss: 0.32221880555152893\n",
      "train epoch: 6/11, round: 470/532, loss: 0.31740039587020874\n",
      "train epoch: 6/11, round: 471/532, loss: 0.4213753640651703\n",
      "train epoch: 6/11, round: 472/532, loss: 0.38554760813713074\n",
      "train epoch: 6/11, round: 473/532, loss: 0.4284820556640625\n",
      "train epoch: 6/11, round: 474/532, loss: 0.402163028717041\n",
      "train epoch: 6/11, round: 475/532, loss: 0.4183619022369385\n",
      "train epoch: 6/11, round: 476/532, loss: 0.394885778427124\n",
      "train epoch: 6/11, round: 477/532, loss: 0.3833426535129547\n",
      "train epoch: 6/11, round: 478/532, loss: 0.42903846502304077\n",
      "train epoch: 6/11, round: 479/532, loss: 0.4400709569454193\n",
      "train epoch: 6/11, round: 480/532, loss: 0.41665011644363403\n",
      "train epoch: 6/11, round: 481/532, loss: 0.4359092116355896\n",
      "train epoch: 6/11, round: 482/532, loss: 0.4136632978916168\n",
      "train epoch: 6/11, round: 483/532, loss: 0.36320775747299194\n",
      "train epoch: 6/11, round: 484/532, loss: 0.3947714865207672\n",
      "train epoch: 6/11, round: 485/532, loss: 0.35901355743408203\n",
      "train epoch: 6/11, round: 486/532, loss: 0.45607441663742065\n",
      "train epoch: 6/11, round: 487/532, loss: 0.3244030475616455\n",
      "train epoch: 6/11, round: 488/532, loss: 0.3986625075340271\n",
      "train epoch: 6/11, round: 489/532, loss: 0.35107725858688354\n",
      "train epoch: 6/11, round: 490/532, loss: 0.4123094081878662\n",
      "train epoch: 6/11, round: 491/532, loss: 0.4531676173210144\n",
      "train epoch: 6/11, round: 492/532, loss: 0.3660287857055664\n",
      "train epoch: 6/11, round: 493/532, loss: 0.47380971908569336\n",
      "train epoch: 6/11, round: 494/532, loss: 0.3767654001712799\n",
      "train epoch: 6/11, round: 495/532, loss: 0.35214462876319885\n",
      "train epoch: 6/11, round: 496/532, loss: 0.43980732560157776\n",
      "train epoch: 6/11, round: 497/532, loss: 0.38432303071022034\n",
      "train epoch: 6/11, round: 498/532, loss: 0.4891350269317627\n",
      "train epoch: 6/11, round: 499/532, loss: 0.36313214898109436\n",
      "train epoch: 6/11, round: 500/532, loss: 0.412036269903183\n",
      "train epoch: 6/11, round: 501/532, loss: 0.43372002243995667\n",
      "train epoch: 6/11, round: 502/532, loss: 0.3932354748249054\n",
      "train epoch: 6/11, round: 503/532, loss: 0.3810676634311676\n",
      "train epoch: 6/11, round: 504/532, loss: 0.35332950949668884\n",
      "train epoch: 6/11, round: 505/532, loss: 0.35783907771110535\n",
      "train epoch: 6/11, round: 506/532, loss: 0.4106658399105072\n",
      "train epoch: 6/11, round: 507/532, loss: 0.39224451780319214\n",
      "train epoch: 6/11, round: 508/532, loss: 0.4205630421638489\n",
      "train epoch: 6/11, round: 509/532, loss: 0.41602787375450134\n",
      "train epoch: 6/11, round: 510/532, loss: 0.36768075823783875\n",
      "train epoch: 6/11, round: 511/532, loss: 0.3995365500450134\n",
      "train epoch: 6/11, round: 512/532, loss: 0.35618314146995544\n",
      "train epoch: 6/11, round: 513/532, loss: 0.340055912733078\n",
      "train epoch: 6/11, round: 514/532, loss: 0.3834936022758484\n",
      "train epoch: 6/11, round: 515/532, loss: 0.44945472478866577\n",
      "train epoch: 6/11, round: 516/532, loss: 0.36492079496383667\n",
      "train epoch: 6/11, round: 517/532, loss: 0.41289886832237244\n",
      "train epoch: 6/11, round: 518/532, loss: 0.38901132345199585\n",
      "train epoch: 6/11, round: 519/532, loss: 0.33374324440956116\n",
      "train epoch: 6/11, round: 520/532, loss: 0.4174421429634094\n",
      "train epoch: 6/11, round: 521/532, loss: 0.46306443214416504\n",
      "train epoch: 6/11, round: 522/532, loss: 0.39327239990234375\n",
      "train epoch: 6/11, round: 523/532, loss: 0.3965303897857666\n",
      "train epoch: 6/11, round: 524/532, loss: 0.4311324656009674\n",
      "train epoch: 6/11, round: 525/532, loss: 0.3556062579154968\n",
      "train epoch: 6/11, round: 526/532, loss: 0.5128713250160217\n",
      "train epoch: 6/11, round: 527/532, loss: 0.3658744692802429\n",
      "train epoch: 6/11, round: 528/532, loss: 0.42326006293296814\n",
      "train epoch: 6/11, round: 529/532, loss: 0.3938102722167969\n",
      "train epoch: 6/11, round: 530/532, loss: 0.3400987982749939\n",
      "train epoch: 6/11, round: 531/532, loss: 0.39997777342796326\n",
      "train epoch: 6/11, round: 532/532, loss: 0.391384482383728\n",
      "train epoch: 6/11, KS: 0.2661771169954642, ROC: 0.6817159374311441\n",
      "test epoch: 6/11, round: 1/501, loss: 0.36564528942108154\n",
      "test epoch: 6/11, round: 2/501, loss: 0.2814818024635315\n",
      "test epoch: 6/11, round: 3/501, loss: 0.21506600081920624\n",
      "test epoch: 6/11, round: 4/501, loss: 0.3485945165157318\n",
      "test epoch: 6/11, round: 5/501, loss: 0.38742345571517944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 6/11, round: 6/501, loss: 0.35095441341400146\n",
      "test epoch: 6/11, round: 7/501, loss: 0.43970969319343567\n",
      "test epoch: 6/11, round: 8/501, loss: 0.4273172616958618\n",
      "test epoch: 6/11, round: 9/501, loss: 0.5704325437545776\n",
      "test epoch: 6/11, round: 10/501, loss: 0.5979710817337036\n",
      "test epoch: 6/11, round: 11/501, loss: 0.24584922194480896\n",
      "test epoch: 6/11, round: 12/501, loss: 0.37260881066322327\n",
      "test epoch: 6/11, round: 13/501, loss: 0.35130035877227783\n",
      "test epoch: 6/11, round: 14/501, loss: 0.3546522259712219\n",
      "test epoch: 6/11, round: 15/501, loss: 0.4886455535888672\n",
      "test epoch: 6/11, round: 16/501, loss: 0.45287826657295227\n",
      "test epoch: 6/11, round: 17/501, loss: 0.34804677963256836\n",
      "test epoch: 6/11, round: 18/501, loss: 0.47158917784690857\n",
      "test epoch: 6/11, round: 19/501, loss: 0.530173659324646\n",
      "test epoch: 6/11, round: 20/501, loss: 0.7682904601097107\n",
      "test epoch: 6/11, round: 21/501, loss: 0.4073772728443146\n",
      "test epoch: 6/11, round: 22/501, loss: 0.5195009708404541\n",
      "test epoch: 6/11, round: 23/501, loss: 0.48482194542884827\n",
      "test epoch: 6/11, round: 24/501, loss: 0.42881932854652405\n",
      "test epoch: 6/11, round: 25/501, loss: 0.6301873326301575\n",
      "test epoch: 6/11, round: 26/501, loss: 0.646513819694519\n",
      "test epoch: 6/11, round: 27/501, loss: 0.249402716755867\n",
      "test epoch: 6/11, round: 28/501, loss: 0.46692970395088196\n",
      "test epoch: 6/11, round: 29/501, loss: 0.301096111536026\n",
      "test epoch: 6/11, round: 30/501, loss: 0.5158447027206421\n",
      "test epoch: 6/11, round: 31/501, loss: 0.5382581353187561\n",
      "test epoch: 6/11, round: 32/501, loss: 0.5177045464515686\n",
      "test epoch: 6/11, round: 33/501, loss: 0.6254633069038391\n",
      "test epoch: 6/11, round: 34/501, loss: 0.4660148024559021\n",
      "test epoch: 6/11, round: 35/501, loss: 0.17596133053302765\n",
      "test epoch: 6/11, round: 36/501, loss: 0.49064353108406067\n",
      "test epoch: 6/11, round: 37/501, loss: 0.43601199984550476\n",
      "test epoch: 6/11, round: 38/501, loss: 0.44010913372039795\n",
      "test epoch: 6/11, round: 39/501, loss: 0.6722494959831238\n",
      "test epoch: 6/11, round: 40/501, loss: 0.5931949615478516\n",
      "test epoch: 6/11, round: 41/501, loss: 0.4307427704334259\n",
      "test epoch: 6/11, round: 42/501, loss: 0.39187726378440857\n",
      "test epoch: 6/11, round: 43/501, loss: 0.4043723940849304\n",
      "test epoch: 6/11, round: 44/501, loss: 0.5252469778060913\n",
      "test epoch: 6/11, round: 45/501, loss: 0.6374302506446838\n",
      "test epoch: 6/11, round: 46/501, loss: 0.499363511800766\n",
      "test epoch: 6/11, round: 47/501, loss: 0.28579801321029663\n",
      "test epoch: 6/11, round: 48/501, loss: 0.513031005859375\n",
      "test epoch: 6/11, round: 49/501, loss: 0.35841891169548035\n",
      "test epoch: 6/11, round: 50/501, loss: 0.2934980094432831\n",
      "test epoch: 6/11, round: 51/501, loss: 0.44937196373939514\n",
      "test epoch: 6/11, round: 52/501, loss: 0.4477439224720001\n",
      "test epoch: 6/11, round: 53/501, loss: 0.5046523809432983\n",
      "test epoch: 6/11, round: 54/501, loss: 0.5555301904678345\n",
      "test epoch: 6/11, round: 55/501, loss: 0.3626265227794647\n",
      "test epoch: 6/11, round: 56/501, loss: 0.3977917432785034\n",
      "test epoch: 6/11, round: 57/501, loss: 0.38137587904930115\n",
      "test epoch: 6/11, round: 58/501, loss: 0.4834953546524048\n",
      "test epoch: 6/11, round: 59/501, loss: 0.2798120081424713\n",
      "test epoch: 6/11, round: 60/501, loss: 0.43012896180152893\n",
      "test epoch: 6/11, round: 61/501, loss: 0.4306263029575348\n",
      "test epoch: 6/11, round: 62/501, loss: 0.6406484246253967\n",
      "test epoch: 6/11, round: 63/501, loss: 0.7711345553398132\n",
      "test epoch: 6/11, round: 64/501, loss: 0.2608356177806854\n",
      "test epoch: 6/11, round: 65/501, loss: 0.5616452693939209\n",
      "test epoch: 6/11, round: 66/501, loss: 0.45469751954078674\n",
      "test epoch: 6/11, round: 67/501, loss: 0.4433835446834564\n",
      "test epoch: 6/11, round: 68/501, loss: 0.5615576505661011\n",
      "test epoch: 6/11, round: 69/501, loss: 0.44327500462532043\n",
      "test epoch: 6/11, round: 70/501, loss: 0.4497818648815155\n",
      "test epoch: 6/11, round: 71/501, loss: 0.5922794938087463\n",
      "test epoch: 6/11, round: 72/501, loss: 0.4715072810649872\n",
      "test epoch: 6/11, round: 73/501, loss: 0.4465554654598236\n",
      "test epoch: 6/11, round: 74/501, loss: 0.4431721270084381\n",
      "test epoch: 6/11, round: 75/501, loss: 0.5191686153411865\n",
      "test epoch: 6/11, round: 76/501, loss: 0.6853228807449341\n",
      "test epoch: 6/11, round: 77/501, loss: 0.38943779468536377\n",
      "test epoch: 6/11, round: 78/501, loss: 0.5381172895431519\n",
      "test epoch: 6/11, round: 79/501, loss: 0.3812516927719116\n",
      "test epoch: 6/11, round: 80/501, loss: 0.5534636378288269\n",
      "test epoch: 6/11, round: 81/501, loss: 0.738021969795227\n",
      "test epoch: 6/11, round: 82/501, loss: 0.550754725933075\n",
      "test epoch: 6/11, round: 83/501, loss: 0.46202367544174194\n",
      "test epoch: 6/11, round: 84/501, loss: 0.576334536075592\n",
      "test epoch: 6/11, round: 85/501, loss: 0.6836870312690735\n",
      "test epoch: 6/11, round: 86/501, loss: 0.30341392755508423\n",
      "test epoch: 6/11, round: 87/501, loss: 0.5020611882209778\n",
      "test epoch: 6/11, round: 88/501, loss: 0.3105769753456116\n",
      "test epoch: 6/11, round: 89/501, loss: 0.35182031989097595\n",
      "test epoch: 6/11, round: 90/501, loss: 0.6644210815429688\n",
      "test epoch: 6/11, round: 91/501, loss: 0.3410213589668274\n",
      "test epoch: 6/11, round: 92/501, loss: 0.614328145980835\n",
      "test epoch: 6/11, round: 93/501, loss: 0.4590349793434143\n",
      "test epoch: 6/11, round: 94/501, loss: 0.5734107494354248\n",
      "test epoch: 6/11, round: 95/501, loss: 0.3784882426261902\n",
      "test epoch: 6/11, round: 96/501, loss: 0.3990124464035034\n",
      "test epoch: 6/11, round: 97/501, loss: 0.5756232738494873\n",
      "test epoch: 6/11, round: 98/501, loss: 0.37127381563186646\n",
      "test epoch: 6/11, round: 99/501, loss: 0.5657294392585754\n",
      "test epoch: 6/11, round: 100/501, loss: 0.5319320559501648\n",
      "test epoch: 6/11, round: 101/501, loss: 0.5639556646347046\n",
      "test epoch: 6/11, round: 102/501, loss: 0.34257155656814575\n",
      "test epoch: 6/11, round: 103/501, loss: 0.44856593012809753\n",
      "test epoch: 6/11, round: 104/501, loss: 0.6760899424552917\n",
      "test epoch: 6/11, round: 105/501, loss: 0.3794148862361908\n",
      "test epoch: 6/11, round: 106/501, loss: 0.5603093504905701\n",
      "test epoch: 6/11, round: 107/501, loss: 0.2917984127998352\n",
      "test epoch: 6/11, round: 108/501, loss: 0.50188809633255\n",
      "test epoch: 6/11, round: 109/501, loss: 0.3484666645526886\n",
      "test epoch: 6/11, round: 110/501, loss: 0.6489987969398499\n",
      "test epoch: 6/11, round: 111/501, loss: 0.24059584736824036\n",
      "test epoch: 6/11, round: 112/501, loss: 0.21467997133731842\n",
      "test epoch: 6/11, round: 113/501, loss: 0.37663328647613525\n",
      "test epoch: 6/11, round: 114/501, loss: 0.3853181004524231\n",
      "test epoch: 6/11, round: 115/501, loss: 0.2838853895664215\n",
      "test epoch: 6/11, round: 116/501, loss: 0.36375313997268677\n",
      "test epoch: 6/11, round: 117/501, loss: 0.41337114572525024\n",
      "test epoch: 6/11, round: 118/501, loss: 0.3162173330783844\n",
      "test epoch: 6/11, round: 119/501, loss: 0.2798653244972229\n",
      "test epoch: 6/11, round: 120/501, loss: 0.3961717188358307\n",
      "test epoch: 6/11, round: 121/501, loss: 0.38125085830688477\n",
      "test epoch: 6/11, round: 122/501, loss: 0.39460259675979614\n",
      "test epoch: 6/11, round: 123/501, loss: 0.40580976009368896\n",
      "test epoch: 6/11, round: 124/501, loss: 0.5961287021636963\n",
      "test epoch: 6/11, round: 125/501, loss: 0.44239628314971924\n",
      "test epoch: 6/11, round: 126/501, loss: 0.39127832651138306\n",
      "test epoch: 6/11, round: 127/501, loss: 0.4314029812812805\n",
      "test epoch: 6/11, round: 128/501, loss: 0.22735370695590973\n",
      "test epoch: 6/11, round: 129/501, loss: 0.4491274058818817\n",
      "test epoch: 6/11, round: 130/501, loss: 0.7828622460365295\n",
      "test epoch: 6/11, round: 131/501, loss: 0.60404372215271\n",
      "test epoch: 6/11, round: 132/501, loss: 0.47063085436820984\n",
      "test epoch: 6/11, round: 133/501, loss: 0.6809028387069702\n",
      "test epoch: 6/11, round: 134/501, loss: 0.4990157186985016\n",
      "test epoch: 6/11, round: 135/501, loss: 0.30140262842178345\n",
      "test epoch: 6/11, round: 136/501, loss: 0.39608994126319885\n",
      "test epoch: 6/11, round: 137/501, loss: 0.4562137722969055\n",
      "test epoch: 6/11, round: 138/501, loss: 0.40933480858802795\n",
      "test epoch: 6/11, round: 139/501, loss: 0.5684748291969299\n",
      "test epoch: 6/11, round: 140/501, loss: 0.46303871273994446\n",
      "test epoch: 6/11, round: 141/501, loss: 0.3323318362236023\n",
      "test epoch: 6/11, round: 142/501, loss: 0.5730444192886353\n",
      "test epoch: 6/11, round: 143/501, loss: 0.3901555836200714\n",
      "test epoch: 6/11, round: 144/501, loss: 0.47366753220558167\n",
      "test epoch: 6/11, round: 145/501, loss: 0.30272915959358215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 6/11, round: 146/501, loss: 0.5883023738861084\n",
      "test epoch: 6/11, round: 147/501, loss: 0.49641963839530945\n",
      "test epoch: 6/11, round: 148/501, loss: 0.4709453880786896\n",
      "test epoch: 6/11, round: 149/501, loss: 0.3540630340576172\n",
      "test epoch: 6/11, round: 150/501, loss: 0.5728960633277893\n",
      "test epoch: 6/11, round: 151/501, loss: 0.4164959490299225\n",
      "test epoch: 6/11, round: 152/501, loss: 0.5152766704559326\n",
      "test epoch: 6/11, round: 153/501, loss: 0.5857436060905457\n",
      "test epoch: 6/11, round: 154/501, loss: 0.5750465393066406\n",
      "test epoch: 6/11, round: 155/501, loss: 0.3880347013473511\n",
      "test epoch: 6/11, round: 156/501, loss: 0.2875679135322571\n",
      "test epoch: 6/11, round: 157/501, loss: 0.28566378355026245\n",
      "test epoch: 6/11, round: 158/501, loss: 0.3794879913330078\n",
      "test epoch: 6/11, round: 159/501, loss: 0.380616694688797\n",
      "test epoch: 6/11, round: 160/501, loss: 0.4185872972011566\n",
      "test epoch: 6/11, round: 161/501, loss: 0.295894980430603\n",
      "test epoch: 6/11, round: 162/501, loss: 0.42891597747802734\n",
      "test epoch: 6/11, round: 163/501, loss: 0.4496036767959595\n",
      "test epoch: 6/11, round: 164/501, loss: 0.3327626883983612\n",
      "test epoch: 6/11, round: 165/501, loss: 0.4701805114746094\n",
      "test epoch: 6/11, round: 166/501, loss: 0.37214982509613037\n",
      "test epoch: 6/11, round: 167/501, loss: 0.24358949065208435\n",
      "test epoch: 6/11, round: 168/501, loss: 0.21123440563678741\n",
      "test epoch: 6/11, round: 169/501, loss: 0.3898560702800751\n",
      "test epoch: 6/11, round: 170/501, loss: 0.43071359395980835\n",
      "test epoch: 6/11, round: 171/501, loss: 0.44430553913116455\n",
      "test epoch: 6/11, round: 172/501, loss: 0.5082237124443054\n",
      "test epoch: 6/11, round: 173/501, loss: 0.2713073194026947\n",
      "test epoch: 6/11, round: 174/501, loss: 0.6457244753837585\n",
      "test epoch: 6/11, round: 175/501, loss: 0.286504328250885\n",
      "test epoch: 6/11, round: 176/501, loss: 0.5730893015861511\n",
      "test epoch: 6/11, round: 177/501, loss: 0.35323256254196167\n",
      "test epoch: 6/11, round: 178/501, loss: 0.23924922943115234\n",
      "test epoch: 6/11, round: 179/501, loss: 0.25552648305892944\n",
      "test epoch: 6/11, round: 180/501, loss: 0.3087259829044342\n",
      "test epoch: 6/11, round: 181/501, loss: 0.5586588382720947\n",
      "test epoch: 6/11, round: 182/501, loss: 0.5447311997413635\n",
      "test epoch: 6/11, round: 183/501, loss: 0.4570396840572357\n",
      "test epoch: 6/11, round: 184/501, loss: 0.563961386680603\n",
      "test epoch: 6/11, round: 185/501, loss: 0.4860776364803314\n",
      "test epoch: 6/11, round: 186/501, loss: 0.6468822360038757\n",
      "test epoch: 6/11, round: 187/501, loss: 0.4887376129627228\n",
      "test epoch: 6/11, round: 188/501, loss: 0.48715370893478394\n",
      "test epoch: 6/11, round: 189/501, loss: 0.5561323761940002\n",
      "test epoch: 6/11, round: 190/501, loss: 0.45415011048316956\n",
      "test epoch: 6/11, round: 191/501, loss: 0.309806227684021\n",
      "test epoch: 6/11, round: 192/501, loss: 0.6003175973892212\n",
      "test epoch: 6/11, round: 193/501, loss: 0.4923638701438904\n",
      "test epoch: 6/11, round: 194/501, loss: 0.4220574200153351\n",
      "test epoch: 6/11, round: 195/501, loss: 0.5879029035568237\n",
      "test epoch: 6/11, round: 196/501, loss: 0.2950632870197296\n",
      "test epoch: 6/11, round: 197/501, loss: 0.4251970946788788\n",
      "test epoch: 6/11, round: 198/501, loss: 0.49370935559272766\n",
      "test epoch: 6/11, round: 199/501, loss: 0.4450851380825043\n",
      "test epoch: 6/11, round: 200/501, loss: 0.6814807057380676\n",
      "test epoch: 6/11, round: 201/501, loss: 0.3503221273422241\n",
      "test epoch: 6/11, round: 202/501, loss: 0.36249783635139465\n",
      "test epoch: 6/11, round: 203/501, loss: 0.5430838465690613\n",
      "test epoch: 6/11, round: 204/501, loss: 0.5498364567756653\n",
      "test epoch: 6/11, round: 205/501, loss: 0.4229497015476227\n",
      "test epoch: 6/11, round: 206/501, loss: 0.24675630033016205\n",
      "test epoch: 6/11, round: 207/501, loss: 0.3476223647594452\n",
      "test epoch: 6/11, round: 208/501, loss: 0.46995553374290466\n",
      "test epoch: 6/11, round: 209/501, loss: 0.30284202098846436\n",
      "test epoch: 6/11, round: 210/501, loss: 0.5006007552146912\n",
      "test epoch: 6/11, round: 211/501, loss: 0.2717992067337036\n",
      "test epoch: 6/11, round: 212/501, loss: 0.33983850479125977\n",
      "test epoch: 6/11, round: 213/501, loss: 0.2900466024875641\n",
      "test epoch: 6/11, round: 214/501, loss: 0.22078292071819305\n",
      "test epoch: 6/11, round: 215/501, loss: 0.2234981209039688\n",
      "test epoch: 6/11, round: 216/501, loss: 0.21216440200805664\n",
      "test epoch: 6/11, round: 217/501, loss: 0.1638999879360199\n",
      "test epoch: 6/11, round: 218/501, loss: 0.1861225664615631\n",
      "test epoch: 6/11, round: 219/501, loss: 0.2265872210264206\n",
      "test epoch: 6/11, round: 220/501, loss: 0.35246866941452026\n",
      "test epoch: 6/11, round: 221/501, loss: 0.34748390316963196\n",
      "test epoch: 6/11, round: 222/501, loss: 0.16495350003242493\n",
      "test epoch: 6/11, round: 223/501, loss: 0.17912918329238892\n",
      "test epoch: 6/11, round: 224/501, loss: 0.21794693171977997\n",
      "test epoch: 6/11, round: 225/501, loss: 0.15938372910022736\n",
      "test epoch: 6/11, round: 226/501, loss: 0.1646903157234192\n",
      "test epoch: 6/11, round: 227/501, loss: 0.22618891298770905\n",
      "test epoch: 6/11, round: 228/501, loss: 0.2236773520708084\n",
      "test epoch: 6/11, round: 229/501, loss: 0.4361577332019806\n",
      "test epoch: 6/11, round: 230/501, loss: 0.3103259801864624\n",
      "test epoch: 6/11, round: 231/501, loss: 0.31158846616744995\n",
      "test epoch: 6/11, round: 232/501, loss: 0.3837868869304657\n",
      "test epoch: 6/11, round: 233/501, loss: 0.5467562079429626\n",
      "test epoch: 6/11, round: 234/501, loss: 0.4903471767902374\n",
      "test epoch: 6/11, round: 235/501, loss: 0.3003067672252655\n",
      "test epoch: 6/11, round: 236/501, loss: 0.3229064345359802\n",
      "test epoch: 6/11, round: 237/501, loss: 0.3157932460308075\n",
      "test epoch: 6/11, round: 238/501, loss: 0.35625120997428894\n",
      "test epoch: 6/11, round: 239/501, loss: 0.42213207483291626\n",
      "test epoch: 6/11, round: 240/501, loss: 0.21882060170173645\n",
      "test epoch: 6/11, round: 241/501, loss: 0.3805580139160156\n",
      "test epoch: 6/11, round: 242/501, loss: 0.2810845375061035\n",
      "test epoch: 6/11, round: 243/501, loss: 0.2688433825969696\n",
      "test epoch: 6/11, round: 244/501, loss: 0.30995532870292664\n",
      "test epoch: 6/11, round: 245/501, loss: 0.3558814823627472\n",
      "test epoch: 6/11, round: 246/501, loss: 0.41481533646583557\n",
      "test epoch: 6/11, round: 247/501, loss: 0.41439151763916016\n",
      "test epoch: 6/11, round: 248/501, loss: 0.19928450882434845\n",
      "test epoch: 6/11, round: 249/501, loss: 0.2793212831020355\n",
      "test epoch: 6/11, round: 250/501, loss: 0.30821311473846436\n",
      "test epoch: 6/11, round: 251/501, loss: 0.3346622586250305\n",
      "test epoch: 6/11, round: 252/501, loss: 0.31483322381973267\n",
      "test epoch: 6/11, round: 253/501, loss: 0.3438052833080292\n",
      "test epoch: 6/11, round: 254/501, loss: 0.2895885109901428\n",
      "test epoch: 6/11, round: 255/501, loss: 0.28019440174102783\n",
      "test epoch: 6/11, round: 256/501, loss: 0.4796331822872162\n",
      "test epoch: 6/11, round: 257/501, loss: 0.36988505721092224\n",
      "test epoch: 6/11, round: 258/501, loss: 0.3883375823497772\n",
      "test epoch: 6/11, round: 259/501, loss: 0.2198835015296936\n",
      "test epoch: 6/11, round: 260/501, loss: 0.48425373435020447\n",
      "test epoch: 6/11, round: 261/501, loss: 0.5721443295478821\n",
      "test epoch: 6/11, round: 262/501, loss: 0.4517982602119446\n",
      "test epoch: 6/11, round: 263/501, loss: 0.3521248996257782\n",
      "test epoch: 6/11, round: 264/501, loss: 0.45224884152412415\n",
      "test epoch: 6/11, round: 265/501, loss: 0.6119455695152283\n",
      "test epoch: 6/11, round: 266/501, loss: 0.3647409975528717\n",
      "test epoch: 6/11, round: 267/501, loss: 0.36662164330482483\n",
      "test epoch: 6/11, round: 268/501, loss: 0.27425727248191833\n",
      "test epoch: 6/11, round: 269/501, loss: 0.473953515291214\n",
      "test epoch: 6/11, round: 270/501, loss: 0.24622179567813873\n",
      "test epoch: 6/11, round: 271/501, loss: 0.5455701351165771\n",
      "test epoch: 6/11, round: 272/501, loss: 0.38774043321609497\n",
      "test epoch: 6/11, round: 273/501, loss: 0.3672524094581604\n",
      "test epoch: 6/11, round: 274/501, loss: 0.4931761920452118\n",
      "test epoch: 6/11, round: 275/501, loss: 0.28522470593452454\n",
      "test epoch: 6/11, round: 276/501, loss: 0.38683807849884033\n",
      "test epoch: 6/11, round: 277/501, loss: 0.37711450457572937\n",
      "test epoch: 6/11, round: 278/501, loss: 0.5540727376937866\n",
      "test epoch: 6/11, round: 279/501, loss: 0.35900652408599854\n",
      "test epoch: 6/11, round: 280/501, loss: 0.2200593650341034\n",
      "test epoch: 6/11, round: 281/501, loss: 0.19774910807609558\n",
      "test epoch: 6/11, round: 282/501, loss: 0.30143654346466064\n",
      "test epoch: 6/11, round: 283/501, loss: 0.26855847239494324\n",
      "test epoch: 6/11, round: 284/501, loss: 0.37198081612586975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 6/11, round: 285/501, loss: 0.4364054501056671\n",
      "test epoch: 6/11, round: 286/501, loss: 0.42878594994544983\n",
      "test epoch: 6/11, round: 287/501, loss: 0.5701152682304382\n",
      "test epoch: 6/11, round: 288/501, loss: 0.22544622421264648\n",
      "test epoch: 6/11, round: 289/501, loss: 0.3209148943424225\n",
      "test epoch: 6/11, round: 290/501, loss: 0.28651899099349976\n",
      "test epoch: 6/11, round: 291/501, loss: 0.5425782799720764\n",
      "test epoch: 6/11, round: 292/501, loss: 0.4894319474697113\n",
      "test epoch: 6/11, round: 293/501, loss: 0.5215638279914856\n",
      "test epoch: 6/11, round: 294/501, loss: 0.2461242973804474\n",
      "test epoch: 6/11, round: 295/501, loss: 0.30051907896995544\n",
      "test epoch: 6/11, round: 296/501, loss: 0.41762059926986694\n",
      "test epoch: 6/11, round: 297/501, loss: 0.3468412458896637\n",
      "test epoch: 6/11, round: 298/501, loss: 0.45801228284835815\n",
      "test epoch: 6/11, round: 299/501, loss: 0.41537511348724365\n",
      "test epoch: 6/11, round: 300/501, loss: 0.5118030309677124\n",
      "test epoch: 6/11, round: 301/501, loss: 0.41857394576072693\n",
      "test epoch: 6/11, round: 302/501, loss: 0.22434574365615845\n",
      "test epoch: 6/11, round: 303/501, loss: 0.5714101195335388\n",
      "test epoch: 6/11, round: 304/501, loss: 0.625041663646698\n",
      "test epoch: 6/11, round: 305/501, loss: 0.19978855550289154\n",
      "test epoch: 6/11, round: 306/501, loss: 0.29937228560447693\n",
      "test epoch: 6/11, round: 307/501, loss: 0.4485786557197571\n",
      "test epoch: 6/11, round: 308/501, loss: 0.29190579056739807\n",
      "test epoch: 6/11, round: 309/501, loss: 0.4386288821697235\n",
      "test epoch: 6/11, round: 310/501, loss: 0.34938010573387146\n",
      "test epoch: 6/11, round: 311/501, loss: 0.5535628199577332\n",
      "test epoch: 6/11, round: 312/501, loss: 0.37148624658584595\n",
      "test epoch: 6/11, round: 313/501, loss: 0.3269067108631134\n",
      "test epoch: 6/11, round: 314/501, loss: 0.3317526876926422\n",
      "test epoch: 6/11, round: 315/501, loss: 0.30710798501968384\n",
      "test epoch: 6/11, round: 316/501, loss: 0.3246850073337555\n",
      "test epoch: 6/11, round: 317/501, loss: 0.3369331955909729\n",
      "test epoch: 6/11, round: 318/501, loss: 0.37810227274894714\n",
      "test epoch: 6/11, round: 319/501, loss: 0.5944114923477173\n",
      "test epoch: 6/11, round: 320/501, loss: 0.41826513409614563\n",
      "test epoch: 6/11, round: 321/501, loss: 0.3363065719604492\n",
      "test epoch: 6/11, round: 322/501, loss: 0.45568007230758667\n",
      "test epoch: 6/11, round: 323/501, loss: 0.4310740530490875\n",
      "test epoch: 6/11, round: 324/501, loss: 0.2922431230545044\n",
      "test epoch: 6/11, round: 325/501, loss: 0.4459940493106842\n",
      "test epoch: 6/11, round: 326/501, loss: 0.4357994496822357\n",
      "test epoch: 6/11, round: 327/501, loss: 0.5881001949310303\n",
      "test epoch: 6/11, round: 328/501, loss: 0.203127920627594\n",
      "test epoch: 6/11, round: 329/501, loss: 0.43477746844291687\n",
      "test epoch: 6/11, round: 330/501, loss: 0.4437050521373749\n",
      "test epoch: 6/11, round: 331/501, loss: 0.38806629180908203\n",
      "test epoch: 6/11, round: 332/501, loss: 0.3504430651664734\n",
      "test epoch: 6/11, round: 333/501, loss: 0.377691388130188\n",
      "test epoch: 6/11, round: 334/501, loss: 0.2315891534090042\n",
      "test epoch: 6/11, round: 335/501, loss: 0.3503340482711792\n",
      "test epoch: 6/11, round: 336/501, loss: 0.33152109384536743\n",
      "test epoch: 6/11, round: 337/501, loss: 0.5442313551902771\n",
      "test epoch: 6/11, round: 338/501, loss: 0.36857858300209045\n",
      "test epoch: 6/11, round: 339/501, loss: 0.7484909892082214\n",
      "test epoch: 6/11, round: 340/501, loss: 0.4216650128364563\n",
      "test epoch: 6/11, round: 341/501, loss: 0.438408762216568\n",
      "test epoch: 6/11, round: 342/501, loss: 0.3774970769882202\n",
      "test epoch: 6/11, round: 343/501, loss: 0.30754679441452026\n",
      "test epoch: 6/11, round: 344/501, loss: 0.2549497187137604\n",
      "test epoch: 6/11, round: 345/501, loss: 0.200918510556221\n",
      "test epoch: 6/11, round: 346/501, loss: 0.3427385091781616\n",
      "test epoch: 6/11, round: 347/501, loss: 0.34302109479904175\n",
      "test epoch: 6/11, round: 348/501, loss: 0.39548203349113464\n",
      "test epoch: 6/11, round: 349/501, loss: 0.34147483110427856\n",
      "test epoch: 6/11, round: 350/501, loss: 0.47880226373672485\n",
      "test epoch: 6/11, round: 351/501, loss: 0.364526629447937\n",
      "test epoch: 6/11, round: 352/501, loss: 0.4303680956363678\n",
      "test epoch: 6/11, round: 353/501, loss: 0.3380524814128876\n",
      "test epoch: 6/11, round: 354/501, loss: 0.5194109678268433\n",
      "test epoch: 6/11, round: 355/501, loss: 0.4026402235031128\n",
      "test epoch: 6/11, round: 356/501, loss: 0.556311845779419\n",
      "test epoch: 6/11, round: 357/501, loss: 0.4097519516944885\n",
      "test epoch: 6/11, round: 358/501, loss: 0.35784584283828735\n",
      "test epoch: 6/11, round: 359/501, loss: 0.3633108139038086\n",
      "test epoch: 6/11, round: 360/501, loss: 0.4988386034965515\n",
      "test epoch: 6/11, round: 361/501, loss: 0.49695613980293274\n",
      "test epoch: 6/11, round: 362/501, loss: 0.36091798543930054\n",
      "test epoch: 6/11, round: 363/501, loss: 0.5205620527267456\n",
      "test epoch: 6/11, round: 364/501, loss: 0.48794493079185486\n",
      "test epoch: 6/11, round: 365/501, loss: 0.3789827227592468\n",
      "test epoch: 6/11, round: 366/501, loss: 0.5548347234725952\n",
      "test epoch: 6/11, round: 367/501, loss: 0.639404296875\n",
      "test epoch: 6/11, round: 368/501, loss: 0.3024533987045288\n",
      "test epoch: 6/11, round: 369/501, loss: 0.34887975454330444\n",
      "test epoch: 6/11, round: 370/501, loss: 0.37874937057495117\n",
      "test epoch: 6/11, round: 371/501, loss: 0.3986552059650421\n",
      "test epoch: 6/11, round: 372/501, loss: 0.33574536442756653\n",
      "test epoch: 6/11, round: 373/501, loss: 0.4017055332660675\n",
      "test epoch: 6/11, round: 374/501, loss: 0.31546148657798767\n",
      "test epoch: 6/11, round: 375/501, loss: 0.49755731225013733\n",
      "test epoch: 6/11, round: 376/501, loss: 0.4975188970565796\n",
      "test epoch: 6/11, round: 377/501, loss: 0.15134474635124207\n",
      "test epoch: 6/11, round: 378/501, loss: 0.18230441212654114\n",
      "test epoch: 6/11, round: 379/501, loss: 0.43468549847602844\n",
      "test epoch: 6/11, round: 380/501, loss: 0.28683343529701233\n",
      "test epoch: 6/11, round: 381/501, loss: 0.41260093450546265\n",
      "test epoch: 6/11, round: 382/501, loss: 0.27868902683258057\n",
      "test epoch: 6/11, round: 383/501, loss: 0.3335041105747223\n",
      "test epoch: 6/11, round: 384/501, loss: 0.228643000125885\n",
      "test epoch: 6/11, round: 385/501, loss: 0.49110233783721924\n",
      "test epoch: 6/11, round: 386/501, loss: 0.5334354639053345\n",
      "test epoch: 6/11, round: 387/501, loss: 0.26118722558021545\n",
      "test epoch: 6/11, round: 388/501, loss: 0.27637550234794617\n",
      "test epoch: 6/11, round: 389/501, loss: 0.3102743327617645\n",
      "test epoch: 6/11, round: 390/501, loss: 0.4035831689834595\n",
      "test epoch: 6/11, round: 391/501, loss: 0.3643385171890259\n",
      "test epoch: 6/11, round: 392/501, loss: 0.5119497776031494\n",
      "test epoch: 6/11, round: 393/501, loss: 0.3412230312824249\n",
      "test epoch: 6/11, round: 394/501, loss: 0.6595731377601624\n",
      "test epoch: 6/11, round: 395/501, loss: 0.24033799767494202\n",
      "test epoch: 6/11, round: 396/501, loss: 0.4197193682193756\n",
      "test epoch: 6/11, round: 397/501, loss: 0.47031816840171814\n",
      "test epoch: 6/11, round: 398/501, loss: 0.4761243164539337\n",
      "test epoch: 6/11, round: 399/501, loss: 0.30285727977752686\n",
      "test epoch: 6/11, round: 400/501, loss: 0.3220910429954529\n",
      "test epoch: 6/11, round: 401/501, loss: 0.6235039830207825\n",
      "test epoch: 6/11, round: 402/501, loss: 0.4017956554889679\n",
      "test epoch: 6/11, round: 403/501, loss: 0.3604850172996521\n",
      "test epoch: 6/11, round: 404/501, loss: 0.2401076853275299\n",
      "test epoch: 6/11, round: 405/501, loss: 0.7490218877792358\n",
      "test epoch: 6/11, round: 406/501, loss: 0.4392401874065399\n",
      "test epoch: 6/11, round: 407/501, loss: 0.4585072100162506\n",
      "test epoch: 6/11, round: 408/501, loss: 0.4923607409000397\n",
      "test epoch: 6/11, round: 409/501, loss: 0.5534371137619019\n",
      "test epoch: 6/11, round: 410/501, loss: 0.3700620234012604\n",
      "test epoch: 6/11, round: 411/501, loss: 0.38237106800079346\n",
      "test epoch: 6/11, round: 412/501, loss: 0.4392396807670593\n",
      "test epoch: 6/11, round: 413/501, loss: 0.4873705804347992\n",
      "test epoch: 6/11, round: 414/501, loss: 0.29699039459228516\n",
      "test epoch: 6/11, round: 415/501, loss: 0.38096949458122253\n",
      "test epoch: 6/11, round: 416/501, loss: 0.3591732978820801\n",
      "test epoch: 6/11, round: 417/501, loss: 0.2533808946609497\n",
      "test epoch: 6/11, round: 418/501, loss: 0.3056548833847046\n",
      "test epoch: 6/11, round: 419/501, loss: 0.3581169843673706\n",
      "test epoch: 6/11, round: 420/501, loss: 0.2870842516422272\n",
      "test epoch: 6/11, round: 421/501, loss: 0.4030258059501648\n",
      "test epoch: 6/11, round: 422/501, loss: 0.43498992919921875\n",
      "test epoch: 6/11, round: 423/501, loss: 0.6832578182220459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 6/11, round: 424/501, loss: 0.44436007738113403\n",
      "test epoch: 6/11, round: 425/501, loss: 0.28802749514579773\n",
      "test epoch: 6/11, round: 426/501, loss: 0.42983004450798035\n",
      "test epoch: 6/11, round: 427/501, loss: 0.3113582730293274\n",
      "test epoch: 6/11, round: 428/501, loss: 0.5169512629508972\n",
      "test epoch: 6/11, round: 429/501, loss: 0.6153792142868042\n",
      "test epoch: 6/11, round: 430/501, loss: 0.5722736716270447\n",
      "test epoch: 6/11, round: 431/501, loss: 0.41972091794013977\n",
      "test epoch: 6/11, round: 432/501, loss: 0.32048115134239197\n",
      "test epoch: 6/11, round: 433/501, loss: 0.37660762667655945\n",
      "test epoch: 6/11, round: 434/501, loss: 0.31841251254081726\n",
      "test epoch: 6/11, round: 435/501, loss: 0.33053532242774963\n",
      "test epoch: 6/11, round: 436/501, loss: 0.33174705505371094\n",
      "test epoch: 6/11, round: 437/501, loss: 0.4748791456222534\n",
      "test epoch: 6/11, round: 438/501, loss: 0.5693870782852173\n",
      "test epoch: 6/11, round: 439/501, loss: 0.3274272382259369\n",
      "test epoch: 6/11, round: 440/501, loss: 0.45935890078544617\n",
      "test epoch: 6/11, round: 441/501, loss: 0.4309828579425812\n",
      "test epoch: 6/11, round: 442/501, loss: 0.32490962743759155\n",
      "test epoch: 6/11, round: 443/501, loss: 0.20049995183944702\n",
      "test epoch: 6/11, round: 444/501, loss: 0.4112130105495453\n",
      "test epoch: 6/11, round: 445/501, loss: 0.42012709379196167\n",
      "test epoch: 6/11, round: 446/501, loss: 0.4554029405117035\n",
      "test epoch: 6/11, round: 447/501, loss: 0.21593323349952698\n",
      "test epoch: 6/11, round: 448/501, loss: 0.3412250876426697\n",
      "test epoch: 6/11, round: 449/501, loss: 0.22738905251026154\n",
      "test epoch: 6/11, round: 450/501, loss: 0.7258264422416687\n",
      "test epoch: 6/11, round: 451/501, loss: 0.3526087701320648\n",
      "test epoch: 6/11, round: 452/501, loss: 0.3861837387084961\n",
      "test epoch: 6/11, round: 453/501, loss: 0.16402782499790192\n",
      "test epoch: 6/11, round: 454/501, loss: 0.23236151039600372\n",
      "test epoch: 6/11, round: 455/501, loss: 0.4983784258365631\n",
      "test epoch: 6/11, round: 456/501, loss: 0.2819947600364685\n",
      "test epoch: 6/11, round: 457/501, loss: 0.23204660415649414\n",
      "test epoch: 6/11, round: 458/501, loss: 0.2664879858493805\n",
      "test epoch: 6/11, round: 459/501, loss: 0.1995042860507965\n",
      "test epoch: 6/11, round: 460/501, loss: 0.149590402841568\n",
      "test epoch: 6/11, round: 461/501, loss: 0.15470725297927856\n",
      "test epoch: 6/11, round: 462/501, loss: 0.12915503978729248\n",
      "test epoch: 6/11, round: 463/501, loss: 0.15829218924045563\n",
      "test epoch: 6/11, round: 464/501, loss: 0.14738430082798004\n",
      "test epoch: 6/11, round: 465/501, loss: 0.16136865317821503\n",
      "test epoch: 6/11, round: 466/501, loss: 0.1467636376619339\n",
      "test epoch: 6/11, round: 467/501, loss: 0.17671933770179749\n",
      "test epoch: 6/11, round: 468/501, loss: 0.17070582509040833\n",
      "test epoch: 6/11, round: 469/501, loss: 0.16868740320205688\n",
      "test epoch: 6/11, round: 470/501, loss: 0.14777952432632446\n",
      "test epoch: 6/11, round: 471/501, loss: 0.19125786423683167\n",
      "test epoch: 6/11, round: 472/501, loss: 0.16145989298820496\n",
      "test epoch: 6/11, round: 473/501, loss: 0.15113864839076996\n",
      "test epoch: 6/11, round: 474/501, loss: 0.1614893227815628\n",
      "test epoch: 6/11, round: 475/501, loss: 0.15101687610149384\n",
      "test epoch: 6/11, round: 476/501, loss: 0.13117723166942596\n",
      "test epoch: 6/11, round: 477/501, loss: 0.11769326776266098\n",
      "test epoch: 6/11, round: 478/501, loss: 0.1430831104516983\n",
      "test epoch: 6/11, round: 479/501, loss: 0.10612954944372177\n",
      "test epoch: 6/11, round: 480/501, loss: 0.13589176535606384\n",
      "test epoch: 6/11, round: 481/501, loss: 0.13770213723182678\n",
      "test epoch: 6/11, round: 482/501, loss: 0.13372927904129028\n",
      "test epoch: 6/11, round: 483/501, loss: 0.16278943419456482\n",
      "test epoch: 6/11, round: 484/501, loss: 0.14368325471878052\n",
      "test epoch: 6/11, round: 485/501, loss: 0.13046032190322876\n",
      "test epoch: 6/11, round: 486/501, loss: 0.1473773866891861\n",
      "test epoch: 6/11, round: 487/501, loss: 0.13135391473770142\n",
      "test epoch: 6/11, round: 488/501, loss: 0.1686021238565445\n",
      "test epoch: 6/11, round: 489/501, loss: 0.14259512722492218\n",
      "test epoch: 6/11, round: 490/501, loss: 0.12921981513500214\n",
      "test epoch: 6/11, round: 491/501, loss: 0.16282762587070465\n",
      "test epoch: 6/11, round: 492/501, loss: 0.17836551368236542\n",
      "test epoch: 6/11, round: 493/501, loss: 0.15215590596199036\n",
      "test epoch: 6/11, round: 494/501, loss: 0.15049584209918976\n",
      "test epoch: 6/11, round: 495/501, loss: 0.13471128046512604\n",
      "test epoch: 6/11, round: 496/501, loss: 0.1531854122877121\n",
      "test epoch: 6/11, round: 497/501, loss: 0.15200060606002808\n",
      "test epoch: 6/11, round: 498/501, loss: 0.1094880923628807\n",
      "test epoch: 6/11, round: 499/501, loss: 0.12276426702737808\n",
      "test epoch: 6/11, round: 500/501, loss: 0.31268900632858276\n",
      "test epoch: 6/11, round: 501/501, loss: 0.9428871273994446\n",
      "test epoch: 6/11, KS: 0.20109684982341386, ROC: 0.6348239738966168\n",
      "cost time: 1996\n",
      "train epoch: 7/11, round: 1/532, loss: 0.3948632776737213\n",
      "train epoch: 7/11, round: 2/532, loss: 0.38494864106178284\n",
      "train epoch: 7/11, round: 3/532, loss: 0.42850255966186523\n",
      "train epoch: 7/11, round: 4/532, loss: 0.4370798170566559\n",
      "train epoch: 7/11, round: 5/532, loss: 0.42189350724220276\n",
      "train epoch: 7/11, round: 6/532, loss: 0.3685244023799896\n",
      "train epoch: 7/11, round: 7/532, loss: 0.3501362204551697\n",
      "train epoch: 7/11, round: 8/532, loss: 0.3830944299697876\n",
      "train epoch: 7/11, round: 9/532, loss: 0.41057777404785156\n",
      "train epoch: 7/11, round: 10/532, loss: 0.4345247149467468\n",
      "train epoch: 7/11, round: 11/532, loss: 0.3805055618286133\n",
      "train epoch: 7/11, round: 12/532, loss: 0.3707458972930908\n",
      "train epoch: 7/11, round: 13/532, loss: 0.3413994312286377\n",
      "train epoch: 7/11, round: 14/532, loss: 0.3773641288280487\n",
      "train epoch: 7/11, round: 15/532, loss: 0.3109385073184967\n",
      "train epoch: 7/11, round: 16/532, loss: 0.3384510278701782\n",
      "train epoch: 7/11, round: 17/532, loss: 0.392996609210968\n",
      "train epoch: 7/11, round: 18/532, loss: 0.43716397881507874\n",
      "train epoch: 7/11, round: 19/532, loss: 0.3621807396411896\n",
      "train epoch: 7/11, round: 20/532, loss: 0.40408945083618164\n",
      "train epoch: 7/11, round: 21/532, loss: 0.39600634574890137\n",
      "train epoch: 7/11, round: 22/532, loss: 0.34551507234573364\n",
      "train epoch: 7/11, round: 23/532, loss: 0.4242214262485504\n",
      "train epoch: 7/11, round: 24/532, loss: 0.3093174695968628\n",
      "train epoch: 7/11, round: 25/532, loss: 0.2908208966255188\n",
      "train epoch: 7/11, round: 26/532, loss: 0.32611602544784546\n",
      "train epoch: 7/11, round: 27/532, loss: 0.2869451344013214\n",
      "train epoch: 7/11, round: 28/532, loss: 0.40672460198402405\n",
      "train epoch: 7/11, round: 29/532, loss: 0.41466841101646423\n",
      "train epoch: 7/11, round: 30/532, loss: 0.33310315012931824\n",
      "train epoch: 7/11, round: 31/532, loss: 0.42092275619506836\n",
      "train epoch: 7/11, round: 32/532, loss: 0.36725321412086487\n",
      "train epoch: 7/11, round: 33/532, loss: 0.3939433693885803\n",
      "train epoch: 7/11, round: 34/532, loss: 0.3954165279865265\n",
      "train epoch: 7/11, round: 35/532, loss: 0.4215177595615387\n",
      "train epoch: 7/11, round: 36/532, loss: 0.3671979010105133\n",
      "train epoch: 7/11, round: 37/532, loss: 0.351543128490448\n",
      "train epoch: 7/11, round: 38/532, loss: 0.3735826909542084\n",
      "train epoch: 7/11, round: 39/532, loss: 0.3737655282020569\n",
      "train epoch: 7/11, round: 40/532, loss: 0.3862163722515106\n",
      "train epoch: 7/11, round: 41/532, loss: 0.39258405566215515\n",
      "train epoch: 7/11, round: 42/532, loss: 0.32781702280044556\n",
      "train epoch: 7/11, round: 43/532, loss: 0.3902469575405121\n",
      "train epoch: 7/11, round: 44/532, loss: 0.42909544706344604\n",
      "train epoch: 7/11, round: 45/532, loss: 0.46811527013778687\n",
      "train epoch: 7/11, round: 46/532, loss: 0.3702619671821594\n",
      "train epoch: 7/11, round: 47/532, loss: 0.4391402304172516\n",
      "train epoch: 7/11, round: 48/532, loss: 0.3477347195148468\n",
      "train epoch: 7/11, round: 49/532, loss: 0.27701228857040405\n",
      "train epoch: 7/11, round: 50/532, loss: 0.3181130886077881\n",
      "train epoch: 7/11, round: 51/532, loss: 0.4054946005344391\n",
      "train epoch: 7/11, round: 52/532, loss: 0.39559993147850037\n",
      "train epoch: 7/11, round: 53/532, loss: 0.4383576512336731\n",
      "train epoch: 7/11, round: 54/532, loss: 0.4767725467681885\n",
      "train epoch: 7/11, round: 55/532, loss: 0.3705444931983948\n",
      "train epoch: 7/11, round: 56/532, loss: 0.3718014061450958\n",
      "train epoch: 7/11, round: 57/532, loss: 0.37584394216537476\n",
      "train epoch: 7/11, round: 58/532, loss: 0.34289246797561646\n",
      "train epoch: 7/11, round: 59/532, loss: 0.37076085805892944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7/11, round: 60/532, loss: 0.36833181977272034\n",
      "train epoch: 7/11, round: 61/532, loss: 0.41049933433532715\n",
      "train epoch: 7/11, round: 62/532, loss: 0.3560903072357178\n",
      "train epoch: 7/11, round: 63/532, loss: 0.4260839521884918\n",
      "train epoch: 7/11, round: 64/532, loss: 0.37227410078048706\n",
      "train epoch: 7/11, round: 65/532, loss: 0.34672021865844727\n",
      "train epoch: 7/11, round: 66/532, loss: 0.4777962565422058\n",
      "train epoch: 7/11, round: 67/532, loss: 0.40815892815589905\n",
      "train epoch: 7/11, round: 68/532, loss: 0.36896735429763794\n",
      "train epoch: 7/11, round: 69/532, loss: 0.359485387802124\n",
      "train epoch: 7/11, round: 70/532, loss: 0.3539486527442932\n",
      "train epoch: 7/11, round: 71/532, loss: 0.44229811429977417\n",
      "train epoch: 7/11, round: 72/532, loss: 0.36830997467041016\n",
      "train epoch: 7/11, round: 73/532, loss: 0.3706399202346802\n",
      "train epoch: 7/11, round: 74/532, loss: 0.37055733799934387\n",
      "train epoch: 7/11, round: 75/532, loss: 0.3834473192691803\n",
      "train epoch: 7/11, round: 76/532, loss: 0.34548598527908325\n",
      "train epoch: 7/11, round: 77/532, loss: 0.4076082110404968\n",
      "train epoch: 7/11, round: 78/532, loss: 0.3810500502586365\n",
      "train epoch: 7/11, round: 79/532, loss: 0.36826375126838684\n",
      "train epoch: 7/11, round: 80/532, loss: 0.3868006467819214\n",
      "train epoch: 7/11, round: 81/532, loss: 0.32193365693092346\n",
      "train epoch: 7/11, round: 82/532, loss: 0.4662068486213684\n",
      "train epoch: 7/11, round: 83/532, loss: 0.4282621443271637\n",
      "train epoch: 7/11, round: 84/532, loss: 0.3367944359779358\n",
      "train epoch: 7/11, round: 85/532, loss: 0.4469253122806549\n",
      "train epoch: 7/11, round: 86/532, loss: 0.4170507490634918\n",
      "train epoch: 7/11, round: 87/532, loss: 0.41831716895103455\n",
      "train epoch: 7/11, round: 88/532, loss: 0.3506200313568115\n",
      "train epoch: 7/11, round: 89/532, loss: 0.3155697286128998\n",
      "train epoch: 7/11, round: 90/532, loss: 0.4335787296295166\n",
      "train epoch: 7/11, round: 91/532, loss: 0.38341420888900757\n",
      "train epoch: 7/11, round: 92/532, loss: 0.3669746518135071\n",
      "train epoch: 7/11, round: 93/532, loss: 0.37995004653930664\n",
      "train epoch: 7/11, round: 94/532, loss: 0.43429064750671387\n",
      "train epoch: 7/11, round: 95/532, loss: 0.3936830163002014\n",
      "train epoch: 7/11, round: 96/532, loss: 0.3469761312007904\n",
      "train epoch: 7/11, round: 97/532, loss: 0.32541126012802124\n",
      "train epoch: 7/11, round: 98/532, loss: 0.4137319028377533\n",
      "train epoch: 7/11, round: 99/532, loss: 0.3680351972579956\n",
      "train epoch: 7/11, round: 100/532, loss: 0.4678646922111511\n",
      "train epoch: 7/11, round: 101/532, loss: 0.33781445026397705\n",
      "train epoch: 7/11, round: 102/532, loss: 0.35134369134902954\n",
      "train epoch: 7/11, round: 103/532, loss: 0.3639225959777832\n",
      "train epoch: 7/11, round: 104/532, loss: 0.46064049005508423\n",
      "train epoch: 7/11, round: 105/532, loss: 0.3618263900279999\n",
      "train epoch: 7/11, round: 106/532, loss: 0.34192484617233276\n",
      "train epoch: 7/11, round: 107/532, loss: 0.3942652642726898\n",
      "train epoch: 7/11, round: 108/532, loss: 0.3226098418235779\n",
      "train epoch: 7/11, round: 109/532, loss: 0.3875771164894104\n",
      "train epoch: 7/11, round: 110/532, loss: 0.3921359181404114\n",
      "train epoch: 7/11, round: 111/532, loss: 0.3783387541770935\n",
      "train epoch: 7/11, round: 112/532, loss: 0.3847602903842926\n",
      "train epoch: 7/11, round: 113/532, loss: 0.42535096406936646\n",
      "train epoch: 7/11, round: 114/532, loss: 0.40685224533081055\n",
      "train epoch: 7/11, round: 115/532, loss: 0.41669926047325134\n",
      "train epoch: 7/11, round: 116/532, loss: 0.35904747247695923\n",
      "train epoch: 7/11, round: 117/532, loss: 0.44695544242858887\n",
      "train epoch: 7/11, round: 118/532, loss: 0.3039249777793884\n",
      "train epoch: 7/11, round: 119/532, loss: 0.3873717188835144\n",
      "train epoch: 7/11, round: 120/532, loss: 0.4443189203739166\n",
      "train epoch: 7/11, round: 121/532, loss: 0.366940975189209\n",
      "train epoch: 7/11, round: 122/532, loss: 0.4102354049682617\n",
      "train epoch: 7/11, round: 123/532, loss: 0.3114356994628906\n",
      "train epoch: 7/11, round: 124/532, loss: 0.4437916874885559\n",
      "train epoch: 7/11, round: 125/532, loss: 0.45727843046188354\n",
      "train epoch: 7/11, round: 126/532, loss: 0.4638769030570984\n",
      "train epoch: 7/11, round: 127/532, loss: 0.41122445464134216\n",
      "train epoch: 7/11, round: 128/532, loss: 0.43026384711265564\n",
      "train epoch: 7/11, round: 129/532, loss: 0.4047248363494873\n",
      "train epoch: 7/11, round: 130/532, loss: 0.31206566095352173\n",
      "train epoch: 7/11, round: 131/532, loss: 0.3454439342021942\n",
      "train epoch: 7/11, round: 132/532, loss: 0.4151689410209656\n",
      "train epoch: 7/11, round: 133/532, loss: 0.38769665360450745\n",
      "train epoch: 7/11, round: 134/532, loss: 0.434075266122818\n",
      "train epoch: 7/11, round: 135/532, loss: 0.3442704379558563\n",
      "train epoch: 7/11, round: 136/532, loss: 0.41870468854904175\n",
      "train epoch: 7/11, round: 137/532, loss: 0.32848936319351196\n",
      "train epoch: 7/11, round: 138/532, loss: 0.41347894072532654\n",
      "train epoch: 7/11, round: 139/532, loss: 0.4549161493778229\n",
      "train epoch: 7/11, round: 140/532, loss: 0.3742500841617584\n",
      "train epoch: 7/11, round: 141/532, loss: 0.4616613984107971\n",
      "train epoch: 7/11, round: 142/532, loss: 0.3061980605125427\n",
      "train epoch: 7/11, round: 143/532, loss: 0.4395427703857422\n",
      "train epoch: 7/11, round: 144/532, loss: 0.4723474085330963\n",
      "train epoch: 7/11, round: 145/532, loss: 0.31130096316337585\n",
      "train epoch: 7/11, round: 146/532, loss: 0.4385654330253601\n",
      "train epoch: 7/11, round: 147/532, loss: 0.3921104073524475\n",
      "train epoch: 7/11, round: 148/532, loss: 0.4038005471229553\n",
      "train epoch: 7/11, round: 149/532, loss: 0.43016186356544495\n",
      "train epoch: 7/11, round: 150/532, loss: 0.37614336609840393\n",
      "train epoch: 7/11, round: 151/532, loss: 0.4285967946052551\n",
      "train epoch: 7/11, round: 152/532, loss: 0.3626116216182709\n",
      "train epoch: 7/11, round: 153/532, loss: 0.42794352769851685\n",
      "train epoch: 7/11, round: 154/532, loss: 0.4008064270019531\n",
      "train epoch: 7/11, round: 155/532, loss: 0.3939294219017029\n",
      "train epoch: 7/11, round: 156/532, loss: 0.2961939871311188\n",
      "train epoch: 7/11, round: 157/532, loss: 0.3449123799800873\n",
      "train epoch: 7/11, round: 158/532, loss: 0.31507036089897156\n",
      "train epoch: 7/11, round: 159/532, loss: 0.417194128036499\n",
      "train epoch: 7/11, round: 160/532, loss: 0.4175741672515869\n",
      "train epoch: 7/11, round: 161/532, loss: 0.31806647777557373\n",
      "train epoch: 7/11, round: 162/532, loss: 0.34984615445137024\n",
      "train epoch: 7/11, round: 163/532, loss: 0.38897475600242615\n",
      "train epoch: 7/11, round: 164/532, loss: 0.3113471567630768\n",
      "train epoch: 7/11, round: 165/532, loss: 0.37789854407310486\n",
      "train epoch: 7/11, round: 166/532, loss: 0.3653416633605957\n",
      "train epoch: 7/11, round: 167/532, loss: 0.43071073293685913\n",
      "train epoch: 7/11, round: 168/532, loss: 0.41169366240501404\n",
      "train epoch: 7/11, round: 169/532, loss: 0.4341565668582916\n",
      "train epoch: 7/11, round: 170/532, loss: 0.5017741918563843\n",
      "train epoch: 7/11, round: 171/532, loss: 0.40762096643447876\n",
      "train epoch: 7/11, round: 172/532, loss: 0.3867305815219879\n",
      "train epoch: 7/11, round: 173/532, loss: 0.4658966064453125\n",
      "train epoch: 7/11, round: 174/532, loss: 0.4117850661277771\n",
      "train epoch: 7/11, round: 175/532, loss: 0.4448501169681549\n",
      "train epoch: 7/11, round: 176/532, loss: 0.35761189460754395\n",
      "train epoch: 7/11, round: 177/532, loss: 0.4007433354854584\n",
      "train epoch: 7/11, round: 178/532, loss: 0.3348481059074402\n",
      "train epoch: 7/11, round: 179/532, loss: 0.4148719906806946\n",
      "train epoch: 7/11, round: 180/532, loss: 0.39099031686782837\n",
      "train epoch: 7/11, round: 181/532, loss: 0.4265907406806946\n",
      "train epoch: 7/11, round: 182/532, loss: 0.45323482155799866\n",
      "train epoch: 7/11, round: 183/532, loss: 0.3707687258720398\n",
      "train epoch: 7/11, round: 184/532, loss: 0.38242679834365845\n",
      "train epoch: 7/11, round: 185/532, loss: 0.3778570592403412\n",
      "train epoch: 7/11, round: 186/532, loss: 0.3133658766746521\n",
      "train epoch: 7/11, round: 187/532, loss: 0.31954631209373474\n",
      "train epoch: 7/11, round: 188/532, loss: 0.4072996973991394\n",
      "train epoch: 7/11, round: 189/532, loss: 0.42989569902420044\n",
      "train epoch: 7/11, round: 190/532, loss: 0.4485117793083191\n",
      "train epoch: 7/11, round: 191/532, loss: 0.33394837379455566\n",
      "train epoch: 7/11, round: 192/532, loss: 0.40959811210632324\n",
      "train epoch: 7/11, round: 193/532, loss: 0.3862440586090088\n",
      "train epoch: 7/11, round: 194/532, loss: 0.4094317853450775\n",
      "train epoch: 7/11, round: 195/532, loss: 0.38176673650741577\n",
      "train epoch: 7/11, round: 196/532, loss: 0.44982919096946716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7/11, round: 197/532, loss: 0.397243857383728\n",
      "train epoch: 7/11, round: 198/532, loss: 0.31631484627723694\n",
      "train epoch: 7/11, round: 199/532, loss: 0.4014057219028473\n",
      "train epoch: 7/11, round: 200/532, loss: 0.44664978981018066\n",
      "train epoch: 7/11, round: 201/532, loss: 0.39241570234298706\n",
      "train epoch: 7/11, round: 202/532, loss: 0.36587655544281006\n",
      "train epoch: 7/11, round: 203/532, loss: 0.38290566205978394\n",
      "train epoch: 7/11, round: 204/532, loss: 0.33144745230674744\n",
      "train epoch: 7/11, round: 205/532, loss: 0.5066972970962524\n",
      "train epoch: 7/11, round: 206/532, loss: 0.43662428855895996\n",
      "train epoch: 7/11, round: 207/532, loss: 0.41478127241134644\n",
      "train epoch: 7/11, round: 208/532, loss: 0.3795773983001709\n",
      "train epoch: 7/11, round: 209/532, loss: 0.3303638994693756\n",
      "train epoch: 7/11, round: 210/532, loss: 0.4112851023674011\n",
      "train epoch: 7/11, round: 211/532, loss: 0.4471016824245453\n",
      "train epoch: 7/11, round: 212/532, loss: 0.3430606424808502\n",
      "train epoch: 7/11, round: 213/532, loss: 0.42248743772506714\n",
      "train epoch: 7/11, round: 214/532, loss: 0.36583852767944336\n",
      "train epoch: 7/11, round: 215/532, loss: 0.37322357296943665\n",
      "train epoch: 7/11, round: 216/532, loss: 0.3686748743057251\n",
      "train epoch: 7/11, round: 217/532, loss: 0.36060991883277893\n",
      "train epoch: 7/11, round: 218/532, loss: 0.4384370744228363\n",
      "train epoch: 7/11, round: 219/532, loss: 0.37044426798820496\n",
      "train epoch: 7/11, round: 220/532, loss: 0.42248788475990295\n",
      "train epoch: 7/11, round: 221/532, loss: 0.47613978385925293\n",
      "train epoch: 7/11, round: 222/532, loss: 0.36654558777809143\n",
      "train epoch: 7/11, round: 223/532, loss: 0.40769267082214355\n",
      "train epoch: 7/11, round: 224/532, loss: 0.39597493410110474\n",
      "train epoch: 7/11, round: 225/532, loss: 0.40444231033325195\n",
      "train epoch: 7/11, round: 226/532, loss: 0.40618252754211426\n",
      "train epoch: 7/11, round: 227/532, loss: 0.37682658433914185\n",
      "train epoch: 7/11, round: 228/532, loss: 0.3380822241306305\n",
      "train epoch: 7/11, round: 229/532, loss: 0.34805208444595337\n",
      "train epoch: 7/11, round: 230/532, loss: 0.38010016083717346\n",
      "train epoch: 7/11, round: 231/532, loss: 0.34038829803466797\n",
      "train epoch: 7/11, round: 232/532, loss: 0.3845585584640503\n",
      "train epoch: 7/11, round: 233/532, loss: 0.35744595527648926\n",
      "train epoch: 7/11, round: 234/532, loss: 0.4205142557621002\n",
      "train epoch: 7/11, round: 235/532, loss: 0.32345011830329895\n",
      "train epoch: 7/11, round: 236/532, loss: 0.39695191383361816\n",
      "train epoch: 7/11, round: 237/532, loss: 0.49318331480026245\n",
      "train epoch: 7/11, round: 238/532, loss: 0.41877835988998413\n",
      "train epoch: 7/11, round: 239/532, loss: 0.41778913140296936\n",
      "train epoch: 7/11, round: 240/532, loss: 0.3302582800388336\n",
      "train epoch: 7/11, round: 241/532, loss: 0.38008958101272583\n",
      "train epoch: 7/11, round: 242/532, loss: 0.37319719791412354\n",
      "train epoch: 7/11, round: 243/532, loss: 0.324601948261261\n",
      "train epoch: 7/11, round: 244/532, loss: 0.4232853055000305\n",
      "train epoch: 7/11, round: 245/532, loss: 0.35813361406326294\n",
      "train epoch: 7/11, round: 246/532, loss: 0.4141974449157715\n",
      "train epoch: 7/11, round: 247/532, loss: 0.46642550826072693\n",
      "train epoch: 7/11, round: 248/532, loss: 0.37524133920669556\n",
      "train epoch: 7/11, round: 249/532, loss: 0.4478531777858734\n",
      "train epoch: 7/11, round: 250/532, loss: 0.39324742555618286\n",
      "train epoch: 7/11, round: 251/532, loss: 0.3796722888946533\n",
      "train epoch: 7/11, round: 252/532, loss: 0.33471617102622986\n",
      "train epoch: 7/11, round: 253/532, loss: 0.42377567291259766\n",
      "train epoch: 7/11, round: 254/532, loss: 0.41269153356552124\n",
      "train epoch: 7/11, round: 255/532, loss: 0.4200877249240875\n",
      "train epoch: 7/11, round: 256/532, loss: 0.34265345335006714\n",
      "train epoch: 7/11, round: 257/532, loss: 0.38956665992736816\n",
      "train epoch: 7/11, round: 258/532, loss: 0.31598928570747375\n",
      "train epoch: 7/11, round: 259/532, loss: 0.4009418487548828\n",
      "train epoch: 7/11, round: 260/532, loss: 0.4256557524204254\n",
      "train epoch: 7/11, round: 261/532, loss: 0.36164146661758423\n",
      "train epoch: 7/11, round: 262/532, loss: 0.3864441514015198\n",
      "train epoch: 7/11, round: 263/532, loss: 0.4176272749900818\n",
      "train epoch: 7/11, round: 264/532, loss: 0.4446721076965332\n",
      "train epoch: 7/11, round: 265/532, loss: 0.3210195004940033\n",
      "train epoch: 7/11, round: 266/532, loss: 0.3667958080768585\n",
      "train epoch: 7/11, round: 267/532, loss: 0.41829603910446167\n",
      "train epoch: 7/11, round: 268/532, loss: 0.4518587589263916\n",
      "train epoch: 7/11, round: 269/532, loss: 0.3560711443424225\n",
      "train epoch: 7/11, round: 270/532, loss: 0.41120442748069763\n",
      "train epoch: 7/11, round: 271/532, loss: 0.4135240614414215\n",
      "train epoch: 7/11, round: 272/532, loss: 0.2856917381286621\n",
      "train epoch: 7/11, round: 273/532, loss: 0.3940799832344055\n",
      "train epoch: 7/11, round: 274/532, loss: 0.3042134940624237\n",
      "train epoch: 7/11, round: 275/532, loss: 0.439257949590683\n",
      "train epoch: 7/11, round: 276/532, loss: 0.3706660866737366\n",
      "train epoch: 7/11, round: 277/532, loss: 0.3164636492729187\n",
      "train epoch: 7/11, round: 278/532, loss: 0.3838236629962921\n",
      "train epoch: 7/11, round: 279/532, loss: 0.42008504271507263\n",
      "train epoch: 7/11, round: 280/532, loss: 0.3839063346385956\n",
      "train epoch: 7/11, round: 281/532, loss: 0.42710191011428833\n",
      "train epoch: 7/11, round: 282/532, loss: 0.3813170790672302\n",
      "train epoch: 7/11, round: 283/532, loss: 0.3464158773422241\n",
      "train epoch: 7/11, round: 284/532, loss: 0.3529506027698517\n",
      "train epoch: 7/11, round: 285/532, loss: 0.35950756072998047\n",
      "train epoch: 7/11, round: 286/532, loss: 0.4206050932407379\n",
      "train epoch: 7/11, round: 287/532, loss: 0.4197660982608795\n",
      "train epoch: 7/11, round: 288/532, loss: 0.5239871740341187\n",
      "train epoch: 7/11, round: 289/532, loss: 0.403927743434906\n",
      "train epoch: 7/11, round: 290/532, loss: 0.3565567135810852\n",
      "train epoch: 7/11, round: 291/532, loss: 0.44836679100990295\n",
      "train epoch: 7/11, round: 292/532, loss: 0.3885556757450104\n",
      "train epoch: 7/11, round: 293/532, loss: 0.42911261320114136\n",
      "train epoch: 7/11, round: 294/532, loss: 0.41982007026672363\n",
      "train epoch: 7/11, round: 295/532, loss: 0.4405304789543152\n",
      "train epoch: 7/11, round: 296/532, loss: 0.40629148483276367\n",
      "train epoch: 7/11, round: 297/532, loss: 0.363948255777359\n",
      "train epoch: 7/11, round: 298/532, loss: 0.3868981599807739\n",
      "train epoch: 7/11, round: 299/532, loss: 0.38868993520736694\n",
      "train epoch: 7/11, round: 300/532, loss: 0.3701678216457367\n",
      "train epoch: 7/11, round: 301/532, loss: 0.3216162323951721\n",
      "train epoch: 7/11, round: 302/532, loss: 0.32864898443222046\n",
      "train epoch: 7/11, round: 303/532, loss: 0.35465508699417114\n",
      "train epoch: 7/11, round: 304/532, loss: 0.4250551760196686\n",
      "train epoch: 7/11, round: 305/532, loss: 0.3810393214225769\n",
      "train epoch: 7/11, round: 306/532, loss: 0.44358891248703003\n",
      "train epoch: 7/11, round: 307/532, loss: 0.46150732040405273\n",
      "train epoch: 7/11, round: 308/532, loss: 0.3673005700111389\n",
      "train epoch: 7/11, round: 309/532, loss: 0.44924455881118774\n",
      "train epoch: 7/11, round: 310/532, loss: 0.40806302428245544\n",
      "train epoch: 7/11, round: 311/532, loss: 0.32737550139427185\n",
      "train epoch: 7/11, round: 312/532, loss: 0.31811875104904175\n",
      "train epoch: 7/11, round: 313/532, loss: 0.30769792199134827\n",
      "train epoch: 7/11, round: 314/532, loss: 0.4676967263221741\n",
      "train epoch: 7/11, round: 315/532, loss: 0.3724181652069092\n",
      "train epoch: 7/11, round: 316/532, loss: 0.3998264670372009\n",
      "train epoch: 7/11, round: 317/532, loss: 0.3559907376766205\n",
      "train epoch: 7/11, round: 318/532, loss: 0.30372506380081177\n",
      "train epoch: 7/11, round: 319/532, loss: 0.40371188521385193\n",
      "train epoch: 7/11, round: 320/532, loss: 0.42194700241088867\n",
      "train epoch: 7/11, round: 321/532, loss: 0.39415186643600464\n",
      "train epoch: 7/11, round: 322/532, loss: 0.3332832455635071\n",
      "train epoch: 7/11, round: 323/532, loss: 0.35660743713378906\n",
      "train epoch: 7/11, round: 324/532, loss: 0.3224446177482605\n",
      "train epoch: 7/11, round: 325/532, loss: 0.28803306818008423\n",
      "train epoch: 7/11, round: 326/532, loss: 0.3583962917327881\n",
      "train epoch: 7/11, round: 327/532, loss: 0.3359379172325134\n",
      "train epoch: 7/11, round: 328/532, loss: 0.40141457319259644\n",
      "train epoch: 7/11, round: 329/532, loss: 0.4433656632900238\n",
      "train epoch: 7/11, round: 330/532, loss: 0.2773746848106384\n",
      "train epoch: 7/11, round: 331/532, loss: 0.33630871772766113\n",
      "train epoch: 7/11, round: 332/532, loss: 0.36141863465309143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7/11, round: 333/532, loss: 0.3467528820037842\n",
      "train epoch: 7/11, round: 334/532, loss: 0.42452970147132874\n",
      "train epoch: 7/11, round: 335/532, loss: 0.4448624551296234\n",
      "train epoch: 7/11, round: 336/532, loss: 0.44521790742874146\n",
      "train epoch: 7/11, round: 337/532, loss: 0.3861846327781677\n",
      "train epoch: 7/11, round: 338/532, loss: 0.4669008255004883\n",
      "train epoch: 7/11, round: 339/532, loss: 0.41728609800338745\n",
      "train epoch: 7/11, round: 340/532, loss: 0.3994755744934082\n",
      "train epoch: 7/11, round: 341/532, loss: 0.432980477809906\n",
      "train epoch: 7/11, round: 342/532, loss: 0.32102370262145996\n",
      "train epoch: 7/11, round: 343/532, loss: 0.4302116930484772\n",
      "train epoch: 7/11, round: 344/532, loss: 0.3412436842918396\n",
      "train epoch: 7/11, round: 345/532, loss: 0.41370463371276855\n",
      "train epoch: 7/11, round: 346/532, loss: 0.3637182116508484\n",
      "train epoch: 7/11, round: 347/532, loss: 0.37525004148483276\n",
      "train epoch: 7/11, round: 348/532, loss: 0.2634730637073517\n",
      "train epoch: 7/11, round: 349/532, loss: 0.42893821001052856\n",
      "train epoch: 7/11, round: 350/532, loss: 0.3950110375881195\n",
      "train epoch: 7/11, round: 351/532, loss: 0.4092036783695221\n",
      "train epoch: 7/11, round: 352/532, loss: 0.353745698928833\n",
      "train epoch: 7/11, round: 353/532, loss: 0.43034639954566956\n",
      "train epoch: 7/11, round: 354/532, loss: 0.33885011076927185\n",
      "train epoch: 7/11, round: 355/532, loss: 0.3406558036804199\n",
      "train epoch: 7/11, round: 356/532, loss: 0.44509896636009216\n",
      "train epoch: 7/11, round: 357/532, loss: 0.3304064869880676\n",
      "train epoch: 7/11, round: 358/532, loss: 0.4333112835884094\n",
      "train epoch: 7/11, round: 359/532, loss: 0.4447444975376129\n",
      "train epoch: 7/11, round: 360/532, loss: 0.44956693053245544\n",
      "train epoch: 7/11, round: 361/532, loss: 0.40519875288009644\n",
      "train epoch: 7/11, round: 362/532, loss: 0.36470556259155273\n",
      "train epoch: 7/11, round: 363/532, loss: 0.3975183367729187\n",
      "train epoch: 7/11, round: 364/532, loss: 0.43845686316490173\n",
      "train epoch: 7/11, round: 365/532, loss: 0.36830323934555054\n",
      "train epoch: 7/11, round: 366/532, loss: 0.37770983576774597\n",
      "train epoch: 7/11, round: 367/532, loss: 0.3477713465690613\n",
      "train epoch: 7/11, round: 368/532, loss: 0.4398580491542816\n",
      "train epoch: 7/11, round: 369/532, loss: 0.408497154712677\n",
      "train epoch: 7/11, round: 370/532, loss: 0.3649347722530365\n",
      "train epoch: 7/11, round: 371/532, loss: 0.4209217429161072\n",
      "train epoch: 7/11, round: 372/532, loss: 0.49748530983924866\n",
      "train epoch: 7/11, round: 373/532, loss: 0.453705370426178\n",
      "train epoch: 7/11, round: 374/532, loss: 0.36348986625671387\n",
      "train epoch: 7/11, round: 375/532, loss: 0.4157469868659973\n",
      "train epoch: 7/11, round: 376/532, loss: 0.30811256170272827\n",
      "train epoch: 7/11, round: 377/532, loss: 0.35187774896621704\n",
      "train epoch: 7/11, round: 378/532, loss: 0.3883647322654724\n",
      "train epoch: 7/11, round: 379/532, loss: 0.37357452511787415\n",
      "train epoch: 7/11, round: 380/532, loss: 0.4191080629825592\n",
      "train epoch: 7/11, round: 381/532, loss: 0.3875052332878113\n",
      "train epoch: 7/11, round: 382/532, loss: 0.35273805260658264\n",
      "train epoch: 7/11, round: 383/532, loss: 0.4132504463195801\n",
      "train epoch: 7/11, round: 384/532, loss: 0.33148831129074097\n",
      "train epoch: 7/11, round: 385/532, loss: 0.4082048535346985\n",
      "train epoch: 7/11, round: 386/532, loss: 0.3866395950317383\n",
      "train epoch: 7/11, round: 387/532, loss: 0.3569481372833252\n",
      "train epoch: 7/11, round: 388/532, loss: 0.38408559560775757\n",
      "train epoch: 7/11, round: 389/532, loss: 0.4540148675441742\n",
      "train epoch: 7/11, round: 390/532, loss: 0.3090445101261139\n",
      "train epoch: 7/11, round: 391/532, loss: 0.46553149819374084\n",
      "train epoch: 7/11, round: 392/532, loss: 0.463015615940094\n",
      "train epoch: 7/11, round: 393/532, loss: 0.4984018802642822\n",
      "train epoch: 7/11, round: 394/532, loss: 0.3704665005207062\n",
      "train epoch: 7/11, round: 395/532, loss: 0.4283390939235687\n",
      "train epoch: 7/11, round: 396/532, loss: 0.3571261763572693\n",
      "train epoch: 7/11, round: 397/532, loss: 0.42503052949905396\n",
      "train epoch: 7/11, round: 398/532, loss: 0.43700671195983887\n",
      "train epoch: 7/11, round: 399/532, loss: 0.3282744288444519\n",
      "train epoch: 7/11, round: 400/532, loss: 0.42183876037597656\n",
      "train epoch: 7/11, round: 401/532, loss: 0.3821974992752075\n",
      "train epoch: 7/11, round: 402/532, loss: 0.3518708646297455\n",
      "train epoch: 7/11, round: 403/532, loss: 0.37947967648506165\n",
      "train epoch: 7/11, round: 404/532, loss: 0.35637837648391724\n",
      "train epoch: 7/11, round: 405/532, loss: 0.46374768018722534\n",
      "train epoch: 7/11, round: 406/532, loss: 0.4187806248664856\n",
      "train epoch: 7/11, round: 407/532, loss: 0.3156370520591736\n",
      "train epoch: 7/11, round: 408/532, loss: 0.37438687682151794\n",
      "train epoch: 7/11, round: 409/532, loss: 0.2676405906677246\n",
      "train epoch: 7/11, round: 410/532, loss: 0.446878582239151\n",
      "train epoch: 7/11, round: 411/532, loss: 0.33702293038368225\n",
      "train epoch: 7/11, round: 412/532, loss: 0.32274413108825684\n",
      "train epoch: 7/11, round: 413/532, loss: 0.444007009267807\n",
      "train epoch: 7/11, round: 414/532, loss: 0.378648966550827\n",
      "train epoch: 7/11, round: 415/532, loss: 0.3372209668159485\n",
      "train epoch: 7/11, round: 416/532, loss: 0.32566532492637634\n",
      "train epoch: 7/11, round: 417/532, loss: 0.33598393201828003\n",
      "train epoch: 7/11, round: 418/532, loss: 0.5018352270126343\n",
      "train epoch: 7/11, round: 419/532, loss: 0.38296279311180115\n",
      "train epoch: 7/11, round: 420/532, loss: 0.36943474411964417\n",
      "train epoch: 7/11, round: 421/532, loss: 0.4593663215637207\n",
      "train epoch: 7/11, round: 422/532, loss: 0.4014928936958313\n",
      "train epoch: 7/11, round: 423/532, loss: 0.3571189045906067\n",
      "train epoch: 7/11, round: 424/532, loss: 0.40614229440689087\n",
      "train epoch: 7/11, round: 425/532, loss: 0.33285969495773315\n",
      "train epoch: 7/11, round: 426/532, loss: 0.3051736056804657\n",
      "train epoch: 7/11, round: 427/532, loss: 0.3164602518081665\n",
      "train epoch: 7/11, round: 428/532, loss: 0.4014454782009125\n",
      "train epoch: 7/11, round: 429/532, loss: 0.35875073075294495\n",
      "train epoch: 7/11, round: 430/532, loss: 0.3460499346256256\n",
      "train epoch: 7/11, round: 431/532, loss: 0.4275693893432617\n",
      "train epoch: 7/11, round: 432/532, loss: 0.3757731318473816\n",
      "train epoch: 7/11, round: 433/532, loss: 0.40168923139572144\n",
      "train epoch: 7/11, round: 434/532, loss: 0.4017640948295593\n",
      "train epoch: 7/11, round: 435/532, loss: 0.39025402069091797\n",
      "train epoch: 7/11, round: 436/532, loss: 0.35325106978416443\n",
      "train epoch: 7/11, round: 437/532, loss: 0.44914954900741577\n",
      "train epoch: 7/11, round: 438/532, loss: 0.34632375836372375\n",
      "train epoch: 7/11, round: 439/532, loss: 0.3524242341518402\n",
      "train epoch: 7/11, round: 440/532, loss: 0.47352004051208496\n",
      "train epoch: 7/11, round: 441/532, loss: 0.29360008239746094\n",
      "train epoch: 7/11, round: 442/532, loss: 0.36031022667884827\n",
      "train epoch: 7/11, round: 443/532, loss: 0.35948899388313293\n",
      "train epoch: 7/11, round: 444/532, loss: 0.3582903742790222\n",
      "train epoch: 7/11, round: 445/532, loss: 0.3719596266746521\n",
      "train epoch: 7/11, round: 446/532, loss: 0.2858482897281647\n",
      "train epoch: 7/11, round: 447/532, loss: 0.40683770179748535\n",
      "train epoch: 7/11, round: 448/532, loss: 0.47628721594810486\n",
      "train epoch: 7/11, round: 449/532, loss: 0.44076746702194214\n",
      "train epoch: 7/11, round: 450/532, loss: 0.3409683108329773\n",
      "train epoch: 7/11, round: 451/532, loss: 0.43463969230651855\n",
      "train epoch: 7/11, round: 452/532, loss: 0.4080254137516022\n",
      "train epoch: 7/11, round: 453/532, loss: 0.4172506332397461\n",
      "train epoch: 7/11, round: 454/532, loss: 0.4111511707305908\n",
      "train epoch: 7/11, round: 455/532, loss: 0.41920480132102966\n",
      "train epoch: 7/11, round: 456/532, loss: 0.33520251512527466\n",
      "train epoch: 7/11, round: 457/532, loss: 0.4313938021659851\n",
      "train epoch: 7/11, round: 458/532, loss: 0.5059733390808105\n",
      "train epoch: 7/11, round: 459/532, loss: 0.45495495200157166\n",
      "train epoch: 7/11, round: 460/532, loss: 0.3720812201499939\n",
      "train epoch: 7/11, round: 461/532, loss: 0.48462921380996704\n",
      "train epoch: 7/11, round: 462/532, loss: 0.434502512216568\n",
      "train epoch: 7/11, round: 463/532, loss: 0.4373621344566345\n",
      "train epoch: 7/11, round: 464/532, loss: 0.34062960743904114\n",
      "train epoch: 7/11, round: 465/532, loss: 0.37882956862449646\n",
      "train epoch: 7/11, round: 466/532, loss: 0.3615565299987793\n",
      "train epoch: 7/11, round: 467/532, loss: 0.3812510371208191\n",
      "train epoch: 7/11, round: 468/532, loss: 0.4886786937713623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7/11, round: 469/532, loss: 0.4263729453086853\n",
      "train epoch: 7/11, round: 470/532, loss: 0.36895185708999634\n",
      "train epoch: 7/11, round: 471/532, loss: 0.38035833835601807\n",
      "train epoch: 7/11, round: 472/532, loss: 0.4904746115207672\n",
      "train epoch: 7/11, round: 473/532, loss: 0.4158596098423004\n",
      "train epoch: 7/11, round: 474/532, loss: 0.4171527326107025\n",
      "train epoch: 7/11, round: 475/532, loss: 0.36516326665878296\n",
      "train epoch: 7/11, round: 476/532, loss: 0.4565432071685791\n",
      "train epoch: 7/11, round: 477/532, loss: 0.3554704785346985\n",
      "train epoch: 7/11, round: 478/532, loss: 0.3232424259185791\n",
      "train epoch: 7/11, round: 479/532, loss: 0.39623454213142395\n",
      "train epoch: 7/11, round: 480/532, loss: 0.383197158575058\n",
      "train epoch: 7/11, round: 481/532, loss: 0.39809900522232056\n",
      "train epoch: 7/11, round: 482/532, loss: 0.488229900598526\n",
      "train epoch: 7/11, round: 483/532, loss: 0.41916418075561523\n",
      "train epoch: 7/11, round: 484/532, loss: 0.35073426365852356\n",
      "train epoch: 7/11, round: 485/532, loss: 0.3947058916091919\n",
      "train epoch: 7/11, round: 486/532, loss: 0.3476889431476593\n",
      "train epoch: 7/11, round: 487/532, loss: 0.34839150309562683\n",
      "train epoch: 7/11, round: 488/532, loss: 0.33305543661117554\n",
      "train epoch: 7/11, round: 489/532, loss: 0.44029656052589417\n",
      "train epoch: 7/11, round: 490/532, loss: 0.4008482098579407\n",
      "train epoch: 7/11, round: 491/532, loss: 0.45421409606933594\n",
      "train epoch: 7/11, round: 492/532, loss: 0.39506807923316956\n",
      "train epoch: 7/11, round: 493/532, loss: 0.3712456524372101\n",
      "train epoch: 7/11, round: 494/532, loss: 0.36865144968032837\n",
      "train epoch: 7/11, round: 495/532, loss: 0.31760087609291077\n",
      "train epoch: 7/11, round: 496/532, loss: 0.3351931571960449\n",
      "train epoch: 7/11, round: 497/532, loss: 0.41990262269973755\n",
      "train epoch: 7/11, round: 498/532, loss: 0.3246152698993683\n",
      "train epoch: 7/11, round: 499/532, loss: 0.4066649079322815\n",
      "train epoch: 7/11, round: 500/532, loss: 0.3920205235481262\n",
      "train epoch: 7/11, round: 501/532, loss: 0.43409472703933716\n",
      "train epoch: 7/11, round: 502/532, loss: 0.4095023572444916\n",
      "train epoch: 7/11, round: 503/532, loss: 0.40916022658348083\n",
      "train epoch: 7/11, round: 504/532, loss: 0.4266369938850403\n",
      "train epoch: 7/11, round: 505/532, loss: 0.3914090692996979\n",
      "train epoch: 7/11, round: 506/532, loss: 0.3888690173625946\n",
      "train epoch: 7/11, round: 507/532, loss: 0.39644405245780945\n",
      "train epoch: 7/11, round: 508/532, loss: 0.2983631491661072\n",
      "train epoch: 7/11, round: 509/532, loss: 0.44221553206443787\n",
      "train epoch: 7/11, round: 510/532, loss: 0.40037965774536133\n",
      "train epoch: 7/11, round: 511/532, loss: 0.34832993149757385\n",
      "train epoch: 7/11, round: 512/532, loss: 0.361491858959198\n",
      "train epoch: 7/11, round: 513/532, loss: 0.4867003560066223\n",
      "train epoch: 7/11, round: 514/532, loss: 0.3636138141155243\n",
      "train epoch: 7/11, round: 515/532, loss: 0.3619626760482788\n",
      "train epoch: 7/11, round: 516/532, loss: 0.29285821318626404\n",
      "train epoch: 7/11, round: 517/532, loss: 0.3487730920314789\n",
      "train epoch: 7/11, round: 518/532, loss: 0.43671661615371704\n",
      "train epoch: 7/11, round: 519/532, loss: 0.3235088586807251\n",
      "train epoch: 7/11, round: 520/532, loss: 0.3359234035015106\n",
      "train epoch: 7/11, round: 521/532, loss: 0.4113547205924988\n",
      "train epoch: 7/11, round: 522/532, loss: 0.34807246923446655\n",
      "train epoch: 7/11, round: 523/532, loss: 0.40153494477272034\n",
      "train epoch: 7/11, round: 524/532, loss: 0.33399951457977295\n",
      "train epoch: 7/11, round: 525/532, loss: 0.29399698972702026\n",
      "train epoch: 7/11, round: 526/532, loss: 0.28917741775512695\n",
      "train epoch: 7/11, round: 527/532, loss: 0.558940052986145\n",
      "train epoch: 7/11, round: 528/532, loss: 0.4489344656467438\n",
      "train epoch: 7/11, round: 529/532, loss: 0.4445978105068207\n",
      "train epoch: 7/11, round: 530/532, loss: 0.44958704710006714\n",
      "train epoch: 7/11, round: 531/532, loss: 0.34303003549575806\n",
      "train epoch: 7/11, round: 532/532, loss: 0.33203426003456116\n",
      "train epoch: 7/11, KS: 0.28963759771318875, ROC: 0.6967925476841126\n",
      "test epoch: 7/11, round: 1/501, loss: 0.37180206179618835\n",
      "test epoch: 7/11, round: 2/501, loss: 0.33469313383102417\n",
      "test epoch: 7/11, round: 3/501, loss: 0.3071037828922272\n",
      "test epoch: 7/11, round: 4/501, loss: 0.42826977372169495\n",
      "test epoch: 7/11, round: 5/501, loss: 0.3806959092617035\n",
      "test epoch: 7/11, round: 6/501, loss: 0.37959349155426025\n",
      "test epoch: 7/11, round: 7/501, loss: 0.465271532535553\n",
      "test epoch: 7/11, round: 8/501, loss: 0.4745092988014221\n",
      "test epoch: 7/11, round: 9/501, loss: 0.5411186218261719\n",
      "test epoch: 7/11, round: 10/501, loss: 0.5825328230857849\n",
      "test epoch: 7/11, round: 11/501, loss: 0.243887260556221\n",
      "test epoch: 7/11, round: 12/501, loss: 0.3690352737903595\n",
      "test epoch: 7/11, round: 13/501, loss: 0.36533936858177185\n",
      "test epoch: 7/11, round: 14/501, loss: 0.32406970858573914\n",
      "test epoch: 7/11, round: 15/501, loss: 0.48499006032943726\n",
      "test epoch: 7/11, round: 16/501, loss: 0.3922386169433594\n",
      "test epoch: 7/11, round: 17/501, loss: 0.36079445481300354\n",
      "test epoch: 7/11, round: 18/501, loss: 0.4931858777999878\n",
      "test epoch: 7/11, round: 19/501, loss: 0.5160736441612244\n",
      "test epoch: 7/11, round: 20/501, loss: 0.708345353603363\n",
      "test epoch: 7/11, round: 21/501, loss: 0.45778125524520874\n",
      "test epoch: 7/11, round: 22/501, loss: 0.5792989134788513\n",
      "test epoch: 7/11, round: 23/501, loss: 0.4767988920211792\n",
      "test epoch: 7/11, round: 24/501, loss: 0.40228164196014404\n",
      "test epoch: 7/11, round: 25/501, loss: 0.6622269153594971\n",
      "test epoch: 7/11, round: 26/501, loss: 0.5401334166526794\n",
      "test epoch: 7/11, round: 27/501, loss: 0.2826058268547058\n",
      "test epoch: 7/11, round: 28/501, loss: 0.5186577439308167\n",
      "test epoch: 7/11, round: 29/501, loss: 0.30570298433303833\n",
      "test epoch: 7/11, round: 30/501, loss: 0.4940199553966522\n",
      "test epoch: 7/11, round: 31/501, loss: 0.5045856833457947\n",
      "test epoch: 7/11, round: 32/501, loss: 0.560357391834259\n",
      "test epoch: 7/11, round: 33/501, loss: 0.6381524801254272\n",
      "test epoch: 7/11, round: 34/501, loss: 0.4392271637916565\n",
      "test epoch: 7/11, round: 35/501, loss: 0.21131333708763123\n",
      "test epoch: 7/11, round: 36/501, loss: 0.463227778673172\n",
      "test epoch: 7/11, round: 37/501, loss: 0.47819676995277405\n",
      "test epoch: 7/11, round: 38/501, loss: 0.4776405990123749\n",
      "test epoch: 7/11, round: 39/501, loss: 0.7199112772941589\n",
      "test epoch: 7/11, round: 40/501, loss: 0.5493566393852234\n",
      "test epoch: 7/11, round: 41/501, loss: 0.41481322050094604\n",
      "test epoch: 7/11, round: 42/501, loss: 0.43188291788101196\n",
      "test epoch: 7/11, round: 43/501, loss: 0.4144934415817261\n",
      "test epoch: 7/11, round: 44/501, loss: 0.5735819339752197\n",
      "test epoch: 7/11, round: 45/501, loss: 0.6698333024978638\n",
      "test epoch: 7/11, round: 46/501, loss: 0.42150676250457764\n",
      "test epoch: 7/11, round: 47/501, loss: 0.26992055773735046\n",
      "test epoch: 7/11, round: 48/501, loss: 0.5192253589630127\n",
      "test epoch: 7/11, round: 49/501, loss: 0.3602481782436371\n",
      "test epoch: 7/11, round: 50/501, loss: 0.21707354485988617\n",
      "test epoch: 7/11, round: 51/501, loss: 0.4301289916038513\n",
      "test epoch: 7/11, round: 52/501, loss: 0.42008888721466064\n",
      "test epoch: 7/11, round: 53/501, loss: 0.5656384229660034\n",
      "test epoch: 7/11, round: 54/501, loss: 0.6203829646110535\n",
      "test epoch: 7/11, round: 55/501, loss: 0.420175701379776\n",
      "test epoch: 7/11, round: 56/501, loss: 0.5073947310447693\n",
      "test epoch: 7/11, round: 57/501, loss: 0.44266971945762634\n",
      "test epoch: 7/11, round: 58/501, loss: 0.4773719608783722\n",
      "test epoch: 7/11, round: 59/501, loss: 0.29486656188964844\n",
      "test epoch: 7/11, round: 60/501, loss: 0.49897199869155884\n",
      "test epoch: 7/11, round: 61/501, loss: 0.4097858965396881\n",
      "test epoch: 7/11, round: 62/501, loss: 0.6132459044456482\n",
      "test epoch: 7/11, round: 63/501, loss: 0.735523521900177\n",
      "test epoch: 7/11, round: 64/501, loss: 0.30577075481414795\n",
      "test epoch: 7/11, round: 65/501, loss: 0.6170094609260559\n",
      "test epoch: 7/11, round: 66/501, loss: 0.3911423981189728\n",
      "test epoch: 7/11, round: 67/501, loss: 0.5569872260093689\n",
      "test epoch: 7/11, round: 68/501, loss: 0.6807499527931213\n",
      "test epoch: 7/11, round: 69/501, loss: 0.45708051323890686\n",
      "test epoch: 7/11, round: 70/501, loss: 0.42014220356941223\n",
      "test epoch: 7/11, round: 71/501, loss: 0.6069085597991943\n",
      "test epoch: 7/11, round: 72/501, loss: 0.45230919122695923\n",
      "test epoch: 7/11, round: 73/501, loss: 0.4545731544494629\n",
      "test epoch: 7/11, round: 74/501, loss: 0.4347609877586365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 7/11, round: 75/501, loss: 0.49719470739364624\n",
      "test epoch: 7/11, round: 76/501, loss: 0.6751803159713745\n",
      "test epoch: 7/11, round: 77/501, loss: 0.3247961699962616\n",
      "test epoch: 7/11, round: 78/501, loss: 0.5944284796714783\n",
      "test epoch: 7/11, round: 79/501, loss: 0.4123283624649048\n",
      "test epoch: 7/11, round: 80/501, loss: 0.572546124458313\n",
      "test epoch: 7/11, round: 81/501, loss: 0.7437341213226318\n",
      "test epoch: 7/11, round: 82/501, loss: 0.5735299587249756\n",
      "test epoch: 7/11, round: 83/501, loss: 0.4054907560348511\n",
      "test epoch: 7/11, round: 84/501, loss: 0.6376450657844543\n",
      "test epoch: 7/11, round: 85/501, loss: 0.6534292101860046\n",
      "test epoch: 7/11, round: 86/501, loss: 0.34073707461357117\n",
      "test epoch: 7/11, round: 87/501, loss: 0.4715898931026459\n",
      "test epoch: 7/11, round: 88/501, loss: 0.3568180501461029\n",
      "test epoch: 7/11, round: 89/501, loss: 0.3737180531024933\n",
      "test epoch: 7/11, round: 90/501, loss: 0.6203464269638062\n",
      "test epoch: 7/11, round: 91/501, loss: 0.3964707553386688\n",
      "test epoch: 7/11, round: 92/501, loss: 0.5070253610610962\n",
      "test epoch: 7/11, round: 93/501, loss: 0.3941689729690552\n",
      "test epoch: 7/11, round: 94/501, loss: 0.5799964666366577\n",
      "test epoch: 7/11, round: 95/501, loss: 0.41222280263900757\n",
      "test epoch: 7/11, round: 96/501, loss: 0.37650319933891296\n",
      "test epoch: 7/11, round: 97/501, loss: 0.5757712125778198\n",
      "test epoch: 7/11, round: 98/501, loss: 0.43648800253868103\n",
      "test epoch: 7/11, round: 99/501, loss: 0.5940836071968079\n",
      "test epoch: 7/11, round: 100/501, loss: 0.5022192001342773\n",
      "test epoch: 7/11, round: 101/501, loss: 0.5147335529327393\n",
      "test epoch: 7/11, round: 102/501, loss: 0.33620116114616394\n",
      "test epoch: 7/11, round: 103/501, loss: 0.4234547019004822\n",
      "test epoch: 7/11, round: 104/501, loss: 0.6882779598236084\n",
      "test epoch: 7/11, round: 105/501, loss: 0.46135780215263367\n",
      "test epoch: 7/11, round: 106/501, loss: 0.6489953398704529\n",
      "test epoch: 7/11, round: 107/501, loss: 0.38551032543182373\n",
      "test epoch: 7/11, round: 108/501, loss: 0.5915558934211731\n",
      "test epoch: 7/11, round: 109/501, loss: 0.3769341707229614\n",
      "test epoch: 7/11, round: 110/501, loss: 0.6934985518455505\n",
      "test epoch: 7/11, round: 111/501, loss: 0.2741055190563202\n",
      "test epoch: 7/11, round: 112/501, loss: 0.2764343321323395\n",
      "test epoch: 7/11, round: 113/501, loss: 0.41760551929473877\n",
      "test epoch: 7/11, round: 114/501, loss: 0.4354422390460968\n",
      "test epoch: 7/11, round: 115/501, loss: 0.3914826214313507\n",
      "test epoch: 7/11, round: 116/501, loss: 0.3212975859642029\n",
      "test epoch: 7/11, round: 117/501, loss: 0.39716288447380066\n",
      "test epoch: 7/11, round: 118/501, loss: 0.37282830476760864\n",
      "test epoch: 7/11, round: 119/501, loss: 0.3313913941383362\n",
      "test epoch: 7/11, round: 120/501, loss: 0.39330214262008667\n",
      "test epoch: 7/11, round: 121/501, loss: 0.4083726704120636\n",
      "test epoch: 7/11, round: 122/501, loss: 0.3880325257778168\n",
      "test epoch: 7/11, round: 123/501, loss: 0.46382635831832886\n",
      "test epoch: 7/11, round: 124/501, loss: 0.6114575862884521\n",
      "test epoch: 7/11, round: 125/501, loss: 0.4864999055862427\n",
      "test epoch: 7/11, round: 126/501, loss: 0.41446688771247864\n",
      "test epoch: 7/11, round: 127/501, loss: 0.46414831280708313\n",
      "test epoch: 7/11, round: 128/501, loss: 0.2639266848564148\n",
      "test epoch: 7/11, round: 129/501, loss: 0.4843592345714569\n",
      "test epoch: 7/11, round: 130/501, loss: 0.7582631707191467\n",
      "test epoch: 7/11, round: 131/501, loss: 0.6412257552146912\n",
      "test epoch: 7/11, round: 132/501, loss: 0.4644011855125427\n",
      "test epoch: 7/11, round: 133/501, loss: 0.7161369323730469\n",
      "test epoch: 7/11, round: 134/501, loss: 0.564613938331604\n",
      "test epoch: 7/11, round: 135/501, loss: 0.3095477521419525\n",
      "test epoch: 7/11, round: 136/501, loss: 0.40780505537986755\n",
      "test epoch: 7/11, round: 137/501, loss: 0.394546777009964\n",
      "test epoch: 7/11, round: 138/501, loss: 0.39399439096450806\n",
      "test epoch: 7/11, round: 139/501, loss: 0.6218355298042297\n",
      "test epoch: 7/11, round: 140/501, loss: 0.4871479868888855\n",
      "test epoch: 7/11, round: 141/501, loss: 0.36567845940589905\n",
      "test epoch: 7/11, round: 142/501, loss: 0.6147481203079224\n",
      "test epoch: 7/11, round: 143/501, loss: 0.4284273386001587\n",
      "test epoch: 7/11, round: 144/501, loss: 0.4824331998825073\n",
      "test epoch: 7/11, round: 145/501, loss: 0.38219889998435974\n",
      "test epoch: 7/11, round: 146/501, loss: 0.595267653465271\n",
      "test epoch: 7/11, round: 147/501, loss: 0.5050402283668518\n",
      "test epoch: 7/11, round: 148/501, loss: 0.5557441711425781\n",
      "test epoch: 7/11, round: 149/501, loss: 0.4132387042045593\n",
      "test epoch: 7/11, round: 150/501, loss: 0.5694707036018372\n",
      "test epoch: 7/11, round: 151/501, loss: 0.3951312303543091\n",
      "test epoch: 7/11, round: 152/501, loss: 0.5624770522117615\n",
      "test epoch: 7/11, round: 153/501, loss: 0.572172999382019\n",
      "test epoch: 7/11, round: 154/501, loss: 0.5780989527702332\n",
      "test epoch: 7/11, round: 155/501, loss: 0.4361490309238434\n",
      "test epoch: 7/11, round: 156/501, loss: 0.33745184540748596\n",
      "test epoch: 7/11, round: 157/501, loss: 0.3568355441093445\n",
      "test epoch: 7/11, round: 158/501, loss: 0.4370407164096832\n",
      "test epoch: 7/11, round: 159/501, loss: 0.41253069043159485\n",
      "test epoch: 7/11, round: 160/501, loss: 0.4468631148338318\n",
      "test epoch: 7/11, round: 161/501, loss: 0.4001025855541229\n",
      "test epoch: 7/11, round: 162/501, loss: 0.41707101464271545\n",
      "test epoch: 7/11, round: 163/501, loss: 0.47832736372947693\n",
      "test epoch: 7/11, round: 164/501, loss: 0.3790998160839081\n",
      "test epoch: 7/11, round: 165/501, loss: 0.4856802523136139\n",
      "test epoch: 7/11, round: 166/501, loss: 0.359531044960022\n",
      "test epoch: 7/11, round: 167/501, loss: 0.309312641620636\n",
      "test epoch: 7/11, round: 168/501, loss: 0.2552609145641327\n",
      "test epoch: 7/11, round: 169/501, loss: 0.40255698561668396\n",
      "test epoch: 7/11, round: 170/501, loss: 0.43172428011894226\n",
      "test epoch: 7/11, round: 171/501, loss: 0.46520259976387024\n",
      "test epoch: 7/11, round: 172/501, loss: 0.46073177456855774\n",
      "test epoch: 7/11, round: 173/501, loss: 0.2977004945278168\n",
      "test epoch: 7/11, round: 174/501, loss: 0.5649705529212952\n",
      "test epoch: 7/11, round: 175/501, loss: 0.29183337092399597\n",
      "test epoch: 7/11, round: 176/501, loss: 0.5829256772994995\n",
      "test epoch: 7/11, round: 177/501, loss: 0.4097457230091095\n",
      "test epoch: 7/11, round: 178/501, loss: 0.2421785145998001\n",
      "test epoch: 7/11, round: 179/501, loss: 0.2942263185977936\n",
      "test epoch: 7/11, round: 180/501, loss: 0.3255002796649933\n",
      "test epoch: 7/11, round: 181/501, loss: 0.5262826085090637\n",
      "test epoch: 7/11, round: 182/501, loss: 0.5447711944580078\n",
      "test epoch: 7/11, round: 183/501, loss: 0.4669170677661896\n",
      "test epoch: 7/11, round: 184/501, loss: 0.513992190361023\n",
      "test epoch: 7/11, round: 185/501, loss: 0.4679557681083679\n",
      "test epoch: 7/11, round: 186/501, loss: 0.5599105358123779\n",
      "test epoch: 7/11, round: 187/501, loss: 0.48979681730270386\n",
      "test epoch: 7/11, round: 188/501, loss: 0.4947583079338074\n",
      "test epoch: 7/11, round: 189/501, loss: 0.5713564157485962\n",
      "test epoch: 7/11, round: 190/501, loss: 0.44635406136512756\n",
      "test epoch: 7/11, round: 191/501, loss: 0.3921702206134796\n",
      "test epoch: 7/11, round: 192/501, loss: 0.5141243934631348\n",
      "test epoch: 7/11, round: 193/501, loss: 0.49397677183151245\n",
      "test epoch: 7/11, round: 194/501, loss: 0.4173983335494995\n",
      "test epoch: 7/11, round: 195/501, loss: 0.5461215376853943\n",
      "test epoch: 7/11, round: 196/501, loss: 0.3484216630458832\n",
      "test epoch: 7/11, round: 197/501, loss: 0.38056260347366333\n",
      "test epoch: 7/11, round: 198/501, loss: 0.4596872627735138\n",
      "test epoch: 7/11, round: 199/501, loss: 0.49148255586624146\n",
      "test epoch: 7/11, round: 200/501, loss: 0.5730254054069519\n",
      "test epoch: 7/11, round: 201/501, loss: 0.37635913491249084\n",
      "test epoch: 7/11, round: 202/501, loss: 0.3070850372314453\n",
      "test epoch: 7/11, round: 203/501, loss: 0.4439062476158142\n",
      "test epoch: 7/11, round: 204/501, loss: 0.50895756483078\n",
      "test epoch: 7/11, round: 205/501, loss: 0.4568866789340973\n",
      "test epoch: 7/11, round: 206/501, loss: 0.26403313875198364\n",
      "test epoch: 7/11, round: 207/501, loss: 0.4104979336261749\n",
      "test epoch: 7/11, round: 208/501, loss: 0.4586273431777954\n",
      "test epoch: 7/11, round: 209/501, loss: 0.33997291326522827\n",
      "test epoch: 7/11, round: 210/501, loss: 0.5275198817253113\n",
      "test epoch: 7/11, round: 211/501, loss: 0.3117019236087799\n",
      "test epoch: 7/11, round: 212/501, loss: 0.3906175494194031\n",
      "test epoch: 7/11, round: 213/501, loss: 0.35714054107666016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 7/11, round: 214/501, loss: 0.24571964144706726\n",
      "test epoch: 7/11, round: 215/501, loss: 0.22178281843662262\n",
      "test epoch: 7/11, round: 216/501, loss: 0.25141093134880066\n",
      "test epoch: 7/11, round: 217/501, loss: 0.19459909200668335\n",
      "test epoch: 7/11, round: 218/501, loss: 0.1959945112466812\n",
      "test epoch: 7/11, round: 219/501, loss: 0.24666288495063782\n",
      "test epoch: 7/11, round: 220/501, loss: 0.39778321981430054\n",
      "test epoch: 7/11, round: 221/501, loss: 0.3480822741985321\n",
      "test epoch: 7/11, round: 222/501, loss: 0.19372238218784332\n",
      "test epoch: 7/11, round: 223/501, loss: 0.2274778038263321\n",
      "test epoch: 7/11, round: 224/501, loss: 0.24842700362205505\n",
      "test epoch: 7/11, round: 225/501, loss: 0.2157246321439743\n",
      "test epoch: 7/11, round: 226/501, loss: 0.2198430895805359\n",
      "test epoch: 7/11, round: 227/501, loss: 0.2768673002719879\n",
      "test epoch: 7/11, round: 228/501, loss: 0.24646618962287903\n",
      "test epoch: 7/11, round: 229/501, loss: 0.40809544920921326\n",
      "test epoch: 7/11, round: 230/501, loss: 0.3291226625442505\n",
      "test epoch: 7/11, round: 231/501, loss: 0.3901781141757965\n",
      "test epoch: 7/11, round: 232/501, loss: 0.41067585349082947\n",
      "test epoch: 7/11, round: 233/501, loss: 0.4749755263328552\n",
      "test epoch: 7/11, round: 234/501, loss: 0.46981048583984375\n",
      "test epoch: 7/11, round: 235/501, loss: 0.3138885498046875\n",
      "test epoch: 7/11, round: 236/501, loss: 0.3499104678630829\n",
      "test epoch: 7/11, round: 237/501, loss: 0.333455353975296\n",
      "test epoch: 7/11, round: 238/501, loss: 0.3566066026687622\n",
      "test epoch: 7/11, round: 239/501, loss: 0.448016494512558\n",
      "test epoch: 7/11, round: 240/501, loss: 0.2545764744281769\n",
      "test epoch: 7/11, round: 241/501, loss: 0.441201388835907\n",
      "test epoch: 7/11, round: 242/501, loss: 0.32434818148612976\n",
      "test epoch: 7/11, round: 243/501, loss: 0.3216906189918518\n",
      "test epoch: 7/11, round: 244/501, loss: 0.32641923427581787\n",
      "test epoch: 7/11, round: 245/501, loss: 0.38013917207717896\n",
      "test epoch: 7/11, round: 246/501, loss: 0.36649954319000244\n",
      "test epoch: 7/11, round: 247/501, loss: 0.42814114689826965\n",
      "test epoch: 7/11, round: 248/501, loss: 0.23527145385742188\n",
      "test epoch: 7/11, round: 249/501, loss: 0.365565687417984\n",
      "test epoch: 7/11, round: 250/501, loss: 0.30945244431495667\n",
      "test epoch: 7/11, round: 251/501, loss: 0.3825402557849884\n",
      "test epoch: 7/11, round: 252/501, loss: 0.3401125967502594\n",
      "test epoch: 7/11, round: 253/501, loss: 0.3296116590499878\n",
      "test epoch: 7/11, round: 254/501, loss: 0.33856043219566345\n",
      "test epoch: 7/11, round: 255/501, loss: 0.3097638189792633\n",
      "test epoch: 7/11, round: 256/501, loss: 0.5249105095863342\n",
      "test epoch: 7/11, round: 257/501, loss: 0.3682042062282562\n",
      "test epoch: 7/11, round: 258/501, loss: 0.44921499490737915\n",
      "test epoch: 7/11, round: 259/501, loss: 0.2684132754802704\n",
      "test epoch: 7/11, round: 260/501, loss: 0.4746170938014984\n",
      "test epoch: 7/11, round: 261/501, loss: 0.5604918003082275\n",
      "test epoch: 7/11, round: 262/501, loss: 0.44382399320602417\n",
      "test epoch: 7/11, round: 263/501, loss: 0.4107798635959625\n",
      "test epoch: 7/11, round: 264/501, loss: 0.48511427640914917\n",
      "test epoch: 7/11, round: 265/501, loss: 0.5896289348602295\n",
      "test epoch: 7/11, round: 266/501, loss: 0.4177539050579071\n",
      "test epoch: 7/11, round: 267/501, loss: 0.38131949305534363\n",
      "test epoch: 7/11, round: 268/501, loss: 0.29973840713500977\n",
      "test epoch: 7/11, round: 269/501, loss: 0.47073766589164734\n",
      "test epoch: 7/11, round: 270/501, loss: 0.3235462009906769\n",
      "test epoch: 7/11, round: 271/501, loss: 0.528293251991272\n",
      "test epoch: 7/11, round: 272/501, loss: 0.41134387254714966\n",
      "test epoch: 7/11, round: 273/501, loss: 0.3629772961139679\n",
      "test epoch: 7/11, round: 274/501, loss: 0.4690513610839844\n",
      "test epoch: 7/11, round: 275/501, loss: 0.33344724774360657\n",
      "test epoch: 7/11, round: 276/501, loss: 0.3969811201095581\n",
      "test epoch: 7/11, round: 277/501, loss: 0.3633793592453003\n",
      "test epoch: 7/11, round: 278/501, loss: 0.5394378900527954\n",
      "test epoch: 7/11, round: 279/501, loss: 0.35580477118492126\n",
      "test epoch: 7/11, round: 280/501, loss: 0.26610979437828064\n",
      "test epoch: 7/11, round: 281/501, loss: 0.2335914969444275\n",
      "test epoch: 7/11, round: 282/501, loss: 0.2960367798805237\n",
      "test epoch: 7/11, round: 283/501, loss: 0.3454682230949402\n",
      "test epoch: 7/11, round: 284/501, loss: 0.38733306527137756\n",
      "test epoch: 7/11, round: 285/501, loss: 0.4480134844779968\n",
      "test epoch: 7/11, round: 286/501, loss: 0.45246440172195435\n",
      "test epoch: 7/11, round: 287/501, loss: 0.5490226745605469\n",
      "test epoch: 7/11, round: 288/501, loss: 0.2918878197669983\n",
      "test epoch: 7/11, round: 289/501, loss: 0.37125200033187866\n",
      "test epoch: 7/11, round: 290/501, loss: 0.3699842393398285\n",
      "test epoch: 7/11, round: 291/501, loss: 0.5563524961471558\n",
      "test epoch: 7/11, round: 292/501, loss: 0.4659483730792999\n",
      "test epoch: 7/11, round: 293/501, loss: 0.5798717141151428\n",
      "test epoch: 7/11, round: 294/501, loss: 0.30215439200401306\n",
      "test epoch: 7/11, round: 295/501, loss: 0.3761653006076813\n",
      "test epoch: 7/11, round: 296/501, loss: 0.43615975975990295\n",
      "test epoch: 7/11, round: 297/501, loss: 0.3613235354423523\n",
      "test epoch: 7/11, round: 298/501, loss: 0.46989700198173523\n",
      "test epoch: 7/11, round: 299/501, loss: 0.4714301824569702\n",
      "test epoch: 7/11, round: 300/501, loss: 0.5105028748512268\n",
      "test epoch: 7/11, round: 301/501, loss: 0.3846760094165802\n",
      "test epoch: 7/11, round: 302/501, loss: 0.27313801646232605\n",
      "test epoch: 7/11, round: 303/501, loss: 0.6236483454704285\n",
      "test epoch: 7/11, round: 304/501, loss: 0.594147264957428\n",
      "test epoch: 7/11, round: 305/501, loss: 0.21930208802223206\n",
      "test epoch: 7/11, round: 306/501, loss: 0.33121222257614136\n",
      "test epoch: 7/11, round: 307/501, loss: 0.41656842827796936\n",
      "test epoch: 7/11, round: 308/501, loss: 0.3284365236759186\n",
      "test epoch: 7/11, round: 309/501, loss: 0.4843460023403168\n",
      "test epoch: 7/11, round: 310/501, loss: 0.41425731778144836\n",
      "test epoch: 7/11, round: 311/501, loss: 0.6043824553489685\n",
      "test epoch: 7/11, round: 312/501, loss: 0.4252721071243286\n",
      "test epoch: 7/11, round: 313/501, loss: 0.3478486239910126\n",
      "test epoch: 7/11, round: 314/501, loss: 0.40059369802474976\n",
      "test epoch: 7/11, round: 315/501, loss: 0.3400195240974426\n",
      "test epoch: 7/11, round: 316/501, loss: 0.36796149611473083\n",
      "test epoch: 7/11, round: 317/501, loss: 0.3813924789428711\n",
      "test epoch: 7/11, round: 318/501, loss: 0.39414775371551514\n",
      "test epoch: 7/11, round: 319/501, loss: 0.4999793469905853\n",
      "test epoch: 7/11, round: 320/501, loss: 0.4288002848625183\n",
      "test epoch: 7/11, round: 321/501, loss: 0.3628135323524475\n",
      "test epoch: 7/11, round: 322/501, loss: 0.4520556330680847\n",
      "test epoch: 7/11, round: 323/501, loss: 0.4124419391155243\n",
      "test epoch: 7/11, round: 324/501, loss: 0.284953773021698\n",
      "test epoch: 7/11, round: 325/501, loss: 0.4343705177307129\n",
      "test epoch: 7/11, round: 326/501, loss: 0.4757338762283325\n",
      "test epoch: 7/11, round: 327/501, loss: 0.5366203188896179\n",
      "test epoch: 7/11, round: 328/501, loss: 0.27798816561698914\n",
      "test epoch: 7/11, round: 329/501, loss: 0.4275270998477936\n",
      "test epoch: 7/11, round: 330/501, loss: 0.42477551102638245\n",
      "test epoch: 7/11, round: 331/501, loss: 0.4366426169872284\n",
      "test epoch: 7/11, round: 332/501, loss: 0.3836464285850525\n",
      "test epoch: 7/11, round: 333/501, loss: 0.4336839020252228\n",
      "test epoch: 7/11, round: 334/501, loss: 0.3504798114299774\n",
      "test epoch: 7/11, round: 335/501, loss: 0.42236337065696716\n",
      "test epoch: 7/11, round: 336/501, loss: 0.3420582115650177\n",
      "test epoch: 7/11, round: 337/501, loss: 0.5446745753288269\n",
      "test epoch: 7/11, round: 338/501, loss: 0.4081976115703583\n",
      "test epoch: 7/11, round: 339/501, loss: 0.7301090359687805\n",
      "test epoch: 7/11, round: 340/501, loss: 0.5387035012245178\n",
      "test epoch: 7/11, round: 341/501, loss: 0.4269033372402191\n",
      "test epoch: 7/11, round: 342/501, loss: 0.40211981534957886\n",
      "test epoch: 7/11, round: 343/501, loss: 0.33510148525238037\n",
      "test epoch: 7/11, round: 344/501, loss: 0.28445911407470703\n",
      "test epoch: 7/11, round: 345/501, loss: 0.2897525727748871\n",
      "test epoch: 7/11, round: 346/501, loss: 0.3359353840351105\n",
      "test epoch: 7/11, round: 347/501, loss: 0.3552587926387787\n",
      "test epoch: 7/11, round: 348/501, loss: 0.4323728680610657\n",
      "test epoch: 7/11, round: 349/501, loss: 0.3469837009906769\n",
      "test epoch: 7/11, round: 350/501, loss: 0.5026741623878479\n",
      "test epoch: 7/11, round: 351/501, loss: 0.4194352328777313\n",
      "test epoch: 7/11, round: 352/501, loss: 0.43318501114845276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 7/11, round: 353/501, loss: 0.37211504578590393\n",
      "test epoch: 7/11, round: 354/501, loss: 0.49652138352394104\n",
      "test epoch: 7/11, round: 355/501, loss: 0.3813613951206207\n",
      "test epoch: 7/11, round: 356/501, loss: 0.5720930099487305\n",
      "test epoch: 7/11, round: 357/501, loss: 0.4253052771091461\n",
      "test epoch: 7/11, round: 358/501, loss: 0.47207990288734436\n",
      "test epoch: 7/11, round: 359/501, loss: 0.37776410579681396\n",
      "test epoch: 7/11, round: 360/501, loss: 0.5694732666015625\n",
      "test epoch: 7/11, round: 361/501, loss: 0.5609639286994934\n",
      "test epoch: 7/11, round: 362/501, loss: 0.3645879030227661\n",
      "test epoch: 7/11, round: 363/501, loss: 0.5000988841056824\n",
      "test epoch: 7/11, round: 364/501, loss: 0.47993937134742737\n",
      "test epoch: 7/11, round: 365/501, loss: 0.37250056862831116\n",
      "test epoch: 7/11, round: 366/501, loss: 0.5247789025306702\n",
      "test epoch: 7/11, round: 367/501, loss: 0.5995675325393677\n",
      "test epoch: 7/11, round: 368/501, loss: 0.3632453382015228\n",
      "test epoch: 7/11, round: 369/501, loss: 0.38143590092658997\n",
      "test epoch: 7/11, round: 370/501, loss: 0.4018089473247528\n",
      "test epoch: 7/11, round: 371/501, loss: 0.39050552248954773\n",
      "test epoch: 7/11, round: 372/501, loss: 0.41333621740341187\n",
      "test epoch: 7/11, round: 373/501, loss: 0.4853663146495819\n",
      "test epoch: 7/11, round: 374/501, loss: 0.37541696429252625\n",
      "test epoch: 7/11, round: 375/501, loss: 0.4812195599079132\n",
      "test epoch: 7/11, round: 376/501, loss: 0.47019022703170776\n",
      "test epoch: 7/11, round: 377/501, loss: 0.20683814585208893\n",
      "test epoch: 7/11, round: 378/501, loss: 0.22812147438526154\n",
      "test epoch: 7/11, round: 379/501, loss: 0.4018474519252777\n",
      "test epoch: 7/11, round: 380/501, loss: 0.3425533175468445\n",
      "test epoch: 7/11, round: 381/501, loss: 0.5130124688148499\n",
      "test epoch: 7/11, round: 382/501, loss: 0.3092125654220581\n",
      "test epoch: 7/11, round: 383/501, loss: 0.38457247614860535\n",
      "test epoch: 7/11, round: 384/501, loss: 0.28690558671951294\n",
      "test epoch: 7/11, round: 385/501, loss: 0.4637225270271301\n",
      "test epoch: 7/11, round: 386/501, loss: 0.48837998509407043\n",
      "test epoch: 7/11, round: 387/501, loss: 0.2567388713359833\n",
      "test epoch: 7/11, round: 388/501, loss: 0.32168757915496826\n",
      "test epoch: 7/11, round: 389/501, loss: 0.36517250537872314\n",
      "test epoch: 7/11, round: 390/501, loss: 0.4617389440536499\n",
      "test epoch: 7/11, round: 391/501, loss: 0.35411104559898376\n",
      "test epoch: 7/11, round: 392/501, loss: 0.42667919397354126\n",
      "test epoch: 7/11, round: 393/501, loss: 0.3762853741645813\n",
      "test epoch: 7/11, round: 394/501, loss: 0.6050246953964233\n",
      "test epoch: 7/11, round: 395/501, loss: 0.30485832691192627\n",
      "test epoch: 7/11, round: 396/501, loss: 0.4080161452293396\n",
      "test epoch: 7/11, round: 397/501, loss: 0.46902960538864136\n",
      "test epoch: 7/11, round: 398/501, loss: 0.5009034276008606\n",
      "test epoch: 7/11, round: 399/501, loss: 0.363042950630188\n",
      "test epoch: 7/11, round: 400/501, loss: 0.3118267059326172\n",
      "test epoch: 7/11, round: 401/501, loss: 0.6470235586166382\n",
      "test epoch: 7/11, round: 402/501, loss: 0.4639681875705719\n",
      "test epoch: 7/11, round: 403/501, loss: 0.3267420828342438\n",
      "test epoch: 7/11, round: 404/501, loss: 0.2817191481590271\n",
      "test epoch: 7/11, round: 405/501, loss: 0.7376576066017151\n",
      "test epoch: 7/11, round: 406/501, loss: 0.4161472022533417\n",
      "test epoch: 7/11, round: 407/501, loss: 0.5451639890670776\n",
      "test epoch: 7/11, round: 408/501, loss: 0.47123095393180847\n",
      "test epoch: 7/11, round: 409/501, loss: 0.5528503656387329\n",
      "test epoch: 7/11, round: 410/501, loss: 0.40397122502326965\n",
      "test epoch: 7/11, round: 411/501, loss: 0.4316686689853668\n",
      "test epoch: 7/11, round: 412/501, loss: 0.4059353470802307\n",
      "test epoch: 7/11, round: 413/501, loss: 0.495968759059906\n",
      "test epoch: 7/11, round: 414/501, loss: 0.35527297854423523\n",
      "test epoch: 7/11, round: 415/501, loss: 0.40829455852508545\n",
      "test epoch: 7/11, round: 416/501, loss: 0.35817044973373413\n",
      "test epoch: 7/11, round: 417/501, loss: 0.3215184807777405\n",
      "test epoch: 7/11, round: 418/501, loss: 0.3888542354106903\n",
      "test epoch: 7/11, round: 419/501, loss: 0.39189136028289795\n",
      "test epoch: 7/11, round: 420/501, loss: 0.34354597330093384\n",
      "test epoch: 7/11, round: 421/501, loss: 0.4235811233520508\n",
      "test epoch: 7/11, round: 422/501, loss: 0.5107246041297913\n",
      "test epoch: 7/11, round: 423/501, loss: 0.6933218836784363\n",
      "test epoch: 7/11, round: 424/501, loss: 0.45731207728385925\n",
      "test epoch: 7/11, round: 425/501, loss: 0.29904958605766296\n",
      "test epoch: 7/11, round: 426/501, loss: 0.49970024824142456\n",
      "test epoch: 7/11, round: 427/501, loss: 0.3501591682434082\n",
      "test epoch: 7/11, round: 428/501, loss: 0.5515242218971252\n",
      "test epoch: 7/11, round: 429/501, loss: 0.6192988157272339\n",
      "test epoch: 7/11, round: 430/501, loss: 0.625719428062439\n",
      "test epoch: 7/11, round: 431/501, loss: 0.4118954539299011\n",
      "test epoch: 7/11, round: 432/501, loss: 0.35543951392173767\n",
      "test epoch: 7/11, round: 433/501, loss: 0.39929479360580444\n",
      "test epoch: 7/11, round: 434/501, loss: 0.2894667983055115\n",
      "test epoch: 7/11, round: 435/501, loss: 0.3337763547897339\n",
      "test epoch: 7/11, round: 436/501, loss: 0.3755110502243042\n",
      "test epoch: 7/11, round: 437/501, loss: 0.5310777425765991\n",
      "test epoch: 7/11, round: 438/501, loss: 0.5595073103904724\n",
      "test epoch: 7/11, round: 439/501, loss: 0.40945643186569214\n",
      "test epoch: 7/11, round: 440/501, loss: 0.5215460658073425\n",
      "test epoch: 7/11, round: 441/501, loss: 0.4694454073905945\n",
      "test epoch: 7/11, round: 442/501, loss: 0.39978358149528503\n",
      "test epoch: 7/11, round: 443/501, loss: 0.24825119972229004\n",
      "test epoch: 7/11, round: 444/501, loss: 0.4351710081100464\n",
      "test epoch: 7/11, round: 445/501, loss: 0.4469519555568695\n",
      "test epoch: 7/11, round: 446/501, loss: 0.5578014254570007\n",
      "test epoch: 7/11, round: 447/501, loss: 0.2542417347431183\n",
      "test epoch: 7/11, round: 448/501, loss: 0.3437536656856537\n",
      "test epoch: 7/11, round: 449/501, loss: 0.2694303095340729\n",
      "test epoch: 7/11, round: 450/501, loss: 0.6035148501396179\n",
      "test epoch: 7/11, round: 451/501, loss: 0.39430680871009827\n",
      "test epoch: 7/11, round: 452/501, loss: 0.40782731771469116\n",
      "test epoch: 7/11, round: 453/501, loss: 0.15963970124721527\n",
      "test epoch: 7/11, round: 454/501, loss: 0.29506248235702515\n",
      "test epoch: 7/11, round: 455/501, loss: 0.49729812145233154\n",
      "test epoch: 7/11, round: 456/501, loss: 0.39393261075019836\n",
      "test epoch: 7/11, round: 457/501, loss: 0.22187630832195282\n",
      "test epoch: 7/11, round: 458/501, loss: 0.32219573855400085\n",
      "test epoch: 7/11, round: 459/501, loss: 0.21322910487651825\n",
      "test epoch: 7/11, round: 460/501, loss: 0.15439584851264954\n",
      "test epoch: 7/11, round: 461/501, loss: 0.19429072737693787\n",
      "test epoch: 7/11, round: 462/501, loss: 0.154876708984375\n",
      "test epoch: 7/11, round: 463/501, loss: 0.23640820384025574\n",
      "test epoch: 7/11, round: 464/501, loss: 0.1700974553823471\n",
      "test epoch: 7/11, round: 465/501, loss: 0.1991797387599945\n",
      "test epoch: 7/11, round: 466/501, loss: 0.17923018336296082\n",
      "test epoch: 7/11, round: 467/501, loss: 0.2039843499660492\n",
      "test epoch: 7/11, round: 468/501, loss: 0.22574353218078613\n",
      "test epoch: 7/11, round: 469/501, loss: 0.21192435920238495\n",
      "test epoch: 7/11, round: 470/501, loss: 0.18108534812927246\n",
      "test epoch: 7/11, round: 471/501, loss: 0.26994478702545166\n",
      "test epoch: 7/11, round: 472/501, loss: 0.21506553888320923\n",
      "test epoch: 7/11, round: 473/501, loss: 0.16570018231868744\n",
      "test epoch: 7/11, round: 474/501, loss: 0.2289527803659439\n",
      "test epoch: 7/11, round: 475/501, loss: 0.2050987184047699\n",
      "test epoch: 7/11, round: 476/501, loss: 0.1674104630947113\n",
      "test epoch: 7/11, round: 477/501, loss: 0.15310706198215485\n",
      "test epoch: 7/11, round: 478/501, loss: 0.19708678126335144\n",
      "test epoch: 7/11, round: 479/501, loss: 0.14127306640148163\n",
      "test epoch: 7/11, round: 480/501, loss: 0.16725215315818787\n",
      "test epoch: 7/11, round: 481/501, loss: 0.15759862959384918\n",
      "test epoch: 7/11, round: 482/501, loss: 0.16438421607017517\n",
      "test epoch: 7/11, round: 483/501, loss: 0.18798331916332245\n",
      "test epoch: 7/11, round: 484/501, loss: 0.19336289167404175\n",
      "test epoch: 7/11, round: 485/501, loss: 0.1428850144147873\n",
      "test epoch: 7/11, round: 486/501, loss: 0.18527789413928986\n",
      "test epoch: 7/11, round: 487/501, loss: 0.15635471045970917\n",
      "test epoch: 7/11, round: 488/501, loss: 0.19325484335422516\n",
      "test epoch: 7/11, round: 489/501, loss: 0.16626033186912537\n",
      "test epoch: 7/11, round: 490/501, loss: 0.17601557075977325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 7/11, round: 491/501, loss: 0.20043154060840607\n",
      "test epoch: 7/11, round: 492/501, loss: 0.19830232858657837\n",
      "test epoch: 7/11, round: 493/501, loss: 0.20543867349624634\n",
      "test epoch: 7/11, round: 494/501, loss: 0.2053719162940979\n",
      "test epoch: 7/11, round: 495/501, loss: 0.1591186672449112\n",
      "test epoch: 7/11, round: 496/501, loss: 0.18869787454605103\n",
      "test epoch: 7/11, round: 497/501, loss: 0.1567915380001068\n",
      "test epoch: 7/11, round: 498/501, loss: 0.13672605156898499\n",
      "test epoch: 7/11, round: 499/501, loss: 0.16028766334056854\n",
      "test epoch: 7/11, round: 500/501, loss: 0.3580223023891449\n",
      "test epoch: 7/11, round: 501/501, loss: 0.8770774006843567\n",
      "test epoch: 7/11, KS: 0.19462289720672893, ROC: 0.6291648560057941\n",
      "cost time: 1992\n",
      "train epoch: 8/11, round: 1/532, loss: 0.2839577794075012\n",
      "train epoch: 8/11, round: 2/532, loss: 0.3797203600406647\n",
      "train epoch: 8/11, round: 3/532, loss: 0.401658833026886\n",
      "train epoch: 8/11, round: 4/532, loss: 0.40096515417099\n",
      "train epoch: 8/11, round: 5/532, loss: 0.3758769631385803\n",
      "train epoch: 8/11, round: 6/532, loss: 0.41471511125564575\n",
      "train epoch: 8/11, round: 7/532, loss: 0.4023129343986511\n",
      "train epoch: 8/11, round: 8/532, loss: 0.322061151266098\n",
      "train epoch: 8/11, round: 9/532, loss: 0.45322757959365845\n",
      "train epoch: 8/11, round: 10/532, loss: 0.34438616037368774\n",
      "train epoch: 8/11, round: 11/532, loss: 0.34185928106307983\n",
      "train epoch: 8/11, round: 12/532, loss: 0.345995157957077\n",
      "train epoch: 8/11, round: 13/532, loss: 0.33239269256591797\n",
      "train epoch: 8/11, round: 14/532, loss: 0.3940863013267517\n",
      "train epoch: 8/11, round: 15/532, loss: 0.33176884055137634\n",
      "train epoch: 8/11, round: 16/532, loss: 0.38947418332099915\n",
      "train epoch: 8/11, round: 17/532, loss: 0.3812088072299957\n",
      "train epoch: 8/11, round: 18/532, loss: 0.2775029242038727\n",
      "train epoch: 8/11, round: 19/532, loss: 0.46444329619407654\n",
      "train epoch: 8/11, round: 20/532, loss: 0.29319530725479126\n",
      "train epoch: 8/11, round: 21/532, loss: 0.36742720007896423\n",
      "train epoch: 8/11, round: 22/532, loss: 0.48245054483413696\n",
      "train epoch: 8/11, round: 23/532, loss: 0.39006584882736206\n",
      "train epoch: 8/11, round: 24/532, loss: 0.43419069051742554\n",
      "train epoch: 8/11, round: 25/532, loss: 0.30922332406044006\n",
      "train epoch: 8/11, round: 26/532, loss: 0.3491031527519226\n",
      "train epoch: 8/11, round: 27/532, loss: 0.272752970457077\n",
      "train epoch: 8/11, round: 28/532, loss: 0.36894461512565613\n",
      "train epoch: 8/11, round: 29/532, loss: 0.3754076361656189\n",
      "train epoch: 8/11, round: 30/532, loss: 0.45860394835472107\n",
      "train epoch: 8/11, round: 31/532, loss: 0.38011953234672546\n",
      "train epoch: 8/11, round: 32/532, loss: 0.31318768858909607\n",
      "train epoch: 8/11, round: 33/532, loss: 0.44816407561302185\n",
      "train epoch: 8/11, round: 34/532, loss: 0.42341431975364685\n",
      "train epoch: 8/11, round: 35/532, loss: 0.3989430069923401\n",
      "train epoch: 8/11, round: 36/532, loss: 0.37740248441696167\n",
      "train epoch: 8/11, round: 37/532, loss: 0.43771108984947205\n",
      "train epoch: 8/11, round: 38/532, loss: 0.36618977785110474\n",
      "train epoch: 8/11, round: 39/532, loss: 0.36823001503944397\n",
      "train epoch: 8/11, round: 40/532, loss: 0.3487737774848938\n",
      "train epoch: 8/11, round: 41/532, loss: 0.40149298310279846\n",
      "train epoch: 8/11, round: 42/532, loss: 0.305044949054718\n",
      "train epoch: 8/11, round: 43/532, loss: 0.43650683760643005\n",
      "train epoch: 8/11, round: 44/532, loss: 0.4244905114173889\n",
      "train epoch: 8/11, round: 45/532, loss: 0.4090505540370941\n",
      "train epoch: 8/11, round: 46/532, loss: 0.3307298719882965\n",
      "train epoch: 8/11, round: 47/532, loss: 0.40402260422706604\n",
      "train epoch: 8/11, round: 48/532, loss: 0.3319946229457855\n",
      "train epoch: 8/11, round: 49/532, loss: 0.38835009932518005\n",
      "train epoch: 8/11, round: 50/532, loss: 0.36148467659950256\n",
      "train epoch: 8/11, round: 51/532, loss: 0.28101688623428345\n",
      "train epoch: 8/11, round: 52/532, loss: 0.31124234199523926\n",
      "train epoch: 8/11, round: 53/532, loss: 0.40945520997047424\n",
      "train epoch: 8/11, round: 54/532, loss: 0.38738635182380676\n",
      "train epoch: 8/11, round: 55/532, loss: 0.4731351435184479\n",
      "train epoch: 8/11, round: 56/532, loss: 0.40303292870521545\n",
      "train epoch: 8/11, round: 57/532, loss: 0.2685524523258209\n",
      "train epoch: 8/11, round: 58/532, loss: 0.3416363596916199\n",
      "train epoch: 8/11, round: 59/532, loss: 0.3168342411518097\n",
      "train epoch: 8/11, round: 60/532, loss: 0.37439295649528503\n",
      "train epoch: 8/11, round: 61/532, loss: 0.38341769576072693\n",
      "train epoch: 8/11, round: 62/532, loss: 0.4399479925632477\n",
      "train epoch: 8/11, round: 63/532, loss: 0.3637475073337555\n",
      "train epoch: 8/11, round: 64/532, loss: 0.33900612592697144\n",
      "train epoch: 8/11, round: 65/532, loss: 0.33284658193588257\n",
      "train epoch: 8/11, round: 66/532, loss: 0.3796347677707672\n",
      "train epoch: 8/11, round: 67/532, loss: 0.447176456451416\n",
      "train epoch: 8/11, round: 68/532, loss: 0.3554210364818573\n",
      "train epoch: 8/11, round: 69/532, loss: 0.42638832330703735\n",
      "train epoch: 8/11, round: 70/532, loss: 0.3913763463497162\n",
      "train epoch: 8/11, round: 71/532, loss: 0.30449843406677246\n",
      "train epoch: 8/11, round: 72/532, loss: 0.4646882116794586\n",
      "train epoch: 8/11, round: 73/532, loss: 0.3386083245277405\n",
      "train epoch: 8/11, round: 74/532, loss: 0.30556952953338623\n",
      "train epoch: 8/11, round: 75/532, loss: 0.30374422669410706\n",
      "train epoch: 8/11, round: 76/532, loss: 0.2981095612049103\n",
      "train epoch: 8/11, round: 77/532, loss: 0.44062548875808716\n",
      "train epoch: 8/11, round: 78/532, loss: 0.22482934594154358\n",
      "train epoch: 8/11, round: 79/532, loss: 0.4136533737182617\n",
      "train epoch: 8/11, round: 80/532, loss: 0.4206799566745758\n",
      "train epoch: 8/11, round: 81/532, loss: 0.3158804774284363\n",
      "train epoch: 8/11, round: 82/532, loss: 0.43212762475013733\n",
      "train epoch: 8/11, round: 83/532, loss: 0.5073075294494629\n",
      "train epoch: 8/11, round: 84/532, loss: 0.46022287011146545\n",
      "train epoch: 8/11, round: 85/532, loss: 0.40728193521499634\n",
      "train epoch: 8/11, round: 86/532, loss: 0.4081351161003113\n",
      "train epoch: 8/11, round: 87/532, loss: 0.48465394973754883\n",
      "train epoch: 8/11, round: 88/532, loss: 0.37532490491867065\n",
      "train epoch: 8/11, round: 89/532, loss: 0.38039854168891907\n",
      "train epoch: 8/11, round: 90/532, loss: 0.37129512429237366\n",
      "train epoch: 8/11, round: 91/532, loss: 0.41975855827331543\n",
      "train epoch: 8/11, round: 92/532, loss: 0.3342859148979187\n",
      "train epoch: 8/11, round: 93/532, loss: 0.35420048236846924\n",
      "train epoch: 8/11, round: 94/532, loss: 0.3986038565635681\n",
      "train epoch: 8/11, round: 95/532, loss: 0.35179099440574646\n",
      "train epoch: 8/11, round: 96/532, loss: 0.4062669277191162\n",
      "train epoch: 8/11, round: 97/532, loss: 0.3210097849369049\n",
      "train epoch: 8/11, round: 98/532, loss: 0.42450112104415894\n",
      "train epoch: 8/11, round: 99/532, loss: 0.33567920327186584\n",
      "train epoch: 8/11, round: 100/532, loss: 0.38675588369369507\n",
      "train epoch: 8/11, round: 101/532, loss: 0.3766508102416992\n",
      "train epoch: 8/11, round: 102/532, loss: 0.35350126028060913\n",
      "train epoch: 8/11, round: 103/532, loss: 0.38482844829559326\n",
      "train epoch: 8/11, round: 104/532, loss: 0.4969204366207123\n",
      "train epoch: 8/11, round: 105/532, loss: 0.32044726610183716\n",
      "train epoch: 8/11, round: 106/532, loss: 0.43565043807029724\n",
      "train epoch: 8/11, round: 107/532, loss: 0.3744744658470154\n",
      "train epoch: 8/11, round: 108/532, loss: 0.3708367943763733\n",
      "train epoch: 8/11, round: 109/532, loss: 0.32929354906082153\n",
      "train epoch: 8/11, round: 110/532, loss: 0.3494904637336731\n",
      "train epoch: 8/11, round: 111/532, loss: 0.3676828145980835\n",
      "train epoch: 8/11, round: 112/532, loss: 0.3427279591560364\n",
      "train epoch: 8/11, round: 113/532, loss: 0.3854464292526245\n",
      "train epoch: 8/11, round: 114/532, loss: 0.31184419989585876\n",
      "train epoch: 8/11, round: 115/532, loss: 0.37108105421066284\n",
      "train epoch: 8/11, round: 116/532, loss: 0.4187372326850891\n",
      "train epoch: 8/11, round: 117/532, loss: 0.4214925765991211\n",
      "train epoch: 8/11, round: 118/532, loss: 0.4647698402404785\n",
      "train epoch: 8/11, round: 119/532, loss: 0.3960645794868469\n",
      "train epoch: 8/11, round: 120/532, loss: 0.35877692699432373\n",
      "train epoch: 8/11, round: 121/532, loss: 0.40985164046287537\n",
      "train epoch: 8/11, round: 122/532, loss: 0.46339836716651917\n",
      "train epoch: 8/11, round: 123/532, loss: 0.44162338972091675\n",
      "train epoch: 8/11, round: 124/532, loss: 0.41553226113319397\n",
      "train epoch: 8/11, round: 125/532, loss: 0.4050234258174896\n",
      "train epoch: 8/11, round: 126/532, loss: 0.3746364116668701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8/11, round: 127/532, loss: 0.3802416920661926\n",
      "train epoch: 8/11, round: 128/532, loss: 0.3088524341583252\n",
      "train epoch: 8/11, round: 129/532, loss: 0.46835142374038696\n",
      "train epoch: 8/11, round: 130/532, loss: 0.4734179973602295\n",
      "train epoch: 8/11, round: 131/532, loss: 0.3561224341392517\n",
      "train epoch: 8/11, round: 132/532, loss: 0.38798224925994873\n",
      "train epoch: 8/11, round: 133/532, loss: 0.4111129343509674\n",
      "train epoch: 8/11, round: 134/532, loss: 0.422323077917099\n",
      "train epoch: 8/11, round: 135/532, loss: 0.4034874439239502\n",
      "train epoch: 8/11, round: 136/532, loss: 0.4526642858982086\n",
      "train epoch: 8/11, round: 137/532, loss: 0.4324548840522766\n",
      "train epoch: 8/11, round: 138/532, loss: 0.4075465798377991\n",
      "train epoch: 8/11, round: 139/532, loss: 0.31885308027267456\n",
      "train epoch: 8/11, round: 140/532, loss: 0.39371588826179504\n",
      "train epoch: 8/11, round: 141/532, loss: 0.353868305683136\n",
      "train epoch: 8/11, round: 142/532, loss: 0.4181777834892273\n",
      "train epoch: 8/11, round: 143/532, loss: 0.3977985978126526\n",
      "train epoch: 8/11, round: 144/532, loss: 0.3677442669868469\n",
      "train epoch: 8/11, round: 145/532, loss: 0.33055177330970764\n",
      "train epoch: 8/11, round: 146/532, loss: 0.4134833812713623\n",
      "train epoch: 8/11, round: 147/532, loss: 0.325529009103775\n",
      "train epoch: 8/11, round: 148/532, loss: 0.3558596968650818\n",
      "train epoch: 8/11, round: 149/532, loss: 0.3665721118450165\n",
      "train epoch: 8/11, round: 150/532, loss: 0.4819709360599518\n",
      "train epoch: 8/11, round: 151/532, loss: 0.48271411657333374\n",
      "train epoch: 8/11, round: 152/532, loss: 0.4062173366546631\n",
      "train epoch: 8/11, round: 153/532, loss: 0.29472053050994873\n",
      "train epoch: 8/11, round: 154/532, loss: 0.3233247697353363\n",
      "train epoch: 8/11, round: 155/532, loss: 0.3421230912208557\n",
      "train epoch: 8/11, round: 156/532, loss: 0.41192904114723206\n",
      "train epoch: 8/11, round: 157/532, loss: 0.30396369099617004\n",
      "train epoch: 8/11, round: 158/532, loss: 0.35464614629745483\n",
      "train epoch: 8/11, round: 159/532, loss: 0.33121341466903687\n",
      "train epoch: 8/11, round: 160/532, loss: 0.36049726605415344\n",
      "train epoch: 8/11, round: 161/532, loss: 0.36696362495422363\n",
      "train epoch: 8/11, round: 162/532, loss: 0.3990328907966614\n",
      "train epoch: 8/11, round: 163/532, loss: 0.3439413607120514\n",
      "train epoch: 8/11, round: 164/532, loss: 0.32801228761672974\n",
      "train epoch: 8/11, round: 165/532, loss: 0.32431188225746155\n",
      "train epoch: 8/11, round: 166/532, loss: 0.2998473644256592\n",
      "train epoch: 8/11, round: 167/532, loss: 0.3370853066444397\n",
      "train epoch: 8/11, round: 168/532, loss: 0.2980071008205414\n",
      "train epoch: 8/11, round: 169/532, loss: 0.37471717596054077\n",
      "train epoch: 8/11, round: 170/532, loss: 0.4377623200416565\n",
      "train epoch: 8/11, round: 171/532, loss: 0.2663084864616394\n",
      "train epoch: 8/11, round: 172/532, loss: 0.33114540576934814\n",
      "train epoch: 8/11, round: 173/532, loss: 0.4306022524833679\n",
      "train epoch: 8/11, round: 174/532, loss: 0.35183247923851013\n",
      "train epoch: 8/11, round: 175/532, loss: 0.35430869460105896\n",
      "train epoch: 8/11, round: 176/532, loss: 0.34374815225601196\n",
      "train epoch: 8/11, round: 177/532, loss: 0.4485495984554291\n",
      "train epoch: 8/11, round: 178/532, loss: 0.42402610182762146\n",
      "train epoch: 8/11, round: 179/532, loss: 0.42950907349586487\n",
      "train epoch: 8/11, round: 180/532, loss: 0.34719449281692505\n",
      "train epoch: 8/11, round: 181/532, loss: 0.4176512658596039\n",
      "train epoch: 8/11, round: 182/532, loss: 0.35607200860977173\n",
      "train epoch: 8/11, round: 183/532, loss: 0.4206579625606537\n",
      "train epoch: 8/11, round: 184/532, loss: 0.3269888460636139\n",
      "train epoch: 8/11, round: 185/532, loss: 0.3896539807319641\n",
      "train epoch: 8/11, round: 186/532, loss: 0.43809619545936584\n",
      "train epoch: 8/11, round: 187/532, loss: 0.34389129281044006\n",
      "train epoch: 8/11, round: 188/532, loss: 0.37415996193885803\n",
      "train epoch: 8/11, round: 189/532, loss: 0.361753910779953\n",
      "train epoch: 8/11, round: 190/532, loss: 0.386904239654541\n",
      "train epoch: 8/11, round: 191/532, loss: 0.3567543923854828\n",
      "train epoch: 8/11, round: 192/532, loss: 0.38984909653663635\n",
      "train epoch: 8/11, round: 193/532, loss: 0.4397459626197815\n",
      "train epoch: 8/11, round: 194/532, loss: 0.329988032579422\n",
      "train epoch: 8/11, round: 195/532, loss: 0.4060301184654236\n",
      "train epoch: 8/11, round: 196/532, loss: 0.44650012254714966\n",
      "train epoch: 8/11, round: 197/532, loss: 0.3616847097873688\n",
      "train epoch: 8/11, round: 198/532, loss: 0.33062320947647095\n",
      "train epoch: 8/11, round: 199/532, loss: 0.4808581471443176\n",
      "train epoch: 8/11, round: 200/532, loss: 0.3785455822944641\n",
      "train epoch: 8/11, round: 201/532, loss: 0.42216992378234863\n",
      "train epoch: 8/11, round: 202/532, loss: 0.3905699849128723\n",
      "train epoch: 8/11, round: 203/532, loss: 0.4709518551826477\n",
      "train epoch: 8/11, round: 204/532, loss: 0.3458094000816345\n",
      "train epoch: 8/11, round: 205/532, loss: 0.33617904782295227\n",
      "train epoch: 8/11, round: 206/532, loss: 0.3936721682548523\n",
      "train epoch: 8/11, round: 207/532, loss: 0.4488399624824524\n",
      "train epoch: 8/11, round: 208/532, loss: 0.3264893889427185\n",
      "train epoch: 8/11, round: 209/532, loss: 0.40421062707901\n",
      "train epoch: 8/11, round: 210/532, loss: 0.33478641510009766\n",
      "train epoch: 8/11, round: 211/532, loss: 0.37617939710617065\n",
      "train epoch: 8/11, round: 212/532, loss: 0.36672502756118774\n",
      "train epoch: 8/11, round: 213/532, loss: 0.307220458984375\n",
      "train epoch: 8/11, round: 214/532, loss: 0.37416189908981323\n",
      "train epoch: 8/11, round: 215/532, loss: 0.37511223554611206\n",
      "train epoch: 8/11, round: 216/532, loss: 0.30315837264060974\n",
      "train epoch: 8/11, round: 217/532, loss: 0.31995150446891785\n",
      "train epoch: 8/11, round: 218/532, loss: 0.3632054626941681\n",
      "train epoch: 8/11, round: 219/532, loss: 0.39570051431655884\n",
      "train epoch: 8/11, round: 220/532, loss: 0.4142920970916748\n",
      "train epoch: 8/11, round: 221/532, loss: 0.3222777843475342\n",
      "train epoch: 8/11, round: 222/532, loss: 0.3745553493499756\n",
      "train epoch: 8/11, round: 223/532, loss: 0.3989514708518982\n",
      "train epoch: 8/11, round: 224/532, loss: 0.3698609471321106\n",
      "train epoch: 8/11, round: 225/532, loss: 0.32245540618896484\n",
      "train epoch: 8/11, round: 226/532, loss: 0.36204496026039124\n",
      "train epoch: 8/11, round: 227/532, loss: 0.4696720242500305\n",
      "train epoch: 8/11, round: 228/532, loss: 0.4773077070713043\n",
      "train epoch: 8/11, round: 229/532, loss: 0.4243604242801666\n",
      "train epoch: 8/11, round: 230/532, loss: 0.42066043615341187\n",
      "train epoch: 8/11, round: 231/532, loss: 0.38811153173446655\n",
      "train epoch: 8/11, round: 232/532, loss: 0.333599328994751\n",
      "train epoch: 8/11, round: 233/532, loss: 0.340623140335083\n",
      "train epoch: 8/11, round: 234/532, loss: 0.4893576502799988\n",
      "train epoch: 8/11, round: 235/532, loss: 0.45851221680641174\n",
      "train epoch: 8/11, round: 236/532, loss: 0.41207313537597656\n",
      "train epoch: 8/11, round: 237/532, loss: 0.3604767918586731\n",
      "train epoch: 8/11, round: 238/532, loss: 0.32300886511802673\n",
      "train epoch: 8/11, round: 239/532, loss: 0.4448257386684418\n",
      "train epoch: 8/11, round: 240/532, loss: 0.4230774939060211\n",
      "train epoch: 8/11, round: 241/532, loss: 0.4029853343963623\n",
      "train epoch: 8/11, round: 242/532, loss: 0.3824060559272766\n",
      "train epoch: 8/11, round: 243/532, loss: 0.41626811027526855\n",
      "train epoch: 8/11, round: 244/532, loss: 0.4171817898750305\n",
      "train epoch: 8/11, round: 245/532, loss: 0.38856497406959534\n",
      "train epoch: 8/11, round: 246/532, loss: 0.31167730689048767\n",
      "train epoch: 8/11, round: 247/532, loss: 0.3289220333099365\n",
      "train epoch: 8/11, round: 248/532, loss: 0.43393707275390625\n",
      "train epoch: 8/11, round: 249/532, loss: 0.43785709142684937\n",
      "train epoch: 8/11, round: 250/532, loss: 0.48998332023620605\n",
      "train epoch: 8/11, round: 251/532, loss: 0.31077665090560913\n",
      "train epoch: 8/11, round: 252/532, loss: 0.43181973695755005\n",
      "train epoch: 8/11, round: 253/532, loss: 0.345052033662796\n",
      "train epoch: 8/11, round: 254/532, loss: 0.3339255452156067\n",
      "train epoch: 8/11, round: 255/532, loss: 0.39986950159072876\n",
      "train epoch: 8/11, round: 256/532, loss: 0.3708829879760742\n",
      "train epoch: 8/11, round: 257/532, loss: 0.3149668574333191\n",
      "train epoch: 8/11, round: 258/532, loss: 0.462047815322876\n",
      "train epoch: 8/11, round: 259/532, loss: 0.34281107783317566\n",
      "train epoch: 8/11, round: 260/532, loss: 0.34775617718696594\n",
      "train epoch: 8/11, round: 261/532, loss: 0.33213332295417786\n",
      "train epoch: 8/11, round: 262/532, loss: 0.4804369807243347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8/11, round: 263/532, loss: 0.38274019956588745\n",
      "train epoch: 8/11, round: 264/532, loss: 0.30775439739227295\n",
      "train epoch: 8/11, round: 265/532, loss: 0.380652517080307\n",
      "train epoch: 8/11, round: 266/532, loss: 0.41959089040756226\n",
      "train epoch: 8/11, round: 267/532, loss: 0.42091965675354004\n",
      "train epoch: 8/11, round: 268/532, loss: 0.34798431396484375\n",
      "train epoch: 8/11, round: 269/532, loss: 0.4150572717189789\n",
      "train epoch: 8/11, round: 270/532, loss: 0.36137741804122925\n",
      "train epoch: 8/11, round: 271/532, loss: 0.36685457825660706\n",
      "train epoch: 8/11, round: 272/532, loss: 0.4014509320259094\n",
      "train epoch: 8/11, round: 273/532, loss: 0.4259132444858551\n",
      "train epoch: 8/11, round: 274/532, loss: 0.4018855094909668\n",
      "train epoch: 8/11, round: 275/532, loss: 0.2999933660030365\n",
      "train epoch: 8/11, round: 276/532, loss: 0.31372562050819397\n",
      "train epoch: 8/11, round: 277/532, loss: 0.2947482168674469\n",
      "train epoch: 8/11, round: 278/532, loss: 0.31710976362228394\n",
      "train epoch: 8/11, round: 279/532, loss: 0.38122424483299255\n",
      "train epoch: 8/11, round: 280/532, loss: 0.3627249300479889\n",
      "train epoch: 8/11, round: 281/532, loss: 0.4386771619319916\n",
      "train epoch: 8/11, round: 282/532, loss: 0.4077727198600769\n",
      "train epoch: 8/11, round: 283/532, loss: 0.4483523368835449\n",
      "train epoch: 8/11, round: 284/532, loss: 0.36345720291137695\n",
      "train epoch: 8/11, round: 285/532, loss: 0.4331894516944885\n",
      "train epoch: 8/11, round: 286/532, loss: 0.3351782560348511\n",
      "train epoch: 8/11, round: 287/532, loss: 0.39188826084136963\n",
      "train epoch: 8/11, round: 288/532, loss: 0.41282719373703003\n",
      "train epoch: 8/11, round: 289/532, loss: 0.4294146001338959\n",
      "train epoch: 8/11, round: 290/532, loss: 0.45741552114486694\n",
      "train epoch: 8/11, round: 291/532, loss: 0.3880375325679779\n",
      "train epoch: 8/11, round: 292/532, loss: 0.37284985184669495\n",
      "train epoch: 8/11, round: 293/532, loss: 0.39370042085647583\n",
      "train epoch: 8/11, round: 294/532, loss: 0.4017595648765564\n",
      "train epoch: 8/11, round: 295/532, loss: 0.39839988946914673\n",
      "train epoch: 8/11, round: 296/532, loss: 0.40211647748947144\n",
      "train epoch: 8/11, round: 297/532, loss: 0.3846820890903473\n",
      "train epoch: 8/11, round: 298/532, loss: 0.34675130248069763\n",
      "train epoch: 8/11, round: 299/532, loss: 0.29679980874061584\n",
      "train epoch: 8/11, round: 300/532, loss: 0.43965816497802734\n",
      "train epoch: 8/11, round: 301/532, loss: 0.32087546586990356\n",
      "train epoch: 8/11, round: 302/532, loss: 0.40851736068725586\n",
      "train epoch: 8/11, round: 303/532, loss: 0.3439444601535797\n",
      "train epoch: 8/11, round: 304/532, loss: 0.38546547293663025\n",
      "train epoch: 8/11, round: 305/532, loss: 0.35277771949768066\n",
      "train epoch: 8/11, round: 306/532, loss: 0.283363938331604\n",
      "train epoch: 8/11, round: 307/532, loss: 0.3580303192138672\n",
      "train epoch: 8/11, round: 308/532, loss: 0.3818511962890625\n",
      "train epoch: 8/11, round: 309/532, loss: 0.4147593080997467\n",
      "train epoch: 8/11, round: 310/532, loss: 0.43843287229537964\n",
      "train epoch: 8/11, round: 311/532, loss: 0.3076069951057434\n",
      "train epoch: 8/11, round: 312/532, loss: 0.3150295615196228\n",
      "train epoch: 8/11, round: 313/532, loss: 0.39169809222221375\n",
      "train epoch: 8/11, round: 314/532, loss: 0.3622656762599945\n",
      "train epoch: 8/11, round: 315/532, loss: 0.3573686480522156\n",
      "train epoch: 8/11, round: 316/532, loss: 0.4782562255859375\n",
      "train epoch: 8/11, round: 317/532, loss: 0.5227510333061218\n",
      "train epoch: 8/11, round: 318/532, loss: 0.3905867040157318\n",
      "train epoch: 8/11, round: 319/532, loss: 0.3895425498485565\n",
      "train epoch: 8/11, round: 320/532, loss: 0.44297170639038086\n",
      "train epoch: 8/11, round: 321/532, loss: 0.4073799252510071\n",
      "train epoch: 8/11, round: 322/532, loss: 0.42838478088378906\n",
      "train epoch: 8/11, round: 323/532, loss: 0.37338680028915405\n",
      "train epoch: 8/11, round: 324/532, loss: 0.43324750661849976\n",
      "train epoch: 8/11, round: 325/532, loss: 0.42147892713546753\n",
      "train epoch: 8/11, round: 326/532, loss: 0.4545205235481262\n",
      "train epoch: 8/11, round: 327/532, loss: 0.37397077679634094\n",
      "train epoch: 8/11, round: 328/532, loss: 0.38462913036346436\n",
      "train epoch: 8/11, round: 329/532, loss: 0.4015837609767914\n",
      "train epoch: 8/11, round: 330/532, loss: 0.38818269968032837\n",
      "train epoch: 8/11, round: 331/532, loss: 0.39888229966163635\n",
      "train epoch: 8/11, round: 332/532, loss: 0.3749162256717682\n",
      "train epoch: 8/11, round: 333/532, loss: 0.39644622802734375\n",
      "train epoch: 8/11, round: 334/532, loss: 0.33599889278411865\n",
      "train epoch: 8/11, round: 335/532, loss: 0.32074522972106934\n",
      "train epoch: 8/11, round: 336/532, loss: 0.3927851915359497\n",
      "train epoch: 8/11, round: 337/532, loss: 0.39472585916519165\n",
      "train epoch: 8/11, round: 338/532, loss: 0.36192527413368225\n",
      "train epoch: 8/11, round: 339/532, loss: 0.3551133871078491\n",
      "train epoch: 8/11, round: 340/532, loss: 0.37348443269729614\n",
      "train epoch: 8/11, round: 341/532, loss: 0.3447924256324768\n",
      "train epoch: 8/11, round: 342/532, loss: 0.42426759004592896\n",
      "train epoch: 8/11, round: 343/532, loss: 0.38964134454727173\n",
      "train epoch: 8/11, round: 344/532, loss: 0.41192588210105896\n",
      "train epoch: 8/11, round: 345/532, loss: 0.44112786650657654\n",
      "train epoch: 8/11, round: 346/532, loss: 0.45654335618019104\n",
      "train epoch: 8/11, round: 347/532, loss: 0.44041651487350464\n",
      "train epoch: 8/11, round: 348/532, loss: 0.4666227400302887\n",
      "train epoch: 8/11, round: 349/532, loss: 0.2890470623970032\n",
      "train epoch: 8/11, round: 350/532, loss: 0.37787336111068726\n",
      "train epoch: 8/11, round: 351/532, loss: 0.3327562212944031\n",
      "train epoch: 8/11, round: 352/532, loss: 0.37470805644989014\n",
      "train epoch: 8/11, round: 353/532, loss: 0.36886900663375854\n",
      "train epoch: 8/11, round: 354/532, loss: 0.4661131799221039\n",
      "train epoch: 8/11, round: 355/532, loss: 0.39735621213912964\n",
      "train epoch: 8/11, round: 356/532, loss: 0.36903753876686096\n",
      "train epoch: 8/11, round: 357/532, loss: 0.4017106890678406\n",
      "train epoch: 8/11, round: 358/532, loss: 0.3584423363208771\n",
      "train epoch: 8/11, round: 359/532, loss: 0.36823564767837524\n",
      "train epoch: 8/11, round: 360/532, loss: 0.3716511130332947\n",
      "train epoch: 8/11, round: 361/532, loss: 0.3260882496833801\n",
      "train epoch: 8/11, round: 362/532, loss: 0.37085601687431335\n",
      "train epoch: 8/11, round: 363/532, loss: 0.33667102456092834\n",
      "train epoch: 8/11, round: 364/532, loss: 0.4255024790763855\n",
      "train epoch: 8/11, round: 365/532, loss: 0.28865352272987366\n",
      "train epoch: 8/11, round: 366/532, loss: 0.48433294892311096\n",
      "train epoch: 8/11, round: 367/532, loss: 0.3356706202030182\n",
      "train epoch: 8/11, round: 368/532, loss: 0.3902032971382141\n",
      "train epoch: 8/11, round: 369/532, loss: 0.37124305963516235\n",
      "train epoch: 8/11, round: 370/532, loss: 0.3963322043418884\n",
      "train epoch: 8/11, round: 371/532, loss: 0.40620869398117065\n",
      "train epoch: 8/11, round: 372/532, loss: 0.40395626425743103\n",
      "train epoch: 8/11, round: 373/532, loss: 0.3419268727302551\n",
      "train epoch: 8/11, round: 374/532, loss: 0.4567548334598541\n",
      "train epoch: 8/11, round: 375/532, loss: 0.356489360332489\n",
      "train epoch: 8/11, round: 376/532, loss: 0.38744238018989563\n",
      "train epoch: 8/11, round: 377/532, loss: 0.3710601329803467\n",
      "train epoch: 8/11, round: 378/532, loss: 0.3738621771335602\n",
      "train epoch: 8/11, round: 379/532, loss: 0.3528604507446289\n",
      "train epoch: 8/11, round: 380/532, loss: 0.32381024956703186\n",
      "train epoch: 8/11, round: 381/532, loss: 0.3326227068901062\n",
      "train epoch: 8/11, round: 382/532, loss: 0.44094887375831604\n",
      "train epoch: 8/11, round: 383/532, loss: 0.3638559877872467\n",
      "train epoch: 8/11, round: 384/532, loss: 0.40839046239852905\n",
      "train epoch: 8/11, round: 385/532, loss: 0.3350939452648163\n",
      "train epoch: 8/11, round: 386/532, loss: 0.42589831352233887\n",
      "train epoch: 8/11, round: 387/532, loss: 0.3880900740623474\n",
      "train epoch: 8/11, round: 388/532, loss: 0.4108911454677582\n",
      "train epoch: 8/11, round: 389/532, loss: 0.47192269563674927\n",
      "train epoch: 8/11, round: 390/532, loss: 0.3815605640411377\n",
      "train epoch: 8/11, round: 391/532, loss: 0.3702428936958313\n",
      "train epoch: 8/11, round: 392/532, loss: 0.39709722995758057\n",
      "train epoch: 8/11, round: 393/532, loss: 0.3525272011756897\n",
      "train epoch: 8/11, round: 394/532, loss: 0.427379846572876\n",
      "train epoch: 8/11, round: 395/532, loss: 0.31553831696510315\n",
      "train epoch: 8/11, round: 396/532, loss: 0.30982163548469543\n",
      "train epoch: 8/11, round: 397/532, loss: 0.3871804475784302\n",
      "train epoch: 8/11, round: 398/532, loss: 0.387014240026474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8/11, round: 399/532, loss: 0.41249799728393555\n",
      "train epoch: 8/11, round: 400/532, loss: 0.3614049553871155\n",
      "train epoch: 8/11, round: 401/532, loss: 0.40420717000961304\n",
      "train epoch: 8/11, round: 402/532, loss: 0.4105105996131897\n",
      "train epoch: 8/11, round: 403/532, loss: 0.4758647084236145\n",
      "train epoch: 8/11, round: 404/532, loss: 0.37619253993034363\n",
      "train epoch: 8/11, round: 405/532, loss: 0.3864915370941162\n",
      "train epoch: 8/11, round: 406/532, loss: 0.3927091360092163\n",
      "train epoch: 8/11, round: 407/532, loss: 0.38052597641944885\n",
      "train epoch: 8/11, round: 408/532, loss: 0.3983493447303772\n",
      "train epoch: 8/11, round: 409/532, loss: 0.3827255964279175\n",
      "train epoch: 8/11, round: 410/532, loss: 0.42940130829811096\n",
      "train epoch: 8/11, round: 411/532, loss: 0.3293003439903259\n",
      "train epoch: 8/11, round: 412/532, loss: 0.45449963212013245\n",
      "train epoch: 8/11, round: 413/532, loss: 0.32273104786872864\n",
      "train epoch: 8/11, round: 414/532, loss: 0.34737730026245117\n",
      "train epoch: 8/11, round: 415/532, loss: 0.4001760482788086\n",
      "train epoch: 8/11, round: 416/532, loss: 0.43653377890586853\n",
      "train epoch: 8/11, round: 417/532, loss: 0.35922127962112427\n",
      "train epoch: 8/11, round: 418/532, loss: 0.39844220876693726\n",
      "train epoch: 8/11, round: 419/532, loss: 0.4644640386104584\n",
      "train epoch: 8/11, round: 420/532, loss: 0.4009690284729004\n",
      "train epoch: 8/11, round: 421/532, loss: 0.38303038477897644\n",
      "train epoch: 8/11, round: 422/532, loss: 0.37232309579849243\n",
      "train epoch: 8/11, round: 423/532, loss: 0.4074765741825104\n",
      "train epoch: 8/11, round: 424/532, loss: 0.3805970251560211\n",
      "train epoch: 8/11, round: 425/532, loss: 0.4246174395084381\n",
      "train epoch: 8/11, round: 426/532, loss: 0.35550013184547424\n",
      "train epoch: 8/11, round: 427/532, loss: 0.42381614446640015\n",
      "train epoch: 8/11, round: 428/532, loss: 0.3196486532688141\n",
      "train epoch: 8/11, round: 429/532, loss: 0.40188536047935486\n",
      "train epoch: 8/11, round: 430/532, loss: 0.34377557039260864\n",
      "train epoch: 8/11, round: 431/532, loss: 0.4169950485229492\n",
      "train epoch: 8/11, round: 432/532, loss: 0.4118092656135559\n",
      "train epoch: 8/11, round: 433/532, loss: 0.2999879717826843\n",
      "train epoch: 8/11, round: 434/532, loss: 0.3965657353401184\n",
      "train epoch: 8/11, round: 435/532, loss: 0.32938942313194275\n",
      "train epoch: 8/11, round: 436/532, loss: 0.3858645260334015\n",
      "train epoch: 8/11, round: 437/532, loss: 0.34973961114883423\n",
      "train epoch: 8/11, round: 438/532, loss: 0.419813334941864\n",
      "train epoch: 8/11, round: 439/532, loss: 0.3280629515647888\n",
      "train epoch: 8/11, round: 440/532, loss: 0.3637992739677429\n",
      "train epoch: 8/11, round: 441/532, loss: 0.3813331723213196\n",
      "train epoch: 8/11, round: 442/532, loss: 0.43236273527145386\n",
      "train epoch: 8/11, round: 443/532, loss: 0.3370972275733948\n",
      "train epoch: 8/11, round: 444/532, loss: 0.405886173248291\n",
      "train epoch: 8/11, round: 445/532, loss: 0.38410213589668274\n",
      "train epoch: 8/11, round: 446/532, loss: 0.35513848066329956\n",
      "train epoch: 8/11, round: 447/532, loss: 0.40695667266845703\n",
      "train epoch: 8/11, round: 448/532, loss: 0.340658962726593\n",
      "train epoch: 8/11, round: 449/532, loss: 0.37493079900741577\n",
      "train epoch: 8/11, round: 450/532, loss: 0.4353761076927185\n",
      "train epoch: 8/11, round: 451/532, loss: 0.392417848110199\n",
      "train epoch: 8/11, round: 452/532, loss: 0.40666571259498596\n",
      "train epoch: 8/11, round: 453/532, loss: 0.39573773741722107\n",
      "train epoch: 8/11, round: 454/532, loss: 0.38610154390335083\n",
      "train epoch: 8/11, round: 455/532, loss: 0.45860904455184937\n",
      "train epoch: 8/11, round: 456/532, loss: 0.376950204372406\n",
      "train epoch: 8/11, round: 457/532, loss: 0.364013135433197\n",
      "train epoch: 8/11, round: 458/532, loss: 0.3090018332004547\n",
      "train epoch: 8/11, round: 459/532, loss: 0.3294476568698883\n",
      "train epoch: 8/11, round: 460/532, loss: 0.37912026047706604\n",
      "train epoch: 8/11, round: 461/532, loss: 0.3611863851547241\n",
      "train epoch: 8/11, round: 462/532, loss: 0.34648069739341736\n",
      "train epoch: 8/11, round: 463/532, loss: 0.35890427231788635\n",
      "train epoch: 8/11, round: 464/532, loss: 0.4638766646385193\n",
      "train epoch: 8/11, round: 465/532, loss: 0.41031232476234436\n",
      "train epoch: 8/11, round: 466/532, loss: 0.40104585886001587\n",
      "train epoch: 8/11, round: 467/532, loss: 0.4320653975009918\n",
      "train epoch: 8/11, round: 468/532, loss: 0.3946145176887512\n",
      "train epoch: 8/11, round: 469/532, loss: 0.38637110590934753\n",
      "train epoch: 8/11, round: 470/532, loss: 0.3169964551925659\n",
      "train epoch: 8/11, round: 471/532, loss: 0.31015971302986145\n",
      "train epoch: 8/11, round: 472/532, loss: 0.3611229956150055\n",
      "train epoch: 8/11, round: 473/532, loss: 0.34743964672088623\n",
      "train epoch: 8/11, round: 474/532, loss: 0.4029772877693176\n",
      "train epoch: 8/11, round: 475/532, loss: 0.29960328340530396\n",
      "train epoch: 8/11, round: 476/532, loss: 0.4474189281463623\n",
      "train epoch: 8/11, round: 477/532, loss: 0.3147965669631958\n",
      "train epoch: 8/11, round: 478/532, loss: 0.3237084448337555\n",
      "train epoch: 8/11, round: 479/532, loss: 0.41928744316101074\n",
      "train epoch: 8/11, round: 480/532, loss: 0.3758440315723419\n",
      "train epoch: 8/11, round: 481/532, loss: 0.36559584736824036\n",
      "train epoch: 8/11, round: 482/532, loss: 0.44144219160079956\n",
      "train epoch: 8/11, round: 483/532, loss: 0.37800729274749756\n",
      "train epoch: 8/11, round: 484/532, loss: 0.41178494691848755\n",
      "train epoch: 8/11, round: 485/532, loss: 0.36222806572914124\n",
      "train epoch: 8/11, round: 486/532, loss: 0.34651702642440796\n",
      "train epoch: 8/11, round: 487/532, loss: 0.3700452148914337\n",
      "train epoch: 8/11, round: 488/532, loss: 0.49088233709335327\n",
      "train epoch: 8/11, round: 489/532, loss: 0.3253428339958191\n",
      "train epoch: 8/11, round: 490/532, loss: 0.35672664642333984\n",
      "train epoch: 8/11, round: 491/532, loss: 0.32644224166870117\n",
      "train epoch: 8/11, round: 492/532, loss: 0.39933323860168457\n",
      "train epoch: 8/11, round: 493/532, loss: 0.31178930401802063\n",
      "train epoch: 8/11, round: 494/532, loss: 0.3822670578956604\n",
      "train epoch: 8/11, round: 495/532, loss: 0.29749876260757446\n",
      "train epoch: 8/11, round: 496/532, loss: 0.551139235496521\n",
      "train epoch: 8/11, round: 497/532, loss: 0.34623271226882935\n",
      "train epoch: 8/11, round: 498/532, loss: 0.40682053565979004\n",
      "train epoch: 8/11, round: 499/532, loss: 0.30627161264419556\n",
      "train epoch: 8/11, round: 500/532, loss: 0.4764562249183655\n",
      "train epoch: 8/11, round: 501/532, loss: 0.3373796045780182\n",
      "train epoch: 8/11, round: 502/532, loss: 0.3633306622505188\n",
      "train epoch: 8/11, round: 503/532, loss: 0.4214712679386139\n",
      "train epoch: 8/11, round: 504/532, loss: 0.3985341191291809\n",
      "train epoch: 8/11, round: 505/532, loss: 0.388299822807312\n",
      "train epoch: 8/11, round: 506/532, loss: 0.45372962951660156\n",
      "train epoch: 8/11, round: 507/532, loss: 0.3433149456977844\n",
      "train epoch: 8/11, round: 508/532, loss: 0.4485081136226654\n",
      "train epoch: 8/11, round: 509/532, loss: 0.36475270986557007\n",
      "train epoch: 8/11, round: 510/532, loss: 0.3841775953769684\n",
      "train epoch: 8/11, round: 511/532, loss: 0.34294021129608154\n",
      "train epoch: 8/11, round: 512/532, loss: 0.45891982316970825\n",
      "train epoch: 8/11, round: 513/532, loss: 0.38426899909973145\n",
      "train epoch: 8/11, round: 514/532, loss: 0.3934515416622162\n",
      "train epoch: 8/11, round: 515/532, loss: 0.393236368894577\n",
      "train epoch: 8/11, round: 516/532, loss: 0.31957897543907166\n",
      "train epoch: 8/11, round: 517/532, loss: 0.30798643827438354\n",
      "train epoch: 8/11, round: 518/532, loss: 0.48224297165870667\n",
      "train epoch: 8/11, round: 519/532, loss: 0.3005647659301758\n",
      "train epoch: 8/11, round: 520/532, loss: 0.3343935012817383\n",
      "train epoch: 8/11, round: 521/532, loss: 0.3356288969516754\n",
      "train epoch: 8/11, round: 522/532, loss: 0.4018443524837494\n",
      "train epoch: 8/11, round: 523/532, loss: 0.43021097779273987\n",
      "train epoch: 8/11, round: 524/532, loss: 0.3312908709049225\n",
      "train epoch: 8/11, round: 525/532, loss: 0.36615294218063354\n",
      "train epoch: 8/11, round: 526/532, loss: 0.442099392414093\n",
      "train epoch: 8/11, round: 527/532, loss: 0.3520187735557556\n",
      "train epoch: 8/11, round: 528/532, loss: 0.3798132836818695\n",
      "train epoch: 8/11, round: 529/532, loss: 0.37267833948135376\n",
      "train epoch: 8/11, round: 530/532, loss: 0.44438356161117554\n",
      "train epoch: 8/11, round: 531/532, loss: 0.4878136217594147\n",
      "train epoch: 8/11, round: 532/532, loss: 0.6321930885314941\n",
      "train epoch: 8/11, KS: 0.31353393306950134, ROC: 0.7122037563837245\n",
      "test epoch: 8/11, round: 1/501, loss: 0.390288382768631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 8/11, round: 2/501, loss: 0.2780173718929291\n",
      "test epoch: 8/11, round: 3/501, loss: 0.23279736936092377\n",
      "test epoch: 8/11, round: 4/501, loss: 0.39550113677978516\n",
      "test epoch: 8/11, round: 5/501, loss: 0.3950687348842621\n",
      "test epoch: 8/11, round: 6/501, loss: 0.31526267528533936\n",
      "test epoch: 8/11, round: 7/501, loss: 0.45588022470474243\n",
      "test epoch: 8/11, round: 8/501, loss: 0.4150308668613434\n",
      "test epoch: 8/11, round: 9/501, loss: 0.5477814078330994\n",
      "test epoch: 8/11, round: 10/501, loss: 0.6469851732254028\n",
      "test epoch: 8/11, round: 11/501, loss: 0.17728328704833984\n",
      "test epoch: 8/11, round: 12/501, loss: 0.34895023703575134\n",
      "test epoch: 8/11, round: 13/501, loss: 0.3431406021118164\n",
      "test epoch: 8/11, round: 14/501, loss: 0.3109964430332184\n",
      "test epoch: 8/11, round: 15/501, loss: 0.5003169178962708\n",
      "test epoch: 8/11, round: 16/501, loss: 0.46441060304641724\n",
      "test epoch: 8/11, round: 17/501, loss: 0.33453595638275146\n",
      "test epoch: 8/11, round: 18/501, loss: 0.5276927947998047\n",
      "test epoch: 8/11, round: 19/501, loss: 0.6264430284500122\n",
      "test epoch: 8/11, round: 20/501, loss: 0.8154371976852417\n",
      "test epoch: 8/11, round: 21/501, loss: 0.3839726150035858\n",
      "test epoch: 8/11, round: 22/501, loss: 0.6006147861480713\n",
      "test epoch: 8/11, round: 23/501, loss: 0.5601623058319092\n",
      "test epoch: 8/11, round: 24/501, loss: 0.40717774629592896\n",
      "test epoch: 8/11, round: 25/501, loss: 0.7009384632110596\n",
      "test epoch: 8/11, round: 26/501, loss: 0.6927816271781921\n",
      "test epoch: 8/11, round: 27/501, loss: 0.22108063101768494\n",
      "test epoch: 8/11, round: 28/501, loss: 0.5034334063529968\n",
      "test epoch: 8/11, round: 29/501, loss: 0.30403804779052734\n",
      "test epoch: 8/11, round: 30/501, loss: 0.548639714717865\n",
      "test epoch: 8/11, round: 31/501, loss: 0.5507529973983765\n",
      "test epoch: 8/11, round: 32/501, loss: 0.5426107048988342\n",
      "test epoch: 8/11, round: 33/501, loss: 0.7356405854225159\n",
      "test epoch: 8/11, round: 34/501, loss: 0.5316696166992188\n",
      "test epoch: 8/11, round: 35/501, loss: 0.15613017976284027\n",
      "test epoch: 8/11, round: 36/501, loss: 0.4800828695297241\n",
      "test epoch: 8/11, round: 37/501, loss: 0.5074456334114075\n",
      "test epoch: 8/11, round: 38/501, loss: 0.46253395080566406\n",
      "test epoch: 8/11, round: 39/501, loss: 0.7535941004753113\n",
      "test epoch: 8/11, round: 40/501, loss: 0.6542143225669861\n",
      "test epoch: 8/11, round: 41/501, loss: 0.4155052900314331\n",
      "test epoch: 8/11, round: 42/501, loss: 0.38208064436912537\n",
      "test epoch: 8/11, round: 43/501, loss: 0.3916616141796112\n",
      "test epoch: 8/11, round: 44/501, loss: 0.6293297410011292\n",
      "test epoch: 8/11, round: 45/501, loss: 0.6581474542617798\n",
      "test epoch: 8/11, round: 46/501, loss: 0.4834059476852417\n",
      "test epoch: 8/11, round: 47/501, loss: 0.23781372606754303\n",
      "test epoch: 8/11, round: 48/501, loss: 0.5424163341522217\n",
      "test epoch: 8/11, round: 49/501, loss: 0.31740596890449524\n",
      "test epoch: 8/11, round: 50/501, loss: 0.2204228788614273\n",
      "test epoch: 8/11, round: 51/501, loss: 0.47883155941963196\n",
      "test epoch: 8/11, round: 52/501, loss: 0.4279091954231262\n",
      "test epoch: 8/11, round: 53/501, loss: 0.5613807439804077\n",
      "test epoch: 8/11, round: 54/501, loss: 0.6514822840690613\n",
      "test epoch: 8/11, round: 55/501, loss: 0.34281742572784424\n",
      "test epoch: 8/11, round: 56/501, loss: 0.4292216897010803\n",
      "test epoch: 8/11, round: 57/501, loss: 0.3300209045410156\n",
      "test epoch: 8/11, round: 58/501, loss: 0.4884752035140991\n",
      "test epoch: 8/11, round: 59/501, loss: 0.23252063989639282\n",
      "test epoch: 8/11, round: 60/501, loss: 0.4424041211605072\n",
      "test epoch: 8/11, round: 61/501, loss: 0.4228264391422272\n",
      "test epoch: 8/11, round: 62/501, loss: 0.7043147683143616\n",
      "test epoch: 8/11, round: 63/501, loss: 0.8178579807281494\n",
      "test epoch: 8/11, round: 64/501, loss: 0.28586921095848083\n",
      "test epoch: 8/11, round: 65/501, loss: 0.661446750164032\n",
      "test epoch: 8/11, round: 66/501, loss: 0.4771293103694916\n",
      "test epoch: 8/11, round: 67/501, loss: 0.553755521774292\n",
      "test epoch: 8/11, round: 68/501, loss: 0.7924689054489136\n",
      "test epoch: 8/11, round: 69/501, loss: 0.5081197023391724\n",
      "test epoch: 8/11, round: 70/501, loss: 0.48212480545043945\n",
      "test epoch: 8/11, round: 71/501, loss: 0.6787205934524536\n",
      "test epoch: 8/11, round: 72/501, loss: 0.5719751119613647\n",
      "test epoch: 8/11, round: 73/501, loss: 0.5465489625930786\n",
      "test epoch: 8/11, round: 74/501, loss: 0.544780433177948\n",
      "test epoch: 8/11, round: 75/501, loss: 0.599017858505249\n",
      "test epoch: 8/11, round: 76/501, loss: 0.823059618473053\n",
      "test epoch: 8/11, round: 77/501, loss: 0.3758847415447235\n",
      "test epoch: 8/11, round: 78/501, loss: 0.6234326958656311\n",
      "test epoch: 8/11, round: 79/501, loss: 0.3938343822956085\n",
      "test epoch: 8/11, round: 80/501, loss: 0.6475997567176819\n",
      "test epoch: 8/11, round: 81/501, loss: 0.8979412317276001\n",
      "test epoch: 8/11, round: 82/501, loss: 0.680701494216919\n",
      "test epoch: 8/11, round: 83/501, loss: 0.4068574011325836\n",
      "test epoch: 8/11, round: 84/501, loss: 0.6899862885475159\n",
      "test epoch: 8/11, round: 85/501, loss: 0.7423282861709595\n",
      "test epoch: 8/11, round: 86/501, loss: 0.3112815320491791\n",
      "test epoch: 8/11, round: 87/501, loss: 0.5206207633018494\n",
      "test epoch: 8/11, round: 88/501, loss: 0.39796727895736694\n",
      "test epoch: 8/11, round: 89/501, loss: 0.2853185832500458\n",
      "test epoch: 8/11, round: 90/501, loss: 0.7807081341743469\n",
      "test epoch: 8/11, round: 91/501, loss: 0.32798442244529724\n",
      "test epoch: 8/11, round: 92/501, loss: 0.6562373638153076\n",
      "test epoch: 8/11, round: 93/501, loss: 0.45847243070602417\n",
      "test epoch: 8/11, round: 94/501, loss: 0.6880142688751221\n",
      "test epoch: 8/11, round: 95/501, loss: 0.3903675675392151\n",
      "test epoch: 8/11, round: 96/501, loss: 0.3533376157283783\n",
      "test epoch: 8/11, round: 97/501, loss: 0.7291187644004822\n",
      "test epoch: 8/11, round: 98/501, loss: 0.44655895233154297\n",
      "test epoch: 8/11, round: 99/501, loss: 0.5897943377494812\n",
      "test epoch: 8/11, round: 100/501, loss: 0.520003080368042\n",
      "test epoch: 8/11, round: 101/501, loss: 0.5689973831176758\n",
      "test epoch: 8/11, round: 102/501, loss: 0.3158901333808899\n",
      "test epoch: 8/11, round: 103/501, loss: 0.4684562087059021\n",
      "test epoch: 8/11, round: 104/501, loss: 0.7301689982414246\n",
      "test epoch: 8/11, round: 105/501, loss: 0.39198538661003113\n",
      "test epoch: 8/11, round: 106/501, loss: 0.6508628726005554\n",
      "test epoch: 8/11, round: 107/501, loss: 0.34177127480506897\n",
      "test epoch: 8/11, round: 108/501, loss: 0.5681859254837036\n",
      "test epoch: 8/11, round: 109/501, loss: 0.31825125217437744\n",
      "test epoch: 8/11, round: 110/501, loss: 0.8096989989280701\n",
      "test epoch: 8/11, round: 111/501, loss: 0.21160992980003357\n",
      "test epoch: 8/11, round: 112/501, loss: 0.16124588251113892\n",
      "test epoch: 8/11, round: 113/501, loss: 0.4503280818462372\n",
      "test epoch: 8/11, round: 114/501, loss: 0.451584130525589\n",
      "test epoch: 8/11, round: 115/501, loss: 0.2895773649215698\n",
      "test epoch: 8/11, round: 116/501, loss: 0.3330768644809723\n",
      "test epoch: 8/11, round: 117/501, loss: 0.39557552337646484\n",
      "test epoch: 8/11, round: 118/501, loss: 0.31906622648239136\n",
      "test epoch: 8/11, round: 119/501, loss: 0.28288203477859497\n",
      "test epoch: 8/11, round: 120/501, loss: 0.39547309279441833\n",
      "test epoch: 8/11, round: 121/501, loss: 0.3802320063114166\n",
      "test epoch: 8/11, round: 122/501, loss: 0.3344002068042755\n",
      "test epoch: 8/11, round: 123/501, loss: 0.40763571858406067\n",
      "test epoch: 8/11, round: 124/501, loss: 0.6192365288734436\n",
      "test epoch: 8/11, round: 125/501, loss: 0.48431167006492615\n",
      "test epoch: 8/11, round: 126/501, loss: 0.4101727306842804\n",
      "test epoch: 8/11, round: 127/501, loss: 0.42146697640419006\n",
      "test epoch: 8/11, round: 128/501, loss: 0.1688356101512909\n",
      "test epoch: 8/11, round: 129/501, loss: 0.4182693362236023\n",
      "test epoch: 8/11, round: 130/501, loss: 0.8888221979141235\n",
      "test epoch: 8/11, round: 131/501, loss: 0.6174682378768921\n",
      "test epoch: 8/11, round: 132/501, loss: 0.46760234236717224\n",
      "test epoch: 8/11, round: 133/501, loss: 0.7782126665115356\n",
      "test epoch: 8/11, round: 134/501, loss: 0.5503597259521484\n",
      "test epoch: 8/11, round: 135/501, loss: 0.262430340051651\n",
      "test epoch: 8/11, round: 136/501, loss: 0.39533376693725586\n",
      "test epoch: 8/11, round: 137/501, loss: 0.4230543076992035\n",
      "test epoch: 8/11, round: 138/501, loss: 0.48537158966064453\n",
      "test epoch: 8/11, round: 139/501, loss: 0.6015111804008484\n",
      "test epoch: 8/11, round: 140/501, loss: 0.45053616166114807\n",
      "test epoch: 8/11, round: 141/501, loss: 0.3733268082141876\n",
      "test epoch: 8/11, round: 142/501, loss: 0.6059831380844116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 8/11, round: 143/501, loss: 0.3928294777870178\n",
      "test epoch: 8/11, round: 144/501, loss: 0.5673075318336487\n",
      "test epoch: 8/11, round: 145/501, loss: 0.30714619159698486\n",
      "test epoch: 8/11, round: 146/501, loss: 0.6217134594917297\n",
      "test epoch: 8/11, round: 147/501, loss: 0.5300344824790955\n",
      "test epoch: 8/11, round: 148/501, loss: 0.5378057360649109\n",
      "test epoch: 8/11, round: 149/501, loss: 0.4024377465248108\n",
      "test epoch: 8/11, round: 150/501, loss: 0.6127402186393738\n",
      "test epoch: 8/11, round: 151/501, loss: 0.415105938911438\n",
      "test epoch: 8/11, round: 152/501, loss: 0.5243331789970398\n",
      "test epoch: 8/11, round: 153/501, loss: 0.5549283623695374\n",
      "test epoch: 8/11, round: 154/501, loss: 0.6083305478096008\n",
      "test epoch: 8/11, round: 155/501, loss: 0.4135366976261139\n",
      "test epoch: 8/11, round: 156/501, loss: 0.3149406611919403\n",
      "test epoch: 8/11, round: 157/501, loss: 0.24789880216121674\n",
      "test epoch: 8/11, round: 158/501, loss: 0.4297906160354614\n",
      "test epoch: 8/11, round: 159/501, loss: 0.37212422490119934\n",
      "test epoch: 8/11, round: 160/501, loss: 0.4372313916683197\n",
      "test epoch: 8/11, round: 161/501, loss: 0.33046233654022217\n",
      "test epoch: 8/11, round: 162/501, loss: 0.3944016098976135\n",
      "test epoch: 8/11, round: 163/501, loss: 0.44343477487564087\n",
      "test epoch: 8/11, round: 164/501, loss: 0.347566694021225\n",
      "test epoch: 8/11, round: 165/501, loss: 0.5054246187210083\n",
      "test epoch: 8/11, round: 166/501, loss: 0.3002863824367523\n",
      "test epoch: 8/11, round: 167/501, loss: 0.1559278815984726\n",
      "test epoch: 8/11, round: 168/501, loss: 0.13001474738121033\n",
      "test epoch: 8/11, round: 169/501, loss: 0.3734532296657562\n",
      "test epoch: 8/11, round: 170/501, loss: 0.39303696155548096\n",
      "test epoch: 8/11, round: 171/501, loss: 0.5118618607521057\n",
      "test epoch: 8/11, round: 172/501, loss: 0.5348265171051025\n",
      "test epoch: 8/11, round: 173/501, loss: 0.21656058728694916\n",
      "test epoch: 8/11, round: 174/501, loss: 0.6222971677780151\n",
      "test epoch: 8/11, round: 175/501, loss: 0.22638796269893646\n",
      "test epoch: 8/11, round: 176/501, loss: 0.5531432628631592\n",
      "test epoch: 8/11, round: 177/501, loss: 0.29520443081855774\n",
      "test epoch: 8/11, round: 178/501, loss: 0.17909470200538635\n",
      "test epoch: 8/11, round: 179/501, loss: 0.1935579627752304\n",
      "test epoch: 8/11, round: 180/501, loss: 0.25399893522262573\n",
      "test epoch: 8/11, round: 181/501, loss: 0.6074937582015991\n",
      "test epoch: 8/11, round: 182/501, loss: 0.5786974430084229\n",
      "test epoch: 8/11, round: 183/501, loss: 0.43259477615356445\n",
      "test epoch: 8/11, round: 184/501, loss: 0.6229307651519775\n",
      "test epoch: 8/11, round: 185/501, loss: 0.5211012959480286\n",
      "test epoch: 8/11, round: 186/501, loss: 0.670612096786499\n",
      "test epoch: 8/11, round: 187/501, loss: 0.5534282922744751\n",
      "test epoch: 8/11, round: 188/501, loss: 0.5260053873062134\n",
      "test epoch: 8/11, round: 189/501, loss: 0.6327818036079407\n",
      "test epoch: 8/11, round: 190/501, loss: 0.4260343313217163\n",
      "test epoch: 8/11, round: 191/501, loss: 0.3315843343734741\n",
      "test epoch: 8/11, round: 192/501, loss: 0.6268479824066162\n",
      "test epoch: 8/11, round: 193/501, loss: 0.6305184960365295\n",
      "test epoch: 8/11, round: 194/501, loss: 0.39053377509117126\n",
      "test epoch: 8/11, round: 195/501, loss: 0.5740293860435486\n",
      "test epoch: 8/11, round: 196/501, loss: 0.2584180235862732\n",
      "test epoch: 8/11, round: 197/501, loss: 0.44143277406692505\n",
      "test epoch: 8/11, round: 198/501, loss: 0.5036458373069763\n",
      "test epoch: 8/11, round: 199/501, loss: 0.4818578064441681\n",
      "test epoch: 8/11, round: 200/501, loss: 0.782778799533844\n",
      "test epoch: 8/11, round: 201/501, loss: 0.3089684844017029\n",
      "test epoch: 8/11, round: 202/501, loss: 0.343276709318161\n",
      "test epoch: 8/11, round: 203/501, loss: 0.5152779221534729\n",
      "test epoch: 8/11, round: 204/501, loss: 0.6257103681564331\n",
      "test epoch: 8/11, round: 205/501, loss: 0.4417800307273865\n",
      "test epoch: 8/11, round: 206/501, loss: 0.19416292011737823\n",
      "test epoch: 8/11, round: 207/501, loss: 0.38618379831314087\n",
      "test epoch: 8/11, round: 208/501, loss: 0.48422330617904663\n",
      "test epoch: 8/11, round: 209/501, loss: 0.3365267515182495\n",
      "test epoch: 8/11, round: 210/501, loss: 0.527953028678894\n",
      "test epoch: 8/11, round: 211/501, loss: 0.25280454754829407\n",
      "test epoch: 8/11, round: 212/501, loss: 0.28150227665901184\n",
      "test epoch: 8/11, round: 213/501, loss: 0.25366833806037903\n",
      "test epoch: 8/11, round: 214/501, loss: 0.18908323347568512\n",
      "test epoch: 8/11, round: 215/501, loss: 0.1335136890411377\n",
      "test epoch: 8/11, round: 216/501, loss: 0.14168472588062286\n",
      "test epoch: 8/11, round: 217/501, loss: 0.1266799420118332\n",
      "test epoch: 8/11, round: 218/501, loss: 0.1606900840997696\n",
      "test epoch: 8/11, round: 219/501, loss: 0.1881171017885208\n",
      "test epoch: 8/11, round: 220/501, loss: 0.3703157305717468\n",
      "test epoch: 8/11, round: 221/501, loss: 0.3673620820045471\n",
      "test epoch: 8/11, round: 222/501, loss: 0.1111534982919693\n",
      "test epoch: 8/11, round: 223/501, loss: 0.12818683683872223\n",
      "test epoch: 8/11, round: 224/501, loss: 0.14666010439395905\n",
      "test epoch: 8/11, round: 225/501, loss: 0.14025965332984924\n",
      "test epoch: 8/11, round: 226/501, loss: 0.12076107412576675\n",
      "test epoch: 8/11, round: 227/501, loss: 0.1721055656671524\n",
      "test epoch: 8/11, round: 228/501, loss: 0.18513081967830658\n",
      "test epoch: 8/11, round: 229/501, loss: 0.43897491693496704\n",
      "test epoch: 8/11, round: 230/501, loss: 0.28983375430107117\n",
      "test epoch: 8/11, round: 231/501, loss: 0.2819575071334839\n",
      "test epoch: 8/11, round: 232/501, loss: 0.38748690485954285\n",
      "test epoch: 8/11, round: 233/501, loss: 0.5472244024276733\n",
      "test epoch: 8/11, round: 234/501, loss: 0.4604615271091461\n",
      "test epoch: 8/11, round: 235/501, loss: 0.27604424953460693\n",
      "test epoch: 8/11, round: 236/501, loss: 0.29622358083724976\n",
      "test epoch: 8/11, round: 237/501, loss: 0.3241569399833679\n",
      "test epoch: 8/11, round: 238/501, loss: 0.37573179602622986\n",
      "test epoch: 8/11, round: 239/501, loss: 0.4224322736263275\n",
      "test epoch: 8/11, round: 240/501, loss: 0.1820334792137146\n",
      "test epoch: 8/11, round: 241/501, loss: 0.3473621904850006\n",
      "test epoch: 8/11, round: 242/501, loss: 0.30761852860450745\n",
      "test epoch: 8/11, round: 243/501, loss: 0.24958080053329468\n",
      "test epoch: 8/11, round: 244/501, loss: 0.2687034010887146\n",
      "test epoch: 8/11, round: 245/501, loss: 0.38420864939689636\n",
      "test epoch: 8/11, round: 246/501, loss: 0.3943774998188019\n",
      "test epoch: 8/11, round: 247/501, loss: 0.4210926592350006\n",
      "test epoch: 8/11, round: 248/501, loss: 0.20408864319324493\n",
      "test epoch: 8/11, round: 249/501, loss: 0.2794073820114136\n",
      "test epoch: 8/11, round: 250/501, loss: 0.2570018768310547\n",
      "test epoch: 8/11, round: 251/501, loss: 0.35795146226882935\n",
      "test epoch: 8/11, round: 252/501, loss: 0.31861573457717896\n",
      "test epoch: 8/11, round: 253/501, loss: 0.3386540710926056\n",
      "test epoch: 8/11, round: 254/501, loss: 0.2894681394100189\n",
      "test epoch: 8/11, round: 255/501, loss: 0.29213273525238037\n",
      "test epoch: 8/11, round: 256/501, loss: 0.4683853089809418\n",
      "test epoch: 8/11, round: 257/501, loss: 0.38439327478408813\n",
      "test epoch: 8/11, round: 258/501, loss: 0.43016260862350464\n",
      "test epoch: 8/11, round: 259/501, loss: 0.23528115451335907\n",
      "test epoch: 8/11, round: 260/501, loss: 0.49816784262657166\n",
      "test epoch: 8/11, round: 261/501, loss: 0.569459080696106\n",
      "test epoch: 8/11, round: 262/501, loss: 0.49431654810905457\n",
      "test epoch: 8/11, round: 263/501, loss: 0.3595198690891266\n",
      "test epoch: 8/11, round: 264/501, loss: 0.47668787837028503\n",
      "test epoch: 8/11, round: 265/501, loss: 0.6156958937644958\n",
      "test epoch: 8/11, round: 266/501, loss: 0.39296504855155945\n",
      "test epoch: 8/11, round: 267/501, loss: 0.3674727976322174\n",
      "test epoch: 8/11, round: 268/501, loss: 0.20498506724834442\n",
      "test epoch: 8/11, round: 269/501, loss: 0.5151678323745728\n",
      "test epoch: 8/11, round: 270/501, loss: 0.24286477267742157\n",
      "test epoch: 8/11, round: 271/501, loss: 0.5634030699729919\n",
      "test epoch: 8/11, round: 272/501, loss: 0.3907075524330139\n",
      "test epoch: 8/11, round: 273/501, loss: 0.356107234954834\n",
      "test epoch: 8/11, round: 274/501, loss: 0.48242828249931335\n",
      "test epoch: 8/11, round: 275/501, loss: 0.2875382602214813\n",
      "test epoch: 8/11, round: 276/501, loss: 0.3736859858036041\n",
      "test epoch: 8/11, round: 277/501, loss: 0.3662855327129364\n",
      "test epoch: 8/11, round: 278/501, loss: 0.5779849290847778\n",
      "test epoch: 8/11, round: 279/501, loss: 0.3183736801147461\n",
      "test epoch: 8/11, round: 280/501, loss: 0.18178585171699524\n",
      "test epoch: 8/11, round: 281/501, loss: 0.16622886061668396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 8/11, round: 282/501, loss: 0.2663835287094116\n",
      "test epoch: 8/11, round: 283/501, loss: 0.25565019249916077\n",
      "test epoch: 8/11, round: 284/501, loss: 0.3667455017566681\n",
      "test epoch: 8/11, round: 285/501, loss: 0.47955211997032166\n",
      "test epoch: 8/11, round: 286/501, loss: 0.4081658124923706\n",
      "test epoch: 8/11, round: 287/501, loss: 0.5885257720947266\n",
      "test epoch: 8/11, round: 288/501, loss: 0.21530704200267792\n",
      "test epoch: 8/11, round: 289/501, loss: 0.31269219517707825\n",
      "test epoch: 8/11, round: 290/501, loss: 0.27747631072998047\n",
      "test epoch: 8/11, round: 291/501, loss: 0.5303952693939209\n",
      "test epoch: 8/11, round: 292/501, loss: 0.46888047456741333\n",
      "test epoch: 8/11, round: 293/501, loss: 0.507279098033905\n",
      "test epoch: 8/11, round: 294/501, loss: 0.21099689602851868\n",
      "test epoch: 8/11, round: 295/501, loss: 0.3290719985961914\n",
      "test epoch: 8/11, round: 296/501, loss: 0.4139214754104614\n",
      "test epoch: 8/11, round: 297/501, loss: 0.33889731764793396\n",
      "test epoch: 8/11, round: 298/501, loss: 0.46804770827293396\n",
      "test epoch: 8/11, round: 299/501, loss: 0.41017964482307434\n",
      "test epoch: 8/11, round: 300/501, loss: 0.5555976033210754\n",
      "test epoch: 8/11, round: 301/501, loss: 0.4207078814506531\n",
      "test epoch: 8/11, round: 302/501, loss: 0.1880357414484024\n",
      "test epoch: 8/11, round: 303/501, loss: 0.6806479096412659\n",
      "test epoch: 8/11, round: 304/501, loss: 0.6598434448242188\n",
      "test epoch: 8/11, round: 305/501, loss: 0.16571098566055298\n",
      "test epoch: 8/11, round: 306/501, loss: 0.26734352111816406\n",
      "test epoch: 8/11, round: 307/501, loss: 0.4975220859050751\n",
      "test epoch: 8/11, round: 308/501, loss: 0.24500176310539246\n",
      "test epoch: 8/11, round: 309/501, loss: 0.46142685413360596\n",
      "test epoch: 8/11, round: 310/501, loss: 0.3574967682361603\n",
      "test epoch: 8/11, round: 311/501, loss: 0.5791507363319397\n",
      "test epoch: 8/11, round: 312/501, loss: 0.39800116419792175\n",
      "test epoch: 8/11, round: 313/501, loss: 0.3188001215457916\n",
      "test epoch: 8/11, round: 314/501, loss: 0.3096512258052826\n",
      "test epoch: 8/11, round: 315/501, loss: 0.2529318630695343\n",
      "test epoch: 8/11, round: 316/501, loss: 0.34027424454689026\n",
      "test epoch: 8/11, round: 317/501, loss: 0.33072730898857117\n",
      "test epoch: 8/11, round: 318/501, loss: 0.3934662640094757\n",
      "test epoch: 8/11, round: 319/501, loss: 0.5882470011711121\n",
      "test epoch: 8/11, round: 320/501, loss: 0.37495917081832886\n",
      "test epoch: 8/11, round: 321/501, loss: 0.2929776906967163\n",
      "test epoch: 8/11, round: 322/501, loss: 0.43778741359710693\n",
      "test epoch: 8/11, round: 323/501, loss: 0.4026506543159485\n",
      "test epoch: 8/11, round: 324/501, loss: 0.24545590579509735\n",
      "test epoch: 8/11, round: 325/501, loss: 0.439343124628067\n",
      "test epoch: 8/11, round: 326/501, loss: 0.4502162039279938\n",
      "test epoch: 8/11, round: 327/501, loss: 0.6358567476272583\n",
      "test epoch: 8/11, round: 328/501, loss: 0.17314761877059937\n",
      "test epoch: 8/11, round: 329/501, loss: 0.44725462794303894\n",
      "test epoch: 8/11, round: 330/501, loss: 0.4729374349117279\n",
      "test epoch: 8/11, round: 331/501, loss: 0.4079481065273285\n",
      "test epoch: 8/11, round: 332/501, loss: 0.34483298659324646\n",
      "test epoch: 8/11, round: 333/501, loss: 0.3996249735355377\n",
      "test epoch: 8/11, round: 334/501, loss: 0.20200499892234802\n",
      "test epoch: 8/11, round: 335/501, loss: 0.381991446018219\n",
      "test epoch: 8/11, round: 336/501, loss: 0.33926132321357727\n",
      "test epoch: 8/11, round: 337/501, loss: 0.657931387424469\n",
      "test epoch: 8/11, round: 338/501, loss: 0.3433089554309845\n",
      "test epoch: 8/11, round: 339/501, loss: 0.9521278142929077\n",
      "test epoch: 8/11, round: 340/501, loss: 0.4679372012615204\n",
      "test epoch: 8/11, round: 341/501, loss: 0.4576740264892578\n",
      "test epoch: 8/11, round: 342/501, loss: 0.37401872873306274\n",
      "test epoch: 8/11, round: 343/501, loss: 0.3123874068260193\n",
      "test epoch: 8/11, round: 344/501, loss: 0.24928875267505646\n",
      "test epoch: 8/11, round: 345/501, loss: 0.18283571302890778\n",
      "test epoch: 8/11, round: 346/501, loss: 0.3321378827095032\n",
      "test epoch: 8/11, round: 347/501, loss: 0.26387542486190796\n",
      "test epoch: 8/11, round: 348/501, loss: 0.3646758198738098\n",
      "test epoch: 8/11, round: 349/501, loss: 0.32527071237564087\n",
      "test epoch: 8/11, round: 350/501, loss: 0.5043836236000061\n",
      "test epoch: 8/11, round: 351/501, loss: 0.4514463543891907\n",
      "test epoch: 8/11, round: 352/501, loss: 0.4764428734779358\n",
      "test epoch: 8/11, round: 353/501, loss: 0.2909795939922333\n",
      "test epoch: 8/11, round: 354/501, loss: 0.5392127633094788\n",
      "test epoch: 8/11, round: 355/501, loss: 0.3975467085838318\n",
      "test epoch: 8/11, round: 356/501, loss: 0.659026563167572\n",
      "test epoch: 8/11, round: 357/501, loss: 0.45480072498321533\n",
      "test epoch: 8/11, round: 358/501, loss: 0.36489951610565186\n",
      "test epoch: 8/11, round: 359/501, loss: 0.29896411299705505\n",
      "test epoch: 8/11, round: 360/501, loss: 0.5887447595596313\n",
      "test epoch: 8/11, round: 361/501, loss: 0.5696396231651306\n",
      "test epoch: 8/11, round: 362/501, loss: 0.3583202362060547\n",
      "test epoch: 8/11, round: 363/501, loss: 0.5418866276741028\n",
      "test epoch: 8/11, round: 364/501, loss: 0.4667949080467224\n",
      "test epoch: 8/11, round: 365/501, loss: 0.38908544182777405\n",
      "test epoch: 8/11, round: 366/501, loss: 0.6193311810493469\n",
      "test epoch: 8/11, round: 367/501, loss: 0.7227545380592346\n",
      "test epoch: 8/11, round: 368/501, loss: 0.28005319833755493\n",
      "test epoch: 8/11, round: 369/501, loss: 0.3633955419063568\n",
      "test epoch: 8/11, round: 370/501, loss: 0.3607957065105438\n",
      "test epoch: 8/11, round: 371/501, loss: 0.4101005494594574\n",
      "test epoch: 8/11, round: 372/501, loss: 0.33491766452789307\n",
      "test epoch: 8/11, round: 373/501, loss: 0.45655903220176697\n",
      "test epoch: 8/11, round: 374/501, loss: 0.33972591161727905\n",
      "test epoch: 8/11, round: 375/501, loss: 0.43459877371788025\n",
      "test epoch: 8/11, round: 376/501, loss: 0.47161784768104553\n",
      "test epoch: 8/11, round: 377/501, loss: 0.1143377274274826\n",
      "test epoch: 8/11, round: 378/501, loss: 0.13868090510368347\n",
      "test epoch: 8/11, round: 379/501, loss: 0.40888574719429016\n",
      "test epoch: 8/11, round: 380/501, loss: 0.25643548369407654\n",
      "test epoch: 8/11, round: 381/501, loss: 0.4116891026496887\n",
      "test epoch: 8/11, round: 382/501, loss: 0.25641930103302\n",
      "test epoch: 8/11, round: 383/501, loss: 0.4010177552700043\n",
      "test epoch: 8/11, round: 384/501, loss: 0.2370348572731018\n",
      "test epoch: 8/11, round: 385/501, loss: 0.5211340188980103\n",
      "test epoch: 8/11, round: 386/501, loss: 0.5593416690826416\n",
      "test epoch: 8/11, round: 387/501, loss: 0.2513519525527954\n",
      "test epoch: 8/11, round: 388/501, loss: 0.26143261790275574\n",
      "test epoch: 8/11, round: 389/501, loss: 0.3095783591270447\n",
      "test epoch: 8/11, round: 390/501, loss: 0.4562581777572632\n",
      "test epoch: 8/11, round: 391/501, loss: 0.373441606760025\n",
      "test epoch: 8/11, round: 392/501, loss: 0.4815925657749176\n",
      "test epoch: 8/11, round: 393/501, loss: 0.3318846821784973\n",
      "test epoch: 8/11, round: 394/501, loss: 0.663931667804718\n",
      "test epoch: 8/11, round: 395/501, loss: 0.25717419385910034\n",
      "test epoch: 8/11, round: 396/501, loss: 0.4411763548851013\n",
      "test epoch: 8/11, round: 397/501, loss: 0.49555957317352295\n",
      "test epoch: 8/11, round: 398/501, loss: 0.5234949588775635\n",
      "test epoch: 8/11, round: 399/501, loss: 0.3180157244205475\n",
      "test epoch: 8/11, round: 400/501, loss: 0.3128512501716614\n",
      "test epoch: 8/11, round: 401/501, loss: 0.6961199641227722\n",
      "test epoch: 8/11, round: 402/501, loss: 0.4483136832714081\n",
      "test epoch: 8/11, round: 403/501, loss: 0.28509625792503357\n",
      "test epoch: 8/11, round: 404/501, loss: 0.20290258526802063\n",
      "test epoch: 8/11, round: 405/501, loss: 0.7815083861351013\n",
      "test epoch: 8/11, round: 406/501, loss: 0.4363479018211365\n",
      "test epoch: 8/11, round: 407/501, loss: 0.48245760798454285\n",
      "test epoch: 8/11, round: 408/501, loss: 0.5175705552101135\n",
      "test epoch: 8/11, round: 409/501, loss: 0.6555041670799255\n",
      "test epoch: 8/11, round: 410/501, loss: 0.3782660663127899\n",
      "test epoch: 8/11, round: 411/501, loss: 0.39144274592399597\n",
      "test epoch: 8/11, round: 412/501, loss: 0.4233846068382263\n",
      "test epoch: 8/11, round: 413/501, loss: 0.4569200575351715\n",
      "test epoch: 8/11, round: 414/501, loss: 0.3170830309391022\n",
      "test epoch: 8/11, round: 415/501, loss: 0.31654131412506104\n",
      "test epoch: 8/11, round: 416/501, loss: 0.4168667793273926\n",
      "test epoch: 8/11, round: 417/501, loss: 0.23946180939674377\n",
      "test epoch: 8/11, round: 418/501, loss: 0.2695499658584595\n",
      "test epoch: 8/11, round: 419/501, loss: 0.3922295570373535\n",
      "test epoch: 8/11, round: 420/501, loss: 0.3127431869506836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 8/11, round: 421/501, loss: 0.4255295693874359\n",
      "test epoch: 8/11, round: 422/501, loss: 0.4245668947696686\n",
      "test epoch: 8/11, round: 423/501, loss: 0.7385916113853455\n",
      "test epoch: 8/11, round: 424/501, loss: 0.4237583577632904\n",
      "test epoch: 8/11, round: 425/501, loss: 0.2839515507221222\n",
      "test epoch: 8/11, round: 426/501, loss: 0.4873467981815338\n",
      "test epoch: 8/11, round: 427/501, loss: 0.3314324617385864\n",
      "test epoch: 8/11, round: 428/501, loss: 0.5612865686416626\n",
      "test epoch: 8/11, round: 429/501, loss: 0.6863135099411011\n",
      "test epoch: 8/11, round: 430/501, loss: 0.6262291073799133\n",
      "test epoch: 8/11, round: 431/501, loss: 0.4615717828273773\n",
      "test epoch: 8/11, round: 432/501, loss: 0.31031695008277893\n",
      "test epoch: 8/11, round: 433/501, loss: 0.38746675848960876\n",
      "test epoch: 8/11, round: 434/501, loss: 0.2821609377861023\n",
      "test epoch: 8/11, round: 435/501, loss: 0.27100732922554016\n",
      "test epoch: 8/11, round: 436/501, loss: 0.3561842739582062\n",
      "test epoch: 8/11, round: 437/501, loss: 0.4396185278892517\n",
      "test epoch: 8/11, round: 438/501, loss: 0.6536945104598999\n",
      "test epoch: 8/11, round: 439/501, loss: 0.3472699820995331\n",
      "test epoch: 8/11, round: 440/501, loss: 0.5098269581794739\n",
      "test epoch: 8/11, round: 441/501, loss: 0.4647761583328247\n",
      "test epoch: 8/11, round: 442/501, loss: 0.3252653181552887\n",
      "test epoch: 8/11, round: 443/501, loss: 0.195281982421875\n",
      "test epoch: 8/11, round: 444/501, loss: 0.43366238474845886\n",
      "test epoch: 8/11, round: 445/501, loss: 0.4110398590564728\n",
      "test epoch: 8/11, round: 446/501, loss: 0.4825447201728821\n",
      "test epoch: 8/11, round: 447/501, loss: 0.20990382134914398\n",
      "test epoch: 8/11, round: 448/501, loss: 0.32108232378959656\n",
      "test epoch: 8/11, round: 449/501, loss: 0.1919419765472412\n",
      "test epoch: 8/11, round: 450/501, loss: 0.73426753282547\n",
      "test epoch: 8/11, round: 451/501, loss: 0.33875641226768494\n",
      "test epoch: 8/11, round: 452/501, loss: 0.38775959610939026\n",
      "test epoch: 8/11, round: 453/501, loss: 0.14911092817783356\n",
      "test epoch: 8/11, round: 454/501, loss: 0.2349010407924652\n",
      "test epoch: 8/11, round: 455/501, loss: 0.5093356966972351\n",
      "test epoch: 8/11, round: 456/501, loss: 0.26497095823287964\n",
      "test epoch: 8/11, round: 457/501, loss: 0.17000322043895721\n",
      "test epoch: 8/11, round: 458/501, loss: 0.22816430032253265\n",
      "test epoch: 8/11, round: 459/501, loss: 0.1289103478193283\n",
      "test epoch: 8/11, round: 460/501, loss: 0.09231522679328918\n",
      "test epoch: 8/11, round: 461/501, loss: 0.09868025779724121\n",
      "test epoch: 8/11, round: 462/501, loss: 0.10368107259273529\n",
      "test epoch: 8/11, round: 463/501, loss: 0.09936924278736115\n",
      "test epoch: 8/11, round: 464/501, loss: 0.09454207122325897\n",
      "test epoch: 8/11, round: 465/501, loss: 0.1263348013162613\n",
      "test epoch: 8/11, round: 466/501, loss: 0.1072470173239708\n",
      "test epoch: 8/11, round: 467/501, loss: 0.12365052849054337\n",
      "test epoch: 8/11, round: 468/501, loss: 0.11512620002031326\n",
      "test epoch: 8/11, round: 469/501, loss: 0.10744477808475494\n",
      "test epoch: 8/11, round: 470/501, loss: 0.09048724174499512\n",
      "test epoch: 8/11, round: 471/501, loss: 0.15270763635635376\n",
      "test epoch: 8/11, round: 472/501, loss: 0.10780569911003113\n",
      "test epoch: 8/11, round: 473/501, loss: 0.0874248668551445\n",
      "test epoch: 8/11, round: 474/501, loss: 0.11822768300771713\n",
      "test epoch: 8/11, round: 475/501, loss: 0.10032927244901657\n",
      "test epoch: 8/11, round: 476/501, loss: 0.09028103947639465\n",
      "test epoch: 8/11, round: 477/501, loss: 0.08326875418424606\n",
      "test epoch: 8/11, round: 478/501, loss: 0.11088620871305466\n",
      "test epoch: 8/11, round: 479/501, loss: 0.08636083453893661\n",
      "test epoch: 8/11, round: 480/501, loss: 0.11004646867513657\n",
      "test epoch: 8/11, round: 481/501, loss: 0.10122327506542206\n",
      "test epoch: 8/11, round: 482/501, loss: 0.08657968789339066\n",
      "test epoch: 8/11, round: 483/501, loss: 0.12705257534980774\n",
      "test epoch: 8/11, round: 484/501, loss: 0.09268955886363983\n",
      "test epoch: 8/11, round: 485/501, loss: 0.09418466687202454\n",
      "test epoch: 8/11, round: 486/501, loss: 0.09613791853189468\n",
      "test epoch: 8/11, round: 487/501, loss: 0.09389841556549072\n",
      "test epoch: 8/11, round: 488/501, loss: 0.12869992852210999\n",
      "test epoch: 8/11, round: 489/501, loss: 0.09967785328626633\n",
      "test epoch: 8/11, round: 490/501, loss: 0.09527933597564697\n",
      "test epoch: 8/11, round: 491/501, loss: 0.11439863592386246\n",
      "test epoch: 8/11, round: 492/501, loss: 0.10379143059253693\n",
      "test epoch: 8/11, round: 493/501, loss: 0.1033916249871254\n",
      "test epoch: 8/11, round: 494/501, loss: 0.10871189087629318\n",
      "test epoch: 8/11, round: 495/501, loss: 0.08154413849115372\n",
      "test epoch: 8/11, round: 496/501, loss: 0.10507579892873764\n",
      "test epoch: 8/11, round: 497/501, loss: 0.10619620978832245\n",
      "test epoch: 8/11, round: 498/501, loss: 0.0843280479311943\n",
      "test epoch: 8/11, round: 499/501, loss: 0.1021517664194107\n",
      "test epoch: 8/11, round: 500/501, loss: 0.3830778896808624\n",
      "test epoch: 8/11, round: 501/501, loss: 1.074486494064331\n",
      "test epoch: 8/11, KS: 0.19072269635403838, ROC: 0.6254485398980056\n",
      "cost time: 2001\n",
      "train epoch: 9/11, round: 1/532, loss: 0.4364355206489563\n",
      "train epoch: 9/11, round: 2/532, loss: 0.45159912109375\n",
      "train epoch: 9/11, round: 3/532, loss: 0.30477845668792725\n",
      "train epoch: 9/11, round: 4/532, loss: 0.4218999743461609\n",
      "train epoch: 9/11, round: 5/532, loss: 0.4087878167629242\n",
      "train epoch: 9/11, round: 6/532, loss: 0.3496212363243103\n",
      "train epoch: 9/11, round: 7/532, loss: 0.41861557960510254\n",
      "train epoch: 9/11, round: 8/532, loss: 0.3529368042945862\n",
      "train epoch: 9/11, round: 9/532, loss: 0.4480651915073395\n",
      "train epoch: 9/11, round: 10/532, loss: 0.3309502601623535\n",
      "train epoch: 9/11, round: 11/532, loss: 0.3962586522102356\n",
      "train epoch: 9/11, round: 12/532, loss: 0.43862900137901306\n",
      "train epoch: 9/11, round: 13/532, loss: 0.42339426279067993\n",
      "train epoch: 9/11, round: 14/532, loss: 0.30775806307792664\n",
      "train epoch: 9/11, round: 15/532, loss: 0.47364264726638794\n",
      "train epoch: 9/11, round: 16/532, loss: 0.3554025888442993\n",
      "train epoch: 9/11, round: 17/532, loss: 0.3584042191505432\n",
      "train epoch: 9/11, round: 18/532, loss: 0.3775140345096588\n",
      "train epoch: 9/11, round: 19/532, loss: 0.3829140067100525\n",
      "train epoch: 9/11, round: 20/532, loss: 0.2781347632408142\n",
      "train epoch: 9/11, round: 21/532, loss: 0.36725595593452454\n",
      "train epoch: 9/11, round: 22/532, loss: 0.3298490047454834\n",
      "train epoch: 9/11, round: 23/532, loss: 0.397938072681427\n",
      "train epoch: 9/11, round: 24/532, loss: 0.4138355851173401\n",
      "train epoch: 9/11, round: 25/532, loss: 0.3402436673641205\n",
      "train epoch: 9/11, round: 26/532, loss: 0.3770328164100647\n",
      "train epoch: 9/11, round: 27/532, loss: 0.3403244614601135\n",
      "train epoch: 9/11, round: 28/532, loss: 0.3318389356136322\n",
      "train epoch: 9/11, round: 29/532, loss: 0.2819434106349945\n",
      "train epoch: 9/11, round: 30/532, loss: 0.3125067353248596\n",
      "train epoch: 9/11, round: 31/532, loss: 0.3833771347999573\n",
      "train epoch: 9/11, round: 32/532, loss: 0.3945363759994507\n",
      "train epoch: 9/11, round: 33/532, loss: 0.3936539590358734\n",
      "train epoch: 9/11, round: 34/532, loss: 0.350579172372818\n",
      "train epoch: 9/11, round: 35/532, loss: 0.4193755090236664\n",
      "train epoch: 9/11, round: 36/532, loss: 0.42243796586990356\n",
      "train epoch: 9/11, round: 37/532, loss: 0.420432984828949\n",
      "train epoch: 9/11, round: 38/532, loss: 0.35087621212005615\n",
      "train epoch: 9/11, round: 39/532, loss: 0.35199466347694397\n",
      "train epoch: 9/11, round: 40/532, loss: 0.4366711676120758\n",
      "train epoch: 9/11, round: 41/532, loss: 0.36698052287101746\n",
      "train epoch: 9/11, round: 42/532, loss: 0.35039305686950684\n",
      "train epoch: 9/11, round: 43/532, loss: 0.3862244486808777\n",
      "train epoch: 9/11, round: 44/532, loss: 0.3526880443096161\n",
      "train epoch: 9/11, round: 45/532, loss: 0.38942667841911316\n",
      "train epoch: 9/11, round: 46/532, loss: 0.44547638297080994\n",
      "train epoch: 9/11, round: 47/532, loss: 0.31600165367126465\n",
      "train epoch: 9/11, round: 48/532, loss: 0.372694194316864\n",
      "train epoch: 9/11, round: 49/532, loss: 0.3506263792514801\n",
      "train epoch: 9/11, round: 50/532, loss: 0.30809804797172546\n",
      "train epoch: 9/11, round: 51/532, loss: 0.35435134172439575\n",
      "train epoch: 9/11, round: 52/532, loss: 0.355829656124115\n",
      "train epoch: 9/11, round: 53/532, loss: 0.37303751707077026\n",
      "train epoch: 9/11, round: 54/532, loss: 0.4343845844268799\n",
      "train epoch: 9/11, round: 55/532, loss: 0.41332849860191345\n",
      "train epoch: 9/11, round: 56/532, loss: 0.38442134857177734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9/11, round: 57/532, loss: 0.4111630320549011\n",
      "train epoch: 9/11, round: 58/532, loss: 0.3862490952014923\n",
      "train epoch: 9/11, round: 59/532, loss: 0.3861772418022156\n",
      "train epoch: 9/11, round: 60/532, loss: 0.4065689146518707\n",
      "train epoch: 9/11, round: 61/532, loss: 0.3751900792121887\n",
      "train epoch: 9/11, round: 62/532, loss: 0.46881452202796936\n",
      "train epoch: 9/11, round: 63/532, loss: 0.3703016936779022\n",
      "train epoch: 9/11, round: 64/532, loss: 0.3605334460735321\n",
      "train epoch: 9/11, round: 65/532, loss: 0.46612653136253357\n",
      "train epoch: 9/11, round: 66/532, loss: 0.427009254693985\n",
      "train epoch: 9/11, round: 67/532, loss: 0.37028229236602783\n",
      "train epoch: 9/11, round: 68/532, loss: 0.3892417848110199\n",
      "train epoch: 9/11, round: 69/532, loss: 0.46260952949523926\n",
      "train epoch: 9/11, round: 70/532, loss: 0.4378710389137268\n",
      "train epoch: 9/11, round: 71/532, loss: 0.3631569445133209\n",
      "train epoch: 9/11, round: 72/532, loss: 0.3948017656803131\n",
      "train epoch: 9/11, round: 73/532, loss: 0.36239320039749146\n",
      "train epoch: 9/11, round: 74/532, loss: 0.3856586813926697\n",
      "train epoch: 9/11, round: 75/532, loss: 0.380676805973053\n",
      "train epoch: 9/11, round: 76/532, loss: 0.3178156018257141\n",
      "train epoch: 9/11, round: 77/532, loss: 0.3980640769004822\n",
      "train epoch: 9/11, round: 78/532, loss: 0.3514750599861145\n",
      "train epoch: 9/11, round: 79/532, loss: 0.391817569732666\n",
      "train epoch: 9/11, round: 80/532, loss: 0.4071877598762512\n",
      "train epoch: 9/11, round: 81/532, loss: 0.3737674355506897\n",
      "train epoch: 9/11, round: 82/532, loss: 0.3712945878505707\n",
      "train epoch: 9/11, round: 83/532, loss: 0.33791857957839966\n",
      "train epoch: 9/11, round: 84/532, loss: 0.31225427985191345\n",
      "train epoch: 9/11, round: 85/532, loss: 0.3899320960044861\n",
      "train epoch: 9/11, round: 86/532, loss: 0.3266870081424713\n",
      "train epoch: 9/11, round: 87/532, loss: 0.32061558961868286\n",
      "train epoch: 9/11, round: 88/532, loss: 0.2889222502708435\n",
      "train epoch: 9/11, round: 89/532, loss: 0.40555158257484436\n",
      "train epoch: 9/11, round: 90/532, loss: 0.42914754152297974\n",
      "train epoch: 9/11, round: 91/532, loss: 0.3845456540584564\n",
      "train epoch: 9/11, round: 92/532, loss: 0.3344194293022156\n",
      "train epoch: 9/11, round: 93/532, loss: 0.49411043524742126\n",
      "train epoch: 9/11, round: 94/532, loss: 0.29242295026779175\n",
      "train epoch: 9/11, round: 95/532, loss: 0.42153865098953247\n",
      "train epoch: 9/11, round: 96/532, loss: 0.3495849668979645\n",
      "train epoch: 9/11, round: 97/532, loss: 0.36278772354125977\n",
      "train epoch: 9/11, round: 98/532, loss: 0.3426455855369568\n",
      "train epoch: 9/11, round: 99/532, loss: 0.41806381940841675\n",
      "train epoch: 9/11, round: 100/532, loss: 0.3752930462360382\n",
      "train epoch: 9/11, round: 101/532, loss: 0.4887120723724365\n",
      "train epoch: 9/11, round: 102/532, loss: 0.38987353444099426\n",
      "train epoch: 9/11, round: 103/532, loss: 0.3756450414657593\n",
      "train epoch: 9/11, round: 104/532, loss: 0.3328166604042053\n",
      "train epoch: 9/11, round: 105/532, loss: 0.3608764708042145\n",
      "train epoch: 9/11, round: 106/532, loss: 0.3980582654476166\n",
      "train epoch: 9/11, round: 107/532, loss: 0.3398221433162689\n",
      "train epoch: 9/11, round: 108/532, loss: 0.33666157722473145\n",
      "train epoch: 9/11, round: 109/532, loss: 0.35322949290275574\n",
      "train epoch: 9/11, round: 110/532, loss: 0.3818743824958801\n",
      "train epoch: 9/11, round: 111/532, loss: 0.42570823431015015\n",
      "train epoch: 9/11, round: 112/532, loss: 0.2656957805156708\n",
      "train epoch: 9/11, round: 113/532, loss: 0.29877206683158875\n",
      "train epoch: 9/11, round: 114/532, loss: 0.3687668442726135\n",
      "train epoch: 9/11, round: 115/532, loss: 0.36342746019363403\n",
      "train epoch: 9/11, round: 116/532, loss: 0.39187270402908325\n",
      "train epoch: 9/11, round: 117/532, loss: 0.4440593123435974\n",
      "train epoch: 9/11, round: 118/532, loss: 0.44348660111427307\n",
      "train epoch: 9/11, round: 119/532, loss: 0.41798654198646545\n",
      "train epoch: 9/11, round: 120/532, loss: 0.3317056894302368\n",
      "train epoch: 9/11, round: 121/532, loss: 0.2694651186466217\n",
      "train epoch: 9/11, round: 122/532, loss: 0.44487589597702026\n",
      "train epoch: 9/11, round: 123/532, loss: 0.36095839738845825\n",
      "train epoch: 9/11, round: 124/532, loss: 0.34221094846725464\n",
      "train epoch: 9/11, round: 125/532, loss: 0.32615429162979126\n",
      "train epoch: 9/11, round: 126/532, loss: 0.3379024863243103\n",
      "train epoch: 9/11, round: 127/532, loss: 0.4136391580104828\n",
      "train epoch: 9/11, round: 128/532, loss: 0.29977667331695557\n",
      "train epoch: 9/11, round: 129/532, loss: 0.3037962019443512\n",
      "train epoch: 9/11, round: 130/532, loss: 0.2952282726764679\n",
      "train epoch: 9/11, round: 131/532, loss: 0.34680789709091187\n",
      "train epoch: 9/11, round: 132/532, loss: 0.2948990762233734\n",
      "train epoch: 9/11, round: 133/532, loss: 0.234445258975029\n",
      "train epoch: 9/11, round: 134/532, loss: 0.33151939511299133\n",
      "train epoch: 9/11, round: 135/532, loss: 0.3913533389568329\n",
      "train epoch: 9/11, round: 136/532, loss: 0.34400856494903564\n",
      "train epoch: 9/11, round: 137/532, loss: 0.29148539900779724\n",
      "train epoch: 9/11, round: 138/532, loss: 0.3900752663612366\n",
      "train epoch: 9/11, round: 139/532, loss: 0.34777000546455383\n",
      "train epoch: 9/11, round: 140/532, loss: 0.3337903618812561\n",
      "train epoch: 9/11, round: 141/532, loss: 0.37351101636886597\n",
      "train epoch: 9/11, round: 142/532, loss: 0.46949338912963867\n",
      "train epoch: 9/11, round: 143/532, loss: 0.31629401445388794\n",
      "train epoch: 9/11, round: 144/532, loss: 0.37621670961380005\n",
      "train epoch: 9/11, round: 145/532, loss: 0.41108107566833496\n",
      "train epoch: 9/11, round: 146/532, loss: 0.32749253511428833\n",
      "train epoch: 9/11, round: 147/532, loss: 0.3642524778842926\n",
      "train epoch: 9/11, round: 148/532, loss: 0.33710068464279175\n",
      "train epoch: 9/11, round: 149/532, loss: 0.3134673833847046\n",
      "train epoch: 9/11, round: 150/532, loss: 0.48863816261291504\n",
      "train epoch: 9/11, round: 151/532, loss: 0.29274898767471313\n",
      "train epoch: 9/11, round: 152/532, loss: 0.3492118716239929\n",
      "train epoch: 9/11, round: 153/532, loss: 0.40803536772727966\n",
      "train epoch: 9/11, round: 154/532, loss: 0.4300769865512848\n",
      "train epoch: 9/11, round: 155/532, loss: 0.43543463945388794\n",
      "train epoch: 9/11, round: 156/532, loss: 0.3513597548007965\n",
      "train epoch: 9/11, round: 157/532, loss: 0.4192412495613098\n",
      "train epoch: 9/11, round: 158/532, loss: 0.4076926112174988\n",
      "train epoch: 9/11, round: 159/532, loss: 0.334667444229126\n",
      "train epoch: 9/11, round: 160/532, loss: 0.46710315346717834\n",
      "train epoch: 9/11, round: 161/532, loss: 0.3633229434490204\n",
      "train epoch: 9/11, round: 162/532, loss: 0.392436683177948\n",
      "train epoch: 9/11, round: 163/532, loss: 0.3412880599498749\n",
      "train epoch: 9/11, round: 164/532, loss: 0.38879209756851196\n",
      "train epoch: 9/11, round: 165/532, loss: 0.2969586253166199\n",
      "train epoch: 9/11, round: 166/532, loss: 0.38685983419418335\n",
      "train epoch: 9/11, round: 167/532, loss: 0.45057326555252075\n",
      "train epoch: 9/11, round: 168/532, loss: 0.3501264750957489\n",
      "train epoch: 9/11, round: 169/532, loss: 0.32064318656921387\n",
      "train epoch: 9/11, round: 170/532, loss: 0.40281909704208374\n",
      "train epoch: 9/11, round: 171/532, loss: 0.36316657066345215\n",
      "train epoch: 9/11, round: 172/532, loss: 0.3935621380805969\n",
      "train epoch: 9/11, round: 173/532, loss: 0.31317660212516785\n",
      "train epoch: 9/11, round: 174/532, loss: 0.37318986654281616\n",
      "train epoch: 9/11, round: 175/532, loss: 0.3552646040916443\n",
      "train epoch: 9/11, round: 176/532, loss: 0.33062276244163513\n",
      "train epoch: 9/11, round: 177/532, loss: 0.3789413273334503\n",
      "train epoch: 9/11, round: 178/532, loss: 0.3995899558067322\n",
      "train epoch: 9/11, round: 179/532, loss: 0.3618147075176239\n",
      "train epoch: 9/11, round: 180/532, loss: 0.3194349706172943\n",
      "train epoch: 9/11, round: 181/532, loss: 0.4358590245246887\n",
      "train epoch: 9/11, round: 182/532, loss: 0.4074614644050598\n",
      "train epoch: 9/11, round: 183/532, loss: 0.3601471483707428\n",
      "train epoch: 9/11, round: 184/532, loss: 0.33716973662376404\n",
      "train epoch: 9/11, round: 185/532, loss: 0.39913445711135864\n",
      "train epoch: 9/11, round: 186/532, loss: 0.34563058614730835\n",
      "train epoch: 9/11, round: 187/532, loss: 0.3286984860897064\n",
      "train epoch: 9/11, round: 188/532, loss: 0.4287177622318268\n",
      "train epoch: 9/11, round: 189/532, loss: 0.3614623546600342\n",
      "train epoch: 9/11, round: 190/532, loss: 0.3315959572792053\n",
      "train epoch: 9/11, round: 191/532, loss: 0.3712007701396942\n",
      "train epoch: 9/11, round: 192/532, loss: 0.36250942945480347\n",
      "train epoch: 9/11, round: 193/532, loss: 0.33534225821495056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9/11, round: 194/532, loss: 0.37765592336654663\n",
      "train epoch: 9/11, round: 195/532, loss: 0.38601812720298767\n",
      "train epoch: 9/11, round: 196/532, loss: 0.34165823459625244\n",
      "train epoch: 9/11, round: 197/532, loss: 0.32562199234962463\n",
      "train epoch: 9/11, round: 198/532, loss: 0.33816754817962646\n",
      "train epoch: 9/11, round: 199/532, loss: 0.3991207182407379\n",
      "train epoch: 9/11, round: 200/532, loss: 0.28703269362449646\n",
      "train epoch: 9/11, round: 201/532, loss: 0.43579792976379395\n",
      "train epoch: 9/11, round: 202/532, loss: 0.3639029860496521\n",
      "train epoch: 9/11, round: 203/532, loss: 0.32268714904785156\n",
      "train epoch: 9/11, round: 204/532, loss: 0.5521165132522583\n",
      "train epoch: 9/11, round: 205/532, loss: 0.363170862197876\n",
      "train epoch: 9/11, round: 206/532, loss: 0.33268091082572937\n",
      "train epoch: 9/11, round: 207/532, loss: 0.40265196561813354\n",
      "train epoch: 9/11, round: 208/532, loss: 0.26611724495887756\n",
      "train epoch: 9/11, round: 209/532, loss: 0.3497372567653656\n",
      "train epoch: 9/11, round: 210/532, loss: 0.4952522814273834\n",
      "train epoch: 9/11, round: 211/532, loss: 0.34161320328712463\n",
      "train epoch: 9/11, round: 212/532, loss: 0.3544219732284546\n",
      "train epoch: 9/11, round: 213/532, loss: 0.41176414489746094\n",
      "train epoch: 9/11, round: 214/532, loss: 0.4459393620491028\n",
      "train epoch: 9/11, round: 215/532, loss: 0.39624643325805664\n",
      "train epoch: 9/11, round: 216/532, loss: 0.40862011909484863\n",
      "train epoch: 9/11, round: 217/532, loss: 0.39930325746536255\n",
      "train epoch: 9/11, round: 218/532, loss: 0.36424142122268677\n",
      "train epoch: 9/11, round: 219/532, loss: 0.35785216093063354\n",
      "train epoch: 9/11, round: 220/532, loss: 0.3692815899848938\n",
      "train epoch: 9/11, round: 221/532, loss: 0.3919893801212311\n",
      "train epoch: 9/11, round: 222/532, loss: 0.4418550431728363\n",
      "train epoch: 9/11, round: 223/532, loss: 0.3752867579460144\n",
      "train epoch: 9/11, round: 224/532, loss: 0.34453892707824707\n",
      "train epoch: 9/11, round: 225/532, loss: 0.30359894037246704\n",
      "train epoch: 9/11, round: 226/532, loss: 0.3370644152164459\n",
      "train epoch: 9/11, round: 227/532, loss: 0.3586745858192444\n",
      "train epoch: 9/11, round: 228/532, loss: 0.38816389441490173\n",
      "train epoch: 9/11, round: 229/532, loss: 0.3395673334598541\n",
      "train epoch: 9/11, round: 230/532, loss: 0.35031989216804504\n",
      "train epoch: 9/11, round: 231/532, loss: 0.3267420530319214\n",
      "train epoch: 9/11, round: 232/532, loss: 0.31514158844947815\n",
      "train epoch: 9/11, round: 233/532, loss: 0.422875314950943\n",
      "train epoch: 9/11, round: 234/532, loss: 0.34363818168640137\n",
      "train epoch: 9/11, round: 235/532, loss: 0.39898473024368286\n",
      "train epoch: 9/11, round: 236/532, loss: 0.4100075662136078\n",
      "train epoch: 9/11, round: 237/532, loss: 0.395426481962204\n",
      "train epoch: 9/11, round: 238/532, loss: 0.4096470773220062\n",
      "train epoch: 9/11, round: 239/532, loss: 0.3545927405357361\n",
      "train epoch: 9/11, round: 240/532, loss: 0.36998122930526733\n",
      "train epoch: 9/11, round: 241/532, loss: 0.40500742197036743\n",
      "train epoch: 9/11, round: 242/532, loss: 0.3716247081756592\n",
      "train epoch: 9/11, round: 243/532, loss: 0.36323636770248413\n",
      "train epoch: 9/11, round: 244/532, loss: 0.3947342038154602\n",
      "train epoch: 9/11, round: 245/532, loss: 0.43806523084640503\n",
      "train epoch: 9/11, round: 246/532, loss: 0.40798482298851013\n",
      "train epoch: 9/11, round: 247/532, loss: 0.3933795094490051\n",
      "train epoch: 9/11, round: 248/532, loss: 0.35479864478111267\n",
      "train epoch: 9/11, round: 249/532, loss: 0.39225995540618896\n",
      "train epoch: 9/11, round: 250/532, loss: 0.33456191420555115\n",
      "train epoch: 9/11, round: 251/532, loss: 0.3581717610359192\n",
      "train epoch: 9/11, round: 252/532, loss: 0.35783907771110535\n",
      "train epoch: 9/11, round: 253/532, loss: 0.41672077775001526\n",
      "train epoch: 9/11, round: 254/532, loss: 0.3657721281051636\n",
      "train epoch: 9/11, round: 255/532, loss: 0.38099759817123413\n",
      "train epoch: 9/11, round: 256/532, loss: 0.45800796151161194\n",
      "train epoch: 9/11, round: 257/532, loss: 0.3946684002876282\n",
      "train epoch: 9/11, round: 258/532, loss: 0.321260541677475\n",
      "train epoch: 9/11, round: 259/532, loss: 0.35925716161727905\n",
      "train epoch: 9/11, round: 260/532, loss: 0.3931772708892822\n",
      "train epoch: 9/11, round: 261/532, loss: 0.31206727027893066\n",
      "train epoch: 9/11, round: 262/532, loss: 0.4317878782749176\n",
      "train epoch: 9/11, round: 263/532, loss: 0.3743801712989807\n",
      "train epoch: 9/11, round: 264/532, loss: 0.4060078263282776\n",
      "train epoch: 9/11, round: 265/532, loss: 0.42075666785240173\n",
      "train epoch: 9/11, round: 266/532, loss: 0.3503853678703308\n",
      "train epoch: 9/11, round: 267/532, loss: 0.3608565330505371\n",
      "train epoch: 9/11, round: 268/532, loss: 0.3932339549064636\n",
      "train epoch: 9/11, round: 269/532, loss: 0.3908732533454895\n",
      "train epoch: 9/11, round: 270/532, loss: 0.31855541467666626\n",
      "train epoch: 9/11, round: 271/532, loss: 0.3251788318157196\n",
      "train epoch: 9/11, round: 272/532, loss: 0.46294212341308594\n",
      "train epoch: 9/11, round: 273/532, loss: 0.38072794675827026\n",
      "train epoch: 9/11, round: 274/532, loss: 0.4479548931121826\n",
      "train epoch: 9/11, round: 275/532, loss: 0.3821001350879669\n",
      "train epoch: 9/11, round: 276/532, loss: 0.3198300898075104\n",
      "train epoch: 9/11, round: 277/532, loss: 0.4107019305229187\n",
      "train epoch: 9/11, round: 278/532, loss: 0.38391920924186707\n",
      "train epoch: 9/11, round: 279/532, loss: 0.4131334722042084\n",
      "train epoch: 9/11, round: 280/532, loss: 0.39920392632484436\n",
      "train epoch: 9/11, round: 281/532, loss: 0.38070568442344666\n",
      "train epoch: 9/11, round: 282/532, loss: 0.3056127429008484\n",
      "train epoch: 9/11, round: 283/532, loss: 0.3385874330997467\n",
      "train epoch: 9/11, round: 284/532, loss: 0.3570922911167145\n",
      "train epoch: 9/11, round: 285/532, loss: 0.40894022583961487\n",
      "train epoch: 9/11, round: 286/532, loss: 0.3225584030151367\n",
      "train epoch: 9/11, round: 287/532, loss: 0.41755008697509766\n",
      "train epoch: 9/11, round: 288/532, loss: 0.3622796833515167\n",
      "train epoch: 9/11, round: 289/532, loss: 0.3783499300479889\n",
      "train epoch: 9/11, round: 290/532, loss: 0.4267372190952301\n",
      "train epoch: 9/11, round: 291/532, loss: 0.34508439898490906\n",
      "train epoch: 9/11, round: 292/532, loss: 0.2892921566963196\n",
      "train epoch: 9/11, round: 293/532, loss: 0.42068299651145935\n",
      "train epoch: 9/11, round: 294/532, loss: 0.32511717081069946\n",
      "train epoch: 9/11, round: 295/532, loss: 0.44709938764572144\n",
      "train epoch: 9/11, round: 296/532, loss: 0.3348015248775482\n",
      "train epoch: 9/11, round: 297/532, loss: 0.3016667366027832\n",
      "train epoch: 9/11, round: 298/532, loss: 0.4094463288784027\n",
      "train epoch: 9/11, round: 299/532, loss: 0.3772619366645813\n",
      "train epoch: 9/11, round: 300/532, loss: 0.28097784519195557\n",
      "train epoch: 9/11, round: 301/532, loss: 0.42709556221961975\n",
      "train epoch: 9/11, round: 302/532, loss: 0.3580694794654846\n",
      "train epoch: 9/11, round: 303/532, loss: 0.3562508821487427\n",
      "train epoch: 9/11, round: 304/532, loss: 0.40995875000953674\n",
      "train epoch: 9/11, round: 305/532, loss: 0.3538742959499359\n",
      "train epoch: 9/11, round: 306/532, loss: 0.33505988121032715\n",
      "train epoch: 9/11, round: 307/532, loss: 0.347817599773407\n",
      "train epoch: 9/11, round: 308/532, loss: 0.4323337972164154\n",
      "train epoch: 9/11, round: 309/532, loss: 0.3666304647922516\n",
      "train epoch: 9/11, round: 310/532, loss: 0.35059496760368347\n",
      "train epoch: 9/11, round: 311/532, loss: 0.3852419853210449\n",
      "train epoch: 9/11, round: 312/532, loss: 0.38914668560028076\n",
      "train epoch: 9/11, round: 313/532, loss: 0.3724498450756073\n",
      "train epoch: 9/11, round: 314/532, loss: 0.311836302280426\n",
      "train epoch: 9/11, round: 315/532, loss: 0.41838255524635315\n",
      "train epoch: 9/11, round: 316/532, loss: 0.4105469286441803\n",
      "train epoch: 9/11, round: 317/532, loss: 0.36410999298095703\n",
      "train epoch: 9/11, round: 318/532, loss: 0.4239768385887146\n",
      "train epoch: 9/11, round: 319/532, loss: 0.35082799196243286\n",
      "train epoch: 9/11, round: 320/532, loss: 0.38325756788253784\n",
      "train epoch: 9/11, round: 321/532, loss: 0.3713994324207306\n",
      "train epoch: 9/11, round: 322/532, loss: 0.3296422064304352\n",
      "train epoch: 9/11, round: 323/532, loss: 0.3981263041496277\n",
      "train epoch: 9/11, round: 324/532, loss: 0.38308143615722656\n",
      "train epoch: 9/11, round: 325/532, loss: 0.40230345726013184\n",
      "train epoch: 9/11, round: 326/532, loss: 0.3577274680137634\n",
      "train epoch: 9/11, round: 327/532, loss: 0.42956995964050293\n",
      "train epoch: 9/11, round: 328/532, loss: 0.2898062765598297\n",
      "train epoch: 9/11, round: 329/532, loss: 0.34686189889907837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9/11, round: 330/532, loss: 0.44332218170166016\n",
      "train epoch: 9/11, round: 331/532, loss: 0.3737996518611908\n",
      "train epoch: 9/11, round: 332/532, loss: 0.27681583166122437\n",
      "train epoch: 9/11, round: 333/532, loss: 0.27797502279281616\n",
      "train epoch: 9/11, round: 334/532, loss: 0.3076677620410919\n",
      "train epoch: 9/11, round: 335/532, loss: 0.33006423711776733\n",
      "train epoch: 9/11, round: 336/532, loss: 0.39498260617256165\n",
      "train epoch: 9/11, round: 337/532, loss: 0.37699630856513977\n",
      "train epoch: 9/11, round: 338/532, loss: 0.28755760192871094\n",
      "train epoch: 9/11, round: 339/532, loss: 0.33781084418296814\n",
      "train epoch: 9/11, round: 340/532, loss: 0.2799849212169647\n",
      "train epoch: 9/11, round: 341/532, loss: 0.48019734025001526\n",
      "train epoch: 9/11, round: 342/532, loss: 0.4622020721435547\n",
      "train epoch: 9/11, round: 343/532, loss: 0.3615097403526306\n",
      "train epoch: 9/11, round: 344/532, loss: 0.3805096745491028\n",
      "train epoch: 9/11, round: 345/532, loss: 0.36203283071517944\n",
      "train epoch: 9/11, round: 346/532, loss: 0.4058641791343689\n",
      "train epoch: 9/11, round: 347/532, loss: 0.3522654175758362\n",
      "train epoch: 9/11, round: 348/532, loss: 0.36408722400665283\n",
      "train epoch: 9/11, round: 349/532, loss: 0.3570316433906555\n",
      "train epoch: 9/11, round: 350/532, loss: 0.4918380677700043\n",
      "train epoch: 9/11, round: 351/532, loss: 0.3414578437805176\n",
      "train epoch: 9/11, round: 352/532, loss: 0.3555664122104645\n",
      "train epoch: 9/11, round: 353/532, loss: 0.3642407953739166\n",
      "train epoch: 9/11, round: 354/532, loss: 0.39764443039894104\n",
      "train epoch: 9/11, round: 355/532, loss: 0.3790140748023987\n",
      "train epoch: 9/11, round: 356/532, loss: 0.3263494670391083\n",
      "train epoch: 9/11, round: 357/532, loss: 0.3986814022064209\n",
      "train epoch: 9/11, round: 358/532, loss: 0.34149169921875\n",
      "train epoch: 9/11, round: 359/532, loss: 0.35803350806236267\n",
      "train epoch: 9/11, round: 360/532, loss: 0.4344853460788727\n",
      "train epoch: 9/11, round: 361/532, loss: 0.349592000246048\n",
      "train epoch: 9/11, round: 362/532, loss: 0.36281639337539673\n",
      "train epoch: 9/11, round: 363/532, loss: 0.3469133973121643\n",
      "train epoch: 9/11, round: 364/532, loss: 0.3304751515388489\n",
      "train epoch: 9/11, round: 365/532, loss: 0.4213014543056488\n",
      "train epoch: 9/11, round: 366/532, loss: 0.3560580611228943\n",
      "train epoch: 9/11, round: 367/532, loss: 0.2930377125740051\n",
      "train epoch: 9/11, round: 368/532, loss: 0.3645194470882416\n",
      "train epoch: 9/11, round: 369/532, loss: 0.3848227560520172\n",
      "train epoch: 9/11, round: 370/532, loss: 0.3649545907974243\n",
      "train epoch: 9/11, round: 371/532, loss: 0.45894256234169006\n",
      "train epoch: 9/11, round: 372/532, loss: 0.2950950562953949\n",
      "train epoch: 9/11, round: 373/532, loss: 0.3936156630516052\n",
      "train epoch: 9/11, round: 374/532, loss: 0.3660045564174652\n",
      "train epoch: 9/11, round: 375/532, loss: 0.4115857183933258\n",
      "train epoch: 9/11, round: 376/532, loss: 0.3887990415096283\n",
      "train epoch: 9/11, round: 377/532, loss: 0.3318200707435608\n",
      "train epoch: 9/11, round: 378/532, loss: 0.40080443024635315\n",
      "train epoch: 9/11, round: 379/532, loss: 0.3009631037712097\n",
      "train epoch: 9/11, round: 380/532, loss: 0.2909933924674988\n",
      "train epoch: 9/11, round: 381/532, loss: 0.3820154070854187\n",
      "train epoch: 9/11, round: 382/532, loss: 0.3846525251865387\n",
      "train epoch: 9/11, round: 383/532, loss: 0.3180500268936157\n",
      "train epoch: 9/11, round: 384/532, loss: 0.4286428391933441\n",
      "train epoch: 9/11, round: 385/532, loss: 0.4154065251350403\n",
      "train epoch: 9/11, round: 386/532, loss: 0.41844525933265686\n",
      "train epoch: 9/11, round: 387/532, loss: 0.3958309292793274\n",
      "train epoch: 9/11, round: 388/532, loss: 0.4438009262084961\n",
      "train epoch: 9/11, round: 389/532, loss: 0.303912878036499\n",
      "train epoch: 9/11, round: 390/532, loss: 0.38855206966400146\n",
      "train epoch: 9/11, round: 391/532, loss: 0.2892409563064575\n",
      "train epoch: 9/11, round: 392/532, loss: 0.45063838362693787\n",
      "train epoch: 9/11, round: 393/532, loss: 0.3637821078300476\n",
      "train epoch: 9/11, round: 394/532, loss: 0.37206074595451355\n",
      "train epoch: 9/11, round: 395/532, loss: 0.34958815574645996\n",
      "train epoch: 9/11, round: 396/532, loss: 0.2922745943069458\n",
      "train epoch: 9/11, round: 397/532, loss: 0.39745908975601196\n",
      "train epoch: 9/11, round: 398/532, loss: 0.38145238161087036\n",
      "train epoch: 9/11, round: 399/532, loss: 0.3876742422580719\n",
      "train epoch: 9/11, round: 400/532, loss: 0.41387468576431274\n",
      "train epoch: 9/11, round: 401/532, loss: 0.3276475965976715\n",
      "train epoch: 9/11, round: 402/532, loss: 0.4766288697719574\n",
      "train epoch: 9/11, round: 403/532, loss: 0.3961348235607147\n",
      "train epoch: 9/11, round: 404/532, loss: 0.40908122062683105\n",
      "train epoch: 9/11, round: 405/532, loss: 0.352264940738678\n",
      "train epoch: 9/11, round: 406/532, loss: 0.4407009184360504\n",
      "train epoch: 9/11, round: 407/532, loss: 0.35899898409843445\n",
      "train epoch: 9/11, round: 408/532, loss: 0.3591616749763489\n",
      "train epoch: 9/11, round: 409/532, loss: 0.41428446769714355\n",
      "train epoch: 9/11, round: 410/532, loss: 0.4382862448692322\n",
      "train epoch: 9/11, round: 411/532, loss: 0.36161044239997864\n",
      "train epoch: 9/11, round: 412/532, loss: 0.4271334111690521\n",
      "train epoch: 9/11, round: 413/532, loss: 0.33701395988464355\n",
      "train epoch: 9/11, round: 414/532, loss: 0.3709705173969269\n",
      "train epoch: 9/11, round: 415/532, loss: 0.3827022910118103\n",
      "train epoch: 9/11, round: 416/532, loss: 0.35983696579933167\n",
      "train epoch: 9/11, round: 417/532, loss: 0.31784430146217346\n",
      "train epoch: 9/11, round: 418/532, loss: 0.3775527775287628\n",
      "train epoch: 9/11, round: 419/532, loss: 0.37738531827926636\n",
      "train epoch: 9/11, round: 420/532, loss: 0.38233667612075806\n",
      "train epoch: 9/11, round: 421/532, loss: 0.321445107460022\n",
      "train epoch: 9/11, round: 422/532, loss: 0.32681626081466675\n",
      "train epoch: 9/11, round: 423/532, loss: 0.4045584797859192\n",
      "train epoch: 9/11, round: 424/532, loss: 0.468305766582489\n",
      "train epoch: 9/11, round: 425/532, loss: 0.4381752908229828\n",
      "train epoch: 9/11, round: 426/532, loss: 0.37825971841812134\n",
      "train epoch: 9/11, round: 427/532, loss: 0.3735892176628113\n",
      "train epoch: 9/11, round: 428/532, loss: 0.42201370000839233\n",
      "train epoch: 9/11, round: 429/532, loss: 0.37806811928749084\n",
      "train epoch: 9/11, round: 430/532, loss: 0.3275747299194336\n",
      "train epoch: 9/11, round: 431/532, loss: 0.39273858070373535\n",
      "train epoch: 9/11, round: 432/532, loss: 0.383863240480423\n",
      "train epoch: 9/11, round: 433/532, loss: 0.31377241015434265\n",
      "train epoch: 9/11, round: 434/532, loss: 0.40769022703170776\n",
      "train epoch: 9/11, round: 435/532, loss: 0.3273186981678009\n",
      "train epoch: 9/11, round: 436/532, loss: 0.33818143606185913\n",
      "train epoch: 9/11, round: 437/532, loss: 0.37656110525131226\n",
      "train epoch: 9/11, round: 438/532, loss: 0.3225909173488617\n",
      "train epoch: 9/11, round: 439/532, loss: 0.3804737627506256\n",
      "train epoch: 9/11, round: 440/532, loss: 0.4051087498664856\n",
      "train epoch: 9/11, round: 441/532, loss: 0.39393264055252075\n",
      "train epoch: 9/11, round: 442/532, loss: 0.39569586515426636\n",
      "train epoch: 9/11, round: 443/532, loss: 0.38339343667030334\n",
      "train epoch: 9/11, round: 444/532, loss: 0.38752976059913635\n",
      "train epoch: 9/11, round: 445/532, loss: 0.493872731924057\n",
      "train epoch: 9/11, round: 446/532, loss: 0.38258326053619385\n",
      "train epoch: 9/11, round: 447/532, loss: 0.3186225891113281\n",
      "train epoch: 9/11, round: 448/532, loss: 0.4138231873512268\n",
      "train epoch: 9/11, round: 449/532, loss: 0.3804660737514496\n",
      "train epoch: 9/11, round: 450/532, loss: 0.3010939657688141\n",
      "train epoch: 9/11, round: 451/532, loss: 0.3356451392173767\n",
      "train epoch: 9/11, round: 452/532, loss: 0.32311201095581055\n",
      "train epoch: 9/11, round: 453/532, loss: 0.3124740719795227\n",
      "train epoch: 9/11, round: 454/532, loss: 0.30095332860946655\n",
      "train epoch: 9/11, round: 455/532, loss: 0.2983331084251404\n",
      "train epoch: 9/11, round: 456/532, loss: 0.409132182598114\n",
      "train epoch: 9/11, round: 457/532, loss: 0.2965225577354431\n",
      "train epoch: 9/11, round: 458/532, loss: 0.3701329231262207\n",
      "train epoch: 9/11, round: 459/532, loss: 0.4148257374763489\n",
      "train epoch: 9/11, round: 460/532, loss: 0.4278225302696228\n",
      "train epoch: 9/11, round: 461/532, loss: 0.42584553360939026\n",
      "train epoch: 9/11, round: 462/532, loss: 0.3535878658294678\n",
      "train epoch: 9/11, round: 463/532, loss: 0.317729651927948\n",
      "train epoch: 9/11, round: 464/532, loss: 0.40656137466430664\n",
      "train epoch: 9/11, round: 465/532, loss: 0.4505346417427063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9/11, round: 466/532, loss: 0.38722872734069824\n",
      "train epoch: 9/11, round: 467/532, loss: 0.32438960671424866\n",
      "train epoch: 9/11, round: 468/532, loss: 0.3951210677623749\n",
      "train epoch: 9/11, round: 469/532, loss: 0.3850528299808502\n",
      "train epoch: 9/11, round: 470/532, loss: 0.3014012277126312\n",
      "train epoch: 9/11, round: 471/532, loss: 0.44321542978286743\n",
      "train epoch: 9/11, round: 472/532, loss: 0.3315185606479645\n",
      "train epoch: 9/11, round: 473/532, loss: 0.32698118686676025\n",
      "train epoch: 9/11, round: 474/532, loss: 0.33621180057525635\n",
      "train epoch: 9/11, round: 475/532, loss: 0.310219943523407\n",
      "train epoch: 9/11, round: 476/532, loss: 0.445283979177475\n",
      "train epoch: 9/11, round: 477/532, loss: 0.4293963313102722\n",
      "train epoch: 9/11, round: 478/532, loss: 0.42348456382751465\n",
      "train epoch: 9/11, round: 479/532, loss: 0.4751625955104828\n",
      "train epoch: 9/11, round: 480/532, loss: 0.4062923491001129\n",
      "train epoch: 9/11, round: 481/532, loss: 0.3610851764678955\n",
      "train epoch: 9/11, round: 482/532, loss: 0.335643470287323\n",
      "train epoch: 9/11, round: 483/532, loss: 0.38128137588500977\n",
      "train epoch: 9/11, round: 484/532, loss: 0.45669692754745483\n",
      "train epoch: 9/11, round: 485/532, loss: 0.37909045815467834\n",
      "train epoch: 9/11, round: 486/532, loss: 0.37980884313583374\n",
      "train epoch: 9/11, round: 487/532, loss: 0.4000065326690674\n",
      "train epoch: 9/11, round: 488/532, loss: 0.36397960782051086\n",
      "train epoch: 9/11, round: 489/532, loss: 0.3341793417930603\n",
      "train epoch: 9/11, round: 490/532, loss: 0.38433974981307983\n",
      "train epoch: 9/11, round: 491/532, loss: 0.3930228352546692\n",
      "train epoch: 9/11, round: 492/532, loss: 0.37676018476486206\n",
      "train epoch: 9/11, round: 493/532, loss: 0.3981894552707672\n",
      "train epoch: 9/11, round: 494/532, loss: 0.3559444546699524\n",
      "train epoch: 9/11, round: 495/532, loss: 0.3796018958091736\n",
      "train epoch: 9/11, round: 496/532, loss: 0.46718159317970276\n",
      "train epoch: 9/11, round: 497/532, loss: 0.4181691110134125\n",
      "train epoch: 9/11, round: 498/532, loss: 0.38059812784194946\n",
      "train epoch: 9/11, round: 499/532, loss: 0.4468948245048523\n",
      "train epoch: 9/11, round: 500/532, loss: 0.3128499388694763\n",
      "train epoch: 9/11, round: 501/532, loss: 0.4069487452507019\n",
      "train epoch: 9/11, round: 502/532, loss: 0.41005939245224\n",
      "train epoch: 9/11, round: 503/532, loss: 0.3638100028038025\n",
      "train epoch: 9/11, round: 504/532, loss: 0.3949689269065857\n",
      "train epoch: 9/11, round: 505/532, loss: 0.3611122965812683\n",
      "train epoch: 9/11, round: 506/532, loss: 0.3565816283226013\n",
      "train epoch: 9/11, round: 507/532, loss: 0.4203365743160248\n",
      "train epoch: 9/11, round: 508/532, loss: 0.38629934191703796\n",
      "train epoch: 9/11, round: 509/532, loss: 0.4121493697166443\n",
      "train epoch: 9/11, round: 510/532, loss: 0.3778405785560608\n",
      "train epoch: 9/11, round: 511/532, loss: 0.46015018224716187\n",
      "train epoch: 9/11, round: 512/532, loss: 0.3458748459815979\n",
      "train epoch: 9/11, round: 513/532, loss: 0.4169343411922455\n",
      "train epoch: 9/11, round: 514/532, loss: 0.47830381989479065\n",
      "train epoch: 9/11, round: 515/532, loss: 0.35186511278152466\n",
      "train epoch: 9/11, round: 516/532, loss: 0.35642480850219727\n",
      "train epoch: 9/11, round: 517/532, loss: 0.4623681902885437\n",
      "train epoch: 9/11, round: 518/532, loss: 0.32461756467819214\n",
      "train epoch: 9/11, round: 519/532, loss: 0.41383010149002075\n",
      "train epoch: 9/11, round: 520/532, loss: 0.3737083077430725\n",
      "train epoch: 9/11, round: 521/532, loss: 0.3908695876598358\n",
      "train epoch: 9/11, round: 522/532, loss: 0.3746398091316223\n",
      "train epoch: 9/11, round: 523/532, loss: 0.3684372007846832\n",
      "train epoch: 9/11, round: 524/532, loss: 0.2940770983695984\n",
      "train epoch: 9/11, round: 525/532, loss: 0.4187719225883484\n",
      "train epoch: 9/11, round: 526/532, loss: 0.3704889118671417\n",
      "train epoch: 9/11, round: 527/532, loss: 0.4532718062400818\n",
      "train epoch: 9/11, round: 528/532, loss: 0.2846587300300598\n",
      "train epoch: 9/11, round: 529/532, loss: 0.4554470181465149\n",
      "train epoch: 9/11, round: 530/532, loss: 0.5062774419784546\n",
      "train epoch: 9/11, round: 531/532, loss: 0.3614279627799988\n",
      "train epoch: 9/11, round: 532/532, loss: 0.2910802364349365\n",
      "train epoch: 9/11, KS: 0.34550490212751556, ROC: 0.7314822621886518\n",
      "test epoch: 9/11, round: 1/501, loss: 0.40183696150779724\n",
      "test epoch: 9/11, round: 2/501, loss: 0.3173903226852417\n",
      "test epoch: 9/11, round: 3/501, loss: 0.22045357525348663\n",
      "test epoch: 9/11, round: 4/501, loss: 0.3710799217224121\n",
      "test epoch: 9/11, round: 5/501, loss: 0.40138229727745056\n",
      "test epoch: 9/11, round: 6/501, loss: 0.3088526129722595\n",
      "test epoch: 9/11, round: 7/501, loss: 0.41311320662498474\n",
      "test epoch: 9/11, round: 8/501, loss: 0.3805590271949768\n",
      "test epoch: 9/11, round: 9/501, loss: 0.5221256613731384\n",
      "test epoch: 9/11, round: 10/501, loss: 0.6445837020874023\n",
      "test epoch: 9/11, round: 11/501, loss: 0.20172090828418732\n",
      "test epoch: 9/11, round: 12/501, loss: 0.36558476090431213\n",
      "test epoch: 9/11, round: 13/501, loss: 0.3263944983482361\n",
      "test epoch: 9/11, round: 14/501, loss: 0.3582935929298401\n",
      "test epoch: 9/11, round: 15/501, loss: 0.449201762676239\n",
      "test epoch: 9/11, round: 16/501, loss: 0.37641382217407227\n",
      "test epoch: 9/11, round: 17/501, loss: 0.3405829668045044\n",
      "test epoch: 9/11, round: 18/501, loss: 0.5106322169303894\n",
      "test epoch: 9/11, round: 19/501, loss: 0.5785209536552429\n",
      "test epoch: 9/11, round: 20/501, loss: 0.8286306858062744\n",
      "test epoch: 9/11, round: 21/501, loss: 0.3761390149593353\n",
      "test epoch: 9/11, round: 22/501, loss: 0.6073398590087891\n",
      "test epoch: 9/11, round: 23/501, loss: 0.5095949172973633\n",
      "test epoch: 9/11, round: 24/501, loss: 0.37835216522216797\n",
      "test epoch: 9/11, round: 25/501, loss: 0.7001699805259705\n",
      "test epoch: 9/11, round: 26/501, loss: 0.6925298571586609\n",
      "test epoch: 9/11, round: 27/501, loss: 0.22308173775672913\n",
      "test epoch: 9/11, round: 28/501, loss: 0.4595017731189728\n",
      "test epoch: 9/11, round: 29/501, loss: 0.3508163094520569\n",
      "test epoch: 9/11, round: 30/501, loss: 0.575972855091095\n",
      "test epoch: 9/11, round: 31/501, loss: 0.5607937574386597\n",
      "test epoch: 9/11, round: 32/501, loss: 0.5063888430595398\n",
      "test epoch: 9/11, round: 33/501, loss: 0.7554864287376404\n",
      "test epoch: 9/11, round: 34/501, loss: 0.5359170436859131\n",
      "test epoch: 9/11, round: 35/501, loss: 0.16931654512882233\n",
      "test epoch: 9/11, round: 36/501, loss: 0.5099103450775146\n",
      "test epoch: 9/11, round: 37/501, loss: 0.47634759545326233\n",
      "test epoch: 9/11, round: 38/501, loss: 0.42156198620796204\n",
      "test epoch: 9/11, round: 39/501, loss: 0.7254458665847778\n",
      "test epoch: 9/11, round: 40/501, loss: 0.6378179788589478\n",
      "test epoch: 9/11, round: 41/501, loss: 0.4267173409461975\n",
      "test epoch: 9/11, round: 42/501, loss: 0.3570634126663208\n",
      "test epoch: 9/11, round: 43/501, loss: 0.4012333154678345\n",
      "test epoch: 9/11, round: 44/501, loss: 0.5597646832466125\n",
      "test epoch: 9/11, round: 45/501, loss: 0.6605722308158875\n",
      "test epoch: 9/11, round: 46/501, loss: 0.49283939599990845\n",
      "test epoch: 9/11, round: 47/501, loss: 0.23012176156044006\n",
      "test epoch: 9/11, round: 48/501, loss: 0.5583849549293518\n",
      "test epoch: 9/11, round: 49/501, loss: 0.3600115478038788\n",
      "test epoch: 9/11, round: 50/501, loss: 0.23122470080852509\n",
      "test epoch: 9/11, round: 51/501, loss: 0.4843257665634155\n",
      "test epoch: 9/11, round: 52/501, loss: 0.4336703419685364\n",
      "test epoch: 9/11, round: 53/501, loss: 0.5421964526176453\n",
      "test epoch: 9/11, round: 54/501, loss: 0.6307421326637268\n",
      "test epoch: 9/11, round: 55/501, loss: 0.28887939453125\n",
      "test epoch: 9/11, round: 56/501, loss: 0.39414671063423157\n",
      "test epoch: 9/11, round: 57/501, loss: 0.3747877776622772\n",
      "test epoch: 9/11, round: 58/501, loss: 0.41100484132766724\n",
      "test epoch: 9/11, round: 59/501, loss: 0.23610635101795197\n",
      "test epoch: 9/11, round: 60/501, loss: 0.4539071023464203\n",
      "test epoch: 9/11, round: 61/501, loss: 0.4629063010215759\n",
      "test epoch: 9/11, round: 62/501, loss: 0.6794905066490173\n",
      "test epoch: 9/11, round: 63/501, loss: 0.8131468892097473\n",
      "test epoch: 9/11, round: 64/501, loss: 0.2925136983394623\n",
      "test epoch: 9/11, round: 65/501, loss: 0.6082777380943298\n",
      "test epoch: 9/11, round: 66/501, loss: 0.42662709951400757\n",
      "test epoch: 9/11, round: 67/501, loss: 0.51966392993927\n",
      "test epoch: 9/11, round: 68/501, loss: 0.6901113986968994\n",
      "test epoch: 9/11, round: 69/501, loss: 0.4953868091106415\n",
      "test epoch: 9/11, round: 70/501, loss: 0.4755280911922455\n",
      "test epoch: 9/11, round: 71/501, loss: 0.5769137740135193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 9/11, round: 72/501, loss: 0.5079063177108765\n",
      "test epoch: 9/11, round: 73/501, loss: 0.5175044536590576\n",
      "test epoch: 9/11, round: 74/501, loss: 0.47687000036239624\n",
      "test epoch: 9/11, round: 75/501, loss: 0.5664979815483093\n",
      "test epoch: 9/11, round: 76/501, loss: 0.8063583970069885\n",
      "test epoch: 9/11, round: 77/501, loss: 0.3418317139148712\n",
      "test epoch: 9/11, round: 78/501, loss: 0.5833112597465515\n",
      "test epoch: 9/11, round: 79/501, loss: 0.3799040615558624\n",
      "test epoch: 9/11, round: 80/501, loss: 0.5767585635185242\n",
      "test epoch: 9/11, round: 81/501, loss: 0.789742648601532\n",
      "test epoch: 9/11, round: 82/501, loss: 0.6204153895378113\n",
      "test epoch: 9/11, round: 83/501, loss: 0.37329408526420593\n",
      "test epoch: 9/11, round: 84/501, loss: 0.667475700378418\n",
      "test epoch: 9/11, round: 85/501, loss: 0.8318200707435608\n",
      "test epoch: 9/11, round: 86/501, loss: 0.31875962018966675\n",
      "test epoch: 9/11, round: 87/501, loss: 0.46214526891708374\n",
      "test epoch: 9/11, round: 88/501, loss: 0.3324078917503357\n",
      "test epoch: 9/11, round: 89/501, loss: 0.3209092319011688\n",
      "test epoch: 9/11, round: 90/501, loss: 0.7103173732757568\n",
      "test epoch: 9/11, round: 91/501, loss: 0.34216323494911194\n",
      "test epoch: 9/11, round: 92/501, loss: 0.6417824029922485\n",
      "test epoch: 9/11, round: 93/501, loss: 0.4337228834629059\n",
      "test epoch: 9/11, round: 94/501, loss: 0.6525773406028748\n",
      "test epoch: 9/11, round: 95/501, loss: 0.36639466881752014\n",
      "test epoch: 9/11, round: 96/501, loss: 0.386130154132843\n",
      "test epoch: 9/11, round: 97/501, loss: 0.6769532561302185\n",
      "test epoch: 9/11, round: 98/501, loss: 0.4652051329612732\n",
      "test epoch: 9/11, round: 99/501, loss: 0.6088737845420837\n",
      "test epoch: 9/11, round: 100/501, loss: 0.556216299533844\n",
      "test epoch: 9/11, round: 101/501, loss: 0.5760723352432251\n",
      "test epoch: 9/11, round: 102/501, loss: 0.2829250693321228\n",
      "test epoch: 9/11, round: 103/501, loss: 0.49317026138305664\n",
      "test epoch: 9/11, round: 104/501, loss: 0.6551363468170166\n",
      "test epoch: 9/11, round: 105/501, loss: 0.4154547452926636\n",
      "test epoch: 9/11, round: 106/501, loss: 0.649222195148468\n",
      "test epoch: 9/11, round: 107/501, loss: 0.3093050420284271\n",
      "test epoch: 9/11, round: 108/501, loss: 0.5265449285507202\n",
      "test epoch: 9/11, round: 109/501, loss: 0.33578336238861084\n",
      "test epoch: 9/11, round: 110/501, loss: 0.7998504638671875\n",
      "test epoch: 9/11, round: 111/501, loss: 0.18585196137428284\n",
      "test epoch: 9/11, round: 112/501, loss: 0.175309956073761\n",
      "test epoch: 9/11, round: 113/501, loss: 0.43845975399017334\n",
      "test epoch: 9/11, round: 114/501, loss: 0.4411129653453827\n",
      "test epoch: 9/11, round: 115/501, loss: 0.31411677598953247\n",
      "test epoch: 9/11, round: 116/501, loss: 0.34932053089141846\n",
      "test epoch: 9/11, round: 117/501, loss: 0.3839200437068939\n",
      "test epoch: 9/11, round: 118/501, loss: 0.3146525025367737\n",
      "test epoch: 9/11, round: 119/501, loss: 0.27421173453330994\n",
      "test epoch: 9/11, round: 120/501, loss: 0.35524648427963257\n",
      "test epoch: 9/11, round: 121/501, loss: 0.37592461705207825\n",
      "test epoch: 9/11, round: 122/501, loss: 0.3774259686470032\n",
      "test epoch: 9/11, round: 123/501, loss: 0.41130530834198\n",
      "test epoch: 9/11, round: 124/501, loss: 0.6516680121421814\n",
      "test epoch: 9/11, round: 125/501, loss: 0.4774147570133209\n",
      "test epoch: 9/11, round: 126/501, loss: 0.3763810396194458\n",
      "test epoch: 9/11, round: 127/501, loss: 0.4184924364089966\n",
      "test epoch: 9/11, round: 128/501, loss: 0.18511532247066498\n",
      "test epoch: 9/11, round: 129/501, loss: 0.38429373502731323\n",
      "test epoch: 9/11, round: 130/501, loss: 0.8733697533607483\n",
      "test epoch: 9/11, round: 131/501, loss: 0.583055317401886\n",
      "test epoch: 9/11, round: 132/501, loss: 0.49845704436302185\n",
      "test epoch: 9/11, round: 133/501, loss: 0.7646006345748901\n",
      "test epoch: 9/11, round: 134/501, loss: 0.5645811557769775\n",
      "test epoch: 9/11, round: 135/501, loss: 0.29584646224975586\n",
      "test epoch: 9/11, round: 136/501, loss: 0.4117203950881958\n",
      "test epoch: 9/11, round: 137/501, loss: 0.42177125811576843\n",
      "test epoch: 9/11, round: 138/501, loss: 0.33623647689819336\n",
      "test epoch: 9/11, round: 139/501, loss: 0.5367389917373657\n",
      "test epoch: 9/11, round: 140/501, loss: 0.5109842419624329\n",
      "test epoch: 9/11, round: 141/501, loss: 0.34663456678390503\n",
      "test epoch: 9/11, round: 142/501, loss: 0.5940440893173218\n",
      "test epoch: 9/11, round: 143/501, loss: 0.39025846123695374\n",
      "test epoch: 9/11, round: 144/501, loss: 0.507197380065918\n",
      "test epoch: 9/11, round: 145/501, loss: 0.31245186924934387\n",
      "test epoch: 9/11, round: 146/501, loss: 0.5648952126502991\n",
      "test epoch: 9/11, round: 147/501, loss: 0.5608987808227539\n",
      "test epoch: 9/11, round: 148/501, loss: 0.5488203763961792\n",
      "test epoch: 9/11, round: 149/501, loss: 0.32101699709892273\n",
      "test epoch: 9/11, round: 150/501, loss: 0.6114047765731812\n",
      "test epoch: 9/11, round: 151/501, loss: 0.3156939446926117\n",
      "test epoch: 9/11, round: 152/501, loss: 0.5357873439788818\n",
      "test epoch: 9/11, round: 153/501, loss: 0.5314613580703735\n",
      "test epoch: 9/11, round: 154/501, loss: 0.5881717205047607\n",
      "test epoch: 9/11, round: 155/501, loss: 0.3820997178554535\n",
      "test epoch: 9/11, round: 156/501, loss: 0.3080405592918396\n",
      "test epoch: 9/11, round: 157/501, loss: 0.28428924083709717\n",
      "test epoch: 9/11, round: 158/501, loss: 0.4224390983581543\n",
      "test epoch: 9/11, round: 159/501, loss: 0.3672093152999878\n",
      "test epoch: 9/11, round: 160/501, loss: 0.45362988114356995\n",
      "test epoch: 9/11, round: 161/501, loss: 0.3653918504714966\n",
      "test epoch: 9/11, round: 162/501, loss: 0.3751874268054962\n",
      "test epoch: 9/11, round: 163/501, loss: 0.4710502624511719\n",
      "test epoch: 9/11, round: 164/501, loss: 0.4453207552433014\n",
      "test epoch: 9/11, round: 165/501, loss: 0.4904252886772156\n",
      "test epoch: 9/11, round: 166/501, loss: 0.34378841519355774\n",
      "test epoch: 9/11, round: 167/501, loss: 0.24716107547283173\n",
      "test epoch: 9/11, round: 168/501, loss: 0.17906178534030914\n",
      "test epoch: 9/11, round: 169/501, loss: 0.3920038938522339\n",
      "test epoch: 9/11, round: 170/501, loss: 0.31790032982826233\n",
      "test epoch: 9/11, round: 171/501, loss: 0.4424319565296173\n",
      "test epoch: 9/11, round: 172/501, loss: 0.5942037105560303\n",
      "test epoch: 9/11, round: 173/501, loss: 0.2506888806819916\n",
      "test epoch: 9/11, round: 174/501, loss: 0.5642277002334595\n",
      "test epoch: 9/11, round: 175/501, loss: 0.2646137773990631\n",
      "test epoch: 9/11, round: 176/501, loss: 0.5283116698265076\n",
      "test epoch: 9/11, round: 177/501, loss: 0.3250664472579956\n",
      "test epoch: 9/11, round: 178/501, loss: 0.21500733494758606\n",
      "test epoch: 9/11, round: 179/501, loss: 0.24992771446704865\n",
      "test epoch: 9/11, round: 180/501, loss: 0.2990812361240387\n",
      "test epoch: 9/11, round: 181/501, loss: 0.57123863697052\n",
      "test epoch: 9/11, round: 182/501, loss: 0.5351800918579102\n",
      "test epoch: 9/11, round: 183/501, loss: 0.40888702869415283\n",
      "test epoch: 9/11, round: 184/501, loss: 0.5805572271347046\n",
      "test epoch: 9/11, round: 185/501, loss: 0.4331240952014923\n",
      "test epoch: 9/11, round: 186/501, loss: 0.5919380784034729\n",
      "test epoch: 9/11, round: 187/501, loss: 0.5340699553489685\n",
      "test epoch: 9/11, round: 188/501, loss: 0.506135106086731\n",
      "test epoch: 9/11, round: 189/501, loss: 0.5328264832496643\n",
      "test epoch: 9/11, round: 190/501, loss: 0.4454358220100403\n",
      "test epoch: 9/11, round: 191/501, loss: 0.4276055693626404\n",
      "test epoch: 9/11, round: 192/501, loss: 0.5660344362258911\n",
      "test epoch: 9/11, round: 193/501, loss: 0.5848507285118103\n",
      "test epoch: 9/11, round: 194/501, loss: 0.3899801969528198\n",
      "test epoch: 9/11, round: 195/501, loss: 0.5547376871109009\n",
      "test epoch: 9/11, round: 196/501, loss: 0.26412948966026306\n",
      "test epoch: 9/11, round: 197/501, loss: 0.4865753948688507\n",
      "test epoch: 9/11, round: 198/501, loss: 0.6186696887016296\n",
      "test epoch: 9/11, round: 199/501, loss: 0.4627777338027954\n",
      "test epoch: 9/11, round: 200/501, loss: 0.7765050530433655\n",
      "test epoch: 9/11, round: 201/501, loss: 0.31849780678749084\n",
      "test epoch: 9/11, round: 202/501, loss: 0.3671654760837555\n",
      "test epoch: 9/11, round: 203/501, loss: 0.5248861312866211\n",
      "test epoch: 9/11, round: 204/501, loss: 0.6230043768882751\n",
      "test epoch: 9/11, round: 205/501, loss: 0.38960132002830505\n",
      "test epoch: 9/11, round: 206/501, loss: 0.23325854539871216\n",
      "test epoch: 9/11, round: 207/501, loss: 0.2884698212146759\n",
      "test epoch: 9/11, round: 208/501, loss: 0.4972551465034485\n",
      "test epoch: 9/11, round: 209/501, loss: 0.2942257523536682\n",
      "test epoch: 9/11, round: 210/501, loss: 0.4985349774360657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 9/11, round: 211/501, loss: 0.22719551622867584\n",
      "test epoch: 9/11, round: 212/501, loss: 0.3396424353122711\n",
      "test epoch: 9/11, round: 213/501, loss: 0.292483925819397\n",
      "test epoch: 9/11, round: 214/501, loss: 0.18633539974689484\n",
      "test epoch: 9/11, round: 215/501, loss: 0.1487591713666916\n",
      "test epoch: 9/11, round: 216/501, loss: 0.17514531314373016\n",
      "test epoch: 9/11, round: 217/501, loss: 0.13121336698532104\n",
      "test epoch: 9/11, round: 218/501, loss: 0.1624203622341156\n",
      "test epoch: 9/11, round: 219/501, loss: 0.19160090386867523\n",
      "test epoch: 9/11, round: 220/501, loss: 0.36870893836021423\n",
      "test epoch: 9/11, round: 221/501, loss: 0.3683727979660034\n",
      "test epoch: 9/11, round: 222/501, loss: 0.1343715339899063\n",
      "test epoch: 9/11, round: 223/501, loss: 0.13989944756031036\n",
      "test epoch: 9/11, round: 224/501, loss: 0.16207905113697052\n",
      "test epoch: 9/11, round: 225/501, loss: 0.15399035811424255\n",
      "test epoch: 9/11, round: 226/501, loss: 0.1483784317970276\n",
      "test epoch: 9/11, round: 227/501, loss: 0.18670281767845154\n",
      "test epoch: 9/11, round: 228/501, loss: 0.18187099695205688\n",
      "test epoch: 9/11, round: 229/501, loss: 0.3851683735847473\n",
      "test epoch: 9/11, round: 230/501, loss: 0.2882910370826721\n",
      "test epoch: 9/11, round: 231/501, loss: 0.22070354223251343\n",
      "test epoch: 9/11, round: 232/501, loss: 0.4576959013938904\n",
      "test epoch: 9/11, round: 233/501, loss: 0.6574738025665283\n",
      "test epoch: 9/11, round: 234/501, loss: 0.4849582612514496\n",
      "test epoch: 9/11, round: 235/501, loss: 0.2766372859477997\n",
      "test epoch: 9/11, round: 236/501, loss: 0.3156645596027374\n",
      "test epoch: 9/11, round: 237/501, loss: 0.32789120078086853\n",
      "test epoch: 9/11, round: 238/501, loss: 0.4234817624092102\n",
      "test epoch: 9/11, round: 239/501, loss: 0.42148521542549133\n",
      "test epoch: 9/11, round: 240/501, loss: 0.20367850363254547\n",
      "test epoch: 9/11, round: 241/501, loss: 0.3563944697380066\n",
      "test epoch: 9/11, round: 242/501, loss: 0.30245494842529297\n",
      "test epoch: 9/11, round: 243/501, loss: 0.23775456845760345\n",
      "test epoch: 9/11, round: 244/501, loss: 0.33329761028289795\n",
      "test epoch: 9/11, round: 245/501, loss: 0.4035088121891022\n",
      "test epoch: 9/11, round: 246/501, loss: 0.45318034291267395\n",
      "test epoch: 9/11, round: 247/501, loss: 0.4192848205566406\n",
      "test epoch: 9/11, round: 248/501, loss: 0.23369622230529785\n",
      "test epoch: 9/11, round: 249/501, loss: 0.2526540160179138\n",
      "test epoch: 9/11, round: 250/501, loss: 0.31057676672935486\n",
      "test epoch: 9/11, round: 251/501, loss: 0.29605764150619507\n",
      "test epoch: 9/11, round: 252/501, loss: 0.3255811035633087\n",
      "test epoch: 9/11, round: 253/501, loss: 0.3218834698200226\n",
      "test epoch: 9/11, round: 254/501, loss: 0.2690030038356781\n",
      "test epoch: 9/11, round: 255/501, loss: 0.30574244260787964\n",
      "test epoch: 9/11, round: 256/501, loss: 0.47525304555892944\n",
      "test epoch: 9/11, round: 257/501, loss: 0.37296056747436523\n",
      "test epoch: 9/11, round: 258/501, loss: 0.44367048144340515\n",
      "test epoch: 9/11, round: 259/501, loss: 0.23191522061824799\n",
      "test epoch: 9/11, round: 260/501, loss: 0.4887058138847351\n",
      "test epoch: 9/11, round: 261/501, loss: 0.6216501593589783\n",
      "test epoch: 9/11, round: 262/501, loss: 0.4502681791782379\n",
      "test epoch: 9/11, round: 263/501, loss: 0.3367535173892975\n",
      "test epoch: 9/11, round: 264/501, loss: 0.4815841019153595\n",
      "test epoch: 9/11, round: 265/501, loss: 0.5649983882904053\n",
      "test epoch: 9/11, round: 266/501, loss: 0.34310290217399597\n",
      "test epoch: 9/11, round: 267/501, loss: 0.4182973802089691\n",
      "test epoch: 9/11, round: 268/501, loss: 0.22748228907585144\n",
      "test epoch: 9/11, round: 269/501, loss: 0.5104123950004578\n",
      "test epoch: 9/11, round: 270/501, loss: 0.2601056396961212\n",
      "test epoch: 9/11, round: 271/501, loss: 0.595059335231781\n",
      "test epoch: 9/11, round: 272/501, loss: 0.4017718732357025\n",
      "test epoch: 9/11, round: 273/501, loss: 0.3379603922367096\n",
      "test epoch: 9/11, round: 274/501, loss: 0.44684654474258423\n",
      "test epoch: 9/11, round: 275/501, loss: 0.29919853806495667\n",
      "test epoch: 9/11, round: 276/501, loss: 0.39348354935646057\n",
      "test epoch: 9/11, round: 277/501, loss: 0.33451950550079346\n",
      "test epoch: 9/11, round: 278/501, loss: 0.5860139727592468\n",
      "test epoch: 9/11, round: 279/501, loss: 0.3537091016769409\n",
      "test epoch: 9/11, round: 280/501, loss: 0.20393531024456024\n",
      "test epoch: 9/11, round: 281/501, loss: 0.14946672320365906\n",
      "test epoch: 9/11, round: 282/501, loss: 0.3109460771083832\n",
      "test epoch: 9/11, round: 283/501, loss: 0.2608795464038849\n",
      "test epoch: 9/11, round: 284/501, loss: 0.38885498046875\n",
      "test epoch: 9/11, round: 285/501, loss: 0.42569202184677124\n",
      "test epoch: 9/11, round: 286/501, loss: 0.41007199883461\n",
      "test epoch: 9/11, round: 287/501, loss: 0.5640885233879089\n",
      "test epoch: 9/11, round: 288/501, loss: 0.22171393036842346\n",
      "test epoch: 9/11, round: 289/501, loss: 0.34107324481010437\n",
      "test epoch: 9/11, round: 290/501, loss: 0.2647559940814972\n",
      "test epoch: 9/11, round: 291/501, loss: 0.5089772343635559\n",
      "test epoch: 9/11, round: 292/501, loss: 0.461569219827652\n",
      "test epoch: 9/11, round: 293/501, loss: 0.5532770752906799\n",
      "test epoch: 9/11, round: 294/501, loss: 0.22738268971443176\n",
      "test epoch: 9/11, round: 295/501, loss: 0.3088131546974182\n",
      "test epoch: 9/11, round: 296/501, loss: 0.4126635789871216\n",
      "test epoch: 9/11, round: 297/501, loss: 0.387978732585907\n",
      "test epoch: 9/11, round: 298/501, loss: 0.5206510424613953\n",
      "test epoch: 9/11, round: 299/501, loss: 0.39702051877975464\n",
      "test epoch: 9/11, round: 300/501, loss: 0.5487728714942932\n",
      "test epoch: 9/11, round: 301/501, loss: 0.385282427072525\n",
      "test epoch: 9/11, round: 302/501, loss: 0.20029433071613312\n",
      "test epoch: 9/11, round: 303/501, loss: 0.6164234280586243\n",
      "test epoch: 9/11, round: 304/501, loss: 0.6234789490699768\n",
      "test epoch: 9/11, round: 305/501, loss: 0.2030649483203888\n",
      "test epoch: 9/11, round: 306/501, loss: 0.2780422866344452\n",
      "test epoch: 9/11, round: 307/501, loss: 0.4717510938644409\n",
      "test epoch: 9/11, round: 308/501, loss: 0.25773295760154724\n",
      "test epoch: 9/11, round: 309/501, loss: 0.41821718215942383\n",
      "test epoch: 9/11, round: 310/501, loss: 0.3842828571796417\n",
      "test epoch: 9/11, round: 311/501, loss: 0.668599009513855\n",
      "test epoch: 9/11, round: 312/501, loss: 0.36872872710227966\n",
      "test epoch: 9/11, round: 313/501, loss: 0.33634576201438904\n",
      "test epoch: 9/11, round: 314/501, loss: 0.3330114781856537\n",
      "test epoch: 9/11, round: 315/501, loss: 0.28644296526908875\n",
      "test epoch: 9/11, round: 316/501, loss: 0.32727012038230896\n",
      "test epoch: 9/11, round: 317/501, loss: 0.29906970262527466\n",
      "test epoch: 9/11, round: 318/501, loss: 0.37895265221595764\n",
      "test epoch: 9/11, round: 319/501, loss: 0.6129855513572693\n",
      "test epoch: 9/11, round: 320/501, loss: 0.4201681315898895\n",
      "test epoch: 9/11, round: 321/501, loss: 0.3889216184616089\n",
      "test epoch: 9/11, round: 322/501, loss: 0.4464775621891022\n",
      "test epoch: 9/11, round: 323/501, loss: 0.42621296644210815\n",
      "test epoch: 9/11, round: 324/501, loss: 0.2946816682815552\n",
      "test epoch: 9/11, round: 325/501, loss: 0.4808940291404724\n",
      "test epoch: 9/11, round: 326/501, loss: 0.5142917633056641\n",
      "test epoch: 9/11, round: 327/501, loss: 0.6316947937011719\n",
      "test epoch: 9/11, round: 328/501, loss: 0.1948608011007309\n",
      "test epoch: 9/11, round: 329/501, loss: 0.40695443749427795\n",
      "test epoch: 9/11, round: 330/501, loss: 0.47946879267692566\n",
      "test epoch: 9/11, round: 331/501, loss: 0.39972081780433655\n",
      "test epoch: 9/11, round: 332/501, loss: 0.301827996969223\n",
      "test epoch: 9/11, round: 333/501, loss: 0.4192677140235901\n",
      "test epoch: 9/11, round: 334/501, loss: 0.19351650774478912\n",
      "test epoch: 9/11, round: 335/501, loss: 0.38489505648612976\n",
      "test epoch: 9/11, round: 336/501, loss: 0.29901859164237976\n",
      "test epoch: 9/11, round: 337/501, loss: 0.6270503997802734\n",
      "test epoch: 9/11, round: 338/501, loss: 0.3304922878742218\n",
      "test epoch: 9/11, round: 339/501, loss: 0.7922515869140625\n",
      "test epoch: 9/11, round: 340/501, loss: 0.45294424891471863\n",
      "test epoch: 9/11, round: 341/501, loss: 0.391899436712265\n",
      "test epoch: 9/11, round: 342/501, loss: 0.38179704546928406\n",
      "test epoch: 9/11, round: 343/501, loss: 0.3326563537120819\n",
      "test epoch: 9/11, round: 344/501, loss: 0.2511025071144104\n",
      "test epoch: 9/11, round: 345/501, loss: 0.19456025958061218\n",
      "test epoch: 9/11, round: 346/501, loss: 0.3182017207145691\n",
      "test epoch: 9/11, round: 347/501, loss: 0.28153595328330994\n",
      "test epoch: 9/11, round: 348/501, loss: 0.39055633544921875\n",
      "test epoch: 9/11, round: 349/501, loss: 0.3440254032611847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 9/11, round: 350/501, loss: 0.4946048855781555\n",
      "test epoch: 9/11, round: 351/501, loss: 0.4306195080280304\n",
      "test epoch: 9/11, round: 352/501, loss: 0.5297902226448059\n",
      "test epoch: 9/11, round: 353/501, loss: 0.28692346811294556\n",
      "test epoch: 9/11, round: 354/501, loss: 0.5757653713226318\n",
      "test epoch: 9/11, round: 355/501, loss: 0.45131778717041016\n",
      "test epoch: 9/11, round: 356/501, loss: 0.6227929592132568\n",
      "test epoch: 9/11, round: 357/501, loss: 0.44398149847984314\n",
      "test epoch: 9/11, round: 358/501, loss: 0.30787956714630127\n",
      "test epoch: 9/11, round: 359/501, loss: 0.3127923309803009\n",
      "test epoch: 9/11, round: 360/501, loss: 0.5860941410064697\n",
      "test epoch: 9/11, round: 361/501, loss: 0.5783873796463013\n",
      "test epoch: 9/11, round: 362/501, loss: 0.3343859314918518\n",
      "test epoch: 9/11, round: 363/501, loss: 0.4855349361896515\n",
      "test epoch: 9/11, round: 364/501, loss: 0.5174797773361206\n",
      "test epoch: 9/11, round: 365/501, loss: 0.4076535999774933\n",
      "test epoch: 9/11, round: 366/501, loss: 0.5309493541717529\n",
      "test epoch: 9/11, round: 367/501, loss: 0.7336333990097046\n",
      "test epoch: 9/11, round: 368/501, loss: 0.3194102644920349\n",
      "test epoch: 9/11, round: 369/501, loss: 0.37226390838623047\n",
      "test epoch: 9/11, round: 370/501, loss: 0.35932132601737976\n",
      "test epoch: 9/11, round: 371/501, loss: 0.4083852767944336\n",
      "test epoch: 9/11, round: 372/501, loss: 0.3938242793083191\n",
      "test epoch: 9/11, round: 373/501, loss: 0.48895496129989624\n",
      "test epoch: 9/11, round: 374/501, loss: 0.29704681038856506\n",
      "test epoch: 9/11, round: 375/501, loss: 0.5077558159828186\n",
      "test epoch: 9/11, round: 376/501, loss: 0.520638644695282\n",
      "test epoch: 9/11, round: 377/501, loss: 0.10888008773326874\n",
      "test epoch: 9/11, round: 378/501, loss: 0.17114229500293732\n",
      "test epoch: 9/11, round: 379/501, loss: 0.4080706238746643\n",
      "test epoch: 9/11, round: 380/501, loss: 0.27933040261268616\n",
      "test epoch: 9/11, round: 381/501, loss: 0.45715591311454773\n",
      "test epoch: 9/11, round: 382/501, loss: 0.25877153873443604\n",
      "test epoch: 9/11, round: 383/501, loss: 0.3656538426876068\n",
      "test epoch: 9/11, round: 384/501, loss: 0.2393757849931717\n",
      "test epoch: 9/11, round: 385/501, loss: 0.5640257000923157\n",
      "test epoch: 9/11, round: 386/501, loss: 0.5833909511566162\n",
      "test epoch: 9/11, round: 387/501, loss: 0.2230803519487381\n",
      "test epoch: 9/11, round: 388/501, loss: 0.2781185507774353\n",
      "test epoch: 9/11, round: 389/501, loss: 0.3657025694847107\n",
      "test epoch: 9/11, round: 390/501, loss: 0.4615752398967743\n",
      "test epoch: 9/11, round: 391/501, loss: 0.41885480284690857\n",
      "test epoch: 9/11, round: 392/501, loss: 0.5624561309814453\n",
      "test epoch: 9/11, round: 393/501, loss: 0.3515144884586334\n",
      "test epoch: 9/11, round: 394/501, loss: 0.7080960869789124\n",
      "test epoch: 9/11, round: 395/501, loss: 0.2551439106464386\n",
      "test epoch: 9/11, round: 396/501, loss: 0.45067423582077026\n",
      "test epoch: 9/11, round: 397/501, loss: 0.49730604887008667\n",
      "test epoch: 9/11, round: 398/501, loss: 0.4973955750465393\n",
      "test epoch: 9/11, round: 399/501, loss: 0.29396140575408936\n",
      "test epoch: 9/11, round: 400/501, loss: 0.32379627227783203\n",
      "test epoch: 9/11, round: 401/501, loss: 0.5900768041610718\n",
      "test epoch: 9/11, round: 402/501, loss: 0.41305291652679443\n",
      "test epoch: 9/11, round: 403/501, loss: 0.30733945965766907\n",
      "test epoch: 9/11, round: 404/501, loss: 0.2332441508769989\n",
      "test epoch: 9/11, round: 405/501, loss: 0.7650441527366638\n",
      "test epoch: 9/11, round: 406/501, loss: 0.42350319027900696\n",
      "test epoch: 9/11, round: 407/501, loss: 0.46370556950569153\n",
      "test epoch: 9/11, round: 408/501, loss: 0.4823119342327118\n",
      "test epoch: 9/11, round: 409/501, loss: 0.5651222467422485\n",
      "test epoch: 9/11, round: 410/501, loss: 0.3845657706260681\n",
      "test epoch: 9/11, round: 411/501, loss: 0.4276253879070282\n",
      "test epoch: 9/11, round: 412/501, loss: 0.41486719250679016\n",
      "test epoch: 9/11, round: 413/501, loss: 0.48117274045944214\n",
      "test epoch: 9/11, round: 414/501, loss: 0.31443846225738525\n",
      "test epoch: 9/11, round: 415/501, loss: 0.33024299144744873\n",
      "test epoch: 9/11, round: 416/501, loss: 0.38469213247299194\n",
      "test epoch: 9/11, round: 417/501, loss: 0.24109302461147308\n",
      "test epoch: 9/11, round: 418/501, loss: 0.3417584002017975\n",
      "test epoch: 9/11, round: 419/501, loss: 0.4301395118236542\n",
      "test epoch: 9/11, round: 420/501, loss: 0.3308120667934418\n",
      "test epoch: 9/11, round: 421/501, loss: 0.4049016237258911\n",
      "test epoch: 9/11, round: 422/501, loss: 0.42222487926483154\n",
      "test epoch: 9/11, round: 423/501, loss: 0.7380381226539612\n",
      "test epoch: 9/11, round: 424/501, loss: 0.42533063888549805\n",
      "test epoch: 9/11, round: 425/501, loss: 0.27570614218711853\n",
      "test epoch: 9/11, round: 426/501, loss: 0.4847923219203949\n",
      "test epoch: 9/11, round: 427/501, loss: 0.29166725277900696\n",
      "test epoch: 9/11, round: 428/501, loss: 0.6064968705177307\n",
      "test epoch: 9/11, round: 429/501, loss: 0.6745807528495789\n",
      "test epoch: 9/11, round: 430/501, loss: 0.6262381076812744\n",
      "test epoch: 9/11, round: 431/501, loss: 0.45078855752944946\n",
      "test epoch: 9/11, round: 432/501, loss: 0.33869120478630066\n",
      "test epoch: 9/11, round: 433/501, loss: 0.33650290966033936\n",
      "test epoch: 9/11, round: 434/501, loss: 0.32173606753349304\n",
      "test epoch: 9/11, round: 435/501, loss: 0.3140142560005188\n",
      "test epoch: 9/11, round: 436/501, loss: 0.32880541682243347\n",
      "test epoch: 9/11, round: 437/501, loss: 0.49012431502342224\n",
      "test epoch: 9/11, round: 438/501, loss: 0.6262477040290833\n",
      "test epoch: 9/11, round: 439/501, loss: 0.3644145429134369\n",
      "test epoch: 9/11, round: 440/501, loss: 0.4248593747615814\n",
      "test epoch: 9/11, round: 441/501, loss: 0.5038167834281921\n",
      "test epoch: 9/11, round: 442/501, loss: 0.3076888918876648\n",
      "test epoch: 9/11, round: 443/501, loss: 0.21141216158866882\n",
      "test epoch: 9/11, round: 444/501, loss: 0.446498304605484\n",
      "test epoch: 9/11, round: 445/501, loss: 0.3797435462474823\n",
      "test epoch: 9/11, round: 446/501, loss: 0.5021296143531799\n",
      "test epoch: 9/11, round: 447/501, loss: 0.2067817747592926\n",
      "test epoch: 9/11, round: 448/501, loss: 0.38368505239486694\n",
      "test epoch: 9/11, round: 449/501, loss: 0.18859459459781647\n",
      "test epoch: 9/11, round: 450/501, loss: 0.7920186519622803\n",
      "test epoch: 9/11, round: 451/501, loss: 0.397577166557312\n",
      "test epoch: 9/11, round: 452/501, loss: 0.39926597476005554\n",
      "test epoch: 9/11, round: 453/501, loss: 0.18440739810466766\n",
      "test epoch: 9/11, round: 454/501, loss: 0.22831913828849792\n",
      "test epoch: 9/11, round: 455/501, loss: 0.46725204586982727\n",
      "test epoch: 9/11, round: 456/501, loss: 0.2796212434768677\n",
      "test epoch: 9/11, round: 457/501, loss: 0.25400790572166443\n",
      "test epoch: 9/11, round: 458/501, loss: 0.2942475974559784\n",
      "test epoch: 9/11, round: 459/501, loss: 0.18386739492416382\n",
      "test epoch: 9/11, round: 460/501, loss: 0.1258334368467331\n",
      "test epoch: 9/11, round: 461/501, loss: 0.13837404549121857\n",
      "test epoch: 9/11, round: 462/501, loss: 0.11847653239965439\n",
      "test epoch: 9/11, round: 463/501, loss: 0.12643979489803314\n",
      "test epoch: 9/11, round: 464/501, loss: 0.14485718309879303\n",
      "test epoch: 9/11, round: 465/501, loss: 0.162923201918602\n",
      "test epoch: 9/11, round: 466/501, loss: 0.1322767585515976\n",
      "test epoch: 9/11, round: 467/501, loss: 0.18028394877910614\n",
      "test epoch: 9/11, round: 468/501, loss: 0.15279480814933777\n",
      "test epoch: 9/11, round: 469/501, loss: 0.16220246255397797\n",
      "test epoch: 9/11, round: 470/501, loss: 0.13960959017276764\n",
      "test epoch: 9/11, round: 471/501, loss: 0.16238412261009216\n",
      "test epoch: 9/11, round: 472/501, loss: 0.16370058059692383\n",
      "test epoch: 9/11, round: 473/501, loss: 0.13685506582260132\n",
      "test epoch: 9/11, round: 474/501, loss: 0.1545625478029251\n",
      "test epoch: 9/11, round: 475/501, loss: 0.17773136496543884\n",
      "test epoch: 9/11, round: 476/501, loss: 0.10616881400346756\n",
      "test epoch: 9/11, round: 477/501, loss: 0.10435811430215836\n",
      "test epoch: 9/11, round: 478/501, loss: 0.13826633989810944\n",
      "test epoch: 9/11, round: 479/501, loss: 0.10982762277126312\n",
      "test epoch: 9/11, round: 480/501, loss: 0.13028216361999512\n",
      "test epoch: 9/11, round: 481/501, loss: 0.14403389394283295\n",
      "test epoch: 9/11, round: 482/501, loss: 0.12349280714988708\n",
      "test epoch: 9/11, round: 483/501, loss: 0.18499375879764557\n",
      "test epoch: 9/11, round: 484/501, loss: 0.1083013117313385\n",
      "test epoch: 9/11, round: 485/501, loss: 0.13868077099323273\n",
      "test epoch: 9/11, round: 486/501, loss: 0.14969119429588318\n",
      "test epoch: 9/11, round: 487/501, loss: 0.1350127011537552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 9/11, round: 488/501, loss: 0.1593913435935974\n",
      "test epoch: 9/11, round: 489/501, loss: 0.12427614629268646\n",
      "test epoch: 9/11, round: 490/501, loss: 0.12423125654459\n",
      "test epoch: 9/11, round: 491/501, loss: 0.13611634075641632\n",
      "test epoch: 9/11, round: 492/501, loss: 0.1329890638589859\n",
      "test epoch: 9/11, round: 493/501, loss: 0.15182138979434967\n",
      "test epoch: 9/11, round: 494/501, loss: 0.13030706346035004\n",
      "test epoch: 9/11, round: 495/501, loss: 0.13041549921035767\n",
      "test epoch: 9/11, round: 496/501, loss: 0.13885392248630524\n",
      "test epoch: 9/11, round: 497/501, loss: 0.14307273924350739\n",
      "test epoch: 9/11, round: 498/501, loss: 0.11368376761674881\n",
      "test epoch: 9/11, round: 499/501, loss: 0.13671328127384186\n",
      "test epoch: 9/11, round: 500/501, loss: 0.3536599576473236\n",
      "test epoch: 9/11, round: 501/501, loss: 0.9928697347640991\n",
      "test epoch: 9/11, KS: 0.1768366074561895, ROC: 0.6202927297299314\n",
      "cost time: 1991\n",
      "train epoch: 10/11, round: 1/532, loss: 0.3221726417541504\n",
      "train epoch: 10/11, round: 2/532, loss: 0.3278675079345703\n",
      "train epoch: 10/11, round: 3/532, loss: 0.3981000781059265\n",
      "train epoch: 10/11, round: 4/532, loss: 0.38624635338783264\n",
      "train epoch: 10/11, round: 5/532, loss: 0.3558739721775055\n",
      "train epoch: 10/11, round: 6/532, loss: 0.3593776822090149\n",
      "train epoch: 10/11, round: 7/532, loss: 0.37868794798851013\n",
      "train epoch: 10/11, round: 8/532, loss: 0.33160069584846497\n",
      "train epoch: 10/11, round: 9/532, loss: 0.3737112879753113\n",
      "train epoch: 10/11, round: 10/532, loss: 0.37543848156929016\n",
      "train epoch: 10/11, round: 11/532, loss: 0.4026103913784027\n",
      "train epoch: 10/11, round: 12/532, loss: 0.34270039200782776\n",
      "train epoch: 10/11, round: 13/532, loss: 0.3444369435310364\n",
      "train epoch: 10/11, round: 14/532, loss: 0.3212229609489441\n",
      "train epoch: 10/11, round: 15/532, loss: 0.4514680504798889\n",
      "train epoch: 10/11, round: 16/532, loss: 0.3509894609451294\n",
      "train epoch: 10/11, round: 17/532, loss: 0.3590634763240814\n",
      "train epoch: 10/11, round: 18/532, loss: 0.3091704845428467\n",
      "train epoch: 10/11, round: 19/532, loss: 0.3276345431804657\n",
      "train epoch: 10/11, round: 20/532, loss: 0.34628933668136597\n",
      "train epoch: 10/11, round: 21/532, loss: 0.3907567858695984\n",
      "train epoch: 10/11, round: 22/532, loss: 0.3190200924873352\n",
      "train epoch: 10/11, round: 23/532, loss: 0.3359786570072174\n",
      "train epoch: 10/11, round: 24/532, loss: 0.3814316391944885\n",
      "train epoch: 10/11, round: 25/532, loss: 0.3269052505493164\n",
      "train epoch: 10/11, round: 26/532, loss: 0.34609895944595337\n",
      "train epoch: 10/11, round: 27/532, loss: 0.3231508731842041\n",
      "train epoch: 10/11, round: 28/532, loss: 0.34690266847610474\n",
      "train epoch: 10/11, round: 29/532, loss: 0.32191863656044006\n",
      "train epoch: 10/11, round: 30/532, loss: 0.2756456136703491\n",
      "train epoch: 10/11, round: 31/532, loss: 0.4119652807712555\n",
      "train epoch: 10/11, round: 32/532, loss: 0.27798667550086975\n",
      "train epoch: 10/11, round: 33/532, loss: 0.37309783697128296\n",
      "train epoch: 10/11, round: 34/532, loss: 0.36026692390441895\n",
      "train epoch: 10/11, round: 35/532, loss: 0.3153734803199768\n",
      "train epoch: 10/11, round: 36/532, loss: 0.4133545756340027\n",
      "train epoch: 10/11, round: 37/532, loss: 0.3542444109916687\n",
      "train epoch: 10/11, round: 38/532, loss: 0.41737455129623413\n",
      "train epoch: 10/11, round: 39/532, loss: 0.4145685136318207\n",
      "train epoch: 10/11, round: 40/532, loss: 0.3955670893192291\n",
      "train epoch: 10/11, round: 41/532, loss: 0.35369259119033813\n",
      "train epoch: 10/11, round: 42/532, loss: 0.37381812930107117\n",
      "train epoch: 10/11, round: 43/532, loss: 0.345955491065979\n",
      "train epoch: 10/11, round: 44/532, loss: 0.3022225499153137\n",
      "train epoch: 10/11, round: 45/532, loss: 0.3149980306625366\n",
      "train epoch: 10/11, round: 46/532, loss: 0.37861019372940063\n",
      "train epoch: 10/11, round: 47/532, loss: 0.36700692772865295\n",
      "train epoch: 10/11, round: 48/532, loss: 0.3839877247810364\n",
      "train epoch: 10/11, round: 49/532, loss: 0.3485170304775238\n",
      "train epoch: 10/11, round: 50/532, loss: 0.3524586856365204\n",
      "train epoch: 10/11, round: 51/532, loss: 0.3240397572517395\n",
      "train epoch: 10/11, round: 52/532, loss: 0.37179774045944214\n",
      "train epoch: 10/11, round: 53/532, loss: 0.3659777045249939\n",
      "train epoch: 10/11, round: 54/532, loss: 0.3377067446708679\n",
      "train epoch: 10/11, round: 55/532, loss: 0.2727991044521332\n",
      "train epoch: 10/11, round: 56/532, loss: 0.35773175954818726\n",
      "train epoch: 10/11, round: 57/532, loss: 0.39343398809432983\n",
      "train epoch: 10/11, round: 58/532, loss: 0.2981831133365631\n",
      "train epoch: 10/11, round: 59/532, loss: 0.3474925756454468\n",
      "train epoch: 10/11, round: 60/532, loss: 0.39358821511268616\n",
      "train epoch: 10/11, round: 61/532, loss: 0.3899497389793396\n",
      "train epoch: 10/11, round: 62/532, loss: 0.4167052209377289\n",
      "train epoch: 10/11, round: 63/532, loss: 0.375194787979126\n",
      "train epoch: 10/11, round: 64/532, loss: 0.3642616868019104\n",
      "train epoch: 10/11, round: 65/532, loss: 0.28185611963272095\n",
      "train epoch: 10/11, round: 66/532, loss: 0.38540568947792053\n",
      "train epoch: 10/11, round: 67/532, loss: 0.47428399324417114\n",
      "train epoch: 10/11, round: 68/532, loss: 0.3721137046813965\n",
      "train epoch: 10/11, round: 69/532, loss: 0.3579047918319702\n",
      "train epoch: 10/11, round: 70/532, loss: 0.3776612877845764\n",
      "train epoch: 10/11, round: 71/532, loss: 0.38384100794792175\n",
      "train epoch: 10/11, round: 72/532, loss: 0.39977192878723145\n",
      "train epoch: 10/11, round: 73/532, loss: 0.39382585883140564\n",
      "train epoch: 10/11, round: 74/532, loss: 0.3404308557510376\n",
      "train epoch: 10/11, round: 75/532, loss: 0.3958461284637451\n",
      "train epoch: 10/11, round: 76/532, loss: 0.30691713094711304\n",
      "train epoch: 10/11, round: 77/532, loss: 0.35225045680999756\n",
      "train epoch: 10/11, round: 78/532, loss: 0.35548385977745056\n",
      "train epoch: 10/11, round: 79/532, loss: 0.36256399750709534\n",
      "train epoch: 10/11, round: 80/532, loss: 0.3635164499282837\n",
      "train epoch: 10/11, round: 81/532, loss: 0.31601476669311523\n",
      "train epoch: 10/11, round: 82/532, loss: 0.43747228384017944\n",
      "train epoch: 10/11, round: 83/532, loss: 0.3713013231754303\n",
      "train epoch: 10/11, round: 84/532, loss: 0.3772837519645691\n",
      "train epoch: 10/11, round: 85/532, loss: 0.3512095510959625\n",
      "train epoch: 10/11, round: 86/532, loss: 0.3416878283023834\n",
      "train epoch: 10/11, round: 87/532, loss: 0.4098796844482422\n",
      "train epoch: 10/11, round: 88/532, loss: 0.3414479196071625\n",
      "train epoch: 10/11, round: 89/532, loss: 0.34281352162361145\n",
      "train epoch: 10/11, round: 90/532, loss: 0.43951910734176636\n",
      "train epoch: 10/11, round: 91/532, loss: 0.36535295844078064\n",
      "train epoch: 10/11, round: 92/532, loss: 0.36572813987731934\n",
      "train epoch: 10/11, round: 93/532, loss: 0.3495734632015228\n",
      "train epoch: 10/11, round: 94/532, loss: 0.40576067566871643\n",
      "train epoch: 10/11, round: 95/532, loss: 0.3260338306427002\n",
      "train epoch: 10/11, round: 96/532, loss: 0.3577190339565277\n",
      "train epoch: 10/11, round: 97/532, loss: 0.2845681607723236\n",
      "train epoch: 10/11, round: 98/532, loss: 0.3532108664512634\n",
      "train epoch: 10/11, round: 99/532, loss: 0.2797824442386627\n",
      "train epoch: 10/11, round: 100/532, loss: 0.46172085404396057\n",
      "train epoch: 10/11, round: 101/532, loss: 0.45056086778640747\n",
      "train epoch: 10/11, round: 102/532, loss: 0.27754154801368713\n",
      "train epoch: 10/11, round: 103/532, loss: 0.3518332839012146\n",
      "train epoch: 10/11, round: 104/532, loss: 0.3470092713832855\n",
      "train epoch: 10/11, round: 105/532, loss: 0.39917436242103577\n",
      "train epoch: 10/11, round: 106/532, loss: 0.3447643220424652\n",
      "train epoch: 10/11, round: 107/532, loss: 0.3543046712875366\n",
      "train epoch: 10/11, round: 108/532, loss: 0.36609604954719543\n",
      "train epoch: 10/11, round: 109/532, loss: 0.35720500349998474\n",
      "train epoch: 10/11, round: 110/532, loss: 0.3666689395904541\n",
      "train epoch: 10/11, round: 111/532, loss: 0.3609141409397125\n",
      "train epoch: 10/11, round: 112/532, loss: 0.3357263207435608\n",
      "train epoch: 10/11, round: 113/532, loss: 0.384439080953598\n",
      "train epoch: 10/11, round: 114/532, loss: 0.48945245146751404\n",
      "train epoch: 10/11, round: 115/532, loss: 0.3704618215560913\n",
      "train epoch: 10/11, round: 116/532, loss: 0.4006378650665283\n",
      "train epoch: 10/11, round: 117/532, loss: 0.4025935232639313\n",
      "train epoch: 10/11, round: 118/532, loss: 0.38717716932296753\n",
      "train epoch: 10/11, round: 119/532, loss: 0.421650230884552\n",
      "train epoch: 10/11, round: 120/532, loss: 0.41252756118774414\n",
      "train epoch: 10/11, round: 121/532, loss: 0.32956328988075256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10/11, round: 122/532, loss: 0.36744752526283264\n",
      "train epoch: 10/11, round: 123/532, loss: 0.29190510511398315\n",
      "train epoch: 10/11, round: 124/532, loss: 0.3667420744895935\n",
      "train epoch: 10/11, round: 125/532, loss: 0.45176753401756287\n",
      "train epoch: 10/11, round: 126/532, loss: 0.2506130337715149\n",
      "train epoch: 10/11, round: 127/532, loss: 0.35875529050827026\n",
      "train epoch: 10/11, round: 128/532, loss: 0.39537209272384644\n",
      "train epoch: 10/11, round: 129/532, loss: 0.3921697437763214\n",
      "train epoch: 10/11, round: 130/532, loss: 0.304521381855011\n",
      "train epoch: 10/11, round: 131/532, loss: 0.32877105474472046\n",
      "train epoch: 10/11, round: 132/532, loss: 0.3541763126850128\n",
      "train epoch: 10/11, round: 133/532, loss: 0.3563932776451111\n",
      "train epoch: 10/11, round: 134/532, loss: 0.3457697927951813\n",
      "train epoch: 10/11, round: 135/532, loss: 0.31776419281959534\n",
      "train epoch: 10/11, round: 136/532, loss: 0.34308379888534546\n",
      "train epoch: 10/11, round: 137/532, loss: 0.3367738723754883\n",
      "train epoch: 10/11, round: 138/532, loss: 0.3385157585144043\n",
      "train epoch: 10/11, round: 139/532, loss: 0.3041597306728363\n",
      "train epoch: 10/11, round: 140/532, loss: 0.31875115633010864\n",
      "train epoch: 10/11, round: 141/532, loss: 0.2529623210430145\n",
      "train epoch: 10/11, round: 142/532, loss: 0.4392644762992859\n",
      "train epoch: 10/11, round: 143/532, loss: 0.35273438692092896\n",
      "train epoch: 10/11, round: 144/532, loss: 0.3286527991294861\n",
      "train epoch: 10/11, round: 145/532, loss: 0.3855845630168915\n",
      "train epoch: 10/11, round: 146/532, loss: 0.4610872268676758\n",
      "train epoch: 10/11, round: 147/532, loss: 0.33240002393722534\n",
      "train epoch: 10/11, round: 148/532, loss: 0.4498406946659088\n",
      "train epoch: 10/11, round: 149/532, loss: 0.34192323684692383\n",
      "train epoch: 10/11, round: 150/532, loss: 0.45400911569595337\n",
      "train epoch: 10/11, round: 151/532, loss: 0.40093064308166504\n",
      "train epoch: 10/11, round: 152/532, loss: 0.307395875453949\n",
      "train epoch: 10/11, round: 153/532, loss: 0.4123400151729584\n",
      "train epoch: 10/11, round: 154/532, loss: 0.3452790677547455\n",
      "train epoch: 10/11, round: 155/532, loss: 0.385141521692276\n",
      "train epoch: 10/11, round: 156/532, loss: 0.38106709718704224\n",
      "train epoch: 10/11, round: 157/532, loss: 0.3412277102470398\n",
      "train epoch: 10/11, round: 158/532, loss: 0.3413723409175873\n",
      "train epoch: 10/11, round: 159/532, loss: 0.3868985176086426\n",
      "train epoch: 10/11, round: 160/532, loss: 0.4136843681335449\n",
      "train epoch: 10/11, round: 161/532, loss: 0.3754798173904419\n",
      "train epoch: 10/11, round: 162/532, loss: 0.31336456537246704\n",
      "train epoch: 10/11, round: 163/532, loss: 0.4348892271518707\n",
      "train epoch: 10/11, round: 164/532, loss: 0.4044480323791504\n",
      "train epoch: 10/11, round: 165/532, loss: 0.3240293860435486\n",
      "train epoch: 10/11, round: 166/532, loss: 0.36375778913497925\n",
      "train epoch: 10/11, round: 167/532, loss: 0.3882419764995575\n",
      "train epoch: 10/11, round: 168/532, loss: 0.3799970746040344\n",
      "train epoch: 10/11, round: 169/532, loss: 0.3545762598514557\n",
      "train epoch: 10/11, round: 170/532, loss: 0.3484010100364685\n",
      "train epoch: 10/11, round: 171/532, loss: 0.3105628788471222\n",
      "train epoch: 10/11, round: 172/532, loss: 0.5254786610603333\n",
      "train epoch: 10/11, round: 173/532, loss: 0.3394016623497009\n",
      "train epoch: 10/11, round: 174/532, loss: 0.30565571784973145\n",
      "train epoch: 10/11, round: 175/532, loss: 0.43264660239219666\n",
      "train epoch: 10/11, round: 176/532, loss: 0.3072982728481293\n",
      "train epoch: 10/11, round: 177/532, loss: 0.415856271982193\n",
      "train epoch: 10/11, round: 178/532, loss: 0.3346680998802185\n",
      "train epoch: 10/11, round: 179/532, loss: 0.39229556918144226\n",
      "train epoch: 10/11, round: 180/532, loss: 0.3005630075931549\n",
      "train epoch: 10/11, round: 181/532, loss: 0.34012269973754883\n",
      "train epoch: 10/11, round: 182/532, loss: 0.382606565952301\n",
      "train epoch: 10/11, round: 183/532, loss: 0.4135615825653076\n",
      "train epoch: 10/11, round: 184/532, loss: 0.28549113869667053\n",
      "train epoch: 10/11, round: 185/532, loss: 0.30430394411087036\n",
      "train epoch: 10/11, round: 186/532, loss: 0.3818241059780121\n",
      "train epoch: 10/11, round: 187/532, loss: 0.3460227847099304\n",
      "train epoch: 10/11, round: 188/532, loss: 0.3205929696559906\n",
      "train epoch: 10/11, round: 189/532, loss: 0.44849443435668945\n",
      "train epoch: 10/11, round: 190/532, loss: 0.42190295457839966\n",
      "train epoch: 10/11, round: 191/532, loss: 0.4368787407875061\n",
      "train epoch: 10/11, round: 192/532, loss: 0.38804665207862854\n",
      "train epoch: 10/11, round: 193/532, loss: 0.3225443363189697\n",
      "train epoch: 10/11, round: 194/532, loss: 0.3802398443222046\n",
      "train epoch: 10/11, round: 195/532, loss: 0.4119222164154053\n",
      "train epoch: 10/11, round: 196/532, loss: 0.37407881021499634\n",
      "train epoch: 10/11, round: 197/532, loss: 0.395963579416275\n",
      "train epoch: 10/11, round: 198/532, loss: 0.3446137309074402\n",
      "train epoch: 10/11, round: 199/532, loss: 0.3235819935798645\n",
      "train epoch: 10/11, round: 200/532, loss: 0.39653661847114563\n",
      "train epoch: 10/11, round: 201/532, loss: 0.45962849259376526\n",
      "train epoch: 10/11, round: 202/532, loss: 0.3341479003429413\n",
      "train epoch: 10/11, round: 203/532, loss: 0.4445646405220032\n",
      "train epoch: 10/11, round: 204/532, loss: 0.32434767484664917\n",
      "train epoch: 10/11, round: 205/532, loss: 0.3284337520599365\n",
      "train epoch: 10/11, round: 206/532, loss: 0.3205137252807617\n",
      "train epoch: 10/11, round: 207/532, loss: 0.3189263939857483\n",
      "train epoch: 10/11, round: 208/532, loss: 0.3129250109195709\n",
      "train epoch: 10/11, round: 209/532, loss: 0.33176344633102417\n",
      "train epoch: 10/11, round: 210/532, loss: 0.3191080689430237\n",
      "train epoch: 10/11, round: 211/532, loss: 0.29800206422805786\n",
      "train epoch: 10/11, round: 212/532, loss: 0.46635428071022034\n",
      "train epoch: 10/11, round: 213/532, loss: 0.3257787823677063\n",
      "train epoch: 10/11, round: 214/532, loss: 0.3056473135948181\n",
      "train epoch: 10/11, round: 215/532, loss: 0.3426603376865387\n",
      "train epoch: 10/11, round: 216/532, loss: 0.4125201106071472\n",
      "train epoch: 10/11, round: 217/532, loss: 0.4443570077419281\n",
      "train epoch: 10/11, round: 218/532, loss: 0.33396512269973755\n",
      "train epoch: 10/11, round: 219/532, loss: 0.3890799283981323\n",
      "train epoch: 10/11, round: 220/532, loss: 0.4028100371360779\n",
      "train epoch: 10/11, round: 221/532, loss: 0.39001816511154175\n",
      "train epoch: 10/11, round: 222/532, loss: 0.38100332021713257\n",
      "train epoch: 10/11, round: 223/532, loss: 0.32829463481903076\n",
      "train epoch: 10/11, round: 224/532, loss: 0.421799898147583\n",
      "train epoch: 10/11, round: 225/532, loss: 0.4315163195133209\n",
      "train epoch: 10/11, round: 226/532, loss: 0.3446813225746155\n",
      "train epoch: 10/11, round: 227/532, loss: 0.4085882306098938\n",
      "train epoch: 10/11, round: 228/532, loss: 0.34999826550483704\n",
      "train epoch: 10/11, round: 229/532, loss: 0.37334489822387695\n",
      "train epoch: 10/11, round: 230/532, loss: 0.3221307098865509\n",
      "train epoch: 10/11, round: 231/532, loss: 0.39961862564086914\n",
      "train epoch: 10/11, round: 232/532, loss: 0.37170061469078064\n",
      "train epoch: 10/11, round: 233/532, loss: 0.41954049468040466\n",
      "train epoch: 10/11, round: 234/532, loss: 0.40922456979751587\n",
      "train epoch: 10/11, round: 235/532, loss: 0.3264243006706238\n",
      "train epoch: 10/11, round: 236/532, loss: 0.3015379011631012\n",
      "train epoch: 10/11, round: 237/532, loss: 0.4054386019706726\n",
      "train epoch: 10/11, round: 238/532, loss: 0.3095599114894867\n",
      "train epoch: 10/11, round: 239/532, loss: 0.3562048375606537\n",
      "train epoch: 10/11, round: 240/532, loss: 0.39889612793922424\n",
      "train epoch: 10/11, round: 241/532, loss: 0.30906254053115845\n",
      "train epoch: 10/11, round: 242/532, loss: 0.29907113313674927\n",
      "train epoch: 10/11, round: 243/532, loss: 0.3469545841217041\n",
      "train epoch: 10/11, round: 244/532, loss: 0.40225109457969666\n",
      "train epoch: 10/11, round: 245/532, loss: 0.5088316798210144\n",
      "train epoch: 10/11, round: 246/532, loss: 0.30694738030433655\n",
      "train epoch: 10/11, round: 247/532, loss: 0.4654604494571686\n",
      "train epoch: 10/11, round: 248/532, loss: 0.40031760931015015\n",
      "train epoch: 10/11, round: 249/532, loss: 0.38714727759361267\n",
      "train epoch: 10/11, round: 250/532, loss: 0.3749316334724426\n",
      "train epoch: 10/11, round: 251/532, loss: 0.4218188226222992\n",
      "train epoch: 10/11, round: 252/532, loss: 0.2813259959220886\n",
      "train epoch: 10/11, round: 253/532, loss: 0.3357776701450348\n",
      "train epoch: 10/11, round: 254/532, loss: 0.3128046691417694\n",
      "train epoch: 10/11, round: 255/532, loss: 0.3369881510734558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10/11, round: 256/532, loss: 0.33979731798171997\n",
      "train epoch: 10/11, round: 257/532, loss: 0.31599894165992737\n",
      "train epoch: 10/11, round: 258/532, loss: 0.3778952956199646\n",
      "train epoch: 10/11, round: 259/532, loss: 0.32343822717666626\n",
      "train epoch: 10/11, round: 260/532, loss: 0.44994741678237915\n",
      "train epoch: 10/11, round: 261/532, loss: 0.3413581848144531\n",
      "train epoch: 10/11, round: 262/532, loss: 0.4066930413246155\n",
      "train epoch: 10/11, round: 263/532, loss: 0.33726203441619873\n",
      "train epoch: 10/11, round: 264/532, loss: 0.37341898679733276\n",
      "train epoch: 10/11, round: 265/532, loss: 0.32191139459609985\n",
      "train epoch: 10/11, round: 266/532, loss: 0.4151119589805603\n",
      "train epoch: 10/11, round: 267/532, loss: 0.3409990966320038\n",
      "train epoch: 10/11, round: 268/532, loss: 0.3252566456794739\n",
      "train epoch: 10/11, round: 269/532, loss: 0.40622520446777344\n",
      "train epoch: 10/11, round: 270/532, loss: 0.3523671627044678\n",
      "train epoch: 10/11, round: 271/532, loss: 0.34723779559135437\n",
      "train epoch: 10/11, round: 272/532, loss: 0.3606297969818115\n",
      "train epoch: 10/11, round: 273/532, loss: 0.2907785475254059\n",
      "train epoch: 10/11, round: 274/532, loss: 0.3494548499584198\n",
      "train epoch: 10/11, round: 275/532, loss: 0.4018568992614746\n",
      "train epoch: 10/11, round: 276/532, loss: 0.26392585039138794\n",
      "train epoch: 10/11, round: 277/532, loss: 0.3988553583621979\n",
      "train epoch: 10/11, round: 278/532, loss: 0.3824803829193115\n",
      "train epoch: 10/11, round: 279/532, loss: 0.3403535485267639\n",
      "train epoch: 10/11, round: 280/532, loss: 0.3502862751483917\n",
      "train epoch: 10/11, round: 281/532, loss: 0.4434565603733063\n",
      "train epoch: 10/11, round: 282/532, loss: 0.397821843624115\n",
      "train epoch: 10/11, round: 283/532, loss: 0.3545067310333252\n",
      "train epoch: 10/11, round: 284/532, loss: 0.35628750920295715\n",
      "train epoch: 10/11, round: 285/532, loss: 0.33435291051864624\n",
      "train epoch: 10/11, round: 286/532, loss: 0.3421420156955719\n",
      "train epoch: 10/11, round: 287/532, loss: 0.32253366708755493\n",
      "train epoch: 10/11, round: 288/532, loss: 0.38308021426200867\n",
      "train epoch: 10/11, round: 289/532, loss: 0.3645191788673401\n",
      "train epoch: 10/11, round: 290/532, loss: 0.35509711503982544\n",
      "train epoch: 10/11, round: 291/532, loss: 0.3841293156147003\n",
      "train epoch: 10/11, round: 292/532, loss: 0.32892781496047974\n",
      "train epoch: 10/11, round: 293/532, loss: 0.4188825488090515\n",
      "train epoch: 10/11, round: 294/532, loss: 0.41238847374916077\n",
      "train epoch: 10/11, round: 295/532, loss: 0.37195777893066406\n",
      "train epoch: 10/11, round: 296/532, loss: 0.35071176290512085\n",
      "train epoch: 10/11, round: 297/532, loss: 0.4652436673641205\n",
      "train epoch: 10/11, round: 298/532, loss: 0.38779816031455994\n",
      "train epoch: 10/11, round: 299/532, loss: 0.3785046935081482\n",
      "train epoch: 10/11, round: 300/532, loss: 0.2908913493156433\n",
      "train epoch: 10/11, round: 301/532, loss: 0.3639628291130066\n",
      "train epoch: 10/11, round: 302/532, loss: 0.4771574139595032\n",
      "train epoch: 10/11, round: 303/532, loss: 0.36334162950515747\n",
      "train epoch: 10/11, round: 304/532, loss: 0.3487926423549652\n",
      "train epoch: 10/11, round: 305/532, loss: 0.45057621598243713\n",
      "train epoch: 10/11, round: 306/532, loss: 0.321261465549469\n",
      "train epoch: 10/11, round: 307/532, loss: 0.4399731159210205\n",
      "train epoch: 10/11, round: 308/532, loss: 0.33781367540359497\n",
      "train epoch: 10/11, round: 309/532, loss: 0.3978804051876068\n",
      "train epoch: 10/11, round: 310/532, loss: 0.3504299223423004\n",
      "train epoch: 10/11, round: 311/532, loss: 0.40235790610313416\n",
      "train epoch: 10/11, round: 312/532, loss: 0.3120807707309723\n",
      "train epoch: 10/11, round: 313/532, loss: 0.40570229291915894\n",
      "train epoch: 10/11, round: 314/532, loss: 0.2892290949821472\n",
      "train epoch: 10/11, round: 315/532, loss: 0.34921741485595703\n",
      "train epoch: 10/11, round: 316/532, loss: 0.30690503120422363\n",
      "train epoch: 10/11, round: 317/532, loss: 0.31527575850486755\n",
      "train epoch: 10/11, round: 318/532, loss: 0.38401979207992554\n",
      "train epoch: 10/11, round: 319/532, loss: 0.46050897240638733\n",
      "train epoch: 10/11, round: 320/532, loss: 0.2998183071613312\n",
      "train epoch: 10/11, round: 321/532, loss: 0.37750592827796936\n",
      "train epoch: 10/11, round: 322/532, loss: 0.3718721866607666\n",
      "train epoch: 10/11, round: 323/532, loss: 0.35530903935432434\n",
      "train epoch: 10/11, round: 324/532, loss: 0.45902127027511597\n",
      "train epoch: 10/11, round: 325/532, loss: 0.27329474687576294\n",
      "train epoch: 10/11, round: 326/532, loss: 0.3985638916492462\n",
      "train epoch: 10/11, round: 327/532, loss: 0.3564230799674988\n",
      "train epoch: 10/11, round: 328/532, loss: 0.3366672396659851\n",
      "train epoch: 10/11, round: 329/532, loss: 0.3381870687007904\n",
      "train epoch: 10/11, round: 330/532, loss: 0.2749594748020172\n",
      "train epoch: 10/11, round: 331/532, loss: 0.3854537904262543\n",
      "train epoch: 10/11, round: 332/532, loss: 0.31201475858688354\n",
      "train epoch: 10/11, round: 333/532, loss: 0.31307023763656616\n",
      "train epoch: 10/11, round: 334/532, loss: 0.34836816787719727\n",
      "train epoch: 10/11, round: 335/532, loss: 0.4027346968650818\n",
      "train epoch: 10/11, round: 336/532, loss: 0.33441418409347534\n",
      "train epoch: 10/11, round: 337/532, loss: 0.38323336839675903\n",
      "train epoch: 10/11, round: 338/532, loss: 0.29283490777015686\n",
      "train epoch: 10/11, round: 339/532, loss: 0.3553747534751892\n",
      "train epoch: 10/11, round: 340/532, loss: 0.38892608880996704\n",
      "train epoch: 10/11, round: 341/532, loss: 0.31718382239341736\n",
      "train epoch: 10/11, round: 342/532, loss: 0.37726593017578125\n",
      "train epoch: 10/11, round: 343/532, loss: 0.42382755875587463\n",
      "train epoch: 10/11, round: 344/532, loss: 0.3243751525878906\n",
      "train epoch: 10/11, round: 345/532, loss: 0.2945771813392639\n",
      "train epoch: 10/11, round: 346/532, loss: 0.27852410078048706\n",
      "train epoch: 10/11, round: 347/532, loss: 0.28213822841644287\n",
      "train epoch: 10/11, round: 348/532, loss: 0.34989917278289795\n",
      "train epoch: 10/11, round: 349/532, loss: 0.2787649631500244\n",
      "train epoch: 10/11, round: 350/532, loss: 0.32828766107559204\n",
      "train epoch: 10/11, round: 351/532, loss: 0.4346916079521179\n",
      "train epoch: 10/11, round: 352/532, loss: 0.33699291944503784\n",
      "train epoch: 10/11, round: 353/532, loss: 0.27081745862960815\n",
      "train epoch: 10/11, round: 354/532, loss: 0.37926095724105835\n",
      "train epoch: 10/11, round: 355/532, loss: 0.24648113548755646\n",
      "train epoch: 10/11, round: 356/532, loss: 0.41135796904563904\n",
      "train epoch: 10/11, round: 357/532, loss: 0.39254212379455566\n",
      "train epoch: 10/11, round: 358/532, loss: 0.34680452942848206\n",
      "train epoch: 10/11, round: 359/532, loss: 0.4073304533958435\n",
      "train epoch: 10/11, round: 360/532, loss: 0.3465118408203125\n",
      "train epoch: 10/11, round: 361/532, loss: 0.38142091035842896\n",
      "train epoch: 10/11, round: 362/532, loss: 0.4761381149291992\n",
      "train epoch: 10/11, round: 363/532, loss: 0.36183491349220276\n",
      "train epoch: 10/11, round: 364/532, loss: 0.4078332781791687\n",
      "train epoch: 10/11, round: 365/532, loss: 0.42276182770729065\n",
      "train epoch: 10/11, round: 366/532, loss: 0.45338988304138184\n",
      "train epoch: 10/11, round: 367/532, loss: 0.41487985849380493\n",
      "train epoch: 10/11, round: 368/532, loss: 0.4083729386329651\n",
      "train epoch: 10/11, round: 369/532, loss: 0.3632776737213135\n",
      "train epoch: 10/11, round: 370/532, loss: 0.37128061056137085\n",
      "train epoch: 10/11, round: 371/532, loss: 0.3544996976852417\n",
      "train epoch: 10/11, round: 372/532, loss: 0.35142022371292114\n",
      "train epoch: 10/11, round: 373/532, loss: 0.3050258755683899\n",
      "train epoch: 10/11, round: 374/532, loss: 0.32190051674842834\n",
      "train epoch: 10/11, round: 375/532, loss: 0.4123920500278473\n",
      "train epoch: 10/11, round: 376/532, loss: 0.3716820776462555\n",
      "train epoch: 10/11, round: 377/532, loss: 0.3408970236778259\n",
      "train epoch: 10/11, round: 378/532, loss: 0.40697112679481506\n",
      "train epoch: 10/11, round: 379/532, loss: 0.4227367341518402\n",
      "train epoch: 10/11, round: 380/532, loss: 0.3333011269569397\n",
      "train epoch: 10/11, round: 381/532, loss: 0.3674786686897278\n",
      "train epoch: 10/11, round: 382/532, loss: 0.3894438147544861\n",
      "train epoch: 10/11, round: 383/532, loss: 0.48379912972450256\n",
      "train epoch: 10/11, round: 384/532, loss: 0.35742053389549255\n",
      "train epoch: 10/11, round: 385/532, loss: 0.3790457844734192\n",
      "train epoch: 10/11, round: 386/532, loss: 0.41833266615867615\n",
      "train epoch: 10/11, round: 387/532, loss: 0.24719586968421936\n",
      "train epoch: 10/11, round: 388/532, loss: 0.3491760790348053\n",
      "train epoch: 10/11, round: 389/532, loss: 0.264690101146698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10/11, round: 390/532, loss: 0.3442233204841614\n",
      "train epoch: 10/11, round: 391/532, loss: 0.3838074803352356\n",
      "train epoch: 10/11, round: 392/532, loss: 0.43044114112854004\n",
      "train epoch: 10/11, round: 393/532, loss: 0.4181627631187439\n",
      "train epoch: 10/11, round: 394/532, loss: 0.3743346333503723\n",
      "train epoch: 10/11, round: 395/532, loss: 0.42300742864608765\n",
      "train epoch: 10/11, round: 396/532, loss: 0.315487802028656\n",
      "train epoch: 10/11, round: 397/532, loss: 0.3477475643157959\n",
      "train epoch: 10/11, round: 398/532, loss: 0.34702807664871216\n",
      "train epoch: 10/11, round: 399/532, loss: 0.4083782732486725\n",
      "train epoch: 10/11, round: 400/532, loss: 0.38245999813079834\n",
      "train epoch: 10/11, round: 401/532, loss: 0.3679121136665344\n",
      "train epoch: 10/11, round: 402/532, loss: 0.32758229970932007\n",
      "train epoch: 10/11, round: 403/532, loss: 0.3985801041126251\n",
      "train epoch: 10/11, round: 404/532, loss: 0.34095507860183716\n",
      "train epoch: 10/11, round: 405/532, loss: 0.34739428758621216\n",
      "train epoch: 10/11, round: 406/532, loss: 0.2843753397464752\n",
      "train epoch: 10/11, round: 407/532, loss: 0.3418505787849426\n",
      "train epoch: 10/11, round: 408/532, loss: 0.3640144467353821\n",
      "train epoch: 10/11, round: 409/532, loss: 0.40118104219436646\n",
      "train epoch: 10/11, round: 410/532, loss: 0.3665044903755188\n",
      "train epoch: 10/11, round: 411/532, loss: 0.3926115334033966\n",
      "train epoch: 10/11, round: 412/532, loss: 0.33634716272354126\n",
      "train epoch: 10/11, round: 413/532, loss: 0.3788549602031708\n",
      "train epoch: 10/11, round: 414/532, loss: 0.33416351675987244\n",
      "train epoch: 10/11, round: 415/532, loss: 0.3714195489883423\n",
      "train epoch: 10/11, round: 416/532, loss: 0.3411802351474762\n",
      "train epoch: 10/11, round: 417/532, loss: 0.32695117592811584\n",
      "train epoch: 10/11, round: 418/532, loss: 0.3918593227863312\n",
      "train epoch: 10/11, round: 419/532, loss: 0.31779712438583374\n",
      "train epoch: 10/11, round: 420/532, loss: 0.40595078468322754\n",
      "train epoch: 10/11, round: 421/532, loss: 0.4094378352165222\n",
      "train epoch: 10/11, round: 422/532, loss: 0.2837492823600769\n",
      "train epoch: 10/11, round: 423/532, loss: 0.41787153482437134\n",
      "train epoch: 10/11, round: 424/532, loss: 0.3712581396102905\n",
      "train epoch: 10/11, round: 425/532, loss: 0.49706974625587463\n",
      "train epoch: 10/11, round: 426/532, loss: 0.3309851586818695\n",
      "train epoch: 10/11, round: 427/532, loss: 0.3077124059200287\n",
      "train epoch: 10/11, round: 428/532, loss: 0.32227712869644165\n",
      "train epoch: 10/11, round: 429/532, loss: 0.3959004878997803\n",
      "train epoch: 10/11, round: 430/532, loss: 0.3868785798549652\n",
      "train epoch: 10/11, round: 431/532, loss: 0.31632575392723083\n",
      "train epoch: 10/11, round: 432/532, loss: 0.4290763735771179\n",
      "train epoch: 10/11, round: 433/532, loss: 0.3368583619594574\n",
      "train epoch: 10/11, round: 434/532, loss: 0.42445865273475647\n",
      "train epoch: 10/11, round: 435/532, loss: 0.2780037224292755\n",
      "train epoch: 10/11, round: 436/532, loss: 0.37472614645957947\n",
      "train epoch: 10/11, round: 437/532, loss: 0.5024617910385132\n",
      "train epoch: 10/11, round: 438/532, loss: 0.3275333344936371\n",
      "train epoch: 10/11, round: 439/532, loss: 0.36406758427619934\n",
      "train epoch: 10/11, round: 440/532, loss: 0.38472506403923035\n",
      "train epoch: 10/11, round: 441/532, loss: 0.39425840973854065\n",
      "train epoch: 10/11, round: 442/532, loss: 0.45526695251464844\n",
      "train epoch: 10/11, round: 443/532, loss: 0.30202215909957886\n",
      "train epoch: 10/11, round: 444/532, loss: 0.3760250508785248\n",
      "train epoch: 10/11, round: 445/532, loss: 0.3903005123138428\n",
      "train epoch: 10/11, round: 446/532, loss: 0.3973153233528137\n",
      "train epoch: 10/11, round: 447/532, loss: 0.4017012119293213\n",
      "train epoch: 10/11, round: 448/532, loss: 0.3909340500831604\n",
      "train epoch: 10/11, round: 449/532, loss: 0.40099889039993286\n",
      "train epoch: 10/11, round: 450/532, loss: 0.40097126364707947\n",
      "train epoch: 10/11, round: 451/532, loss: 0.3510895371437073\n",
      "train epoch: 10/11, round: 452/532, loss: 0.4632700979709625\n",
      "train epoch: 10/11, round: 453/532, loss: 0.46398836374282837\n",
      "train epoch: 10/11, round: 454/532, loss: 0.46546706557273865\n",
      "train epoch: 10/11, round: 455/532, loss: 0.33331286907196045\n",
      "train epoch: 10/11, round: 456/532, loss: 0.34841713309288025\n",
      "train epoch: 10/11, round: 457/532, loss: 0.33952221274375916\n",
      "train epoch: 10/11, round: 458/532, loss: 0.3802536129951477\n",
      "train epoch: 10/11, round: 459/532, loss: 0.41167959570884705\n",
      "train epoch: 10/11, round: 460/532, loss: 0.3995141386985779\n",
      "train epoch: 10/11, round: 461/532, loss: 0.38918155431747437\n",
      "train epoch: 10/11, round: 462/532, loss: 0.38130226731300354\n",
      "train epoch: 10/11, round: 463/532, loss: 0.32894930243492126\n",
      "train epoch: 10/11, round: 464/532, loss: 0.3995763957500458\n",
      "train epoch: 10/11, round: 465/532, loss: 0.34404200315475464\n",
      "train epoch: 10/11, round: 466/532, loss: 0.34633997082710266\n",
      "train epoch: 10/11, round: 467/532, loss: 0.3892209529876709\n",
      "train epoch: 10/11, round: 468/532, loss: 0.4286423623561859\n",
      "train epoch: 10/11, round: 469/532, loss: 0.3988991379737854\n",
      "train epoch: 10/11, round: 470/532, loss: 0.3758818805217743\n",
      "train epoch: 10/11, round: 471/532, loss: 0.4130379557609558\n",
      "train epoch: 10/11, round: 472/532, loss: 0.3826936185359955\n",
      "train epoch: 10/11, round: 473/532, loss: 0.3213963210582733\n",
      "train epoch: 10/11, round: 474/532, loss: 0.29200997948646545\n",
      "train epoch: 10/11, round: 475/532, loss: 0.4029064178466797\n",
      "train epoch: 10/11, round: 476/532, loss: 0.36246126890182495\n",
      "train epoch: 10/11, round: 477/532, loss: 0.4003725051879883\n",
      "train epoch: 10/11, round: 478/532, loss: 0.3820425570011139\n",
      "train epoch: 10/11, round: 479/532, loss: 0.31973618268966675\n",
      "train epoch: 10/11, round: 480/532, loss: 0.3649057447910309\n",
      "train epoch: 10/11, round: 481/532, loss: 0.354450523853302\n",
      "train epoch: 10/11, round: 482/532, loss: 0.4392615854740143\n",
      "train epoch: 10/11, round: 483/532, loss: 0.38286739587783813\n",
      "train epoch: 10/11, round: 484/532, loss: 0.2720724642276764\n",
      "train epoch: 10/11, round: 485/532, loss: 0.37614113092422485\n",
      "train epoch: 10/11, round: 486/532, loss: 0.4399476945400238\n",
      "train epoch: 10/11, round: 487/532, loss: 0.33018985390663147\n",
      "train epoch: 10/11, round: 488/532, loss: 0.42581701278686523\n",
      "train epoch: 10/11, round: 489/532, loss: 0.33215799927711487\n",
      "train epoch: 10/11, round: 490/532, loss: 0.29701751470565796\n",
      "train epoch: 10/11, round: 491/532, loss: 0.3235262930393219\n",
      "train epoch: 10/11, round: 492/532, loss: 0.339205801486969\n",
      "train epoch: 10/11, round: 493/532, loss: 0.36142200231552124\n",
      "train epoch: 10/11, round: 494/532, loss: 0.2743641436100006\n",
      "train epoch: 10/11, round: 495/532, loss: 0.41804438829421997\n",
      "train epoch: 10/11, round: 496/532, loss: 0.4809057116508484\n",
      "train epoch: 10/11, round: 497/532, loss: 0.4575769305229187\n",
      "train epoch: 10/11, round: 498/532, loss: 0.3699791431427002\n",
      "train epoch: 10/11, round: 499/532, loss: 0.34553059935569763\n",
      "train epoch: 10/11, round: 500/532, loss: 0.3384284973144531\n",
      "train epoch: 10/11, round: 501/532, loss: 0.40771523118019104\n",
      "train epoch: 10/11, round: 502/532, loss: 0.3133689761161804\n",
      "train epoch: 10/11, round: 503/532, loss: 0.36870285868644714\n",
      "train epoch: 10/11, round: 504/532, loss: 0.3179796636104584\n",
      "train epoch: 10/11, round: 505/532, loss: 0.39878740906715393\n",
      "train epoch: 10/11, round: 506/532, loss: 0.4166313111782074\n",
      "train epoch: 10/11, round: 507/532, loss: 0.3755967915058136\n",
      "train epoch: 10/11, round: 508/532, loss: 0.4667993485927582\n",
      "train epoch: 10/11, round: 509/532, loss: 0.30760544538497925\n",
      "train epoch: 10/11, round: 510/532, loss: 0.36455222964286804\n",
      "train epoch: 10/11, round: 511/532, loss: 0.4420148432254791\n",
      "train epoch: 10/11, round: 512/532, loss: 0.2899126410484314\n",
      "train epoch: 10/11, round: 513/532, loss: 0.3984162211418152\n",
      "train epoch: 10/11, round: 514/532, loss: 0.45366325974464417\n",
      "train epoch: 10/11, round: 515/532, loss: 0.3294048309326172\n",
      "train epoch: 10/11, round: 516/532, loss: 0.3993789851665497\n",
      "train epoch: 10/11, round: 517/532, loss: 0.32951027154922485\n",
      "train epoch: 10/11, round: 518/532, loss: 0.3534809947013855\n",
      "train epoch: 10/11, round: 519/532, loss: 0.3916114270687103\n",
      "train epoch: 10/11, round: 520/532, loss: 0.4157397747039795\n",
      "train epoch: 10/11, round: 521/532, loss: 0.32595667243003845\n",
      "train epoch: 10/11, round: 522/532, loss: 0.3501080870628357\n",
      "train epoch: 10/11, round: 523/532, loss: 0.476544052362442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10/11, round: 524/532, loss: 0.3841235935688019\n",
      "train epoch: 10/11, round: 525/532, loss: 0.30728480219841003\n",
      "train epoch: 10/11, round: 526/532, loss: 0.4253990650177002\n",
      "train epoch: 10/11, round: 527/532, loss: 0.36738091707229614\n",
      "train epoch: 10/11, round: 528/532, loss: 0.35560059547424316\n",
      "train epoch: 10/11, round: 529/532, loss: 0.39750394225120544\n",
      "train epoch: 10/11, round: 530/532, loss: 0.48519593477249146\n",
      "train epoch: 10/11, round: 531/532, loss: 0.423661470413208\n",
      "train epoch: 10/11, round: 532/532, loss: 0.33661094307899475\n",
      "train epoch: 10/11, KS: 0.36946842675538394, ROC: 0.7496407140967632\n",
      "test epoch: 10/11, round: 1/501, loss: 0.40043723583221436\n",
      "test epoch: 10/11, round: 2/501, loss: 0.3560679256916046\n",
      "test epoch: 10/11, round: 3/501, loss: 0.30795302987098694\n",
      "test epoch: 10/11, round: 4/501, loss: 0.4230116605758667\n",
      "test epoch: 10/11, round: 5/501, loss: 0.42956727743148804\n",
      "test epoch: 10/11, round: 6/501, loss: 0.42112642526626587\n",
      "test epoch: 10/11, round: 7/501, loss: 0.48051413893699646\n",
      "test epoch: 10/11, round: 8/501, loss: 0.4658086895942688\n",
      "test epoch: 10/11, round: 9/501, loss: 0.4948192238807678\n",
      "test epoch: 10/11, round: 10/501, loss: 0.6560689806938171\n",
      "test epoch: 10/11, round: 11/501, loss: 0.29364508390426636\n",
      "test epoch: 10/11, round: 12/501, loss: 0.5079644918441772\n",
      "test epoch: 10/11, round: 13/501, loss: 0.403311163187027\n",
      "test epoch: 10/11, round: 14/501, loss: 0.35595569014549255\n",
      "test epoch: 10/11, round: 15/501, loss: 0.5047364830970764\n",
      "test epoch: 10/11, round: 16/501, loss: 0.42312729358673096\n",
      "test epoch: 10/11, round: 17/501, loss: 0.33463582396507263\n",
      "test epoch: 10/11, round: 18/501, loss: 0.5416699647903442\n",
      "test epoch: 10/11, round: 19/501, loss: 0.5446845889091492\n",
      "test epoch: 10/11, round: 20/501, loss: 0.7401801943778992\n",
      "test epoch: 10/11, round: 21/501, loss: 0.3970687985420227\n",
      "test epoch: 10/11, round: 22/501, loss: 0.5913265943527222\n",
      "test epoch: 10/11, round: 23/501, loss: 0.447407603263855\n",
      "test epoch: 10/11, round: 24/501, loss: 0.4567579925060272\n",
      "test epoch: 10/11, round: 25/501, loss: 0.67900151014328\n",
      "test epoch: 10/11, round: 26/501, loss: 0.6421072483062744\n",
      "test epoch: 10/11, round: 27/501, loss: 0.3049040734767914\n",
      "test epoch: 10/11, round: 28/501, loss: 0.45814576745033264\n",
      "test epoch: 10/11, round: 29/501, loss: 0.3443276286125183\n",
      "test epoch: 10/11, round: 30/501, loss: 0.49887484312057495\n",
      "test epoch: 10/11, round: 31/501, loss: 0.518652617931366\n",
      "test epoch: 10/11, round: 32/501, loss: 0.5360361337661743\n",
      "test epoch: 10/11, round: 33/501, loss: 0.7216224670410156\n",
      "test epoch: 10/11, round: 34/501, loss: 0.5120401978492737\n",
      "test epoch: 10/11, round: 35/501, loss: 0.19787202775478363\n",
      "test epoch: 10/11, round: 36/501, loss: 0.5361106395721436\n",
      "test epoch: 10/11, round: 37/501, loss: 0.4568225145339966\n",
      "test epoch: 10/11, round: 38/501, loss: 0.5013782382011414\n",
      "test epoch: 10/11, round: 39/501, loss: 0.7686465382575989\n",
      "test epoch: 10/11, round: 40/501, loss: 0.6441991329193115\n",
      "test epoch: 10/11, round: 41/501, loss: 0.5005452632904053\n",
      "test epoch: 10/11, round: 42/501, loss: 0.44537562131881714\n",
      "test epoch: 10/11, round: 43/501, loss: 0.38254082202911377\n",
      "test epoch: 10/11, round: 44/501, loss: 0.5750096440315247\n",
      "test epoch: 10/11, round: 45/501, loss: 0.7170582413673401\n",
      "test epoch: 10/11, round: 46/501, loss: 0.49593862891197205\n",
      "test epoch: 10/11, round: 47/501, loss: 0.3238663971424103\n",
      "test epoch: 10/11, round: 48/501, loss: 0.6389641165733337\n",
      "test epoch: 10/11, round: 49/501, loss: 0.4009036421775818\n",
      "test epoch: 10/11, round: 50/501, loss: 0.2968972623348236\n",
      "test epoch: 10/11, round: 51/501, loss: 0.41375643014907837\n",
      "test epoch: 10/11, round: 52/501, loss: 0.40111204981803894\n",
      "test epoch: 10/11, round: 53/501, loss: 0.6038612723350525\n",
      "test epoch: 10/11, round: 54/501, loss: 0.6144490838050842\n",
      "test epoch: 10/11, round: 55/501, loss: 0.37532487511634827\n",
      "test epoch: 10/11, round: 56/501, loss: 0.46964341402053833\n",
      "test epoch: 10/11, round: 57/501, loss: 0.4391551911830902\n",
      "test epoch: 10/11, round: 58/501, loss: 0.4726167619228363\n",
      "test epoch: 10/11, round: 59/501, loss: 0.2713382840156555\n",
      "test epoch: 10/11, round: 60/501, loss: 0.4811113476753235\n",
      "test epoch: 10/11, round: 61/501, loss: 0.40340757369995117\n",
      "test epoch: 10/11, round: 62/501, loss: 0.6692525744438171\n",
      "test epoch: 10/11, round: 63/501, loss: 0.818966269493103\n",
      "test epoch: 10/11, round: 64/501, loss: 0.2959481179714203\n",
      "test epoch: 10/11, round: 65/501, loss: 0.6535291075706482\n",
      "test epoch: 10/11, round: 66/501, loss: 0.45797696709632874\n",
      "test epoch: 10/11, round: 67/501, loss: 0.5383622050285339\n",
      "test epoch: 10/11, round: 68/501, loss: 0.5253808498382568\n",
      "test epoch: 10/11, round: 69/501, loss: 0.5674573183059692\n",
      "test epoch: 10/11, round: 70/501, loss: 0.3840963542461395\n",
      "test epoch: 10/11, round: 71/501, loss: 0.6051549911499023\n",
      "test epoch: 10/11, round: 72/501, loss: 0.47714683413505554\n",
      "test epoch: 10/11, round: 73/501, loss: 0.4878649115562439\n",
      "test epoch: 10/11, round: 74/501, loss: 0.4346628785133362\n",
      "test epoch: 10/11, round: 75/501, loss: 0.5410058498382568\n",
      "test epoch: 10/11, round: 76/501, loss: 0.6661044955253601\n",
      "test epoch: 10/11, round: 77/501, loss: 0.32408905029296875\n",
      "test epoch: 10/11, round: 78/501, loss: 0.5619198679924011\n",
      "test epoch: 10/11, round: 79/501, loss: 0.41327178478240967\n",
      "test epoch: 10/11, round: 80/501, loss: 0.632255494594574\n",
      "test epoch: 10/11, round: 81/501, loss: 0.6310001611709595\n",
      "test epoch: 10/11, round: 82/501, loss: 0.5479891300201416\n",
      "test epoch: 10/11, round: 83/501, loss: 0.40513673424720764\n",
      "test epoch: 10/11, round: 84/501, loss: 0.7378600835800171\n",
      "test epoch: 10/11, round: 85/501, loss: 0.7934644222259521\n",
      "test epoch: 10/11, round: 86/501, loss: 0.38952186703681946\n",
      "test epoch: 10/11, round: 87/501, loss: 0.458619087934494\n",
      "test epoch: 10/11, round: 88/501, loss: 0.3146142065525055\n",
      "test epoch: 10/11, round: 89/501, loss: 0.36868610978126526\n",
      "test epoch: 10/11, round: 90/501, loss: 0.6584242582321167\n",
      "test epoch: 10/11, round: 91/501, loss: 0.406147837638855\n",
      "test epoch: 10/11, round: 92/501, loss: 0.6772122979164124\n",
      "test epoch: 10/11, round: 93/501, loss: 0.42062097787857056\n",
      "test epoch: 10/11, round: 94/501, loss: 0.5785683393478394\n",
      "test epoch: 10/11, round: 95/501, loss: 0.34720146656036377\n",
      "test epoch: 10/11, round: 96/501, loss: 0.4140290319919586\n",
      "test epoch: 10/11, round: 97/501, loss: 0.5877840518951416\n",
      "test epoch: 10/11, round: 98/501, loss: 0.45178747177124023\n",
      "test epoch: 10/11, round: 99/501, loss: 0.7038050293922424\n",
      "test epoch: 10/11, round: 100/501, loss: 0.6043009161949158\n",
      "test epoch: 10/11, round: 101/501, loss: 0.4895220398902893\n",
      "test epoch: 10/11, round: 102/501, loss: 0.36818936467170715\n",
      "test epoch: 10/11, round: 103/501, loss: 0.4605419337749481\n",
      "test epoch: 10/11, round: 104/501, loss: 0.5931726098060608\n",
      "test epoch: 10/11, round: 105/501, loss: 0.4263049364089966\n",
      "test epoch: 10/11, round: 106/501, loss: 0.6273735165596008\n",
      "test epoch: 10/11, round: 107/501, loss: 0.3669033944606781\n",
      "test epoch: 10/11, round: 108/501, loss: 0.5765295624732971\n",
      "test epoch: 10/11, round: 109/501, loss: 0.3444921374320984\n",
      "test epoch: 10/11, round: 110/501, loss: 0.7141128778457642\n",
      "test epoch: 10/11, round: 111/501, loss: 0.24511241912841797\n",
      "test epoch: 10/11, round: 112/501, loss: 0.2660089433193207\n",
      "test epoch: 10/11, round: 113/501, loss: 0.37903892993927\n",
      "test epoch: 10/11, round: 114/501, loss: 0.38800564408302307\n",
      "test epoch: 10/11, round: 115/501, loss: 0.49659934639930725\n",
      "test epoch: 10/11, round: 116/501, loss: 0.3838008940219879\n",
      "test epoch: 10/11, round: 117/501, loss: 0.45674094557762146\n",
      "test epoch: 10/11, round: 118/501, loss: 0.3967122733592987\n",
      "test epoch: 10/11, round: 119/501, loss: 0.3448466360569\n",
      "test epoch: 10/11, round: 120/501, loss: 0.41498374938964844\n",
      "test epoch: 10/11, round: 121/501, loss: 0.3967156708240509\n",
      "test epoch: 10/11, round: 122/501, loss: 0.516780436038971\n",
      "test epoch: 10/11, round: 123/501, loss: 0.5105680823326111\n",
      "test epoch: 10/11, round: 124/501, loss: 0.5813027620315552\n",
      "test epoch: 10/11, round: 125/501, loss: 0.5522929430007935\n",
      "test epoch: 10/11, round: 126/501, loss: 0.5673485398292542\n",
      "test epoch: 10/11, round: 127/501, loss: 0.5948807001113892\n",
      "test epoch: 10/11, round: 128/501, loss: 0.32007402181625366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 10/11, round: 129/501, loss: 0.3943270444869995\n",
      "test epoch: 10/11, round: 130/501, loss: 0.7620502710342407\n",
      "test epoch: 10/11, round: 131/501, loss: 0.6160984039306641\n",
      "test epoch: 10/11, round: 132/501, loss: 0.5148758292198181\n",
      "test epoch: 10/11, round: 133/501, loss: 0.7311611175537109\n",
      "test epoch: 10/11, round: 134/501, loss: 0.5112650990486145\n",
      "test epoch: 10/11, round: 135/501, loss: 0.35863831639289856\n",
      "test epoch: 10/11, round: 136/501, loss: 0.5352503657341003\n",
      "test epoch: 10/11, round: 137/501, loss: 0.3684280812740326\n",
      "test epoch: 10/11, round: 138/501, loss: 0.35097771883010864\n",
      "test epoch: 10/11, round: 139/501, loss: 0.5637807846069336\n",
      "test epoch: 10/11, round: 140/501, loss: 0.5723670721054077\n",
      "test epoch: 10/11, round: 141/501, loss: 0.38216114044189453\n",
      "test epoch: 10/11, round: 142/501, loss: 0.5630878210067749\n",
      "test epoch: 10/11, round: 143/501, loss: 0.45634326338768005\n",
      "test epoch: 10/11, round: 144/501, loss: 0.5253621935844421\n",
      "test epoch: 10/11, round: 145/501, loss: 0.4165959656238556\n",
      "test epoch: 10/11, round: 146/501, loss: 0.53348708152771\n",
      "test epoch: 10/11, round: 147/501, loss: 0.5447602868080139\n",
      "test epoch: 10/11, round: 148/501, loss: 0.5925127863883972\n",
      "test epoch: 10/11, round: 149/501, loss: 0.3921085298061371\n",
      "test epoch: 10/11, round: 150/501, loss: 0.5779865384101868\n",
      "test epoch: 10/11, round: 151/501, loss: 0.3479408323764801\n",
      "test epoch: 10/11, round: 152/501, loss: 0.6629296541213989\n",
      "test epoch: 10/11, round: 153/501, loss: 0.5670406222343445\n",
      "test epoch: 10/11, round: 154/501, loss: 0.5632328391075134\n",
      "test epoch: 10/11, round: 155/501, loss: 0.35365569591522217\n",
      "test epoch: 10/11, round: 156/501, loss: 0.35516172647476196\n",
      "test epoch: 10/11, round: 157/501, loss: 0.42500945925712585\n",
      "test epoch: 10/11, round: 158/501, loss: 0.4488731920719147\n",
      "test epoch: 10/11, round: 159/501, loss: 0.3794163465499878\n",
      "test epoch: 10/11, round: 160/501, loss: 0.6357829570770264\n",
      "test epoch: 10/11, round: 161/501, loss: 0.4019908905029297\n",
      "test epoch: 10/11, round: 162/501, loss: 0.44286778569221497\n",
      "test epoch: 10/11, round: 163/501, loss: 0.5436724424362183\n",
      "test epoch: 10/11, round: 164/501, loss: 0.5472829937934875\n",
      "test epoch: 10/11, round: 165/501, loss: 0.50923091173172\n",
      "test epoch: 10/11, round: 166/501, loss: 0.589328944683075\n",
      "test epoch: 10/11, round: 167/501, loss: 0.5453711152076721\n",
      "test epoch: 10/11, round: 168/501, loss: 0.34512779116630554\n",
      "test epoch: 10/11, round: 169/501, loss: 0.5102511644363403\n",
      "test epoch: 10/11, round: 170/501, loss: 0.41420069336891174\n",
      "test epoch: 10/11, round: 171/501, loss: 0.5093426704406738\n",
      "test epoch: 10/11, round: 172/501, loss: 0.4743689000606537\n",
      "test epoch: 10/11, round: 173/501, loss: 0.35321903228759766\n",
      "test epoch: 10/11, round: 174/501, loss: 0.5993205904960632\n",
      "test epoch: 10/11, round: 175/501, loss: 0.35332050919532776\n",
      "test epoch: 10/11, round: 176/501, loss: 0.5952444076538086\n",
      "test epoch: 10/11, round: 177/501, loss: 0.4885086119174957\n",
      "test epoch: 10/11, round: 178/501, loss: 0.38263776898384094\n",
      "test epoch: 10/11, round: 179/501, loss: 0.5278856158256531\n",
      "test epoch: 10/11, round: 180/501, loss: 0.49492964148521423\n",
      "test epoch: 10/11, round: 181/501, loss: 0.5688123106956482\n",
      "test epoch: 10/11, round: 182/501, loss: 0.5156266093254089\n",
      "test epoch: 10/11, round: 183/501, loss: 0.5648120641708374\n",
      "test epoch: 10/11, round: 184/501, loss: 0.46595972776412964\n",
      "test epoch: 10/11, round: 185/501, loss: 0.4617122411727905\n",
      "test epoch: 10/11, round: 186/501, loss: 0.5406312942504883\n",
      "test epoch: 10/11, round: 187/501, loss: 0.5407149195671082\n",
      "test epoch: 10/11, round: 188/501, loss: 0.610412061214447\n",
      "test epoch: 10/11, round: 189/501, loss: 0.5361112952232361\n",
      "test epoch: 10/11, round: 190/501, loss: 0.5562970042228699\n",
      "test epoch: 10/11, round: 191/501, loss: 0.46939143538475037\n",
      "test epoch: 10/11, round: 192/501, loss: 0.5564477443695068\n",
      "test epoch: 10/11, round: 193/501, loss: 0.5117613673210144\n",
      "test epoch: 10/11, round: 194/501, loss: 0.43345126509666443\n",
      "test epoch: 10/11, round: 195/501, loss: 0.7314034104347229\n",
      "test epoch: 10/11, round: 196/501, loss: 0.37436729669570923\n",
      "test epoch: 10/11, round: 197/501, loss: 0.4926406443119049\n",
      "test epoch: 10/11, round: 198/501, loss: 0.5569199919700623\n",
      "test epoch: 10/11, round: 199/501, loss: 0.4420887529850006\n",
      "test epoch: 10/11, round: 200/501, loss: 0.637710452079773\n",
      "test epoch: 10/11, round: 201/501, loss: 0.36205196380615234\n",
      "test epoch: 10/11, round: 202/501, loss: 0.34983760118484497\n",
      "test epoch: 10/11, round: 203/501, loss: 0.5609366297721863\n",
      "test epoch: 10/11, round: 204/501, loss: 0.5549601316452026\n",
      "test epoch: 10/11, round: 205/501, loss: 0.4911174476146698\n",
      "test epoch: 10/11, round: 206/501, loss: 0.3346468508243561\n",
      "test epoch: 10/11, round: 207/501, loss: 0.31474941968917847\n",
      "test epoch: 10/11, round: 208/501, loss: 0.5559116005897522\n",
      "test epoch: 10/11, round: 209/501, loss: 0.34768182039260864\n",
      "test epoch: 10/11, round: 210/501, loss: 0.5487543940544128\n",
      "test epoch: 10/11, round: 211/501, loss: 0.4086419939994812\n",
      "test epoch: 10/11, round: 212/501, loss: 0.4750877320766449\n",
      "test epoch: 10/11, round: 213/501, loss: 0.42504221200942993\n",
      "test epoch: 10/11, round: 214/501, loss: 0.3713575303554535\n",
      "test epoch: 10/11, round: 215/501, loss: 0.3611564338207245\n",
      "test epoch: 10/11, round: 216/501, loss: 0.4644445478916168\n",
      "test epoch: 10/11, round: 217/501, loss: 0.30067023634910583\n",
      "test epoch: 10/11, round: 218/501, loss: 0.2996358871459961\n",
      "test epoch: 10/11, round: 219/501, loss: 0.3684178590774536\n",
      "test epoch: 10/11, round: 220/501, loss: 0.36819788813591003\n",
      "test epoch: 10/11, round: 221/501, loss: 0.4838172197341919\n",
      "test epoch: 10/11, round: 222/501, loss: 0.3514942526817322\n",
      "test epoch: 10/11, round: 223/501, loss: 0.2859962582588196\n",
      "test epoch: 10/11, round: 224/501, loss: 0.37111586332321167\n",
      "test epoch: 10/11, round: 225/501, loss: 0.3503459393978119\n",
      "test epoch: 10/11, round: 226/501, loss: 0.32145988941192627\n",
      "test epoch: 10/11, round: 227/501, loss: 0.3798864185810089\n",
      "test epoch: 10/11, round: 228/501, loss: 0.34072473645210266\n",
      "test epoch: 10/11, round: 229/501, loss: 0.42720267176628113\n",
      "test epoch: 10/11, round: 230/501, loss: 0.3965514302253723\n",
      "test epoch: 10/11, round: 231/501, loss: 0.28616082668304443\n",
      "test epoch: 10/11, round: 232/501, loss: 0.4271757900714874\n",
      "test epoch: 10/11, round: 233/501, loss: 0.6276003122329712\n",
      "test epoch: 10/11, round: 234/501, loss: 0.5662723779678345\n",
      "test epoch: 10/11, round: 235/501, loss: 0.4150169789791107\n",
      "test epoch: 10/11, round: 236/501, loss: 0.412743479013443\n",
      "test epoch: 10/11, round: 237/501, loss: 0.4152795672416687\n",
      "test epoch: 10/11, round: 238/501, loss: 0.41041117906570435\n",
      "test epoch: 10/11, round: 239/501, loss: 0.5058644413948059\n",
      "test epoch: 10/11, round: 240/501, loss: 0.2932141423225403\n",
      "test epoch: 10/11, round: 241/501, loss: 0.39178377389907837\n",
      "test epoch: 10/11, round: 242/501, loss: 0.3180910646915436\n",
      "test epoch: 10/11, round: 243/501, loss: 0.32719624042510986\n",
      "test epoch: 10/11, round: 244/501, loss: 0.45117679238319397\n",
      "test epoch: 10/11, round: 245/501, loss: 0.35789915919303894\n",
      "test epoch: 10/11, round: 246/501, loss: 0.4037955105304718\n",
      "test epoch: 10/11, round: 247/501, loss: 0.4359263777732849\n",
      "test epoch: 10/11, round: 248/501, loss: 0.29209432005882263\n",
      "test epoch: 10/11, round: 249/501, loss: 0.33926644921302795\n",
      "test epoch: 10/11, round: 250/501, loss: 0.4073728024959564\n",
      "test epoch: 10/11, round: 251/501, loss: 0.4024600088596344\n",
      "test epoch: 10/11, round: 252/501, loss: 0.4066022038459778\n",
      "test epoch: 10/11, round: 253/501, loss: 0.40592530369758606\n",
      "test epoch: 10/11, round: 254/501, loss: 0.3492739498615265\n",
      "test epoch: 10/11, round: 255/501, loss: 0.3796594738960266\n",
      "test epoch: 10/11, round: 256/501, loss: 0.5440270900726318\n",
      "test epoch: 10/11, round: 257/501, loss: 0.42763838171958923\n",
      "test epoch: 10/11, round: 258/501, loss: 0.5008906126022339\n",
      "test epoch: 10/11, round: 259/501, loss: 0.34574925899505615\n",
      "test epoch: 10/11, round: 260/501, loss: 0.4931715428829193\n",
      "test epoch: 10/11, round: 261/501, loss: 0.6183064579963684\n",
      "test epoch: 10/11, round: 262/501, loss: 0.4836425483226776\n",
      "test epoch: 10/11, round: 263/501, loss: 0.4185316264629364\n",
      "test epoch: 10/11, round: 264/501, loss: 0.518232524394989\n",
      "test epoch: 10/11, round: 265/501, loss: 0.6274552941322327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 10/11, round: 266/501, loss: 0.39851799607276917\n",
      "test epoch: 10/11, round: 267/501, loss: 0.4365749955177307\n",
      "test epoch: 10/11, round: 268/501, loss: 0.3275904953479767\n",
      "test epoch: 10/11, round: 269/501, loss: 0.455724835395813\n",
      "test epoch: 10/11, round: 270/501, loss: 0.28857213258743286\n",
      "test epoch: 10/11, round: 271/501, loss: 0.5696322321891785\n",
      "test epoch: 10/11, round: 272/501, loss: 0.4273315370082855\n",
      "test epoch: 10/11, round: 273/501, loss: 0.47508445382118225\n",
      "test epoch: 10/11, round: 274/501, loss: 0.5000989437103271\n",
      "test epoch: 10/11, round: 275/501, loss: 0.37986576557159424\n",
      "test epoch: 10/11, round: 276/501, loss: 0.3733484148979187\n",
      "test epoch: 10/11, round: 277/501, loss: 0.39851391315460205\n",
      "test epoch: 10/11, round: 278/501, loss: 0.5181864500045776\n",
      "test epoch: 10/11, round: 279/501, loss: 0.4360786974430084\n",
      "test epoch: 10/11, round: 280/501, loss: 0.25271832942962646\n",
      "test epoch: 10/11, round: 281/501, loss: 0.2521601915359497\n",
      "test epoch: 10/11, round: 282/501, loss: 0.401257187128067\n",
      "test epoch: 10/11, round: 283/501, loss: 0.3506993055343628\n",
      "test epoch: 10/11, round: 284/501, loss: 0.47816336154937744\n",
      "test epoch: 10/11, round: 285/501, loss: 0.37402665615081787\n",
      "test epoch: 10/11, round: 286/501, loss: 0.5274304747581482\n",
      "test epoch: 10/11, round: 287/501, loss: 0.5938700437545776\n",
      "test epoch: 10/11, round: 288/501, loss: 0.27715566754341125\n",
      "test epoch: 10/11, round: 289/501, loss: 0.38302403688430786\n",
      "test epoch: 10/11, round: 290/501, loss: 0.38403093814849854\n",
      "test epoch: 10/11, round: 291/501, loss: 0.5683597326278687\n",
      "test epoch: 10/11, round: 292/501, loss: 0.5479131937026978\n",
      "test epoch: 10/11, round: 293/501, loss: 0.563876748085022\n",
      "test epoch: 10/11, round: 294/501, loss: 0.3131643831729889\n",
      "test epoch: 10/11, round: 295/501, loss: 0.33039596676826477\n",
      "test epoch: 10/11, round: 296/501, loss: 0.36474254727363586\n",
      "test epoch: 10/11, round: 297/501, loss: 0.36026737093925476\n",
      "test epoch: 10/11, round: 298/501, loss: 0.48206865787506104\n",
      "test epoch: 10/11, round: 299/501, loss: 0.417471319437027\n",
      "test epoch: 10/11, round: 300/501, loss: 0.48780539631843567\n",
      "test epoch: 10/11, round: 301/501, loss: 0.4134712815284729\n",
      "test epoch: 10/11, round: 302/501, loss: 0.23058971762657166\n",
      "test epoch: 10/11, round: 303/501, loss: 0.6194818615913391\n",
      "test epoch: 10/11, round: 304/501, loss: 0.7642038464546204\n",
      "test epoch: 10/11, round: 305/501, loss: 0.30668866634368896\n",
      "test epoch: 10/11, round: 306/501, loss: 0.4206755459308624\n",
      "test epoch: 10/11, round: 307/501, loss: 0.4736804962158203\n",
      "test epoch: 10/11, round: 308/501, loss: 0.4867141842842102\n",
      "test epoch: 10/11, round: 309/501, loss: 0.4374406635761261\n",
      "test epoch: 10/11, round: 310/501, loss: 0.4579553008079529\n",
      "test epoch: 10/11, round: 311/501, loss: 0.6647474765777588\n",
      "test epoch: 10/11, round: 312/501, loss: 0.5013894438743591\n",
      "test epoch: 10/11, round: 313/501, loss: 0.4098980128765106\n",
      "test epoch: 10/11, round: 314/501, loss: 0.46360448002815247\n",
      "test epoch: 10/11, round: 315/501, loss: 0.37679633498191833\n",
      "test epoch: 10/11, round: 316/501, loss: 0.37677842378616333\n",
      "test epoch: 10/11, round: 317/501, loss: 0.3988298177719116\n",
      "test epoch: 10/11, round: 318/501, loss: 0.43643271923065186\n",
      "test epoch: 10/11, round: 319/501, loss: 0.5124887228012085\n",
      "test epoch: 10/11, round: 320/501, loss: 0.5428221225738525\n",
      "test epoch: 10/11, round: 321/501, loss: 0.47423505783081055\n",
      "test epoch: 10/11, round: 322/501, loss: 0.5606244802474976\n",
      "test epoch: 10/11, round: 323/501, loss: 0.40946051478385925\n",
      "test epoch: 10/11, round: 324/501, loss: 0.3223514258861542\n",
      "test epoch: 10/11, round: 325/501, loss: 0.5355433821678162\n",
      "test epoch: 10/11, round: 326/501, loss: 0.509518027305603\n",
      "test epoch: 10/11, round: 327/501, loss: 0.5190035104751587\n",
      "test epoch: 10/11, round: 328/501, loss: 0.351918488740921\n",
      "test epoch: 10/11, round: 329/501, loss: 0.41494041681289673\n",
      "test epoch: 10/11, round: 330/501, loss: 0.5225035548210144\n",
      "test epoch: 10/11, round: 331/501, loss: 0.5493784546852112\n",
      "test epoch: 10/11, round: 332/501, loss: 0.49035751819610596\n",
      "test epoch: 10/11, round: 333/501, loss: 0.5339769721031189\n",
      "test epoch: 10/11, round: 334/501, loss: 0.5001129508018494\n",
      "test epoch: 10/11, round: 335/501, loss: 0.3902243673801422\n",
      "test epoch: 10/11, round: 336/501, loss: 0.39240559935569763\n",
      "test epoch: 10/11, round: 337/501, loss: 0.6078711152076721\n",
      "test epoch: 10/11, round: 338/501, loss: 0.42795494198799133\n",
      "test epoch: 10/11, round: 339/501, loss: 0.6004106998443604\n",
      "test epoch: 10/11, round: 340/501, loss: 0.49526944756507874\n",
      "test epoch: 10/11, round: 341/501, loss: 0.4344898760318756\n",
      "test epoch: 10/11, round: 342/501, loss: 0.4628960192203522\n",
      "test epoch: 10/11, round: 343/501, loss: 0.3676998019218445\n",
      "test epoch: 10/11, round: 344/501, loss: 0.33910229802131653\n",
      "test epoch: 10/11, round: 345/501, loss: 0.31838691234588623\n",
      "test epoch: 10/11, round: 346/501, loss: 0.331786185503006\n",
      "test epoch: 10/11, round: 347/501, loss: 0.3858269453048706\n",
      "test epoch: 10/11, round: 348/501, loss: 0.4712757170200348\n",
      "test epoch: 10/11, round: 349/501, loss: 0.37374407052993774\n",
      "test epoch: 10/11, round: 350/501, loss: 0.5996857285499573\n",
      "test epoch: 10/11, round: 351/501, loss: 0.3931233286857605\n",
      "test epoch: 10/11, round: 352/501, loss: 0.4784468412399292\n",
      "test epoch: 10/11, round: 353/501, loss: 0.27872219681739807\n",
      "test epoch: 10/11, round: 354/501, loss: 0.537460446357727\n",
      "test epoch: 10/11, round: 355/501, loss: 0.4955485463142395\n",
      "test epoch: 10/11, round: 356/501, loss: 0.5363461971282959\n",
      "test epoch: 10/11, round: 357/501, loss: 0.42614346742630005\n",
      "test epoch: 10/11, round: 358/501, loss: 0.4020511507987976\n",
      "test epoch: 10/11, round: 359/501, loss: 0.46933677792549133\n",
      "test epoch: 10/11, round: 360/501, loss: 0.54688960313797\n",
      "test epoch: 10/11, round: 361/501, loss: 0.5443726778030396\n",
      "test epoch: 10/11, round: 362/501, loss: 0.37760213017463684\n",
      "test epoch: 10/11, round: 363/501, loss: 0.46183541417121887\n",
      "test epoch: 10/11, round: 364/501, loss: 0.550464928150177\n",
      "test epoch: 10/11, round: 365/501, loss: 0.39761883020401\n",
      "test epoch: 10/11, round: 366/501, loss: 0.46206721663475037\n",
      "test epoch: 10/11, round: 367/501, loss: 0.5596229434013367\n",
      "test epoch: 10/11, round: 368/501, loss: 0.5313131809234619\n",
      "test epoch: 10/11, round: 369/501, loss: 0.4068107604980469\n",
      "test epoch: 10/11, round: 370/501, loss: 0.44763806462287903\n",
      "test epoch: 10/11, round: 371/501, loss: 0.4399004578590393\n",
      "test epoch: 10/11, round: 372/501, loss: 0.3936333954334259\n",
      "test epoch: 10/11, round: 373/501, loss: 0.5140689015388489\n",
      "test epoch: 10/11, round: 374/501, loss: 0.3386693000793457\n",
      "test epoch: 10/11, round: 375/501, loss: 0.5636728405952454\n",
      "test epoch: 10/11, round: 376/501, loss: 0.5057924389839172\n",
      "test epoch: 10/11, round: 377/501, loss: 0.24327825009822845\n",
      "test epoch: 10/11, round: 378/501, loss: 0.30866414308547974\n",
      "test epoch: 10/11, round: 379/501, loss: 0.43239066004753113\n",
      "test epoch: 10/11, round: 380/501, loss: 0.3732094466686249\n",
      "test epoch: 10/11, round: 381/501, loss: 0.5282688736915588\n",
      "test epoch: 10/11, round: 382/501, loss: 0.32366612553596497\n",
      "test epoch: 10/11, round: 383/501, loss: 0.3757535517215729\n",
      "test epoch: 10/11, round: 384/501, loss: 0.38572508096694946\n",
      "test epoch: 10/11, round: 385/501, loss: 0.6257808208465576\n",
      "test epoch: 10/11, round: 386/501, loss: 0.49594515562057495\n",
      "test epoch: 10/11, round: 387/501, loss: 0.3272486925125122\n",
      "test epoch: 10/11, round: 388/501, loss: 0.37508314847946167\n",
      "test epoch: 10/11, round: 389/501, loss: 0.42516204714775085\n",
      "test epoch: 10/11, round: 390/501, loss: 0.5431454181671143\n",
      "test epoch: 10/11, round: 391/501, loss: 0.4043258726596832\n",
      "test epoch: 10/11, round: 392/501, loss: 0.6026282906532288\n",
      "test epoch: 10/11, round: 393/501, loss: 0.4211421608924866\n",
      "test epoch: 10/11, round: 394/501, loss: 0.731458306312561\n",
      "test epoch: 10/11, round: 395/501, loss: 0.35157614946365356\n",
      "test epoch: 10/11, round: 396/501, loss: 0.4919586181640625\n",
      "test epoch: 10/11, round: 397/501, loss: 0.548547625541687\n",
      "test epoch: 10/11, round: 398/501, loss: 0.4735561013221741\n",
      "test epoch: 10/11, round: 399/501, loss: 0.38486698269844055\n",
      "test epoch: 10/11, round: 400/501, loss: 0.34431880712509155\n",
      "test epoch: 10/11, round: 401/501, loss: 0.5928407907485962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 10/11, round: 402/501, loss: 0.46033719182014465\n",
      "test epoch: 10/11, round: 403/501, loss: 0.441496342420578\n",
      "test epoch: 10/11, round: 404/501, loss: 0.3779265582561493\n",
      "test epoch: 10/11, round: 405/501, loss: 0.7971962094306946\n",
      "test epoch: 10/11, round: 406/501, loss: 0.4927314519882202\n",
      "test epoch: 10/11, round: 407/501, loss: 0.5178901553153992\n",
      "test epoch: 10/11, round: 408/501, loss: 0.43625614047050476\n",
      "test epoch: 10/11, round: 409/501, loss: 0.5039430856704712\n",
      "test epoch: 10/11, round: 410/501, loss: 0.4352184534072876\n",
      "test epoch: 10/11, round: 411/501, loss: 0.48221006989479065\n",
      "test epoch: 10/11, round: 412/501, loss: 0.47254377603530884\n",
      "test epoch: 10/11, round: 413/501, loss: 0.5298338532447815\n",
      "test epoch: 10/11, round: 414/501, loss: 0.3754858672618866\n",
      "test epoch: 10/11, round: 415/501, loss: 0.42739593982696533\n",
      "test epoch: 10/11, round: 416/501, loss: 0.3379283845424652\n",
      "test epoch: 10/11, round: 417/501, loss: 0.30919888615608215\n",
      "test epoch: 10/11, round: 418/501, loss: 0.44563260674476624\n",
      "test epoch: 10/11, round: 419/501, loss: 0.45892098546028137\n",
      "test epoch: 10/11, round: 420/501, loss: 0.3991697430610657\n",
      "test epoch: 10/11, round: 421/501, loss: 0.42369556427001953\n",
      "test epoch: 10/11, round: 422/501, loss: 0.4730258882045746\n",
      "test epoch: 10/11, round: 423/501, loss: 0.6755737662315369\n",
      "test epoch: 10/11, round: 424/501, loss: 0.43325480818748474\n",
      "test epoch: 10/11, round: 425/501, loss: 0.34888628125190735\n",
      "test epoch: 10/11, round: 426/501, loss: 0.5234487056732178\n",
      "test epoch: 10/11, round: 427/501, loss: 0.3407761752605438\n",
      "test epoch: 10/11, round: 428/501, loss: 0.4711667001247406\n",
      "test epoch: 10/11, round: 429/501, loss: 0.6462783813476562\n",
      "test epoch: 10/11, round: 430/501, loss: 0.5599706172943115\n",
      "test epoch: 10/11, round: 431/501, loss: 0.5735267400741577\n",
      "test epoch: 10/11, round: 432/501, loss: 0.4110584855079651\n",
      "test epoch: 10/11, round: 433/501, loss: 0.45639100670814514\n",
      "test epoch: 10/11, round: 434/501, loss: 0.38213852047920227\n",
      "test epoch: 10/11, round: 435/501, loss: 0.3677996098995209\n",
      "test epoch: 10/11, round: 436/501, loss: 0.5324870944023132\n",
      "test epoch: 10/11, round: 437/501, loss: 0.433781236410141\n",
      "test epoch: 10/11, round: 438/501, loss: 0.5600950717926025\n",
      "test epoch: 10/11, round: 439/501, loss: 0.49586746096611023\n",
      "test epoch: 10/11, round: 440/501, loss: 0.43434199690818787\n",
      "test epoch: 10/11, round: 441/501, loss: 0.5575612187385559\n",
      "test epoch: 10/11, round: 442/501, loss: 0.37428414821624756\n",
      "test epoch: 10/11, round: 443/501, loss: 0.35541635751724243\n",
      "test epoch: 10/11, round: 444/501, loss: 0.5738788843154907\n",
      "test epoch: 10/11, round: 445/501, loss: 0.40343913435935974\n",
      "test epoch: 10/11, round: 446/501, loss: 0.5883570313453674\n",
      "test epoch: 10/11, round: 447/501, loss: 0.3310485780239105\n",
      "test epoch: 10/11, round: 448/501, loss: 0.45744648575782776\n",
      "test epoch: 10/11, round: 449/501, loss: 0.3351416289806366\n",
      "test epoch: 10/11, round: 450/501, loss: 0.7461767792701721\n",
      "test epoch: 10/11, round: 451/501, loss: 0.42907124757766724\n",
      "test epoch: 10/11, round: 452/501, loss: 0.5283445119857788\n",
      "test epoch: 10/11, round: 453/501, loss: 0.2591785192489624\n",
      "test epoch: 10/11, round: 454/501, loss: 0.3763285279273987\n",
      "test epoch: 10/11, round: 455/501, loss: 0.4794073700904846\n",
      "test epoch: 10/11, round: 456/501, loss: 0.5456517338752747\n",
      "test epoch: 10/11, round: 457/501, loss: 0.32222920656204224\n",
      "test epoch: 10/11, round: 458/501, loss: 0.43779295682907104\n",
      "test epoch: 10/11, round: 459/501, loss: 0.2857343554496765\n",
      "test epoch: 10/11, round: 460/501, loss: 0.214918315410614\n",
      "test epoch: 10/11, round: 461/501, loss: 0.27034297585487366\n",
      "test epoch: 10/11, round: 462/501, loss: 0.24390289187431335\n",
      "test epoch: 10/11, round: 463/501, loss: 0.246202751994133\n",
      "test epoch: 10/11, round: 464/501, loss: 0.2564452290534973\n",
      "test epoch: 10/11, round: 465/501, loss: 0.2877095341682434\n",
      "test epoch: 10/11, round: 466/501, loss: 0.23608511686325073\n",
      "test epoch: 10/11, round: 467/501, loss: 0.3395277261734009\n",
      "test epoch: 10/11, round: 468/501, loss: 0.24924591183662415\n",
      "test epoch: 10/11, round: 469/501, loss: 0.28663063049316406\n",
      "test epoch: 10/11, round: 470/501, loss: 0.24754749238491058\n",
      "test epoch: 10/11, round: 471/501, loss: 0.36085954308509827\n",
      "test epoch: 10/11, round: 472/501, loss: 0.26641395688056946\n",
      "test epoch: 10/11, round: 473/501, loss: 0.2244122326374054\n",
      "test epoch: 10/11, round: 474/501, loss: 0.25439584255218506\n",
      "test epoch: 10/11, round: 475/501, loss: 0.29499539732933044\n",
      "test epoch: 10/11, round: 476/501, loss: 0.19096770882606506\n",
      "test epoch: 10/11, round: 477/501, loss: 0.2133145034313202\n",
      "test epoch: 10/11, round: 478/501, loss: 0.2611287236213684\n",
      "test epoch: 10/11, round: 479/501, loss: 0.1979687213897705\n",
      "test epoch: 10/11, round: 480/501, loss: 0.21533675491809845\n",
      "test epoch: 10/11, round: 481/501, loss: 0.2445199340581894\n",
      "test epoch: 10/11, round: 482/501, loss: 0.1911485195159912\n",
      "test epoch: 10/11, round: 483/501, loss: 0.33073216676712036\n",
      "test epoch: 10/11, round: 484/501, loss: 0.22233261168003082\n",
      "test epoch: 10/11, round: 485/501, loss: 0.2530990242958069\n",
      "test epoch: 10/11, round: 486/501, loss: 0.23970629274845123\n",
      "test epoch: 10/11, round: 487/501, loss: 0.19713789224624634\n",
      "test epoch: 10/11, round: 488/501, loss: 0.24436791241168976\n",
      "test epoch: 10/11, round: 489/501, loss: 0.21818043291568756\n",
      "test epoch: 10/11, round: 490/501, loss: 0.20609937608242035\n",
      "test epoch: 10/11, round: 491/501, loss: 0.23640885949134827\n",
      "test epoch: 10/11, round: 492/501, loss: 0.24152202904224396\n",
      "test epoch: 10/11, round: 493/501, loss: 0.23139385879039764\n",
      "test epoch: 10/11, round: 494/501, loss: 0.18614371120929718\n",
      "test epoch: 10/11, round: 495/501, loss: 0.21336475014686584\n",
      "test epoch: 10/11, round: 496/501, loss: 0.27342185378074646\n",
      "test epoch: 10/11, round: 497/501, loss: 0.2376375049352646\n",
      "test epoch: 10/11, round: 498/501, loss: 0.1798056662082672\n",
      "test epoch: 10/11, round: 499/501, loss: 0.2390248030424118\n",
      "test epoch: 10/11, round: 500/501, loss: 0.4186202883720398\n",
      "test epoch: 10/11, round: 501/501, loss: 0.8530864715576172\n",
      "test epoch: 10/11, KS: 0.18368986552576366, ROC: 0.6180326329622412\n",
      "cost time: 1992\n",
      "train epoch: 11/11, round: 1/532, loss: 0.32022303342819214\n",
      "train epoch: 11/11, round: 2/532, loss: 0.3500540852546692\n",
      "train epoch: 11/11, round: 3/532, loss: 0.36151596903800964\n",
      "train epoch: 11/11, round: 4/532, loss: 0.3527466654777527\n",
      "train epoch: 11/11, round: 5/532, loss: 0.33385607600212097\n",
      "train epoch: 11/11, round: 6/532, loss: 0.33972448110580444\n",
      "train epoch: 11/11, round: 7/532, loss: 0.34979116916656494\n",
      "train epoch: 11/11, round: 8/532, loss: 0.39129796624183655\n",
      "train epoch: 11/11, round: 9/532, loss: 0.33934342861175537\n",
      "train epoch: 11/11, round: 10/532, loss: 0.3513597548007965\n",
      "train epoch: 11/11, round: 11/532, loss: 0.2922564148902893\n",
      "train epoch: 11/11, round: 12/532, loss: 0.3382760286331177\n",
      "train epoch: 11/11, round: 13/532, loss: 0.30894720554351807\n",
      "train epoch: 11/11, round: 14/532, loss: 0.3137463927268982\n",
      "train epoch: 11/11, round: 15/532, loss: 0.3060457706451416\n",
      "train epoch: 11/11, round: 16/532, loss: 0.40947800874710083\n",
      "train epoch: 11/11, round: 17/532, loss: 0.2996969223022461\n",
      "train epoch: 11/11, round: 18/532, loss: 0.3169868588447571\n",
      "train epoch: 11/11, round: 19/532, loss: 0.3032309114933014\n",
      "train epoch: 11/11, round: 20/532, loss: 0.2911059260368347\n",
      "train epoch: 11/11, round: 21/532, loss: 0.31413912773132324\n",
      "train epoch: 11/11, round: 22/532, loss: 0.4631217122077942\n",
      "train epoch: 11/11, round: 23/532, loss: 0.40075555443763733\n",
      "train epoch: 11/11, round: 24/532, loss: 0.3404543399810791\n",
      "train epoch: 11/11, round: 25/532, loss: 0.29012277722358704\n",
      "train epoch: 11/11, round: 26/532, loss: 0.2707647681236267\n",
      "train epoch: 11/11, round: 27/532, loss: 0.33556410670280457\n",
      "train epoch: 11/11, round: 28/532, loss: 0.4107186794281006\n",
      "train epoch: 11/11, round: 29/532, loss: 0.3773007392883301\n",
      "train epoch: 11/11, round: 30/532, loss: 0.28450581431388855\n",
      "train epoch: 11/11, round: 31/532, loss: 0.2901049852371216\n",
      "train epoch: 11/11, round: 32/532, loss: 0.3535357117652893\n",
      "train epoch: 11/11, round: 33/532, loss: 0.3223932981491089\n",
      "train epoch: 11/11, round: 34/532, loss: 0.33554381132125854\n",
      "train epoch: 11/11, round: 35/532, loss: 0.3781653046607971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 11/11, round: 36/532, loss: 0.40902137756347656\n",
      "train epoch: 11/11, round: 37/532, loss: 0.35143035650253296\n",
      "train epoch: 11/11, round: 38/532, loss: 0.3740164339542389\n",
      "train epoch: 11/11, round: 39/532, loss: 0.3892275393009186\n",
      "train epoch: 11/11, round: 40/532, loss: 0.3298795819282532\n",
      "train epoch: 11/11, round: 41/532, loss: 0.30626946687698364\n",
      "train epoch: 11/11, round: 42/532, loss: 0.3357314169406891\n",
      "train epoch: 11/11, round: 43/532, loss: 0.23920698463916779\n",
      "train epoch: 11/11, round: 44/532, loss: 0.317359983921051\n",
      "train epoch: 11/11, round: 45/532, loss: 0.38024359941482544\n",
      "train epoch: 11/11, round: 46/532, loss: 0.301811546087265\n",
      "train epoch: 11/11, round: 47/532, loss: 0.31454339623451233\n",
      "train epoch: 11/11, round: 48/532, loss: 0.32554858922958374\n",
      "train epoch: 11/11, round: 49/532, loss: 0.30364304780960083\n",
      "train epoch: 11/11, round: 50/532, loss: 0.4062446057796478\n",
      "train epoch: 11/11, round: 51/532, loss: 0.34847038984298706\n",
      "train epoch: 11/11, round: 52/532, loss: 0.39027300477027893\n",
      "train epoch: 11/11, round: 53/532, loss: 0.3083179295063019\n",
      "train epoch: 11/11, round: 54/532, loss: 0.3630181550979614\n",
      "train epoch: 11/11, round: 55/532, loss: 0.2918546199798584\n",
      "train epoch: 11/11, round: 56/532, loss: 0.3455732762813568\n",
      "train epoch: 11/11, round: 57/532, loss: 0.3179037570953369\n",
      "train epoch: 11/11, round: 58/532, loss: 0.4060489535331726\n",
      "train epoch: 11/11, round: 59/532, loss: 0.39057233929634094\n",
      "train epoch: 11/11, round: 60/532, loss: 0.3125467002391815\n",
      "train epoch: 11/11, round: 61/532, loss: 0.37949931621551514\n",
      "train epoch: 11/11, round: 62/532, loss: 0.2958628237247467\n",
      "train epoch: 11/11, round: 63/532, loss: 0.3527148365974426\n",
      "train epoch: 11/11, round: 64/532, loss: 0.36740005016326904\n",
      "train epoch: 11/11, round: 65/532, loss: 0.3575070798397064\n",
      "train epoch: 11/11, round: 66/532, loss: 0.4555028975009918\n",
      "train epoch: 11/11, round: 67/532, loss: 0.3248448371887207\n",
      "train epoch: 11/11, round: 68/532, loss: 0.35112881660461426\n",
      "train epoch: 11/11, round: 69/532, loss: 0.38626283407211304\n",
      "train epoch: 11/11, round: 70/532, loss: 0.41082853078842163\n",
      "train epoch: 11/11, round: 71/532, loss: 0.27481573820114136\n",
      "train epoch: 11/11, round: 72/532, loss: 0.33820614218711853\n",
      "train epoch: 11/11, round: 73/532, loss: 0.4367334246635437\n",
      "train epoch: 11/11, round: 74/532, loss: 0.3233862519264221\n",
      "train epoch: 11/11, round: 75/532, loss: 0.35284221172332764\n",
      "train epoch: 11/11, round: 76/532, loss: 0.3798304796218872\n",
      "train epoch: 11/11, round: 77/532, loss: 0.4003855586051941\n",
      "train epoch: 11/11, round: 78/532, loss: 0.34707212448120117\n",
      "train epoch: 11/11, round: 79/532, loss: 0.3220592141151428\n",
      "train epoch: 11/11, round: 80/532, loss: 0.27826017141342163\n",
      "train epoch: 11/11, round: 81/532, loss: 0.4054013192653656\n",
      "train epoch: 11/11, round: 82/532, loss: 0.3941970765590668\n",
      "train epoch: 11/11, round: 83/532, loss: 0.24926002323627472\n",
      "train epoch: 11/11, round: 84/532, loss: 0.35958942770957947\n",
      "train epoch: 11/11, round: 85/532, loss: 0.277630478143692\n",
      "train epoch: 11/11, round: 86/532, loss: 0.3672240376472473\n",
      "train epoch: 11/11, round: 87/532, loss: 0.3914748728275299\n",
      "train epoch: 11/11, round: 88/532, loss: 0.4005376696586609\n",
      "train epoch: 11/11, round: 89/532, loss: 0.2863570749759674\n",
      "train epoch: 11/11, round: 90/532, loss: 0.35851535201072693\n",
      "train epoch: 11/11, round: 91/532, loss: 0.41694822907447815\n",
      "train epoch: 11/11, round: 92/532, loss: 0.31100934743881226\n",
      "train epoch: 11/11, round: 93/532, loss: 0.34032732248306274\n",
      "train epoch: 11/11, round: 94/532, loss: 0.4142267107963562\n",
      "train epoch: 11/11, round: 95/532, loss: 0.319551557302475\n",
      "train epoch: 11/11, round: 96/532, loss: 0.34477657079696655\n",
      "train epoch: 11/11, round: 97/532, loss: 0.40748587250709534\n",
      "train epoch: 11/11, round: 98/532, loss: 0.36613526940345764\n",
      "train epoch: 11/11, round: 99/532, loss: 0.48655766248703003\n",
      "train epoch: 11/11, round: 100/532, loss: 0.381266713142395\n",
      "train epoch: 11/11, round: 101/532, loss: 0.3506356179714203\n",
      "train epoch: 11/11, round: 102/532, loss: 0.326488196849823\n",
      "train epoch: 11/11, round: 103/532, loss: 0.34047284722328186\n",
      "train epoch: 11/11, round: 104/532, loss: 0.4088274836540222\n",
      "train epoch: 11/11, round: 105/532, loss: 0.35962632298469543\n",
      "train epoch: 11/11, round: 106/532, loss: 0.37848904728889465\n",
      "train epoch: 11/11, round: 107/532, loss: 0.31184178590774536\n",
      "train epoch: 11/11, round: 108/532, loss: 0.3115007281303406\n",
      "train epoch: 11/11, round: 109/532, loss: 0.29254546761512756\n",
      "train epoch: 11/11, round: 110/532, loss: 0.413372278213501\n",
      "train epoch: 11/11, round: 111/532, loss: 0.28329095244407654\n",
      "train epoch: 11/11, round: 112/532, loss: 0.3395616114139557\n",
      "train epoch: 11/11, round: 113/532, loss: 0.4263588786125183\n",
      "train epoch: 11/11, round: 114/532, loss: 0.3670331835746765\n",
      "train epoch: 11/11, round: 115/532, loss: 0.3626163601875305\n",
      "train epoch: 11/11, round: 116/532, loss: 0.39383751153945923\n",
      "train epoch: 11/11, round: 117/532, loss: 0.31574222445487976\n",
      "train epoch: 11/11, round: 118/532, loss: 0.33109360933303833\n",
      "train epoch: 11/11, round: 119/532, loss: 0.43825021386146545\n",
      "train epoch: 11/11, round: 120/532, loss: 0.3427148461341858\n",
      "train epoch: 11/11, round: 121/532, loss: 0.3634726405143738\n",
      "train epoch: 11/11, round: 122/532, loss: 0.31160813570022583\n",
      "train epoch: 11/11, round: 123/532, loss: 0.3634144067764282\n",
      "train epoch: 11/11, round: 124/532, loss: 0.4204102158546448\n",
      "train epoch: 11/11, round: 125/532, loss: 0.30835846066474915\n",
      "train epoch: 11/11, round: 126/532, loss: 0.4290497899055481\n",
      "train epoch: 11/11, round: 127/532, loss: 0.3251360058784485\n",
      "train epoch: 11/11, round: 128/532, loss: 0.3275415301322937\n",
      "train epoch: 11/11, round: 129/532, loss: 0.3293547034263611\n",
      "train epoch: 11/11, round: 130/532, loss: 0.4149535298347473\n",
      "train epoch: 11/11, round: 131/532, loss: 0.35941585898399353\n",
      "train epoch: 11/11, round: 132/532, loss: 0.26533976197242737\n",
      "train epoch: 11/11, round: 133/532, loss: 0.3737386465072632\n",
      "train epoch: 11/11, round: 134/532, loss: 0.29717254638671875\n",
      "train epoch: 11/11, round: 135/532, loss: 0.34379392862319946\n",
      "train epoch: 11/11, round: 136/532, loss: 0.29005932807922363\n",
      "train epoch: 11/11, round: 137/532, loss: 0.3065865635871887\n",
      "train epoch: 11/11, round: 138/532, loss: 0.31895893812179565\n",
      "train epoch: 11/11, round: 139/532, loss: 0.3828914761543274\n",
      "train epoch: 11/11, round: 140/532, loss: 0.38313981890678406\n",
      "train epoch: 11/11, round: 141/532, loss: 0.38823357224464417\n",
      "train epoch: 11/11, round: 142/532, loss: 0.38214513659477234\n",
      "train epoch: 11/11, round: 143/532, loss: 0.3259119391441345\n",
      "train epoch: 11/11, round: 144/532, loss: 0.3300814628601074\n",
      "train epoch: 11/11, round: 145/532, loss: 0.4628567695617676\n",
      "train epoch: 11/11, round: 146/532, loss: 0.4451754093170166\n",
      "train epoch: 11/11, round: 147/532, loss: 0.3044705390930176\n",
      "train epoch: 11/11, round: 148/532, loss: 0.3321038782596588\n",
      "train epoch: 11/11, round: 149/532, loss: 0.2619607746601105\n",
      "train epoch: 11/11, round: 150/532, loss: 0.31873196363449097\n",
      "train epoch: 11/11, round: 151/532, loss: 0.31428393721580505\n",
      "train epoch: 11/11, round: 152/532, loss: 0.31095340847969055\n",
      "train epoch: 11/11, round: 153/532, loss: 0.27106693387031555\n",
      "train epoch: 11/11, round: 154/532, loss: 0.3361893594264984\n",
      "train epoch: 11/11, round: 155/532, loss: 0.28565627336502075\n",
      "train epoch: 11/11, round: 156/532, loss: 0.321601927280426\n",
      "train epoch: 11/11, round: 157/532, loss: 0.35267728567123413\n",
      "train epoch: 11/11, round: 158/532, loss: 0.3222958445549011\n",
      "train epoch: 11/11, round: 159/532, loss: 0.40629053115844727\n",
      "train epoch: 11/11, round: 160/532, loss: 0.36831289529800415\n",
      "train epoch: 11/11, round: 161/532, loss: 0.3898445665836334\n",
      "train epoch: 11/11, round: 162/532, loss: 0.2990660071372986\n",
      "train epoch: 11/11, round: 163/532, loss: 0.3901267945766449\n",
      "train epoch: 11/11, round: 164/532, loss: 0.328740656375885\n",
      "train epoch: 11/11, round: 165/532, loss: 0.3247499167919159\n",
      "train epoch: 11/11, round: 166/532, loss: 0.3622453212738037\n",
      "train epoch: 11/11, round: 167/532, loss: 0.38460952043533325\n",
      "train epoch: 11/11, round: 168/532, loss: 0.40528613328933716\n",
      "train epoch: 11/11, round: 169/532, loss: 0.3415271043777466\n",
      "train epoch: 11/11, round: 170/532, loss: 0.3551781177520752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 11/11, round: 171/532, loss: 0.41600313782691956\n",
      "train epoch: 11/11, round: 172/532, loss: 0.31044137477874756\n",
      "train epoch: 11/11, round: 173/532, loss: 0.32808738946914673\n",
      "train epoch: 11/11, round: 174/532, loss: 0.35666292905807495\n",
      "train epoch: 11/11, round: 175/532, loss: 0.3888110816478729\n",
      "train epoch: 11/11, round: 176/532, loss: 0.40233325958251953\n",
      "train epoch: 11/11, round: 177/532, loss: 0.30223560333251953\n",
      "train epoch: 11/11, round: 178/532, loss: 0.3482207953929901\n",
      "train epoch: 11/11, round: 179/532, loss: 0.3424772620201111\n",
      "train epoch: 11/11, round: 180/532, loss: 0.37226733565330505\n",
      "train epoch: 11/11, round: 181/532, loss: 0.327867329120636\n",
      "train epoch: 11/11, round: 182/532, loss: 0.43772149085998535\n",
      "train epoch: 11/11, round: 183/532, loss: 0.3738216757774353\n",
      "train epoch: 11/11, round: 184/532, loss: 0.3536795377731323\n",
      "train epoch: 11/11, round: 185/532, loss: 0.3404969871044159\n",
      "train epoch: 11/11, round: 186/532, loss: 0.3500956892967224\n",
      "train epoch: 11/11, round: 187/532, loss: 0.33640724420547485\n",
      "train epoch: 11/11, round: 188/532, loss: 0.2806978225708008\n",
      "train epoch: 11/11, round: 189/532, loss: 0.38358864188194275\n",
      "train epoch: 11/11, round: 190/532, loss: 0.2806606590747833\n",
      "train epoch: 11/11, round: 191/532, loss: 0.39805781841278076\n",
      "train epoch: 11/11, round: 192/532, loss: 0.3181876242160797\n",
      "train epoch: 11/11, round: 193/532, loss: 0.33959218859672546\n",
      "train epoch: 11/11, round: 194/532, loss: 0.409503698348999\n",
      "train epoch: 11/11, round: 195/532, loss: 0.4114442467689514\n",
      "train epoch: 11/11, round: 196/532, loss: 0.3887821435928345\n",
      "train epoch: 11/11, round: 197/532, loss: 0.32276254892349243\n",
      "train epoch: 11/11, round: 198/532, loss: 0.34767410159111023\n",
      "train epoch: 11/11, round: 199/532, loss: 0.3185364603996277\n",
      "train epoch: 11/11, round: 200/532, loss: 0.43625783920288086\n",
      "train epoch: 11/11, round: 201/532, loss: 0.3968695104122162\n",
      "train epoch: 11/11, round: 202/532, loss: 0.33348730206489563\n",
      "train epoch: 11/11, round: 203/532, loss: 0.42663612961769104\n",
      "train epoch: 11/11, round: 204/532, loss: 0.25479546189308167\n",
      "train epoch: 11/11, round: 205/532, loss: 0.4521273672580719\n",
      "train epoch: 11/11, round: 206/532, loss: 0.37753236293792725\n",
      "train epoch: 11/11, round: 207/532, loss: 0.3417894244194031\n",
      "train epoch: 11/11, round: 208/532, loss: 0.4067983627319336\n",
      "train epoch: 11/11, round: 209/532, loss: 0.3495834171772003\n",
      "train epoch: 11/11, round: 210/532, loss: 0.3890417218208313\n",
      "train epoch: 11/11, round: 211/532, loss: 0.4404281675815582\n",
      "train epoch: 11/11, round: 212/532, loss: 0.35880595445632935\n",
      "train epoch: 11/11, round: 213/532, loss: 0.3440496027469635\n",
      "train epoch: 11/11, round: 214/532, loss: 0.28768178820610046\n",
      "train epoch: 11/11, round: 215/532, loss: 0.3384215831756592\n",
      "train epoch: 11/11, round: 216/532, loss: 0.41217583417892456\n",
      "train epoch: 11/11, round: 217/532, loss: 0.32166677713394165\n",
      "train epoch: 11/11, round: 218/532, loss: 0.34180235862731934\n",
      "train epoch: 11/11, round: 219/532, loss: 0.3395159840583801\n",
      "train epoch: 11/11, round: 220/532, loss: 0.3512960374355316\n",
      "train epoch: 11/11, round: 221/532, loss: 0.4158652722835541\n",
      "train epoch: 11/11, round: 222/532, loss: 0.3499533236026764\n",
      "train epoch: 11/11, round: 223/532, loss: 0.40266141295433044\n",
      "train epoch: 11/11, round: 224/532, loss: 0.3184143006801605\n",
      "train epoch: 11/11, round: 225/532, loss: 0.40959230065345764\n",
      "train epoch: 11/11, round: 226/532, loss: 0.39349082112312317\n",
      "train epoch: 11/11, round: 227/532, loss: 0.3831551671028137\n",
      "train epoch: 11/11, round: 228/532, loss: 0.4380466341972351\n",
      "train epoch: 11/11, round: 229/532, loss: 0.3309462070465088\n",
      "train epoch: 11/11, round: 230/532, loss: 0.3856637477874756\n",
      "train epoch: 11/11, round: 231/532, loss: 0.38107073307037354\n",
      "train epoch: 11/11, round: 232/532, loss: 0.35225898027420044\n",
      "train epoch: 11/11, round: 233/532, loss: 0.3655126094818115\n",
      "train epoch: 11/11, round: 234/532, loss: 0.31986045837402344\n",
      "train epoch: 11/11, round: 235/532, loss: 0.28750330209732056\n",
      "train epoch: 11/11, round: 236/532, loss: 0.34167104959487915\n",
      "train epoch: 11/11, round: 237/532, loss: 0.30645379424095154\n",
      "train epoch: 11/11, round: 238/532, loss: 0.3603476285934448\n",
      "train epoch: 11/11, round: 239/532, loss: 0.34132060408592224\n",
      "train epoch: 11/11, round: 240/532, loss: 0.31697899103164673\n",
      "train epoch: 11/11, round: 241/532, loss: 0.35846173763275146\n",
      "train epoch: 11/11, round: 242/532, loss: 0.29080504179000854\n",
      "train epoch: 11/11, round: 243/532, loss: 0.35515326261520386\n",
      "train epoch: 11/11, round: 244/532, loss: 0.282531201839447\n",
      "train epoch: 11/11, round: 245/532, loss: 0.35915419459342957\n",
      "train epoch: 11/11, round: 246/532, loss: 0.39230218529701233\n",
      "train epoch: 11/11, round: 247/532, loss: 0.42691102623939514\n",
      "train epoch: 11/11, round: 248/532, loss: 0.32408320903778076\n",
      "train epoch: 11/11, round: 249/532, loss: 0.3219992220401764\n",
      "train epoch: 11/11, round: 250/532, loss: 0.37363356351852417\n",
      "train epoch: 11/11, round: 251/532, loss: 0.34115535020828247\n",
      "train epoch: 11/11, round: 252/532, loss: 0.2609997093677521\n",
      "train epoch: 11/11, round: 253/532, loss: 0.4665204584598541\n",
      "train epoch: 11/11, round: 254/532, loss: 0.2850255072116852\n",
      "train epoch: 11/11, round: 255/532, loss: 0.26992374658584595\n",
      "train epoch: 11/11, round: 256/532, loss: 0.3690524101257324\n",
      "train epoch: 11/11, round: 257/532, loss: 0.4080985188484192\n",
      "train epoch: 11/11, round: 258/532, loss: 0.3799692690372467\n",
      "train epoch: 11/11, round: 259/532, loss: 0.34480470418930054\n",
      "train epoch: 11/11, round: 260/532, loss: 0.3443315029144287\n",
      "train epoch: 11/11, round: 261/532, loss: 0.42800450325012207\n",
      "train epoch: 11/11, round: 262/532, loss: 0.269209086894989\n",
      "train epoch: 11/11, round: 263/532, loss: 0.3527753949165344\n",
      "train epoch: 11/11, round: 264/532, loss: 0.36144834756851196\n",
      "train epoch: 11/11, round: 265/532, loss: 0.3187303841114044\n",
      "train epoch: 11/11, round: 266/532, loss: 0.43148916959762573\n",
      "train epoch: 11/11, round: 267/532, loss: 0.3248947262763977\n",
      "train epoch: 11/11, round: 268/532, loss: 0.33837124705314636\n",
      "train epoch: 11/11, round: 269/532, loss: 0.36633387207984924\n",
      "train epoch: 11/11, round: 270/532, loss: 0.3331491947174072\n",
      "train epoch: 11/11, round: 271/532, loss: 0.32504403591156006\n",
      "train epoch: 11/11, round: 272/532, loss: 0.3255290389060974\n",
      "train epoch: 11/11, round: 273/532, loss: 0.36745065450668335\n",
      "train epoch: 11/11, round: 274/532, loss: 0.4409761428833008\n",
      "train epoch: 11/11, round: 275/532, loss: 0.32166391611099243\n",
      "train epoch: 11/11, round: 276/532, loss: 0.37701743841171265\n",
      "train epoch: 11/11, round: 277/532, loss: 0.30511653423309326\n",
      "train epoch: 11/11, round: 278/532, loss: 0.3604850172996521\n",
      "train epoch: 11/11, round: 279/532, loss: 0.3538784980773926\n",
      "train epoch: 11/11, round: 280/532, loss: 0.4440701901912689\n",
      "train epoch: 11/11, round: 281/532, loss: 0.38034123182296753\n",
      "train epoch: 11/11, round: 282/532, loss: 0.35482659935951233\n",
      "train epoch: 11/11, round: 283/532, loss: 0.36111360788345337\n",
      "train epoch: 11/11, round: 284/532, loss: 0.3618800938129425\n",
      "train epoch: 11/11, round: 285/532, loss: 0.4151674211025238\n",
      "train epoch: 11/11, round: 286/532, loss: 0.359285444021225\n",
      "train epoch: 11/11, round: 287/532, loss: 0.3890380263328552\n",
      "train epoch: 11/11, round: 288/532, loss: 0.3306763172149658\n",
      "train epoch: 11/11, round: 289/532, loss: 0.3874543607234955\n",
      "train epoch: 11/11, round: 290/532, loss: 0.37838250398635864\n",
      "train epoch: 11/11, round: 291/532, loss: 0.40043726563453674\n",
      "train epoch: 11/11, round: 292/532, loss: 0.32961830496788025\n",
      "train epoch: 11/11, round: 293/532, loss: 0.439591646194458\n",
      "train epoch: 11/11, round: 294/532, loss: 0.33863210678100586\n",
      "train epoch: 11/11, round: 295/532, loss: 0.3784710168838501\n",
      "train epoch: 11/11, round: 296/532, loss: 0.3499124348163605\n",
      "train epoch: 11/11, round: 297/532, loss: 0.3114588260650635\n",
      "train epoch: 11/11, round: 298/532, loss: 0.3777129054069519\n",
      "train epoch: 11/11, round: 299/532, loss: 0.4369868338108063\n",
      "train epoch: 11/11, round: 300/532, loss: 0.3615363836288452\n",
      "train epoch: 11/11, round: 301/532, loss: 0.3325807750225067\n",
      "train epoch: 11/11, round: 302/532, loss: 0.3988614082336426\n",
      "train epoch: 11/11, round: 303/532, loss: 0.4122404456138611\n",
      "train epoch: 11/11, round: 304/532, loss: 0.3885735869407654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 11/11, round: 305/532, loss: 0.3208746016025543\n",
      "train epoch: 11/11, round: 306/532, loss: 0.38843920826911926\n",
      "train epoch: 11/11, round: 307/532, loss: 0.275168240070343\n",
      "train epoch: 11/11, round: 308/532, loss: 0.38219383358955383\n",
      "train epoch: 11/11, round: 309/532, loss: 0.3428117632865906\n",
      "train epoch: 11/11, round: 310/532, loss: 0.3674386143684387\n",
      "train epoch: 11/11, round: 311/532, loss: 0.3313542604446411\n",
      "train epoch: 11/11, round: 312/532, loss: 0.31948432326316833\n",
      "train epoch: 11/11, round: 313/532, loss: 0.35784822702407837\n",
      "train epoch: 11/11, round: 314/532, loss: 0.3621671199798584\n",
      "train epoch: 11/11, round: 315/532, loss: 0.3871062397956848\n",
      "train epoch: 11/11, round: 316/532, loss: 0.38651204109191895\n",
      "train epoch: 11/11, round: 317/532, loss: 0.3623724579811096\n",
      "train epoch: 11/11, round: 318/532, loss: 0.37025436758995056\n",
      "train epoch: 11/11, round: 319/532, loss: 0.2890467047691345\n",
      "train epoch: 11/11, round: 320/532, loss: 0.27761033177375793\n",
      "train epoch: 11/11, round: 321/532, loss: 0.34997060894966125\n",
      "train epoch: 11/11, round: 322/532, loss: 0.3676343560218811\n",
      "train epoch: 11/11, round: 323/532, loss: 0.366182416677475\n",
      "train epoch: 11/11, round: 324/532, loss: 0.3552587032318115\n",
      "train epoch: 11/11, round: 325/532, loss: 0.505689799785614\n",
      "train epoch: 11/11, round: 326/532, loss: 0.4936150908470154\n",
      "train epoch: 11/11, round: 327/532, loss: 0.3915296196937561\n",
      "train epoch: 11/11, round: 328/532, loss: 0.39405322074890137\n",
      "train epoch: 11/11, round: 329/532, loss: 0.377490758895874\n",
      "train epoch: 11/11, round: 330/532, loss: 0.29339975118637085\n",
      "train epoch: 11/11, round: 331/532, loss: 0.3276594281196594\n",
      "train epoch: 11/11, round: 332/532, loss: 0.3911387324333191\n",
      "train epoch: 11/11, round: 333/532, loss: 0.38373762369155884\n",
      "train epoch: 11/11, round: 334/532, loss: 0.3606584072113037\n",
      "train epoch: 11/11, round: 335/532, loss: 0.362041711807251\n",
      "train epoch: 11/11, round: 336/532, loss: 0.4013156294822693\n",
      "train epoch: 11/11, round: 337/532, loss: 0.43409156799316406\n",
      "train epoch: 11/11, round: 338/532, loss: 0.3431248664855957\n",
      "train epoch: 11/11, round: 339/532, loss: 0.3292195498943329\n",
      "train epoch: 11/11, round: 340/532, loss: 0.3565899729728699\n",
      "train epoch: 11/11, round: 341/532, loss: 0.3207734227180481\n",
      "train epoch: 11/11, round: 342/532, loss: 0.4197823405265808\n",
      "train epoch: 11/11, round: 343/532, loss: 0.4007028043270111\n",
      "train epoch: 11/11, round: 344/532, loss: 0.38643521070480347\n",
      "train epoch: 11/11, round: 345/532, loss: 0.36511939764022827\n",
      "train epoch: 11/11, round: 346/532, loss: 0.41948309540748596\n",
      "train epoch: 11/11, round: 347/532, loss: 0.33246082067489624\n",
      "train epoch: 11/11, round: 348/532, loss: 0.48524436354637146\n",
      "train epoch: 11/11, round: 349/532, loss: 0.32627785205841064\n",
      "train epoch: 11/11, round: 350/532, loss: 0.3061440885066986\n",
      "train epoch: 11/11, round: 351/532, loss: 0.4171399176120758\n",
      "train epoch: 11/11, round: 352/532, loss: 0.31062084436416626\n",
      "train epoch: 11/11, round: 353/532, loss: 0.3689025044441223\n",
      "train epoch: 11/11, round: 354/532, loss: 0.45135554671287537\n",
      "train epoch: 11/11, round: 355/532, loss: 0.27256518602371216\n",
      "train epoch: 11/11, round: 356/532, loss: 0.34520596265792847\n",
      "train epoch: 11/11, round: 357/532, loss: 0.3873389661312103\n",
      "train epoch: 11/11, round: 358/532, loss: 0.38459834456443787\n",
      "train epoch: 11/11, round: 359/532, loss: 0.37885093688964844\n",
      "train epoch: 11/11, round: 360/532, loss: 0.368469774723053\n",
      "train epoch: 11/11, round: 361/532, loss: 0.4245266020298004\n",
      "train epoch: 11/11, round: 362/532, loss: 0.36147284507751465\n",
      "train epoch: 11/11, round: 363/532, loss: 0.35705775022506714\n",
      "train epoch: 11/11, round: 364/532, loss: 0.3233531713485718\n",
      "train epoch: 11/11, round: 365/532, loss: 0.3665766716003418\n",
      "train epoch: 11/11, round: 366/532, loss: 0.3637694716453552\n",
      "train epoch: 11/11, round: 367/532, loss: 0.32737916707992554\n",
      "train epoch: 11/11, round: 368/532, loss: 0.3219277858734131\n",
      "train epoch: 11/11, round: 369/532, loss: 0.3549959659576416\n",
      "train epoch: 11/11, round: 370/532, loss: 0.308218777179718\n",
      "train epoch: 11/11, round: 371/532, loss: 0.42015543580055237\n",
      "train epoch: 11/11, round: 372/532, loss: 0.32792678475379944\n",
      "train epoch: 11/11, round: 373/532, loss: 0.37272825837135315\n",
      "train epoch: 11/11, round: 374/532, loss: 0.3604455590248108\n",
      "train epoch: 11/11, round: 375/532, loss: 0.36539945006370544\n",
      "train epoch: 11/11, round: 376/532, loss: 0.39483898878097534\n",
      "train epoch: 11/11, round: 377/532, loss: 0.3418393135070801\n",
      "train epoch: 11/11, round: 378/532, loss: 0.3787073493003845\n",
      "train epoch: 11/11, round: 379/532, loss: 0.34835514426231384\n",
      "train epoch: 11/11, round: 380/532, loss: 0.3821188509464264\n",
      "train epoch: 11/11, round: 381/532, loss: 0.3853556513786316\n",
      "train epoch: 11/11, round: 382/532, loss: 0.4058265686035156\n",
      "train epoch: 11/11, round: 383/532, loss: 0.36012277007102966\n",
      "train epoch: 11/11, round: 384/532, loss: 0.3170934319496155\n",
      "train epoch: 11/11, round: 385/532, loss: 0.4219619631767273\n",
      "train epoch: 11/11, round: 386/532, loss: 0.39383959770202637\n",
      "train epoch: 11/11, round: 387/532, loss: 0.34426653385162354\n",
      "train epoch: 11/11, round: 388/532, loss: 0.37414926290512085\n",
      "train epoch: 11/11, round: 389/532, loss: 0.3580259382724762\n",
      "train epoch: 11/11, round: 390/532, loss: 0.36384591460227966\n",
      "train epoch: 11/11, round: 391/532, loss: 0.3438342213630676\n",
      "train epoch: 11/11, round: 392/532, loss: 0.3835809826850891\n",
      "train epoch: 11/11, round: 393/532, loss: 0.4185023307800293\n",
      "train epoch: 11/11, round: 394/532, loss: 0.32307305932044983\n",
      "train epoch: 11/11, round: 395/532, loss: 0.35817256569862366\n",
      "train epoch: 11/11, round: 396/532, loss: 0.3683319389820099\n",
      "train epoch: 11/11, round: 397/532, loss: 0.3373153507709503\n",
      "train epoch: 11/11, round: 398/532, loss: 0.3733915686607361\n",
      "train epoch: 11/11, round: 399/532, loss: 0.35063061118125916\n",
      "train epoch: 11/11, round: 400/532, loss: 0.3424014449119568\n",
      "train epoch: 11/11, round: 401/532, loss: 0.35941237211227417\n",
      "train epoch: 11/11, round: 402/532, loss: 0.4111769199371338\n",
      "train epoch: 11/11, round: 403/532, loss: 0.26400119066238403\n",
      "train epoch: 11/11, round: 404/532, loss: 0.3374965190887451\n",
      "train epoch: 11/11, round: 405/532, loss: 0.22991475462913513\n",
      "train epoch: 11/11, round: 406/532, loss: 0.4544447958469391\n",
      "train epoch: 11/11, round: 407/532, loss: 0.3356315493583679\n",
      "train epoch: 11/11, round: 408/532, loss: 0.36621907353401184\n",
      "train epoch: 11/11, round: 409/532, loss: 0.44232720136642456\n",
      "train epoch: 11/11, round: 410/532, loss: 0.340980589389801\n",
      "train epoch: 11/11, round: 411/532, loss: 0.42081302404403687\n",
      "train epoch: 11/11, round: 412/532, loss: 0.3703773617744446\n",
      "train epoch: 11/11, round: 413/532, loss: 0.37909966707229614\n",
      "train epoch: 11/11, round: 414/532, loss: 0.4222847819328308\n",
      "train epoch: 11/11, round: 415/532, loss: 0.3192005753517151\n",
      "train epoch: 11/11, round: 416/532, loss: 0.39926600456237793\n",
      "train epoch: 11/11, round: 417/532, loss: 0.3926085829734802\n",
      "train epoch: 11/11, round: 418/532, loss: 0.306986004114151\n",
      "train epoch: 11/11, round: 419/532, loss: 0.35957667231559753\n",
      "train epoch: 11/11, round: 420/532, loss: 0.36087965965270996\n",
      "train epoch: 11/11, round: 421/532, loss: 0.4957338273525238\n",
      "train epoch: 11/11, round: 422/532, loss: 0.3412718176841736\n",
      "train epoch: 11/11, round: 423/532, loss: 0.3276711702346802\n",
      "train epoch: 11/11, round: 424/532, loss: 0.26245126128196716\n",
      "train epoch: 11/11, round: 425/532, loss: 0.398902952671051\n",
      "train epoch: 11/11, round: 426/532, loss: 0.34496134519577026\n",
      "train epoch: 11/11, round: 427/532, loss: 0.3502029478549957\n",
      "train epoch: 11/11, round: 428/532, loss: 0.319966197013855\n",
      "train epoch: 11/11, round: 429/532, loss: 0.2575428783893585\n",
      "train epoch: 11/11, round: 430/532, loss: 0.35785242915153503\n",
      "train epoch: 11/11, round: 431/532, loss: 0.31295907497406006\n",
      "train epoch: 11/11, round: 432/532, loss: 0.29144740104675293\n",
      "train epoch: 11/11, round: 433/532, loss: 0.3173397183418274\n",
      "train epoch: 11/11, round: 434/532, loss: 0.3534752428531647\n",
      "train epoch: 11/11, round: 435/532, loss: 0.29365986585617065\n",
      "train epoch: 11/11, round: 436/532, loss: 0.25851374864578247\n",
      "train epoch: 11/11, round: 437/532, loss: 0.38499313592910767\n",
      "train epoch: 11/11, round: 438/532, loss: 0.39083415269851685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 11/11, round: 439/532, loss: 0.23563846945762634\n",
      "train epoch: 11/11, round: 440/532, loss: 0.32183483242988586\n",
      "train epoch: 11/11, round: 441/532, loss: 0.3062857985496521\n",
      "train epoch: 11/11, round: 442/532, loss: 0.3904515504837036\n",
      "train epoch: 11/11, round: 443/532, loss: 0.29814213514328003\n",
      "train epoch: 11/11, round: 444/532, loss: 0.36400556564331055\n",
      "train epoch: 11/11, round: 445/532, loss: 0.3456394672393799\n",
      "train epoch: 11/11, round: 446/532, loss: 0.4290781021118164\n",
      "train epoch: 11/11, round: 447/532, loss: 0.3131128251552582\n",
      "train epoch: 11/11, round: 448/532, loss: 0.44577592611312866\n",
      "train epoch: 11/11, round: 449/532, loss: 0.32580453157424927\n",
      "train epoch: 11/11, round: 450/532, loss: 0.3021591305732727\n",
      "train epoch: 11/11, round: 451/532, loss: 0.3574487864971161\n",
      "train epoch: 11/11, round: 452/532, loss: 0.32064276933670044\n",
      "train epoch: 11/11, round: 453/532, loss: 0.42190995812416077\n",
      "train epoch: 11/11, round: 454/532, loss: 0.36237093806266785\n",
      "train epoch: 11/11, round: 455/532, loss: 0.36173921823501587\n",
      "train epoch: 11/11, round: 456/532, loss: 0.3491203486919403\n",
      "train epoch: 11/11, round: 457/532, loss: 0.3840872347354889\n",
      "train epoch: 11/11, round: 458/532, loss: 0.37049806118011475\n",
      "train epoch: 11/11, round: 459/532, loss: 0.3918887674808502\n",
      "train epoch: 11/11, round: 460/532, loss: 0.3568635880947113\n",
      "train epoch: 11/11, round: 461/532, loss: 0.3288935720920563\n",
      "train epoch: 11/11, round: 462/532, loss: 0.4593249261379242\n",
      "train epoch: 11/11, round: 463/532, loss: 0.3494485020637512\n",
      "train epoch: 11/11, round: 464/532, loss: 0.4366251826286316\n",
      "train epoch: 11/11, round: 465/532, loss: 0.39494314789772034\n",
      "train epoch: 11/11, round: 466/532, loss: 0.3184564709663391\n",
      "train epoch: 11/11, round: 467/532, loss: 0.38881915807724\n",
      "train epoch: 11/11, round: 468/532, loss: 0.3354043662548065\n",
      "train epoch: 11/11, round: 469/532, loss: 0.4686671793460846\n",
      "train epoch: 11/11, round: 470/532, loss: 0.27903446555137634\n",
      "train epoch: 11/11, round: 471/532, loss: 0.37109628319740295\n",
      "train epoch: 11/11, round: 472/532, loss: 0.34498199820518494\n",
      "train epoch: 11/11, round: 473/532, loss: 0.3961869776248932\n",
      "train epoch: 11/11, round: 474/532, loss: 0.3984621465206146\n",
      "train epoch: 11/11, round: 475/532, loss: 0.38017910718917847\n",
      "train epoch: 11/11, round: 476/532, loss: 0.34042268991470337\n",
      "train epoch: 11/11, round: 477/532, loss: 0.3772970736026764\n",
      "train epoch: 11/11, round: 478/532, loss: 0.3340713083744049\n",
      "train epoch: 11/11, round: 479/532, loss: 0.39824944734573364\n",
      "train epoch: 11/11, round: 480/532, loss: 0.3576192855834961\n",
      "train epoch: 11/11, round: 481/532, loss: 0.359870970249176\n",
      "train epoch: 11/11, round: 482/532, loss: 0.3634021282196045\n",
      "train epoch: 11/11, round: 483/532, loss: 0.31072455644607544\n",
      "train epoch: 11/11, round: 484/532, loss: 0.3002876341342926\n",
      "train epoch: 11/11, round: 485/532, loss: 0.42953985929489136\n",
      "train epoch: 11/11, round: 486/532, loss: 0.38323330879211426\n",
      "train epoch: 11/11, round: 487/532, loss: 0.3674227297306061\n",
      "train epoch: 11/11, round: 488/532, loss: 0.4589698910713196\n",
      "train epoch: 11/11, round: 489/532, loss: 0.33461812138557434\n",
      "train epoch: 11/11, round: 490/532, loss: 0.3117406666278839\n",
      "train epoch: 11/11, round: 491/532, loss: 0.40535658597946167\n",
      "train epoch: 11/11, round: 492/532, loss: 0.2863073945045471\n",
      "train epoch: 11/11, round: 493/532, loss: 0.3749304711818695\n",
      "train epoch: 11/11, round: 494/532, loss: 0.289810448884964\n",
      "train epoch: 11/11, round: 495/532, loss: 0.4109816551208496\n",
      "train epoch: 11/11, round: 496/532, loss: 0.326734721660614\n",
      "train epoch: 11/11, round: 497/532, loss: 0.37982895970344543\n",
      "train epoch: 11/11, round: 498/532, loss: 0.35761475563049316\n",
      "train epoch: 11/11, round: 499/532, loss: 0.340043306350708\n",
      "train epoch: 11/11, round: 500/532, loss: 0.3077270984649658\n",
      "train epoch: 11/11, round: 501/532, loss: 0.34770455956459045\n",
      "train epoch: 11/11, round: 502/532, loss: 0.4331100583076477\n",
      "train epoch: 11/11, round: 503/532, loss: 0.28969311714172363\n",
      "train epoch: 11/11, round: 504/532, loss: 0.3712614178657532\n",
      "train epoch: 11/11, round: 505/532, loss: 0.390857458114624\n",
      "train epoch: 11/11, round: 506/532, loss: 0.2578766942024231\n",
      "train epoch: 11/11, round: 507/532, loss: 0.3933919370174408\n",
      "train epoch: 11/11, round: 508/532, loss: 0.36967071890830994\n",
      "train epoch: 11/11, round: 509/532, loss: 0.40887314081192017\n",
      "train epoch: 11/11, round: 510/532, loss: 0.3460525572299957\n",
      "train epoch: 11/11, round: 511/532, loss: 0.33368563652038574\n",
      "train epoch: 11/11, round: 512/532, loss: 0.30924123525619507\n",
      "train epoch: 11/11, round: 513/532, loss: 0.3870953321456909\n",
      "train epoch: 11/11, round: 514/532, loss: 0.37751805782318115\n",
      "train epoch: 11/11, round: 515/532, loss: 0.342882364988327\n",
      "train epoch: 11/11, round: 516/532, loss: 0.3115973174571991\n",
      "train epoch: 11/11, round: 517/532, loss: 0.3201696276664734\n",
      "train epoch: 11/11, round: 518/532, loss: 0.32658645510673523\n",
      "train epoch: 11/11, round: 519/532, loss: 0.38536638021469116\n",
      "train epoch: 11/11, round: 520/532, loss: 0.29646915197372437\n",
      "train epoch: 11/11, round: 521/532, loss: 0.4269888401031494\n",
      "train epoch: 11/11, round: 522/532, loss: 0.37066465616226196\n",
      "train epoch: 11/11, round: 523/532, loss: 0.3464721143245697\n",
      "train epoch: 11/11, round: 524/532, loss: 0.43688899278640747\n",
      "train epoch: 11/11, round: 525/532, loss: 0.38194534182548523\n",
      "train epoch: 11/11, round: 526/532, loss: 0.3881944715976715\n",
      "train epoch: 11/11, round: 527/532, loss: 0.3755578100681305\n",
      "train epoch: 11/11, round: 528/532, loss: 0.48281222581863403\n",
      "train epoch: 11/11, round: 529/532, loss: 0.4316432476043701\n",
      "train epoch: 11/11, round: 530/532, loss: 0.39591819047927856\n",
      "train epoch: 11/11, round: 531/532, loss: 0.3090352714061737\n",
      "train epoch: 11/11, round: 532/532, loss: 0.24445655941963196\n",
      "train epoch: 11/11, KS: 0.40130625063883285, ROC: 0.7682754297490298\n",
      "test epoch: 11/11, round: 1/501, loss: 0.36864814162254333\n",
      "test epoch: 11/11, round: 2/501, loss: 0.3537307679653168\n",
      "test epoch: 11/11, round: 3/501, loss: 0.25245046615600586\n",
      "test epoch: 11/11, round: 4/501, loss: 0.35550373792648315\n",
      "test epoch: 11/11, round: 5/501, loss: 0.41467028856277466\n",
      "test epoch: 11/11, round: 6/501, loss: 0.3146045506000519\n",
      "test epoch: 11/11, round: 7/501, loss: 0.4485653042793274\n",
      "test epoch: 11/11, round: 8/501, loss: 0.4238678514957428\n",
      "test epoch: 11/11, round: 9/501, loss: 0.4913169741630554\n",
      "test epoch: 11/11, round: 10/501, loss: 0.6189524531364441\n",
      "test epoch: 11/11, round: 11/501, loss: 0.22791124880313873\n",
      "test epoch: 11/11, round: 12/501, loss: 0.4474727213382721\n",
      "test epoch: 11/11, round: 13/501, loss: 0.33308643102645874\n",
      "test epoch: 11/11, round: 14/501, loss: 0.30242136120796204\n",
      "test epoch: 11/11, round: 15/501, loss: 0.4511517584323883\n",
      "test epoch: 11/11, round: 16/501, loss: 0.4459405243396759\n",
      "test epoch: 11/11, round: 17/501, loss: 0.3596208989620209\n",
      "test epoch: 11/11, round: 18/501, loss: 0.49768319725990295\n",
      "test epoch: 11/11, round: 19/501, loss: 0.5505828857421875\n",
      "test epoch: 11/11, round: 20/501, loss: 0.8086223602294922\n",
      "test epoch: 11/11, round: 21/501, loss: 0.3813217282295227\n",
      "test epoch: 11/11, round: 22/501, loss: 0.6072372794151306\n",
      "test epoch: 11/11, round: 23/501, loss: 0.4759620130062103\n",
      "test epoch: 11/11, round: 24/501, loss: 0.4404100179672241\n",
      "test epoch: 11/11, round: 25/501, loss: 0.6926019787788391\n",
      "test epoch: 11/11, round: 26/501, loss: 0.6106154918670654\n",
      "test epoch: 11/11, round: 27/501, loss: 0.2439592033624649\n",
      "test epoch: 11/11, round: 28/501, loss: 0.4666937291622162\n",
      "test epoch: 11/11, round: 29/501, loss: 0.33162450790405273\n",
      "test epoch: 11/11, round: 30/501, loss: 0.5681260824203491\n",
      "test epoch: 11/11, round: 31/501, loss: 0.4687548279762268\n",
      "test epoch: 11/11, round: 32/501, loss: 0.5057173371315002\n",
      "test epoch: 11/11, round: 33/501, loss: 0.6781218647956848\n",
      "test epoch: 11/11, round: 34/501, loss: 0.5610311031341553\n",
      "test epoch: 11/11, round: 35/501, loss: 0.21878738701343536\n",
      "test epoch: 11/11, round: 36/501, loss: 0.420602023601532\n",
      "test epoch: 11/11, round: 37/501, loss: 0.44463852047920227\n",
      "test epoch: 11/11, round: 38/501, loss: 0.4439961016178131\n",
      "test epoch: 11/11, round: 39/501, loss: 0.82491135597229\n",
      "test epoch: 11/11, round: 40/501, loss: 0.5520459413528442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 41/501, loss: 0.4042665660381317\n",
      "test epoch: 11/11, round: 42/501, loss: 0.3796650767326355\n",
      "test epoch: 11/11, round: 43/501, loss: 0.3392970860004425\n",
      "test epoch: 11/11, round: 44/501, loss: 0.5845600962638855\n",
      "test epoch: 11/11, round: 45/501, loss: 0.6405214071273804\n",
      "test epoch: 11/11, round: 46/501, loss: 0.5037298202514648\n",
      "test epoch: 11/11, round: 47/501, loss: 0.25352743268013\n",
      "test epoch: 11/11, round: 48/501, loss: 0.5227482914924622\n",
      "test epoch: 11/11, round: 49/501, loss: 0.3155593276023865\n",
      "test epoch: 11/11, round: 50/501, loss: 0.2465369999408722\n",
      "test epoch: 11/11, round: 51/501, loss: 0.47862404584884644\n",
      "test epoch: 11/11, round: 52/501, loss: 0.3927147686481476\n",
      "test epoch: 11/11, round: 53/501, loss: 0.579917848110199\n",
      "test epoch: 11/11, round: 54/501, loss: 0.6118279695510864\n",
      "test epoch: 11/11, round: 55/501, loss: 0.29200229048728943\n",
      "test epoch: 11/11, round: 56/501, loss: 0.40150752663612366\n",
      "test epoch: 11/11, round: 57/501, loss: 0.30668768286705017\n",
      "test epoch: 11/11, round: 58/501, loss: 0.4316493272781372\n",
      "test epoch: 11/11, round: 59/501, loss: 0.2549034357070923\n",
      "test epoch: 11/11, round: 60/501, loss: 0.42348992824554443\n",
      "test epoch: 11/11, round: 61/501, loss: 0.4365195035934448\n",
      "test epoch: 11/11, round: 62/501, loss: 0.6737138032913208\n",
      "test epoch: 11/11, round: 63/501, loss: 0.7925225496292114\n",
      "test epoch: 11/11, round: 64/501, loss: 0.27231737971305847\n",
      "test epoch: 11/11, round: 65/501, loss: 0.6481176614761353\n",
      "test epoch: 11/11, round: 66/501, loss: 0.43769723176956177\n",
      "test epoch: 11/11, round: 67/501, loss: 0.5532482862472534\n",
      "test epoch: 11/11, round: 68/501, loss: 0.6642476320266724\n",
      "test epoch: 11/11, round: 69/501, loss: 0.5790081024169922\n",
      "test epoch: 11/11, round: 70/501, loss: 0.42624127864837646\n",
      "test epoch: 11/11, round: 71/501, loss: 0.5965955257415771\n",
      "test epoch: 11/11, round: 72/501, loss: 0.5053157210350037\n",
      "test epoch: 11/11, round: 73/501, loss: 0.4953508973121643\n",
      "test epoch: 11/11, round: 74/501, loss: 0.4773135185241699\n",
      "test epoch: 11/11, round: 75/501, loss: 0.5855152010917664\n",
      "test epoch: 11/11, round: 76/501, loss: 0.803591787815094\n",
      "test epoch: 11/11, round: 77/501, loss: 0.3363158404827118\n",
      "test epoch: 11/11, round: 78/501, loss: 0.5192854404449463\n",
      "test epoch: 11/11, round: 79/501, loss: 0.40086829662323\n",
      "test epoch: 11/11, round: 80/501, loss: 0.6116076111793518\n",
      "test epoch: 11/11, round: 81/501, loss: 0.7405955791473389\n",
      "test epoch: 11/11, round: 82/501, loss: 0.6000528335571289\n",
      "test epoch: 11/11, round: 83/501, loss: 0.38826388120651245\n",
      "test epoch: 11/11, round: 84/501, loss: 0.6580972671508789\n",
      "test epoch: 11/11, round: 85/501, loss: 0.6605815887451172\n",
      "test epoch: 11/11, round: 86/501, loss: 0.3202872574329376\n",
      "test epoch: 11/11, round: 87/501, loss: 0.41521796584129333\n",
      "test epoch: 11/11, round: 88/501, loss: 0.3997974395751953\n",
      "test epoch: 11/11, round: 89/501, loss: 0.30839988589286804\n",
      "test epoch: 11/11, round: 90/501, loss: 0.7070302367210388\n",
      "test epoch: 11/11, round: 91/501, loss: 0.3246672749519348\n",
      "test epoch: 11/11, round: 92/501, loss: 0.6930671334266663\n",
      "test epoch: 11/11, round: 93/501, loss: 0.4020841717720032\n",
      "test epoch: 11/11, round: 94/501, loss: 0.6469174027442932\n",
      "test epoch: 11/11, round: 95/501, loss: 0.38926056027412415\n",
      "test epoch: 11/11, round: 96/501, loss: 0.36039307713508606\n",
      "test epoch: 11/11, round: 97/501, loss: 0.6210681796073914\n",
      "test epoch: 11/11, round: 98/501, loss: 0.4531410038471222\n",
      "test epoch: 11/11, round: 99/501, loss: 0.5935462713241577\n",
      "test epoch: 11/11, round: 100/501, loss: 0.5598100423812866\n",
      "test epoch: 11/11, round: 101/501, loss: 0.49188148975372314\n",
      "test epoch: 11/11, round: 102/501, loss: 0.29314735531806946\n",
      "test epoch: 11/11, round: 103/501, loss: 0.46946704387664795\n",
      "test epoch: 11/11, round: 104/501, loss: 0.681977391242981\n",
      "test epoch: 11/11, round: 105/501, loss: 0.4026354253292084\n",
      "test epoch: 11/11, round: 106/501, loss: 0.6237403750419617\n",
      "test epoch: 11/11, round: 107/501, loss: 0.34576380252838135\n",
      "test epoch: 11/11, round: 108/501, loss: 0.6142463684082031\n",
      "test epoch: 11/11, round: 109/501, loss: 0.3195587694644928\n",
      "test epoch: 11/11, round: 110/501, loss: 0.8461323976516724\n",
      "test epoch: 11/11, round: 111/501, loss: 0.18711432814598083\n",
      "test epoch: 11/11, round: 112/501, loss: 0.23314349353313446\n",
      "test epoch: 11/11, round: 113/501, loss: 0.4628467559814453\n",
      "test epoch: 11/11, round: 114/501, loss: 0.4409216344356537\n",
      "test epoch: 11/11, round: 115/501, loss: 0.3221806287765503\n",
      "test epoch: 11/11, round: 116/501, loss: 0.3593709170818329\n",
      "test epoch: 11/11, round: 117/501, loss: 0.3400305509567261\n",
      "test epoch: 11/11, round: 118/501, loss: 0.35615235567092896\n",
      "test epoch: 11/11, round: 119/501, loss: 0.2915063202381134\n",
      "test epoch: 11/11, round: 120/501, loss: 0.40040937066078186\n",
      "test epoch: 11/11, round: 121/501, loss: 0.36797401309013367\n",
      "test epoch: 11/11, round: 122/501, loss: 0.38098227977752686\n",
      "test epoch: 11/11, round: 123/501, loss: 0.4256666600704193\n",
      "test epoch: 11/11, round: 124/501, loss: 0.6071946620941162\n",
      "test epoch: 11/11, round: 125/501, loss: 0.4724150598049164\n",
      "test epoch: 11/11, round: 126/501, loss: 0.40152817964553833\n",
      "test epoch: 11/11, round: 127/501, loss: 0.4049222767353058\n",
      "test epoch: 11/11, round: 128/501, loss: 0.1948976218700409\n",
      "test epoch: 11/11, round: 129/501, loss: 0.36148062348365784\n",
      "test epoch: 11/11, round: 130/501, loss: 0.8742437958717346\n",
      "test epoch: 11/11, round: 131/501, loss: 0.5600765347480774\n",
      "test epoch: 11/11, round: 132/501, loss: 0.4732523560523987\n",
      "test epoch: 11/11, round: 133/501, loss: 0.713128924369812\n",
      "test epoch: 11/11, round: 134/501, loss: 0.5096633434295654\n",
      "test epoch: 11/11, round: 135/501, loss: 0.2822172939777374\n",
      "test epoch: 11/11, round: 136/501, loss: 0.42776501178741455\n",
      "test epoch: 11/11, round: 137/501, loss: 0.39540523290634155\n",
      "test epoch: 11/11, round: 138/501, loss: 0.4435839056968689\n",
      "test epoch: 11/11, round: 139/501, loss: 0.5977187752723694\n",
      "test epoch: 11/11, round: 140/501, loss: 0.4057479202747345\n",
      "test epoch: 11/11, round: 141/501, loss: 0.3613833785057068\n",
      "test epoch: 11/11, round: 142/501, loss: 0.5491025447845459\n",
      "test epoch: 11/11, round: 143/501, loss: 0.4124405086040497\n",
      "test epoch: 11/11, round: 144/501, loss: 0.5592065453529358\n",
      "test epoch: 11/11, round: 145/501, loss: 0.30914077162742615\n",
      "test epoch: 11/11, round: 146/501, loss: 0.5492025017738342\n",
      "test epoch: 11/11, round: 147/501, loss: 0.5581271648406982\n",
      "test epoch: 11/11, round: 148/501, loss: 0.5532341003417969\n",
      "test epoch: 11/11, round: 149/501, loss: 0.316018670797348\n",
      "test epoch: 11/11, round: 150/501, loss: 0.5462176203727722\n",
      "test epoch: 11/11, round: 151/501, loss: 0.30122649669647217\n",
      "test epoch: 11/11, round: 152/501, loss: 0.546654999256134\n",
      "test epoch: 11/11, round: 153/501, loss: 0.4852309823036194\n",
      "test epoch: 11/11, round: 154/501, loss: 0.5933972597122192\n",
      "test epoch: 11/11, round: 155/501, loss: 0.35670387744903564\n",
      "test epoch: 11/11, round: 156/501, loss: 0.33391073346138\n",
      "test epoch: 11/11, round: 157/501, loss: 0.27193230390548706\n",
      "test epoch: 11/11, round: 158/501, loss: 0.45619997382164\n",
      "test epoch: 11/11, round: 159/501, loss: 0.40122362971305847\n",
      "test epoch: 11/11, round: 160/501, loss: 0.44532185792922974\n",
      "test epoch: 11/11, round: 161/501, loss: 0.3495107591152191\n",
      "test epoch: 11/11, round: 162/501, loss: 0.4407544434070587\n",
      "test epoch: 11/11, round: 163/501, loss: 0.43542569875717163\n",
      "test epoch: 11/11, round: 164/501, loss: 0.4058660566806793\n",
      "test epoch: 11/11, round: 165/501, loss: 0.487287700176239\n",
      "test epoch: 11/11, round: 166/501, loss: 0.31515440344810486\n",
      "test epoch: 11/11, round: 167/501, loss: 0.22324545681476593\n",
      "test epoch: 11/11, round: 168/501, loss: 0.1741534024477005\n",
      "test epoch: 11/11, round: 169/501, loss: 0.42382267117500305\n",
      "test epoch: 11/11, round: 170/501, loss: 0.39275607466697693\n",
      "test epoch: 11/11, round: 171/501, loss: 0.5128544569015503\n",
      "test epoch: 11/11, round: 172/501, loss: 0.5150914788246155\n",
      "test epoch: 11/11, round: 173/501, loss: 0.25308266282081604\n",
      "test epoch: 11/11, round: 174/501, loss: 0.5951681733131409\n",
      "test epoch: 11/11, round: 175/501, loss: 0.2505890727043152\n",
      "test epoch: 11/11, round: 176/501, loss: 0.6316675543785095\n",
      "test epoch: 11/11, round: 177/501, loss: 0.29829999804496765\n",
      "test epoch: 11/11, round: 178/501, loss: 0.19789288938045502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 179/501, loss: 0.2764410078525543\n",
      "test epoch: 11/11, round: 180/501, loss: 0.29713425040245056\n",
      "test epoch: 11/11, round: 181/501, loss: 0.5829992890357971\n",
      "test epoch: 11/11, round: 182/501, loss: 0.5832056403160095\n",
      "test epoch: 11/11, round: 183/501, loss: 0.4692832827568054\n",
      "test epoch: 11/11, round: 184/501, loss: 0.6192670464515686\n",
      "test epoch: 11/11, round: 185/501, loss: 0.4604606032371521\n",
      "test epoch: 11/11, round: 186/501, loss: 0.5717681646347046\n",
      "test epoch: 11/11, round: 187/501, loss: 0.5385062098503113\n",
      "test epoch: 11/11, round: 188/501, loss: 0.47446316480636597\n",
      "test epoch: 11/11, round: 189/501, loss: 0.5144062638282776\n",
      "test epoch: 11/11, round: 190/501, loss: 0.4893653988838196\n",
      "test epoch: 11/11, round: 191/501, loss: 0.3843797445297241\n",
      "test epoch: 11/11, round: 192/501, loss: 0.6020694971084595\n",
      "test epoch: 11/11, round: 193/501, loss: 0.5989486575126648\n",
      "test epoch: 11/11, round: 194/501, loss: 0.38252246379852295\n",
      "test epoch: 11/11, round: 195/501, loss: 0.5418115258216858\n",
      "test epoch: 11/11, round: 196/501, loss: 0.26022371649742126\n",
      "test epoch: 11/11, round: 197/501, loss: 0.46198558807373047\n",
      "test epoch: 11/11, round: 198/501, loss: 0.5104774236679077\n",
      "test epoch: 11/11, round: 199/501, loss: 0.46900805830955505\n",
      "test epoch: 11/11, round: 200/501, loss: 0.6805071234703064\n",
      "test epoch: 11/11, round: 201/501, loss: 0.3519980013370514\n",
      "test epoch: 11/11, round: 202/501, loss: 0.37260061502456665\n",
      "test epoch: 11/11, round: 203/501, loss: 0.48815590143203735\n",
      "test epoch: 11/11, round: 204/501, loss: 0.5874536037445068\n",
      "test epoch: 11/11, round: 205/501, loss: 0.4320477247238159\n",
      "test epoch: 11/11, round: 206/501, loss: 0.2416934221982956\n",
      "test epoch: 11/11, round: 207/501, loss: 0.39085420966148376\n",
      "test epoch: 11/11, round: 208/501, loss: 0.47877705097198486\n",
      "test epoch: 11/11, round: 209/501, loss: 0.3132564425468445\n",
      "test epoch: 11/11, round: 210/501, loss: 0.4950365126132965\n",
      "test epoch: 11/11, round: 211/501, loss: 0.2678789794445038\n",
      "test epoch: 11/11, round: 212/501, loss: 0.33147522807121277\n",
      "test epoch: 11/11, round: 213/501, loss: 0.28166401386260986\n",
      "test epoch: 11/11, round: 214/501, loss: 0.2110309600830078\n",
      "test epoch: 11/11, round: 215/501, loss: 0.19736212491989136\n",
      "test epoch: 11/11, round: 216/501, loss: 0.20654115080833435\n",
      "test epoch: 11/11, round: 217/501, loss: 0.13687200844287872\n",
      "test epoch: 11/11, round: 218/501, loss: 0.20240215957164764\n",
      "test epoch: 11/11, round: 219/501, loss: 0.23648390173912048\n",
      "test epoch: 11/11, round: 220/501, loss: 0.3522859215736389\n",
      "test epoch: 11/11, round: 221/501, loss: 0.3608604669570923\n",
      "test epoch: 11/11, round: 222/501, loss: 0.14581532776355743\n",
      "test epoch: 11/11, round: 223/501, loss: 0.17203013598918915\n",
      "test epoch: 11/11, round: 224/501, loss: 0.19015946984291077\n",
      "test epoch: 11/11, round: 225/501, loss: 0.16793575882911682\n",
      "test epoch: 11/11, round: 226/501, loss: 0.16275981068611145\n",
      "test epoch: 11/11, round: 227/501, loss: 0.21507033705711365\n",
      "test epoch: 11/11, round: 228/501, loss: 0.21485178172588348\n",
      "test epoch: 11/11, round: 229/501, loss: 0.39421653747558594\n",
      "test epoch: 11/11, round: 230/501, loss: 0.31120941042900085\n",
      "test epoch: 11/11, round: 231/501, loss: 0.2606486678123474\n",
      "test epoch: 11/11, round: 232/501, loss: 0.44500118494033813\n",
      "test epoch: 11/11, round: 233/501, loss: 0.6205330491065979\n",
      "test epoch: 11/11, round: 234/501, loss: 0.49201202392578125\n",
      "test epoch: 11/11, round: 235/501, loss: 0.28379884362220764\n",
      "test epoch: 11/11, round: 236/501, loss: 0.321728378534317\n",
      "test epoch: 11/11, round: 237/501, loss: 0.3586665987968445\n",
      "test epoch: 11/11, round: 238/501, loss: 0.3793756067752838\n",
      "test epoch: 11/11, round: 239/501, loss: 0.4285043776035309\n",
      "test epoch: 11/11, round: 240/501, loss: 0.21808494627475739\n",
      "test epoch: 11/11, round: 241/501, loss: 0.3721354305744171\n",
      "test epoch: 11/11, round: 242/501, loss: 0.2877022922039032\n",
      "test epoch: 11/11, round: 243/501, loss: 0.30738964676856995\n",
      "test epoch: 11/11, round: 244/501, loss: 0.350711464881897\n",
      "test epoch: 11/11, round: 245/501, loss: 0.3529379665851593\n",
      "test epoch: 11/11, round: 246/501, loss: 0.39581984281539917\n",
      "test epoch: 11/11, round: 247/501, loss: 0.4457797110080719\n",
      "test epoch: 11/11, round: 248/501, loss: 0.2298787236213684\n",
      "test epoch: 11/11, round: 249/501, loss: 0.3108603060245514\n",
      "test epoch: 11/11, round: 250/501, loss: 0.31134337186813354\n",
      "test epoch: 11/11, round: 251/501, loss: 0.32363829016685486\n",
      "test epoch: 11/11, round: 252/501, loss: 0.2737274169921875\n",
      "test epoch: 11/11, round: 253/501, loss: 0.33270689845085144\n",
      "test epoch: 11/11, round: 254/501, loss: 0.2926511764526367\n",
      "test epoch: 11/11, round: 255/501, loss: 0.325893759727478\n",
      "test epoch: 11/11, round: 256/501, loss: 0.4710569679737091\n",
      "test epoch: 11/11, round: 257/501, loss: 0.37654584646224976\n",
      "test epoch: 11/11, round: 258/501, loss: 0.4689564108848572\n",
      "test epoch: 11/11, round: 259/501, loss: 0.24707995355129242\n",
      "test epoch: 11/11, round: 260/501, loss: 0.4937328100204468\n",
      "test epoch: 11/11, round: 261/501, loss: 0.5548338294029236\n",
      "test epoch: 11/11, round: 262/501, loss: 0.4507545232772827\n",
      "test epoch: 11/11, round: 263/501, loss: 0.3548184931278229\n",
      "test epoch: 11/11, round: 264/501, loss: 0.48336970806121826\n",
      "test epoch: 11/11, round: 265/501, loss: 0.5931427478790283\n",
      "test epoch: 11/11, round: 266/501, loss: 0.33931031823158264\n",
      "test epoch: 11/11, round: 267/501, loss: 0.396945595741272\n",
      "test epoch: 11/11, round: 268/501, loss: 0.27539440989494324\n",
      "test epoch: 11/11, round: 269/501, loss: 0.5120460391044617\n",
      "test epoch: 11/11, round: 270/501, loss: 0.26783597469329834\n",
      "test epoch: 11/11, round: 271/501, loss: 0.5594727396965027\n",
      "test epoch: 11/11, round: 272/501, loss: 0.42043536901474\n",
      "test epoch: 11/11, round: 273/501, loss: 0.3553858995437622\n",
      "test epoch: 11/11, round: 274/501, loss: 0.5074326395988464\n",
      "test epoch: 11/11, round: 275/501, loss: 0.3141917586326599\n",
      "test epoch: 11/11, round: 276/501, loss: 0.41728922724723816\n",
      "test epoch: 11/11, round: 277/501, loss: 0.33090630173683167\n",
      "test epoch: 11/11, round: 278/501, loss: 0.5472671389579773\n",
      "test epoch: 11/11, round: 279/501, loss: 0.33252519369125366\n",
      "test epoch: 11/11, round: 280/501, loss: 0.2535955607891083\n",
      "test epoch: 11/11, round: 281/501, loss: 0.20626166462898254\n",
      "test epoch: 11/11, round: 282/501, loss: 0.3314688801765442\n",
      "test epoch: 11/11, round: 283/501, loss: 0.2883042097091675\n",
      "test epoch: 11/11, round: 284/501, loss: 0.373847633600235\n",
      "test epoch: 11/11, round: 285/501, loss: 0.4086085557937622\n",
      "test epoch: 11/11, round: 286/501, loss: 0.46791303157806396\n",
      "test epoch: 11/11, round: 287/501, loss: 0.5810040831565857\n",
      "test epoch: 11/11, round: 288/501, loss: 0.2487335056066513\n",
      "test epoch: 11/11, round: 289/501, loss: 0.3595597445964813\n",
      "test epoch: 11/11, round: 290/501, loss: 0.3046756386756897\n",
      "test epoch: 11/11, round: 291/501, loss: 0.49467647075653076\n",
      "test epoch: 11/11, round: 292/501, loss: 0.5000702738761902\n",
      "test epoch: 11/11, round: 293/501, loss: 0.5221236944198608\n",
      "test epoch: 11/11, round: 294/501, loss: 0.27246129512786865\n",
      "test epoch: 11/11, round: 295/501, loss: 0.3324368894100189\n",
      "test epoch: 11/11, round: 296/501, loss: 0.4231739640235901\n",
      "test epoch: 11/11, round: 297/501, loss: 0.36141377687454224\n",
      "test epoch: 11/11, round: 298/501, loss: 0.43418052792549133\n",
      "test epoch: 11/11, round: 299/501, loss: 0.3996581435203552\n",
      "test epoch: 11/11, round: 300/501, loss: 0.529326856136322\n",
      "test epoch: 11/11, round: 301/501, loss: 0.39442113041877747\n",
      "test epoch: 11/11, round: 302/501, loss: 0.22584566473960876\n",
      "test epoch: 11/11, round: 303/501, loss: 0.5601110458374023\n",
      "test epoch: 11/11, round: 304/501, loss: 0.6559141874313354\n",
      "test epoch: 11/11, round: 305/501, loss: 0.25857335329055786\n",
      "test epoch: 11/11, round: 306/501, loss: 0.3319913148880005\n",
      "test epoch: 11/11, round: 307/501, loss: 0.4561554789543152\n",
      "test epoch: 11/11, round: 308/501, loss: 0.30079787969589233\n",
      "test epoch: 11/11, round: 309/501, loss: 0.3989409804344177\n",
      "test epoch: 11/11, round: 310/501, loss: 0.38118216395378113\n",
      "test epoch: 11/11, round: 311/501, loss: 0.5619519352912903\n",
      "test epoch: 11/11, round: 312/501, loss: 0.45660367608070374\n",
      "test epoch: 11/11, round: 313/501, loss: 0.39275532960891724\n",
      "test epoch: 11/11, round: 314/501, loss: 0.30426087975502014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 315/501, loss: 0.27311375737190247\n",
      "test epoch: 11/11, round: 316/501, loss: 0.30337899923324585\n",
      "test epoch: 11/11, round: 317/501, loss: 0.31848543882369995\n",
      "test epoch: 11/11, round: 318/501, loss: 0.3925429880619049\n",
      "test epoch: 11/11, round: 319/501, loss: 0.5041639804840088\n",
      "test epoch: 11/11, round: 320/501, loss: 0.3972015380859375\n",
      "test epoch: 11/11, round: 321/501, loss: 0.35850995779037476\n",
      "test epoch: 11/11, round: 322/501, loss: 0.48416435718536377\n",
      "test epoch: 11/11, round: 323/501, loss: 0.46007126569747925\n",
      "test epoch: 11/11, round: 324/501, loss: 0.3085686266422272\n",
      "test epoch: 11/11, round: 325/501, loss: 0.4097965359687805\n",
      "test epoch: 11/11, round: 326/501, loss: 0.5187082290649414\n",
      "test epoch: 11/11, round: 327/501, loss: 0.5827713012695312\n",
      "test epoch: 11/11, round: 328/501, loss: 0.19415010511875153\n",
      "test epoch: 11/11, round: 329/501, loss: 0.3969644010066986\n",
      "test epoch: 11/11, round: 330/501, loss: 0.4260938763618469\n",
      "test epoch: 11/11, round: 331/501, loss: 0.42858222126960754\n",
      "test epoch: 11/11, round: 332/501, loss: 0.3187796175479889\n",
      "test epoch: 11/11, round: 333/501, loss: 0.4280962646007538\n",
      "test epoch: 11/11, round: 334/501, loss: 0.29199421405792236\n",
      "test epoch: 11/11, round: 335/501, loss: 0.3566740155220032\n",
      "test epoch: 11/11, round: 336/501, loss: 0.3669591248035431\n",
      "test epoch: 11/11, round: 337/501, loss: 0.5649694800376892\n",
      "test epoch: 11/11, round: 338/501, loss: 0.35812684893608093\n",
      "test epoch: 11/11, round: 339/501, loss: 0.8033101558685303\n",
      "test epoch: 11/11, round: 340/501, loss: 0.4459732174873352\n",
      "test epoch: 11/11, round: 341/501, loss: 0.4592224061489105\n",
      "test epoch: 11/11, round: 342/501, loss: 0.43109792470932007\n",
      "test epoch: 11/11, round: 343/501, loss: 0.3512284457683563\n",
      "test epoch: 11/11, round: 344/501, loss: 0.26785019040107727\n",
      "test epoch: 11/11, round: 345/501, loss: 0.24615511298179626\n",
      "test epoch: 11/11, round: 346/501, loss: 0.32982781529426575\n",
      "test epoch: 11/11, round: 347/501, loss: 0.30189770460128784\n",
      "test epoch: 11/11, round: 348/501, loss: 0.3730418086051941\n",
      "test epoch: 11/11, round: 349/501, loss: 0.2825177013874054\n",
      "test epoch: 11/11, round: 350/501, loss: 0.463204950094223\n",
      "test epoch: 11/11, round: 351/501, loss: 0.4161856472492218\n",
      "test epoch: 11/11, round: 352/501, loss: 0.4961152970790863\n",
      "test epoch: 11/11, round: 353/501, loss: 0.31440791487693787\n",
      "test epoch: 11/11, round: 354/501, loss: 0.5272209048271179\n",
      "test epoch: 11/11, round: 355/501, loss: 0.4052869975566864\n",
      "test epoch: 11/11, round: 356/501, loss: 0.577046811580658\n",
      "test epoch: 11/11, round: 357/501, loss: 0.42715898156166077\n",
      "test epoch: 11/11, round: 358/501, loss: 0.327926367521286\n",
      "test epoch: 11/11, round: 359/501, loss: 0.3748931288719177\n",
      "test epoch: 11/11, round: 360/501, loss: 0.5365012884140015\n",
      "test epoch: 11/11, round: 361/501, loss: 0.5236719250679016\n",
      "test epoch: 11/11, round: 362/501, loss: 0.3177083730697632\n",
      "test epoch: 11/11, round: 363/501, loss: 0.4949455261230469\n",
      "test epoch: 11/11, round: 364/501, loss: 0.45657309889793396\n",
      "test epoch: 11/11, round: 365/501, loss: 0.3989669680595398\n",
      "test epoch: 11/11, round: 366/501, loss: 0.5069150328636169\n",
      "test epoch: 11/11, round: 367/501, loss: 0.6753463745117188\n",
      "test epoch: 11/11, round: 368/501, loss: 0.3246866762638092\n",
      "test epoch: 11/11, round: 369/501, loss: 0.35398751497268677\n",
      "test epoch: 11/11, round: 370/501, loss: 0.40204840898513794\n",
      "test epoch: 11/11, round: 371/501, loss: 0.40037718415260315\n",
      "test epoch: 11/11, round: 372/501, loss: 0.359797865152359\n",
      "test epoch: 11/11, round: 373/501, loss: 0.4594177007675171\n",
      "test epoch: 11/11, round: 374/501, loss: 0.308449923992157\n",
      "test epoch: 11/11, round: 375/501, loss: 0.36666929721832275\n",
      "test epoch: 11/11, round: 376/501, loss: 0.49518883228302\n",
      "test epoch: 11/11, round: 377/501, loss: 0.16522376239299774\n",
      "test epoch: 11/11, round: 378/501, loss: 0.1719963252544403\n",
      "test epoch: 11/11, round: 379/501, loss: 0.41521841287612915\n",
      "test epoch: 11/11, round: 380/501, loss: 0.2954762876033783\n",
      "test epoch: 11/11, round: 381/501, loss: 0.46932318806648254\n",
      "test epoch: 11/11, round: 382/501, loss: 0.2783210575580597\n",
      "test epoch: 11/11, round: 383/501, loss: 0.34171873331069946\n",
      "test epoch: 11/11, round: 384/501, loss: 0.27227458357810974\n",
      "test epoch: 11/11, round: 385/501, loss: 0.5200734734535217\n",
      "test epoch: 11/11, round: 386/501, loss: 0.569445013999939\n",
      "test epoch: 11/11, round: 387/501, loss: 0.26720720529556274\n",
      "test epoch: 11/11, round: 388/501, loss: 0.3389741778373718\n",
      "test epoch: 11/11, round: 389/501, loss: 0.30677279829978943\n",
      "test epoch: 11/11, round: 390/501, loss: 0.44269850850105286\n",
      "test epoch: 11/11, round: 391/501, loss: 0.3888963758945465\n",
      "test epoch: 11/11, round: 392/501, loss: 0.4899933636188507\n",
      "test epoch: 11/11, round: 393/501, loss: 0.3612426817417145\n",
      "test epoch: 11/11, round: 394/501, loss: 0.6254327893257141\n",
      "test epoch: 11/11, round: 395/501, loss: 0.2781391441822052\n",
      "test epoch: 11/11, round: 396/501, loss: 0.41333720088005066\n",
      "test epoch: 11/11, round: 397/501, loss: 0.5089250802993774\n",
      "test epoch: 11/11, round: 398/501, loss: 0.5586258172988892\n",
      "test epoch: 11/11, round: 399/501, loss: 0.35558897256851196\n",
      "test epoch: 11/11, round: 400/501, loss: 0.3164364695549011\n",
      "test epoch: 11/11, round: 401/501, loss: 0.6229643225669861\n",
      "test epoch: 11/11, round: 402/501, loss: 0.419911652803421\n",
      "test epoch: 11/11, round: 403/501, loss: 0.27915629744529724\n",
      "test epoch: 11/11, round: 404/501, loss: 0.23118025064468384\n",
      "test epoch: 11/11, round: 405/501, loss: 0.7365512251853943\n",
      "test epoch: 11/11, round: 406/501, loss: 0.4251022934913635\n",
      "test epoch: 11/11, round: 407/501, loss: 0.4512091875076294\n",
      "test epoch: 11/11, round: 408/501, loss: 0.46751490235328674\n",
      "test epoch: 11/11, round: 409/501, loss: 0.509523868560791\n",
      "test epoch: 11/11, round: 410/501, loss: 0.3480761647224426\n",
      "test epoch: 11/11, round: 411/501, loss: 0.42005234956741333\n",
      "test epoch: 11/11, round: 412/501, loss: 0.4070776104927063\n",
      "test epoch: 11/11, round: 413/501, loss: 0.4530717730522156\n",
      "test epoch: 11/11, round: 414/501, loss: 0.3419443666934967\n",
      "test epoch: 11/11, round: 415/501, loss: 0.38218075037002563\n",
      "test epoch: 11/11, round: 416/501, loss: 0.4015594720840454\n",
      "test epoch: 11/11, round: 417/501, loss: 0.23314127326011658\n",
      "test epoch: 11/11, round: 418/501, loss: 0.3457649350166321\n",
      "test epoch: 11/11, round: 419/501, loss: 0.38887083530426025\n",
      "test epoch: 11/11, round: 420/501, loss: 0.3162589371204376\n",
      "test epoch: 11/11, round: 421/501, loss: 0.4052641689777374\n",
      "test epoch: 11/11, round: 422/501, loss: 0.43155375123023987\n",
      "test epoch: 11/11, round: 423/501, loss: 0.7240273952484131\n",
      "test epoch: 11/11, round: 424/501, loss: 0.39412185549736023\n",
      "test epoch: 11/11, round: 425/501, loss: 0.2925441861152649\n",
      "test epoch: 11/11, round: 426/501, loss: 0.4585660994052887\n",
      "test epoch: 11/11, round: 427/501, loss: 0.2845481038093567\n",
      "test epoch: 11/11, round: 428/501, loss: 0.4772144854068756\n",
      "test epoch: 11/11, round: 429/501, loss: 0.6361256241798401\n",
      "test epoch: 11/11, round: 430/501, loss: 0.5820038318634033\n",
      "test epoch: 11/11, round: 431/501, loss: 0.50230872631073\n",
      "test epoch: 11/11, round: 432/501, loss: 0.32156580686569214\n",
      "test epoch: 11/11, round: 433/501, loss: 0.37166017293930054\n",
      "test epoch: 11/11, round: 434/501, loss: 0.33422553539276123\n",
      "test epoch: 11/11, round: 435/501, loss: 0.3176220655441284\n",
      "test epoch: 11/11, round: 436/501, loss: 0.3730524480342865\n",
      "test epoch: 11/11, round: 437/501, loss: 0.4090980887413025\n",
      "test epoch: 11/11, round: 438/501, loss: 0.5605871081352234\n",
      "test epoch: 11/11, round: 439/501, loss: 0.3717360496520996\n",
      "test epoch: 11/11, round: 440/501, loss: 0.4396347105503082\n",
      "test epoch: 11/11, round: 441/501, loss: 0.4719535708427429\n",
      "test epoch: 11/11, round: 442/501, loss: 0.31617486476898193\n",
      "test epoch: 11/11, round: 443/501, loss: 0.2607586979866028\n",
      "test epoch: 11/11, round: 444/501, loss: 0.4051228165626526\n",
      "test epoch: 11/11, round: 445/501, loss: 0.3726390302181244\n",
      "test epoch: 11/11, round: 446/501, loss: 0.4433909058570862\n",
      "test epoch: 11/11, round: 447/501, loss: 0.23434190452098846\n",
      "test epoch: 11/11, round: 448/501, loss: 0.34108030796051025\n",
      "test epoch: 11/11, round: 449/501, loss: 0.21505409479141235\n",
      "test epoch: 11/11, round: 450/501, loss: 0.6520704627037048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 451/501, loss: 0.3373474180698395\n",
      "test epoch: 11/11, round: 452/501, loss: 0.4088172912597656\n",
      "test epoch: 11/11, round: 453/501, loss: 0.18053951859474182\n",
      "test epoch: 11/11, round: 454/501, loss: 0.2127797156572342\n",
      "test epoch: 11/11, round: 455/501, loss: 0.4944216310977936\n",
      "test epoch: 11/11, round: 456/501, loss: 0.3313247561454773\n",
      "test epoch: 11/11, round: 457/501, loss: 0.2372807413339615\n",
      "test epoch: 11/11, round: 458/501, loss: 0.26587170362472534\n",
      "test epoch: 11/11, round: 459/501, loss: 0.1454218477010727\n",
      "test epoch: 11/11, round: 460/501, loss: 0.11061026155948639\n",
      "test epoch: 11/11, round: 461/501, loss: 0.12498220056295395\n",
      "test epoch: 11/11, round: 462/501, loss: 0.11028016358613968\n",
      "test epoch: 11/11, round: 463/501, loss: 0.1254880577325821\n",
      "test epoch: 11/11, round: 464/501, loss: 0.13463075459003448\n",
      "test epoch: 11/11, round: 465/501, loss: 0.13386224210262299\n",
      "test epoch: 11/11, round: 466/501, loss: 0.12897342443466187\n",
      "test epoch: 11/11, round: 467/501, loss: 0.15469738841056824\n",
      "test epoch: 11/11, round: 468/501, loss: 0.14311151206493378\n",
      "test epoch: 11/11, round: 469/501, loss: 0.14062853157520294\n",
      "test epoch: 11/11, round: 470/501, loss: 0.12132395058870316\n",
      "test epoch: 11/11, round: 471/501, loss: 0.17062200605869293\n",
      "test epoch: 11/11, round: 472/501, loss: 0.14410445094108582\n",
      "test epoch: 11/11, round: 473/501, loss: 0.1151912733912468\n",
      "test epoch: 11/11, round: 474/501, loss: 0.16343221068382263\n",
      "test epoch: 11/11, round: 475/501, loss: 0.1279725432395935\n",
      "test epoch: 11/11, round: 476/501, loss: 0.12674841284751892\n",
      "test epoch: 11/11, round: 477/501, loss: 0.11720018088817596\n",
      "test epoch: 11/11, round: 478/501, loss: 0.1340869516134262\n",
      "test epoch: 11/11, round: 479/501, loss: 0.09927814453840256\n",
      "test epoch: 11/11, round: 480/501, loss: 0.11875171214342117\n",
      "test epoch: 11/11, round: 481/501, loss: 0.12349482625722885\n",
      "test epoch: 11/11, round: 482/501, loss: 0.11268778890371323\n",
      "test epoch: 11/11, round: 483/501, loss: 0.12169389426708221\n",
      "test epoch: 11/11, round: 484/501, loss: 0.12360837310552597\n",
      "test epoch: 11/11, round: 485/501, loss: 0.13190637528896332\n",
      "test epoch: 11/11, round: 486/501, loss: 0.11464723199605942\n",
      "test epoch: 11/11, round: 487/501, loss: 0.10877284407615662\n",
      "test epoch: 11/11, round: 488/501, loss: 0.15676721930503845\n",
      "test epoch: 11/11, round: 489/501, loss: 0.14266131818294525\n",
      "test epoch: 11/11, round: 490/501, loss: 0.14153267443180084\n",
      "test epoch: 11/11, round: 491/501, loss: 0.1587270349264145\n",
      "test epoch: 11/11, round: 492/501, loss: 0.15503931045532227\n",
      "test epoch: 11/11, round: 493/501, loss: 0.1481582075357437\n",
      "test epoch: 11/11, round: 494/501, loss: 0.1617305427789688\n",
      "test epoch: 11/11, round: 495/501, loss: 0.12730886042118073\n",
      "test epoch: 11/11, round: 496/501, loss: 0.17465226352214813\n",
      "test epoch: 11/11, round: 497/501, loss: 0.15759186446666718\n",
      "test epoch: 11/11, round: 498/501, loss: 0.12726087868213654\n",
      "test epoch: 11/11, round: 499/501, loss: 0.15765827894210815\n",
      "test epoch: 11/11, round: 500/501, loss: 0.36351385712623596\n",
      "test epoch: 11/11, round: 501/501, loss: 0.8665875196456909\n",
      "test epoch: 11/11, KS: 0.1765368217488371, ROC: 0.6204173853310336\n",
      "cost time: 2001\n",
      "217889.523ms per batch\n"
     ]
    }
   ],
   "source": [
    "kss = []\n",
    "start = time.time()\n",
    "total_step = len(train_loader)\n",
    "total_step_test = len(test_loader)\n",
    "num_epochs = 11\n",
    "ks_record_train = []\n",
    "ks_record_test = []\n",
    "auc_record_train = []\n",
    "auc_record_test = []\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    train_label = []\n",
    "    train_pred = []\n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        print('train epoch: {}/{}, round: {}/{}, loss: {}'.format(epoch + 1, num_epochs,  i + 1, total_step, loss))\n",
    "        train_label.extend(labels.cpu().numpy().flatten().tolist())\n",
    "        train_pred.extend(out.detach().cpu().numpy().flatten().tolist())\n",
    "        \n",
    "    fpr_lm_train, tpr_lm_train, _ = roc_curve(np.array(train_label), np.array(train_pred))\n",
    "    ks = abs(fpr_lm_train - tpr_lm_train).max()\n",
    "    auc = metrics.auc(fpr_lm_train, tpr_lm_train)\n",
    "    ks_record_train.append(ks)\n",
    "    auc_record_train.append(auc)\n",
    "    print('train epoch: {}/{}, KS: {}, ROC: {}'.format(\n",
    "        epoch + 1, num_epochs, ks, auc))\n",
    "    \n",
    "    test_label = []\n",
    "    test_pred = []\n",
    "    model.eval()\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        print('test epoch: {}/{}, round: {}/{}, loss: {}'.format(epoch + 1, num_epochs,  i + 1, total_step_test, loss))\n",
    "        test_label.extend(labels.cpu().numpy().flatten().tolist())\n",
    "        test_pred.extend(out.detach().cpu().numpy().flatten().tolist())\n",
    "    fpr_lm_test, tpr_lm_test, _ = roc_curve(np.array(test_label), np.array(test_pred))\n",
    "    ks = abs(fpr_lm_test - tpr_lm_test).max()\n",
    "    auc = metrics.auc(fpr_lm_test, tpr_lm_test)\n",
    "    ks_record_test.append(ks)\n",
    "    auc_record_test.append(auc)\n",
    "    print('test epoch: {}/{}, KS: {}, ROC: {}'.format(\n",
    "        epoch + 1, num_epochs, ks, auc))\n",
    "    print('cost time: {}'.format(int(time.time() - epoch_start)))\n",
    "    \n",
    "    # save each model\n",
    "    kss.append(ks)\n",
    "    torch.save(model, 'model_{}.pkl'.format(epoch))\n",
    "end = time.time()\n",
    "elapsed = end-start\n",
    "print(\"{:.3f}ms per batch\".format(elapsed/100 * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1477622471608091,\n",
       " 0.1637916358667652,\n",
       " 0.1731648858723652,\n",
       " 0.2096319691776986,\n",
       " 0.19467516370614282,\n",
       " 0.20109684982341386,\n",
       " 0.19462289720672893,\n",
       " 0.19072269635403838,\n",
       " 0.1768366074561895,\n",
       " 0.18368986552576366,\n",
       " 0.1765368217488371]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存和加载整个模型\n",
    "# torch.save(model, 'model.pkl')\n",
    "model = torch.load('model_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 1/501, loss: 0.3973984122276306\n",
      "test epoch: 11/11, round: 2/501, loss: 0.2994649112224579\n",
      "test epoch: 11/11, round: 3/501, loss: 0.2328028827905655\n",
      "test epoch: 11/11, round: 4/501, loss: 0.3724810779094696\n",
      "test epoch: 11/11, round: 5/501, loss: 0.39677804708480835\n",
      "test epoch: 11/11, round: 6/501, loss: 0.3484899401664734\n",
      "test epoch: 11/11, round: 7/501, loss: 0.4631138741970062\n",
      "test epoch: 11/11, round: 8/501, loss: 0.4428720474243164\n",
      "test epoch: 11/11, round: 9/501, loss: 0.5974291563034058\n",
      "test epoch: 11/11, round: 10/501, loss: 0.6457154154777527\n",
      "test epoch: 11/11, round: 11/501, loss: 0.216862291097641\n",
      "test epoch: 11/11, round: 12/501, loss: 0.35410892963409424\n",
      "test epoch: 11/11, round: 13/501, loss: 0.32568931579589844\n",
      "test epoch: 11/11, round: 14/501, loss: 0.31599894165992737\n",
      "test epoch: 11/11, round: 15/501, loss: 0.4862963855266571\n",
      "test epoch: 11/11, round: 16/501, loss: 0.47851887345314026\n",
      "test epoch: 11/11, round: 17/501, loss: 0.4092242419719696\n",
      "test epoch: 11/11, round: 18/501, loss: 0.49393174052238464\n",
      "test epoch: 11/11, round: 19/501, loss: 0.5475783944129944\n",
      "test epoch: 11/11, round: 20/501, loss: 0.7610218524932861\n",
      "test epoch: 11/11, round: 21/501, loss: 0.4350907504558563\n",
      "test epoch: 11/11, round: 22/501, loss: 0.6147230863571167\n",
      "test epoch: 11/11, round: 23/501, loss: 0.5059613585472107\n",
      "test epoch: 11/11, round: 24/501, loss: 0.4467758536338806\n",
      "test epoch: 11/11, round: 25/501, loss: 0.6334646344184875\n",
      "test epoch: 11/11, round: 26/501, loss: 0.638595700263977\n",
      "test epoch: 11/11, round: 27/501, loss: 0.23205681145191193\n",
      "test epoch: 11/11, round: 28/501, loss: 0.4914127290248871\n",
      "test epoch: 11/11, round: 29/501, loss: 0.27121537923812866\n",
      "test epoch: 11/11, round: 30/501, loss: 0.5269864797592163\n",
      "test epoch: 11/11, round: 31/501, loss: 0.498418927192688\n",
      "test epoch: 11/11, round: 32/501, loss: 0.5744979977607727\n",
      "test epoch: 11/11, round: 33/501, loss: 0.586923360824585\n",
      "test epoch: 11/11, round: 34/501, loss: 0.5017133355140686\n",
      "test epoch: 11/11, round: 35/501, loss: 0.14709140360355377\n",
      "test epoch: 11/11, round: 36/501, loss: 0.4510159194469452\n",
      "test epoch: 11/11, round: 37/501, loss: 0.4231177866458893\n",
      "test epoch: 11/11, round: 38/501, loss: 0.4165264070034027\n",
      "test epoch: 11/11, round: 39/501, loss: 0.6923336386680603\n",
      "test epoch: 11/11, round: 40/501, loss: 0.6186440587043762\n",
      "test epoch: 11/11, round: 41/501, loss: 0.42225825786590576\n",
      "test epoch: 11/11, round: 42/501, loss: 0.39470118284225464\n",
      "test epoch: 11/11, round: 43/501, loss: 0.36591750383377075\n",
      "test epoch: 11/11, round: 44/501, loss: 0.5999024510383606\n",
      "test epoch: 11/11, round: 45/501, loss: 0.6653236150741577\n",
      "test epoch: 11/11, round: 46/501, loss: 0.49653181433677673\n",
      "test epoch: 11/11, round: 47/501, loss: 0.24543753266334534\n",
      "test epoch: 11/11, round: 48/501, loss: 0.5353514552116394\n",
      "test epoch: 11/11, round: 49/501, loss: 0.3153420388698578\n",
      "test epoch: 11/11, round: 50/501, loss: 0.19596093893051147\n",
      "test epoch: 11/11, round: 51/501, loss: 0.4662984311580658\n",
      "test epoch: 11/11, round: 52/501, loss: 0.433624267578125\n",
      "test epoch: 11/11, round: 53/501, loss: 0.5066332221031189\n",
      "test epoch: 11/11, round: 54/501, loss: 0.5698769688606262\n",
      "test epoch: 11/11, round: 55/501, loss: 0.33398640155792236\n",
      "test epoch: 11/11, round: 56/501, loss: 0.46238547563552856\n",
      "test epoch: 11/11, round: 57/501, loss: 0.36760321259498596\n",
      "test epoch: 11/11, round: 58/501, loss: 0.47249355912208557\n",
      "test epoch: 11/11, round: 59/501, loss: 0.2420012503862381\n",
      "test epoch: 11/11, round: 60/501, loss: 0.4981260895729065\n",
      "test epoch: 11/11, round: 61/501, loss: 0.40096911787986755\n",
      "test epoch: 11/11, round: 62/501, loss: 0.6928775310516357\n",
      "test epoch: 11/11, round: 63/501, loss: 0.8264448046684265\n",
      "test epoch: 11/11, round: 64/501, loss: 0.2404932677745819\n",
      "test epoch: 11/11, round: 65/501, loss: 0.6337708830833435\n",
      "test epoch: 11/11, round: 66/501, loss: 0.42042145133018494\n",
      "test epoch: 11/11, round: 67/501, loss: 0.5420656800270081\n",
      "test epoch: 11/11, round: 68/501, loss: 0.6703869104385376\n",
      "test epoch: 11/11, round: 69/501, loss: 0.45197805762290955\n",
      "test epoch: 11/11, round: 70/501, loss: 0.44117873907089233\n",
      "test epoch: 11/11, round: 71/501, loss: 0.5951530933380127\n",
      "test epoch: 11/11, round: 72/501, loss: 0.5464362502098083\n",
      "test epoch: 11/11, round: 73/501, loss: 0.46959051489830017\n",
      "test epoch: 11/11, round: 74/501, loss: 0.48390260338783264\n",
      "test epoch: 11/11, round: 75/501, loss: 0.5587493181228638\n",
      "test epoch: 11/11, round: 76/501, loss: 0.7612679600715637\n",
      "test epoch: 11/11, round: 77/501, loss: 0.3491141200065613\n",
      "test epoch: 11/11, round: 78/501, loss: 0.6459518074989319\n",
      "test epoch: 11/11, round: 79/501, loss: 0.39549192786216736\n",
      "test epoch: 11/11, round: 80/501, loss: 0.5838662981987\n",
      "test epoch: 11/11, round: 81/501, loss: 0.8025224208831787\n",
      "test epoch: 11/11, round: 82/501, loss: 0.6234763860702515\n",
      "test epoch: 11/11, round: 83/501, loss: 0.4249509274959564\n",
      "test epoch: 11/11, round: 84/501, loss: 0.6638756394386292\n",
      "test epoch: 11/11, round: 85/501, loss: 0.5793635845184326\n",
      "test epoch: 11/11, round: 86/501, loss: 0.3166861832141876\n",
      "test epoch: 11/11, round: 87/501, loss: 0.46434077620506287\n",
      "test epoch: 11/11, round: 88/501, loss: 0.3360541760921478\n",
      "test epoch: 11/11, round: 89/501, loss: 0.3332323431968689\n",
      "test epoch: 11/11, round: 90/501, loss: 0.7186608910560608\n",
      "test epoch: 11/11, round: 91/501, loss: 0.3238728940486908\n",
      "test epoch: 11/11, round: 92/501, loss: 0.5939744710922241\n",
      "test epoch: 11/11, round: 93/501, loss: 0.4470893144607544\n",
      "test epoch: 11/11, round: 94/501, loss: 0.6454970836639404\n",
      "test epoch: 11/11, round: 95/501, loss: 0.37637683749198914\n",
      "test epoch: 11/11, round: 96/501, loss: 0.3622906506061554\n",
      "test epoch: 11/11, round: 97/501, loss: 0.6480622887611389\n",
      "test epoch: 11/11, round: 98/501, loss: 0.4021892547607422\n",
      "test epoch: 11/11, round: 99/501, loss: 0.5696058869361877\n",
      "test epoch: 11/11, round: 100/501, loss: 0.5263256430625916\n",
      "test epoch: 11/11, round: 101/501, loss: 0.5533052086830139\n",
      "test epoch: 11/11, round: 102/501, loss: 0.30589327216148376\n",
      "test epoch: 11/11, round: 103/501, loss: 0.4311569929122925\n",
      "test epoch: 11/11, round: 104/501, loss: 0.7069753408432007\n",
      "test epoch: 11/11, round: 105/501, loss: 0.34993693232536316\n",
      "test epoch: 11/11, round: 106/501, loss: 0.6007834076881409\n",
      "test epoch: 11/11, round: 107/501, loss: 0.2885860800743103\n",
      "test epoch: 11/11, round: 108/501, loss: 0.5518075227737427\n",
      "test epoch: 11/11, round: 109/501, loss: 0.3580299913883209\n",
      "test epoch: 11/11, round: 110/501, loss: 0.8180914521217346\n",
      "test epoch: 11/11, round: 111/501, loss: 0.2085927277803421\n",
      "test epoch: 11/11, round: 112/501, loss: 0.20506611466407776\n",
      "test epoch: 11/11, round: 113/501, loss: 0.37791183590888977\n",
      "test epoch: 11/11, round: 114/501, loss: 0.3603496551513672\n",
      "test epoch: 11/11, round: 115/501, loss: 0.28338465094566345\n",
      "test epoch: 11/11, round: 116/501, loss: 0.33147621154785156\n",
      "test epoch: 11/11, round: 117/501, loss: 0.32563626766204834\n",
      "test epoch: 11/11, round: 118/501, loss: 0.29401636123657227\n",
      "test epoch: 11/11, round: 119/501, loss: 0.3112010657787323\n",
      "test epoch: 11/11, round: 120/501, loss: 0.4201526641845703\n",
      "test epoch: 11/11, round: 121/501, loss: 0.40738731622695923\n",
      "test epoch: 11/11, round: 122/501, loss: 0.39633262157440186\n",
      "test epoch: 11/11, round: 123/501, loss: 0.39263781905174255\n",
      "test epoch: 11/11, round: 124/501, loss: 0.6172899603843689\n",
      "test epoch: 11/11, round: 125/501, loss: 0.4166378974914551\n",
      "test epoch: 11/11, round: 126/501, loss: 0.35327452421188354\n",
      "test epoch: 11/11, round: 127/501, loss: 0.41529661417007446\n",
      "test epoch: 11/11, round: 128/501, loss: 0.18085524439811707\n",
      "test epoch: 11/11, round: 129/501, loss: 0.4697292447090149\n",
      "test epoch: 11/11, round: 130/501, loss: 0.795265257358551\n",
      "test epoch: 11/11, round: 131/501, loss: 0.6760513186454773\n",
      "test epoch: 11/11, round: 132/501, loss: 0.4382387399673462\n",
      "test epoch: 11/11, round: 133/501, loss: 0.7768587470054626\n",
      "test epoch: 11/11, round: 134/501, loss: 0.49979811906814575\n",
      "test epoch: 11/11, round: 135/501, loss: 0.29311439394950867\n",
      "test epoch: 11/11, round: 136/501, loss: 0.44709861278533936\n",
      "test epoch: 11/11, round: 137/501, loss: 0.37162160873413086\n",
      "test epoch: 11/11, round: 138/501, loss: 0.4166053831577301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 139/501, loss: 0.5683423280715942\n",
      "test epoch: 11/11, round: 140/501, loss: 0.441366970539093\n",
      "test epoch: 11/11, round: 141/501, loss: 0.2920878827571869\n",
      "test epoch: 11/11, round: 142/501, loss: 0.6085051894187927\n",
      "test epoch: 11/11, round: 143/501, loss: 0.3984758257865906\n",
      "test epoch: 11/11, round: 144/501, loss: 0.43620580434799194\n",
      "test epoch: 11/11, round: 145/501, loss: 0.33844202756881714\n",
      "test epoch: 11/11, round: 146/501, loss: 0.6454355716705322\n",
      "test epoch: 11/11, round: 147/501, loss: 0.46240293979644775\n",
      "test epoch: 11/11, round: 148/501, loss: 0.5067057013511658\n",
      "test epoch: 11/11, round: 149/501, loss: 0.37359854578971863\n",
      "test epoch: 11/11, round: 150/501, loss: 0.6029193997383118\n",
      "test epoch: 11/11, round: 151/501, loss: 0.4489237368106842\n",
      "test epoch: 11/11, round: 152/501, loss: 0.5084524154663086\n",
      "test epoch: 11/11, round: 153/501, loss: 0.6027807593345642\n",
      "test epoch: 11/11, round: 154/501, loss: 0.58971107006073\n",
      "test epoch: 11/11, round: 155/501, loss: 0.39416390657424927\n",
      "test epoch: 11/11, round: 156/501, loss: 0.23563390970230103\n",
      "test epoch: 11/11, round: 157/501, loss: 0.2988570034503937\n",
      "test epoch: 11/11, round: 158/501, loss: 0.4017665982246399\n",
      "test epoch: 11/11, round: 159/501, loss: 0.3772217333316803\n",
      "test epoch: 11/11, round: 160/501, loss: 0.32751426100730896\n",
      "test epoch: 11/11, round: 161/501, loss: 0.3399585783481598\n",
      "test epoch: 11/11, round: 162/501, loss: 0.483158141374588\n",
      "test epoch: 11/11, round: 163/501, loss: 0.4562821090221405\n",
      "test epoch: 11/11, round: 164/501, loss: 0.33012261986732483\n",
      "test epoch: 11/11, round: 165/501, loss: 0.47138386964797974\n",
      "test epoch: 11/11, round: 166/501, loss: 0.2619079053401947\n",
      "test epoch: 11/11, round: 167/501, loss: 0.16733840107917786\n",
      "test epoch: 11/11, round: 168/501, loss: 0.12219800800085068\n",
      "test epoch: 11/11, round: 169/501, loss: 0.3415948748588562\n",
      "test epoch: 11/11, round: 170/501, loss: 0.3603549897670746\n",
      "test epoch: 11/11, round: 171/501, loss: 0.4750900864601135\n",
      "test epoch: 11/11, round: 172/501, loss: 0.5429742336273193\n",
      "test epoch: 11/11, round: 173/501, loss: 0.28859370946884155\n",
      "test epoch: 11/11, round: 174/501, loss: 0.6313574910163879\n",
      "test epoch: 11/11, round: 175/501, loss: 0.22883263230323792\n",
      "test epoch: 11/11, round: 176/501, loss: 0.5677383542060852\n",
      "test epoch: 11/11, round: 177/501, loss: 0.2599204182624817\n",
      "test epoch: 11/11, round: 178/501, loss: 0.17565830051898956\n",
      "test epoch: 11/11, round: 179/501, loss: 0.1686840057373047\n",
      "test epoch: 11/11, round: 180/501, loss: 0.25344741344451904\n",
      "test epoch: 11/11, round: 181/501, loss: 0.5817206501960754\n",
      "test epoch: 11/11, round: 182/501, loss: 0.5674065947532654\n",
      "test epoch: 11/11, round: 183/501, loss: 0.4415903687477112\n",
      "test epoch: 11/11, round: 184/501, loss: 0.5158030986785889\n",
      "test epoch: 11/11, round: 185/501, loss: 0.4659596383571625\n",
      "test epoch: 11/11, round: 186/501, loss: 0.6572971343994141\n",
      "test epoch: 11/11, round: 187/501, loss: 0.5038334727287292\n",
      "test epoch: 11/11, round: 188/501, loss: 0.47300633788108826\n",
      "test epoch: 11/11, round: 189/501, loss: 0.6907145977020264\n",
      "test epoch: 11/11, round: 190/501, loss: 0.4738820791244507\n",
      "test epoch: 11/11, round: 191/501, loss: 0.31033262610435486\n",
      "test epoch: 11/11, round: 192/501, loss: 0.5980460047721863\n",
      "test epoch: 11/11, round: 193/501, loss: 0.48799437284469604\n",
      "test epoch: 11/11, round: 194/501, loss: 0.4825458824634552\n",
      "test epoch: 11/11, round: 195/501, loss: 0.5528191924095154\n",
      "test epoch: 11/11, round: 196/501, loss: 0.2863622307777405\n",
      "test epoch: 11/11, round: 197/501, loss: 0.4063400328159332\n",
      "test epoch: 11/11, round: 198/501, loss: 0.48817339539527893\n",
      "test epoch: 11/11, round: 199/501, loss: 0.5280593037605286\n",
      "test epoch: 11/11, round: 200/501, loss: 0.654388964176178\n",
      "test epoch: 11/11, round: 201/501, loss: 0.31582218408584595\n",
      "test epoch: 11/11, round: 202/501, loss: 0.3340816795825958\n",
      "test epoch: 11/11, round: 203/501, loss: 0.46292632818222046\n",
      "test epoch: 11/11, round: 204/501, loss: 0.6103731393814087\n",
      "test epoch: 11/11, round: 205/501, loss: 0.4123135507106781\n",
      "test epoch: 11/11, round: 206/501, loss: 0.22724966704845428\n",
      "test epoch: 11/11, round: 207/501, loss: 0.38922253251075745\n",
      "test epoch: 11/11, round: 208/501, loss: 0.4926968216896057\n",
      "test epoch: 11/11, round: 209/501, loss: 0.29498279094696045\n",
      "test epoch: 11/11, round: 210/501, loss: 0.49450168013572693\n",
      "test epoch: 11/11, round: 211/501, loss: 0.2398291677236557\n",
      "test epoch: 11/11, round: 212/501, loss: 0.292143315076828\n",
      "test epoch: 11/11, round: 213/501, loss: 0.26163944602012634\n",
      "test epoch: 11/11, round: 214/501, loss: 0.15516676008701324\n",
      "test epoch: 11/11, round: 215/501, loss: 0.11245763301849365\n",
      "test epoch: 11/11, round: 216/501, loss: 0.12132929265499115\n",
      "test epoch: 11/11, round: 217/501, loss: 0.1047251969575882\n",
      "test epoch: 11/11, round: 218/501, loss: 0.13686780631542206\n",
      "test epoch: 11/11, round: 219/501, loss: 0.18342804908752441\n",
      "test epoch: 11/11, round: 220/501, loss: 0.38292211294174194\n",
      "test epoch: 11/11, round: 221/501, loss: 0.3533901572227478\n",
      "test epoch: 11/11, round: 222/501, loss: 0.10066213458776474\n",
      "test epoch: 11/11, round: 223/501, loss: 0.12781701982021332\n",
      "test epoch: 11/11, round: 224/501, loss: 0.11898894608020782\n",
      "test epoch: 11/11, round: 225/501, loss: 0.10795257240533829\n",
      "test epoch: 11/11, round: 226/501, loss: 0.1038801446557045\n",
      "test epoch: 11/11, round: 227/501, loss: 0.15497885644435883\n",
      "test epoch: 11/11, round: 228/501, loss: 0.18794196844100952\n",
      "test epoch: 11/11, round: 229/501, loss: 0.41906148195266724\n",
      "test epoch: 11/11, round: 230/501, loss: 0.2562861442565918\n",
      "test epoch: 11/11, round: 231/501, loss: 0.30367061495780945\n",
      "test epoch: 11/11, round: 232/501, loss: 0.41628584265708923\n",
      "test epoch: 11/11, round: 233/501, loss: 0.5098476409912109\n",
      "test epoch: 11/11, round: 234/501, loss: 0.4823351800441742\n",
      "test epoch: 11/11, round: 235/501, loss: 0.25256994366645813\n",
      "test epoch: 11/11, round: 236/501, loss: 0.3212457001209259\n",
      "test epoch: 11/11, round: 237/501, loss: 0.3244727551937103\n",
      "test epoch: 11/11, round: 238/501, loss: 0.3277931213378906\n",
      "test epoch: 11/11, round: 239/501, loss: 0.4323461651802063\n",
      "test epoch: 11/11, round: 240/501, loss: 0.20567919313907623\n",
      "test epoch: 11/11, round: 241/501, loss: 0.39142316579818726\n",
      "test epoch: 11/11, round: 242/501, loss: 0.24130943417549133\n",
      "test epoch: 11/11, round: 243/501, loss: 0.26660192012786865\n",
      "test epoch: 11/11, round: 244/501, loss: 0.2790144681930542\n",
      "test epoch: 11/11, round: 245/501, loss: 0.3855668902397156\n",
      "test epoch: 11/11, round: 246/501, loss: 0.384326308965683\n",
      "test epoch: 11/11, round: 247/501, loss: 0.46525007486343384\n",
      "test epoch: 11/11, round: 248/501, loss: 0.19454005360603333\n",
      "test epoch: 11/11, round: 249/501, loss: 0.3210345506668091\n",
      "test epoch: 11/11, round: 250/501, loss: 0.2875886857509613\n",
      "test epoch: 11/11, round: 251/501, loss: 0.3442096710205078\n",
      "test epoch: 11/11, round: 252/501, loss: 0.28728580474853516\n",
      "test epoch: 11/11, round: 253/501, loss: 0.330303817987442\n",
      "test epoch: 11/11, round: 254/501, loss: 0.2708373963832855\n",
      "test epoch: 11/11, round: 255/501, loss: 0.33365240693092346\n",
      "test epoch: 11/11, round: 256/501, loss: 0.4411452114582062\n",
      "test epoch: 11/11, round: 257/501, loss: 0.3584538400173187\n",
      "test epoch: 11/11, round: 258/501, loss: 0.39194777607917786\n",
      "test epoch: 11/11, round: 259/501, loss: 0.23317572474479675\n",
      "test epoch: 11/11, round: 260/501, loss: 0.4702794849872589\n",
      "test epoch: 11/11, round: 261/501, loss: 0.5457204580307007\n",
      "test epoch: 11/11, round: 262/501, loss: 0.45789462327957153\n",
      "test epoch: 11/11, round: 263/501, loss: 0.3912122845649719\n",
      "test epoch: 11/11, round: 264/501, loss: 0.47049781680107117\n",
      "test epoch: 11/11, round: 265/501, loss: 0.6374430060386658\n",
      "test epoch: 11/11, round: 266/501, loss: 0.38110026717185974\n",
      "test epoch: 11/11, round: 267/501, loss: 0.3703441321849823\n",
      "test epoch: 11/11, round: 268/501, loss: 0.2659761905670166\n",
      "test epoch: 11/11, round: 269/501, loss: 0.4689141511917114\n",
      "test epoch: 11/11, round: 270/501, loss: 0.26063042879104614\n",
      "test epoch: 11/11, round: 271/501, loss: 0.5477166771888733\n",
      "test epoch: 11/11, round: 272/501, loss: 0.4306362271308899\n",
      "test epoch: 11/11, round: 273/501, loss: 0.3596489727497101\n",
      "test epoch: 11/11, round: 274/501, loss: 0.5095797777175903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 275/501, loss: 0.30187708139419556\n",
      "test epoch: 11/11, round: 276/501, loss: 0.3446420133113861\n",
      "test epoch: 11/11, round: 277/501, loss: 0.3874594271183014\n",
      "test epoch: 11/11, round: 278/501, loss: 0.6420825123786926\n",
      "test epoch: 11/11, round: 279/501, loss: 0.31419387459754944\n",
      "test epoch: 11/11, round: 280/501, loss: 0.1672978699207306\n",
      "test epoch: 11/11, round: 281/501, loss: 0.14619861543178558\n",
      "test epoch: 11/11, round: 282/501, loss: 0.23954330384731293\n",
      "test epoch: 11/11, round: 283/501, loss: 0.24017122387886047\n",
      "test epoch: 11/11, round: 284/501, loss: 0.3733217120170593\n",
      "test epoch: 11/11, round: 285/501, loss: 0.4870239198207855\n",
      "test epoch: 11/11, round: 286/501, loss: 0.33702611923217773\n",
      "test epoch: 11/11, round: 287/501, loss: 0.5459907650947571\n",
      "test epoch: 11/11, round: 288/501, loss: 0.21611028909683228\n",
      "test epoch: 11/11, round: 289/501, loss: 0.3393224775791168\n",
      "test epoch: 11/11, round: 290/501, loss: 0.3367862105369568\n",
      "test epoch: 11/11, round: 291/501, loss: 0.5786649584770203\n",
      "test epoch: 11/11, round: 292/501, loss: 0.5021764636039734\n",
      "test epoch: 11/11, round: 293/501, loss: 0.578682005405426\n",
      "test epoch: 11/11, round: 294/501, loss: 0.21421022713184357\n",
      "test epoch: 11/11, round: 295/501, loss: 0.31165754795074463\n",
      "test epoch: 11/11, round: 296/501, loss: 0.45211726427078247\n",
      "test epoch: 11/11, round: 297/501, loss: 0.3625123202800751\n",
      "test epoch: 11/11, round: 298/501, loss: 0.3884645402431488\n",
      "test epoch: 11/11, round: 299/501, loss: 0.4356403052806854\n",
      "test epoch: 11/11, round: 300/501, loss: 0.5998476147651672\n",
      "test epoch: 11/11, round: 301/501, loss: 0.3565923571586609\n",
      "test epoch: 11/11, round: 302/501, loss: 0.1935875564813614\n",
      "test epoch: 11/11, round: 303/501, loss: 0.658591628074646\n",
      "test epoch: 11/11, round: 304/501, loss: 0.6509389877319336\n",
      "test epoch: 11/11, round: 305/501, loss: 0.14427782595157623\n",
      "test epoch: 11/11, round: 306/501, loss: 0.22973795235157013\n",
      "test epoch: 11/11, round: 307/501, loss: 0.4479157328605652\n",
      "test epoch: 11/11, round: 308/501, loss: 0.25626593828201294\n",
      "test epoch: 11/11, round: 309/501, loss: 0.4724408984184265\n",
      "test epoch: 11/11, round: 310/501, loss: 0.3999205231666565\n",
      "test epoch: 11/11, round: 311/501, loss: 0.6177424192428589\n",
      "test epoch: 11/11, round: 312/501, loss: 0.34759265184402466\n",
      "test epoch: 11/11, round: 313/501, loss: 0.3287791907787323\n",
      "test epoch: 11/11, round: 314/501, loss: 0.3084939122200012\n",
      "test epoch: 11/11, round: 315/501, loss: 0.28335195779800415\n",
      "test epoch: 11/11, round: 316/501, loss: 0.32305005192756653\n",
      "test epoch: 11/11, round: 317/501, loss: 0.3699798882007599\n",
      "test epoch: 11/11, round: 318/501, loss: 0.38260719180107117\n",
      "test epoch: 11/11, round: 319/501, loss: 0.5950702428817749\n",
      "test epoch: 11/11, round: 320/501, loss: 0.39660879969596863\n",
      "test epoch: 11/11, round: 321/501, loss: 0.300021767616272\n",
      "test epoch: 11/11, round: 322/501, loss: 0.4673559069633484\n",
      "test epoch: 11/11, round: 323/501, loss: 0.48139041662216187\n",
      "test epoch: 11/11, round: 324/501, loss: 0.3022502064704895\n",
      "test epoch: 11/11, round: 325/501, loss: 0.45026957988739014\n",
      "test epoch: 11/11, round: 326/501, loss: 0.44851094484329224\n",
      "test epoch: 11/11, round: 327/501, loss: 0.6447716355323792\n",
      "test epoch: 11/11, round: 328/501, loss: 0.1741635501384735\n",
      "test epoch: 11/11, round: 329/501, loss: 0.4567471444606781\n",
      "test epoch: 11/11, round: 330/501, loss: 0.5331871509552002\n",
      "test epoch: 11/11, round: 331/501, loss: 0.4289373457431793\n",
      "test epoch: 11/11, round: 332/501, loss: 0.35276931524276733\n",
      "test epoch: 11/11, round: 333/501, loss: 0.3740958869457245\n",
      "test epoch: 11/11, round: 334/501, loss: 0.25516775250434875\n",
      "test epoch: 11/11, round: 335/501, loss: 0.37231704592704773\n",
      "test epoch: 11/11, round: 336/501, loss: 0.35989513993263245\n",
      "test epoch: 11/11, round: 337/501, loss: 0.6346757411956787\n",
      "test epoch: 11/11, round: 338/501, loss: 0.4003179371356964\n",
      "test epoch: 11/11, round: 339/501, loss: 0.9894537329673767\n",
      "test epoch: 11/11, round: 340/501, loss: 0.49460774660110474\n",
      "test epoch: 11/11, round: 341/501, loss: 0.43494364619255066\n",
      "test epoch: 11/11, round: 342/501, loss: 0.36716416478157043\n",
      "test epoch: 11/11, round: 343/501, loss: 0.35921892523765564\n",
      "test epoch: 11/11, round: 344/501, loss: 0.23229926824569702\n",
      "test epoch: 11/11, round: 345/501, loss: 0.20287984609603882\n",
      "test epoch: 11/11, round: 346/501, loss: 0.30450159311294556\n",
      "test epoch: 11/11, round: 347/501, loss: 0.3363039195537567\n",
      "test epoch: 11/11, round: 348/501, loss: 0.4070102572441101\n",
      "test epoch: 11/11, round: 349/501, loss: 0.34792986512184143\n",
      "test epoch: 11/11, round: 350/501, loss: 0.4969251751899719\n",
      "test epoch: 11/11, round: 351/501, loss: 0.3860844671726227\n",
      "test epoch: 11/11, round: 352/501, loss: 0.46727341413497925\n",
      "test epoch: 11/11, round: 353/501, loss: 0.38531601428985596\n",
      "test epoch: 11/11, round: 354/501, loss: 0.5508154034614563\n",
      "test epoch: 11/11, round: 355/501, loss: 0.3618941009044647\n",
      "test epoch: 11/11, round: 356/501, loss: 0.6140856146812439\n",
      "test epoch: 11/11, round: 357/501, loss: 0.4510502517223358\n",
      "test epoch: 11/11, round: 358/501, loss: 0.4477505385875702\n",
      "test epoch: 11/11, round: 359/501, loss: 0.3916839063167572\n",
      "test epoch: 11/11, round: 360/501, loss: 0.5919421911239624\n",
      "test epoch: 11/11, round: 361/501, loss: 0.5867023468017578\n",
      "test epoch: 11/11, round: 362/501, loss: 0.39866480231285095\n",
      "test epoch: 11/11, round: 363/501, loss: 0.5365254878997803\n",
      "test epoch: 11/11, round: 364/501, loss: 0.5635319948196411\n",
      "test epoch: 11/11, round: 365/501, loss: 0.39864635467529297\n",
      "test epoch: 11/11, round: 366/501, loss: 0.6591619253158569\n",
      "test epoch: 11/11, round: 367/501, loss: 0.7026675939559937\n",
      "test epoch: 11/11, round: 368/501, loss: 0.2601025402545929\n",
      "test epoch: 11/11, round: 369/501, loss: 0.31450405716896057\n",
      "test epoch: 11/11, round: 370/501, loss: 0.44062504172325134\n",
      "test epoch: 11/11, round: 371/501, loss: 0.42179134488105774\n",
      "test epoch: 11/11, round: 372/501, loss: 0.35869741439819336\n",
      "test epoch: 11/11, round: 373/501, loss: 0.4496869444847107\n",
      "test epoch: 11/11, round: 374/501, loss: 0.33853858709335327\n",
      "test epoch: 11/11, round: 375/501, loss: 0.48376062512397766\n",
      "test epoch: 11/11, round: 376/501, loss: 0.6037737727165222\n",
      "test epoch: 11/11, round: 377/501, loss: 0.10303617268800735\n",
      "test epoch: 11/11, round: 378/501, loss: 0.11743629723787308\n",
      "test epoch: 11/11, round: 379/501, loss: 0.46284469962120056\n",
      "test epoch: 11/11, round: 380/501, loss: 0.26708489656448364\n",
      "test epoch: 11/11, round: 381/501, loss: 0.46458521485328674\n",
      "test epoch: 11/11, round: 382/501, loss: 0.23529648780822754\n",
      "test epoch: 11/11, round: 383/501, loss: 0.33401644229888916\n",
      "test epoch: 11/11, round: 384/501, loss: 0.21137575805187225\n",
      "test epoch: 11/11, round: 385/501, loss: 0.5045430660247803\n",
      "test epoch: 11/11, round: 386/501, loss: 0.5980921387672424\n",
      "test epoch: 11/11, round: 387/501, loss: 0.26061350107192993\n",
      "test epoch: 11/11, round: 388/501, loss: 0.25824272632598877\n",
      "test epoch: 11/11, round: 389/501, loss: 0.2918958067893982\n",
      "test epoch: 11/11, round: 390/501, loss: 0.4120313823223114\n",
      "test epoch: 11/11, round: 391/501, loss: 0.36738836765289307\n",
      "test epoch: 11/11, round: 392/501, loss: 0.44928133487701416\n",
      "test epoch: 11/11, round: 393/501, loss: 0.40571674704551697\n",
      "test epoch: 11/11, round: 394/501, loss: 0.6975677013397217\n",
      "test epoch: 11/11, round: 395/501, loss: 0.21865420043468475\n",
      "test epoch: 11/11, round: 396/501, loss: 0.4197811484336853\n",
      "test epoch: 11/11, round: 397/501, loss: 0.527549147605896\n",
      "test epoch: 11/11, round: 398/501, loss: 0.49990272521972656\n",
      "test epoch: 11/11, round: 399/501, loss: 0.31995028257369995\n",
      "test epoch: 11/11, round: 400/501, loss: 0.2865872383117676\n",
      "test epoch: 11/11, round: 401/501, loss: 0.6917074918746948\n",
      "test epoch: 11/11, round: 402/501, loss: 0.47760385274887085\n",
      "test epoch: 11/11, round: 403/501, loss: 0.2743185758590698\n",
      "test epoch: 11/11, round: 404/501, loss: 0.20920512080192566\n",
      "test epoch: 11/11, round: 405/501, loss: 0.8566337823867798\n",
      "test epoch: 11/11, round: 406/501, loss: 0.46644723415374756\n",
      "test epoch: 11/11, round: 407/501, loss: 0.543067991733551\n",
      "test epoch: 11/11, round: 408/501, loss: 0.5862447023391724\n",
      "test epoch: 11/11, round: 409/501, loss: 0.6133424043655396\n",
      "test epoch: 11/11, round: 410/501, loss: 0.351066917181015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch: 11/11, round: 411/501, loss: 0.42277559638023376\n",
      "test epoch: 11/11, round: 412/501, loss: 0.4124056398868561\n",
      "test epoch: 11/11, round: 413/501, loss: 0.5048304796218872\n",
      "test epoch: 11/11, round: 414/501, loss: 0.34697067737579346\n",
      "test epoch: 11/11, round: 415/501, loss: 0.3871397078037262\n",
      "test epoch: 11/11, round: 416/501, loss: 0.4115300476551056\n",
      "test epoch: 11/11, round: 417/501, loss: 0.23815512657165527\n",
      "test epoch: 11/11, round: 418/501, loss: 0.29875048995018005\n",
      "test epoch: 11/11, round: 419/501, loss: 0.3703180253505707\n",
      "test epoch: 11/11, round: 420/501, loss: 0.3106139004230499\n",
      "test epoch: 11/11, round: 421/501, loss: 0.3943749666213989\n",
      "test epoch: 11/11, round: 422/501, loss: 0.47324231266975403\n",
      "test epoch: 11/11, round: 423/501, loss: 0.6822034120559692\n",
      "test epoch: 11/11, round: 424/501, loss: 0.4543965756893158\n",
      "test epoch: 11/11, round: 425/501, loss: 0.32222387194633484\n",
      "test epoch: 11/11, round: 426/501, loss: 0.5167838335037231\n",
      "test epoch: 11/11, round: 427/501, loss: 0.3039768934249878\n",
      "test epoch: 11/11, round: 428/501, loss: 0.5259690880775452\n",
      "test epoch: 11/11, round: 429/501, loss: 0.616436779499054\n",
      "test epoch: 11/11, round: 430/501, loss: 0.6572915315628052\n",
      "test epoch: 11/11, round: 431/501, loss: 0.3971811532974243\n",
      "test epoch: 11/11, round: 432/501, loss: 0.35297998785972595\n",
      "test epoch: 11/11, round: 433/501, loss: 0.45099762082099915\n",
      "test epoch: 11/11, round: 434/501, loss: 0.31054675579071045\n",
      "test epoch: 11/11, round: 435/501, loss: 0.3129884600639343\n",
      "test epoch: 11/11, round: 436/501, loss: 0.36637720465660095\n",
      "test epoch: 11/11, round: 437/501, loss: 0.49549242854118347\n",
      "test epoch: 11/11, round: 438/501, loss: 0.5966746211051941\n",
      "test epoch: 11/11, round: 439/501, loss: 0.3657732605934143\n",
      "test epoch: 11/11, round: 440/501, loss: 0.5002790093421936\n",
      "test epoch: 11/11, round: 441/501, loss: 0.39867985248565674\n",
      "test epoch: 11/11, round: 442/501, loss: 0.34933948516845703\n",
      "test epoch: 11/11, round: 443/501, loss: 0.24082094430923462\n",
      "test epoch: 11/11, round: 444/501, loss: 0.40997403860092163\n",
      "test epoch: 11/11, round: 445/501, loss: 0.44136765599250793\n",
      "test epoch: 11/11, round: 446/501, loss: 0.5486850738525391\n",
      "test epoch: 11/11, round: 447/501, loss: 0.22137035429477692\n",
      "test epoch: 11/11, round: 448/501, loss: 0.315606951713562\n",
      "test epoch: 11/11, round: 449/501, loss: 0.20602545142173767\n",
      "test epoch: 11/11, round: 450/501, loss: 0.7302305102348328\n",
      "test epoch: 11/11, round: 451/501, loss: 0.35017603635787964\n",
      "test epoch: 11/11, round: 452/501, loss: 0.43485021591186523\n",
      "test epoch: 11/11, round: 453/501, loss: 0.12011706084012985\n",
      "test epoch: 11/11, round: 454/501, loss: 0.21309417486190796\n",
      "test epoch: 11/11, round: 455/501, loss: 0.5448792576789856\n",
      "test epoch: 11/11, round: 456/501, loss: 0.28885725140571594\n",
      "test epoch: 11/11, round: 457/501, loss: 0.190487802028656\n",
      "test epoch: 11/11, round: 458/501, loss: 0.23521389067173004\n",
      "test epoch: 11/11, round: 459/501, loss: 0.12862664461135864\n",
      "test epoch: 11/11, round: 460/501, loss: 0.12576760351657867\n",
      "test epoch: 11/11, round: 461/501, loss: 0.11528463661670685\n",
      "test epoch: 11/11, round: 462/501, loss: 0.11076890677213669\n",
      "test epoch: 11/11, round: 463/501, loss: 0.11405747383832932\n",
      "test epoch: 11/11, round: 464/501, loss: 0.11755544692277908\n",
      "test epoch: 11/11, round: 465/501, loss: 0.1490742415189743\n",
      "test epoch: 11/11, round: 466/501, loss: 0.12313392758369446\n",
      "test epoch: 11/11, round: 467/501, loss: 0.15099000930786133\n",
      "test epoch: 11/11, round: 468/501, loss: 0.12443602830171585\n",
      "test epoch: 11/11, round: 469/501, loss: 0.1325816661119461\n",
      "test epoch: 11/11, round: 470/501, loss: 0.11759787052869797\n",
      "test epoch: 11/11, round: 471/501, loss: 0.15596376359462738\n",
      "test epoch: 11/11, round: 472/501, loss: 0.13055215775966644\n",
      "test epoch: 11/11, round: 473/501, loss: 0.10708889365196228\n",
      "test epoch: 11/11, round: 474/501, loss: 0.1292990893125534\n",
      "test epoch: 11/11, round: 475/501, loss: 0.12617385387420654\n",
      "test epoch: 11/11, round: 476/501, loss: 0.0977008119225502\n",
      "test epoch: 11/11, round: 477/501, loss: 0.10768216103315353\n",
      "test epoch: 11/11, round: 478/501, loss: 0.10789290815591812\n",
      "test epoch: 11/11, round: 479/501, loss: 0.07987166196107864\n",
      "test epoch: 11/11, round: 480/501, loss: 0.09608820080757141\n",
      "test epoch: 11/11, round: 481/501, loss: 0.09937524050474167\n",
      "test epoch: 11/11, round: 482/501, loss: 0.09889639168977737\n",
      "test epoch: 11/11, round: 483/501, loss: 0.10855193436145782\n",
      "test epoch: 11/11, round: 484/501, loss: 0.1345711052417755\n",
      "test epoch: 11/11, round: 485/501, loss: 0.08736928552389145\n",
      "test epoch: 11/11, round: 486/501, loss: 0.09244231134653091\n",
      "test epoch: 11/11, round: 487/501, loss: 0.09073392301797867\n",
      "test epoch: 11/11, round: 488/501, loss: 0.13369394838809967\n",
      "test epoch: 11/11, round: 489/501, loss: 0.10038426518440247\n",
      "test epoch: 11/11, round: 490/501, loss: 0.07643251121044159\n",
      "test epoch: 11/11, round: 491/501, loss: 0.11370695382356644\n",
      "test epoch: 11/11, round: 492/501, loss: 0.10916389524936676\n",
      "test epoch: 11/11, round: 493/501, loss: 0.1223403587937355\n",
      "test epoch: 11/11, round: 494/501, loss: 0.13587337732315063\n",
      "test epoch: 11/11, round: 495/501, loss: 0.08341493457555771\n",
      "test epoch: 11/11, round: 496/501, loss: 0.11257065087556839\n",
      "test epoch: 11/11, round: 497/501, loss: 0.09069838374853134\n",
      "test epoch: 11/11, round: 498/501, loss: 0.08377072960138321\n",
      "test epoch: 11/11, round: 499/501, loss: 0.0775960236787796\n",
      "test epoch: 11/11, round: 500/501, loss: 0.3362387418746948\n",
      "test epoch: 11/11, round: 501/501, loss: 1.046407699584961\n"
     ]
    }
   ],
   "source": [
    "test_label = []\n",
    "test_pred = []\n",
    "# model.eval()\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    out = model(images)\n",
    "    loss = criterion(out, labels)\n",
    "    print('test epoch: {}/{}, round: {}/{}, loss: {}'.format(epoch + 1, num_epochs,  i + 1, total_step_test, loss))\n",
    "    test_label.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    test_pred.extend(out.detach().cpu().numpy().flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.044049546122550964,\n",
       " 0.2345128208398819,\n",
       " 0.10399012267589569,\n",
       " 0.047530170530080795,\n",
       " 0.10066536068916321,\n",
       " 0.1304420679807663,\n",
       " 0.07475595921278,\n",
       " 0.08165820688009262,\n",
       " 0.04309720918536186,\n",
       " 0.17516040802001953,\n",
       " 0.07249382138252258,\n",
       " 0.10393200069665909,\n",
       " 0.09334211051464081,\n",
       " 0.13484381139278412,\n",
       " 0.13223084807395935,\n",
       " 0.06460276991128922,\n",
       " 0.17493398487567902,\n",
       " 0.09255404770374298,\n",
       " 0.0909789428114891,\n",
       " 0.08940394967794418,\n",
       " 0.07806077599525452,\n",
       " 0.18272213637828827,\n",
       " 0.1020895317196846,\n",
       " 0.034803878515958786,\n",
       " 0.15620091557502747,\n",
       " 0.04620646312832832,\n",
       " 0.11799341440200806,\n",
       " 0.03598358854651451,\n",
       " 0.12071331590414047,\n",
       " 0.08005756884813309,\n",
       " 0.418770432472229,\n",
       " 0.15280479192733765,\n",
       " 0.11832275241613388,\n",
       " 0.04518819972872734,\n",
       " 0.09281561523675919,\n",
       " 0.11084058880805969,\n",
       " 0.09233279526233673,\n",
       " 0.04216582700610161,\n",
       " 0.2027457356452942,\n",
       " 0.10715745389461517,\n",
       " 0.09536615759134293,\n",
       " 0.2607821822166443,\n",
       " 0.04116865247488022,\n",
       " 0.18536357581615448,\n",
       " 0.1475083827972412,\n",
       " 0.19869370758533478,\n",
       " 0.37272927165031433,\n",
       " 0.04833187907934189,\n",
       " 0.16578508913516998,\n",
       " 0.05708407610654831,\n",
       " 0.18770189583301544,\n",
       " 0.06617622822523117,\n",
       " 0.04087066277861595,\n",
       " 0.04547802731394768,\n",
       " 0.06713320314884186,\n",
       " 0.2649015188217163,\n",
       " 0.05131847783923149,\n",
       " 0.06494360417127609,\n",
       " 0.09560098499059677,\n",
       " 0.21073952317237854,\n",
       " 0.06686240434646606,\n",
       " 0.040422555059194565,\n",
       " 0.22753643989562988,\n",
       " 0.08584993332624435,\n",
       " 0.1754681020975113,\n",
       " 0.3260380029678345,\n",
       " 0.04937981441617012,\n",
       " 0.05391593649983406,\n",
       " 0.06160007789731026,\n",
       " 0.1174619197845459,\n",
       " 0.1518116295337677,\n",
       " 0.1799686998128891,\n",
       " 0.10534194856882095,\n",
       " 0.25675925612449646,\n",
       " 0.04371480271220207,\n",
       " 0.13152499496936798,\n",
       " 0.11257840692996979,\n",
       " 0.2111290842294693,\n",
       " 0.13349691033363342,\n",
       " 0.21770334243774414,\n",
       " 0.2342483103275299,\n",
       " 0.03649561107158661,\n",
       " 0.03685230761766434,\n",
       " 0.05702349543571472,\n",
       " 0.08347639441490173,\n",
       " 0.1090100109577179,\n",
       " 0.05236374959349632,\n",
       " 0.45326077938079834,\n",
       " 0.17340631783008575,\n",
       " 0.13793553411960602,\n",
       " 0.07491419464349747,\n",
       " 0.14714016020298004,\n",
       " 0.10986404120922089,\n",
       " 0.05305295065045357,\n",
       " 0.0895514190196991,\n",
       " 0.1412738412618637,\n",
       " 0.3984583020210266,\n",
       " 0.13158021867275238,\n",
       " 0.06640983372926712,\n",
       " 0.26327449083328247,\n",
       " 0.07881225645542145,\n",
       " 0.06782204657793045,\n",
       " 0.13034355640411377,\n",
       " 0.14427471160888672,\n",
       " 0.07015227526426315,\n",
       " 0.06483068317174911,\n",
       " 0.07145475596189499,\n",
       " 0.043664414435625076,\n",
       " 0.03980260342359543,\n",
       " 0.18706014752388,\n",
       " 0.3288126289844513,\n",
       " 0.051473453640937805,\n",
       " 0.2342996597290039,\n",
       " 0.03399442881345749,\n",
       " 0.13051316142082214,\n",
       " 0.07163621485233307,\n",
       " 0.2226378619670868,\n",
       " 0.06955831497907639,\n",
       " 0.08127816021442413,\n",
       " 0.18722164630889893,\n",
       " 0.1931019425392151,\n",
       " 0.04369381070137024,\n",
       " 0.037485189735889435,\n",
       " 0.15411756932735443,\n",
       " 0.28579598665237427,\n",
       " 0.18009549379348755,\n",
       " 0.05216185748577118,\n",
       " 0.057304851710796356,\n",
       " 0.14977490901947021,\n",
       " 0.07051096111536026,\n",
       " 0.04889599606394768,\n",
       " 0.06037415936589241,\n",
       " 0.11470136046409607,\n",
       " 0.11459563672542572,\n",
       " 0.22042910754680634,\n",
       " 0.19991563260555267,\n",
       " 0.2101212441921234,\n",
       " 0.043678123503923416,\n",
       " 0.0691101998090744,\n",
       " 0.13335010409355164,\n",
       " 0.3839581608772278,\n",
       " 0.052161622792482376,\n",
       " 0.08824707567691803,\n",
       " 0.31362664699554443,\n",
       " 0.33649134635925293,\n",
       " 0.03399442881345749,\n",
       " 0.17296698689460754,\n",
       " 0.17097823321819305,\n",
       " 0.08350284397602081,\n",
       " 0.03827712684869766,\n",
       " 0.3013854920864105,\n",
       " 0.18009549379348755,\n",
       " 0.04532656446099281,\n",
       " 0.07630074769258499,\n",
       " 0.17855311930179596,\n",
       " 0.051330242305994034,\n",
       " 0.042257875204086304,\n",
       " 0.14050990343093872,\n",
       " 0.07519418746232986,\n",
       " 0.0359342135488987,\n",
       " 0.03832467272877693,\n",
       " 0.2316754162311554,\n",
       " 0.20202741026878357,\n",
       " 0.06378433853387833,\n",
       " 0.18865303695201874,\n",
       " 0.13998830318450928,\n",
       " 0.04933564364910126,\n",
       " 0.08548090606927872,\n",
       " 0.14749708771705627,\n",
       " 0.17397449910640717,\n",
       " 0.1825147569179535,\n",
       " 0.06418619304895401,\n",
       " 0.07770352810621262,\n",
       " 0.24468041956424713,\n",
       " 0.04527934640645981,\n",
       " 0.1170516312122345,\n",
       " 0.12344393879175186,\n",
       " 0.06448464095592499,\n",
       " 0.0912637934088707,\n",
       " 0.44525590538978577,\n",
       " 0.05781101807951927,\n",
       " 0.07482202351093292,\n",
       " 0.1978825479745865,\n",
       " 0.03869609534740448,\n",
       " 0.04067618399858475,\n",
       " 0.1800372451543808,\n",
       " 0.32688790559768677,\n",
       " 0.07388447970151901,\n",
       " 0.20115427672863007,\n",
       " 0.040752261877059937,\n",
       " 0.07927702367305756,\n",
       " 0.09796009212732315,\n",
       " 0.0549209825694561,\n",
       " 0.13817135989665985,\n",
       " 0.23664236068725586,\n",
       " 0.03454071283340454,\n",
       " 0.03939063474535942,\n",
       " 0.16596679389476776,\n",
       " 0.051725585013628006,\n",
       " 0.12358089536428452,\n",
       " 0.04207698255777359,\n",
       " 0.05938614904880524,\n",
       " 0.2360214740037918,\n",
       " 0.44441524147987366,\n",
       " 0.1907779723405838,\n",
       " 0.05242646113038063,\n",
       " 0.06777605414390564,\n",
       " 0.11224424839019775,\n",
       " 0.15752215683460236,\n",
       " 0.4909508526325226,\n",
       " 0.056735895574092865,\n",
       " 0.12483346462249756,\n",
       " 0.1442704200744629,\n",
       " 0.03698248788714409,\n",
       " 0.0360613688826561,\n",
       " 0.03973844274878502,\n",
       " 0.17478644847869873,\n",
       " 0.05558999255299568,\n",
       " 0.04680539295077324,\n",
       " 0.33386245369911194,\n",
       " 0.26784080266952515,\n",
       " 0.2567911446094513,\n",
       " 0.04251720756292343,\n",
       " 0.09710624068975449,\n",
       " 0.2690224051475525,\n",
       " 0.04690241068601608,\n",
       " 0.14963994920253754,\n",
       " 0.16045185923576355,\n",
       " 0.15360839664936066,\n",
       " 0.055546872317790985,\n",
       " 0.12625907361507416,\n",
       " 0.17356079816818237,\n",
       " 0.07403356581926346,\n",
       " 0.04707973822951317,\n",
       " 0.08451872318983078,\n",
       " 0.10101338475942612,\n",
       " 0.40537217259407043,\n",
       " 0.061567794531583786,\n",
       " 0.08876273036003113,\n",
       " 0.08499705791473389,\n",
       " 0.0740990936756134,\n",
       " 0.044328074902296066,\n",
       " 0.1386060118675232,\n",
       " 0.24787160754203796,\n",
       " 0.11515926569700241,\n",
       " 0.13815495371818542,\n",
       " 0.0782557800412178,\n",
       " 0.03409036248922348,\n",
       " 0.2630542516708374,\n",
       " 0.07305143773555756,\n",
       " 0.24913877248764038,\n",
       " 0.05842311680316925,\n",
       " 0.04355233162641525,\n",
       " 0.07622798532247543,\n",
       " 0.17884325981140137,\n",
       " 0.22246979176998138,\n",
       " 0.04489826038479805,\n",
       " 0.1358729898929596,\n",
       " 0.11239007115364075,\n",
       " 0.1173207238316536,\n",
       " 0.08275972306728363,\n",
       " 0.04040142521262169,\n",
       " 0.06939628720283508,\n",
       " 0.2306639701128006,\n",
       " 0.11147072166204453,\n",
       " 0.20196600258350372,\n",
       " 0.1061929315328598,\n",
       " 0.09098200500011444,\n",
       " 0.08627050369977951,\n",
       " 0.12890082597732544,\n",
       " 0.07765898108482361,\n",
       " 0.2633119225502014,\n",
       " 0.08282168209552765,\n",
       " 0.04222533851861954,\n",
       " 0.1615016609430313,\n",
       " 0.040921639651060104,\n",
       " 0.04141366109251976,\n",
       " 0.051791440695524216,\n",
       " 0.12085485458374023,\n",
       " 0.04761519283056259,\n",
       " 0.14623795449733734,\n",
       " 0.1571701020002365,\n",
       " 0.46687498688697815,\n",
       " 0.22356343269348145,\n",
       " 0.08451451361179352,\n",
       " 0.0269736647605896,\n",
       " 0.08044938743114471,\n",
       " 0.09776182472705841,\n",
       " 0.22077663242816925,\n",
       " 0.06143968552350998,\n",
       " 0.04248849302530289,\n",
       " 0.42519664764404297,\n",
       " 0.06854555755853653,\n",
       " 0.29776108264923096,\n",
       " 0.05047599598765373,\n",
       " 0.03318222612142563,\n",
       " 0.07504191994667053,\n",
       " 0.41694176197052,\n",
       " 0.09988348931074142,\n",
       " 0.13028623163700104,\n",
       " 0.4068247973918915,\n",
       " 0.18150775134563446,\n",
       " 0.035950079560279846,\n",
       " 0.12828117609024048,\n",
       " 0.05426742881536484,\n",
       " 0.05081181973218918,\n",
       " 0.03602151945233345,\n",
       " 0.03564753010869026,\n",
       " 0.13765354454517365,\n",
       " 0.09724655002355576,\n",
       " 0.03929607942700386,\n",
       " 0.12835054099559784,\n",
       " 0.31173181533813477,\n",
       " 0.06662309169769287,\n",
       " 0.18213409185409546,\n",
       " 0.07409781962633133,\n",
       " 0.03745057061314583,\n",
       " 0.07237890362739563,\n",
       " 0.08537216484546661,\n",
       " 0.1798214614391327,\n",
       " 0.03270505368709564,\n",
       " 0.04438813030719757,\n",
       " 0.13982728123664856,\n",
       " 0.09824532270431519,\n",
       " 0.16313210129737854,\n",
       " 0.10396790504455566,\n",
       " 0.12525305151939392,\n",
       " 0.036437179893255234,\n",
       " 0.04683412238955498,\n",
       " 0.16621895134449005,\n",
       " 0.09108148515224457,\n",
       " 0.15161488950252533,\n",
       " 0.1476028710603714,\n",
       " 0.2885751724243164,\n",
       " 0.05058194324374199,\n",
       " 0.20857641100883484,\n",
       " 0.051018472760915756,\n",
       " 0.12179997563362122,\n",
       " 0.07181865721940994,\n",
       " 0.11816253513097763,\n",
       " 0.16621895134449005,\n",
       " 0.039696186780929565,\n",
       " 0.15559980273246765,\n",
       " 0.05876501277089119,\n",
       " 0.13602493703365326,\n",
       " 0.03530197963118553,\n",
       " 0.059483602643013,\n",
       " 0.0762348547577858,\n",
       " 0.14782074093818665,\n",
       " 0.27021142840385437,\n",
       " 0.1251349300146103,\n",
       " 0.20450259745121002,\n",
       " 0.08296389132738113,\n",
       " 0.14444831013679504,\n",
       " 0.22031134366989136,\n",
       " 0.18076777458190918,\n",
       " 0.06874755024909973,\n",
       " 0.11419764161109924,\n",
       " 0.03924334794282913,\n",
       " 0.048265356570482254,\n",
       " 0.09021855145692825,\n",
       " 0.27626389265060425,\n",
       " 0.20610806345939636,\n",
       " 0.19328367710113525,\n",
       " 0.05377655476331711,\n",
       " 0.0371982678771019,\n",
       " 0.13926222920417786,\n",
       " 0.08975052833557129,\n",
       " 0.10495860874652863,\n",
       " 0.04451053589582443,\n",
       " 0.06458546966314316,\n",
       " 0.1621048003435135,\n",
       " 0.089677594602108,\n",
       " 0.1458224058151245,\n",
       " 0.05170813947916031,\n",
       " 0.17792877554893494,\n",
       " 0.06999596953392029,\n",
       " 0.12436556816101074,\n",
       " 0.28027406334877014,\n",
       " 0.17665952444076538,\n",
       " 0.13365191221237183,\n",
       " 0.08500652015209198,\n",
       " 0.11985736340284348,\n",
       " 0.11271066963672638,\n",
       " 0.06843656301498413,\n",
       " 0.3005700707435608,\n",
       " 0.12527257204055786,\n",
       " 0.3943459689617157,\n",
       " 0.04473995417356491,\n",
       " 0.0377262681722641,\n",
       " 0.0676194354891777,\n",
       " 0.04534412920475006,\n",
       " 0.07622187584638596,\n",
       " 0.16581860184669495,\n",
       " 0.19649457931518555,\n",
       " 0.05883702263236046,\n",
       " 0.15911945700645447,\n",
       " 0.0467665009200573,\n",
       " 0.17813840508460999,\n",
       " 0.06656663864850998,\n",
       " 0.10013536363840103,\n",
       " 0.3975816071033478,\n",
       " 0.18269971013069153,\n",
       " 0.1411224752664566,\n",
       " 0.24491067230701447,\n",
       " 0.0862659141421318,\n",
       " 0.16854175925254822,\n",
       " 0.1522390991449356,\n",
       " 0.16240136325359344,\n",
       " 0.05132068321108818,\n",
       " 0.44351842999458313,\n",
       " 0.1311655044555664,\n",
       " 0.1850283145904541,\n",
       " 0.05467638373374939,\n",
       " 0.19618816673755646,\n",
       " 0.08125656843185425,\n",
       " 0.07883144915103912,\n",
       " 0.10385888069868088,\n",
       " 0.04375261440873146,\n",
       " 0.16652268171310425,\n",
       " 0.11551533639431,\n",
       " 0.05405581369996071,\n",
       " 0.19884058833122253,\n",
       " 0.0761009231209755,\n",
       " 0.20758174359798431,\n",
       " 0.055358316749334335,\n",
       " 0.05390315502882004,\n",
       " 0.058435503393411636,\n",
       " 0.06195833906531334,\n",
       " 0.036959968507289886,\n",
       " 0.03939063474535942,\n",
       " 0.0651870146393776,\n",
       " 0.08488418161869049,\n",
       " 0.03361068665981293,\n",
       " 0.06611578911542892,\n",
       " 0.17054785788059235,\n",
       " 0.10036798566579819,\n",
       " 0.14613766968250275,\n",
       " 0.132881760597229,\n",
       " 0.07459595799446106,\n",
       " 0.04167203605175018,\n",
       " 0.14025810360908508,\n",
       " 0.07392659783363342,\n",
       " 0.0779062956571579,\n",
       " 0.3165717124938965,\n",
       " 0.08484833687543869,\n",
       " 0.05170813947916031,\n",
       " 0.0659915953874588,\n",
       " 0.04743413254618645,\n",
       " 0.17113593220710754,\n",
       " 0.35585692524909973,\n",
       " 0.04209659993648529,\n",
       " 0.10478612780570984,\n",
       " 0.06425365060567856,\n",
       " 0.09781451523303986,\n",
       " 0.3570566177368164,\n",
       " 0.07205703109502792,\n",
       " 0.06422644853591919,\n",
       " 0.2020101696252823,\n",
       " 0.06700043380260468,\n",
       " 0.14644880592823029,\n",
       " 0.1989736407995224,\n",
       " 0.08146968483924866,\n",
       " 0.06826622784137726,\n",
       " 0.1778472512960434,\n",
       " 0.08334086835384369,\n",
       " 0.08699292689561844,\n",
       " 0.25990307331085205,\n",
       " 0.1400611251592636,\n",
       " 0.285280704498291,\n",
       " 0.07198003679513931,\n",
       " 0.050129227340221405,\n",
       " 0.14233437180519104,\n",
       " 0.3987257778644562,\n",
       " 0.05144796520471573,\n",
       " 0.07396349310874939,\n",
       " 0.16651731729507446,\n",
       " 0.1835847645998001,\n",
       " 0.3650347590446472,\n",
       " 0.06517529487609863,\n",
       " 0.07704982906579971,\n",
       " 0.08593925088644028,\n",
       " 0.05378462374210358,\n",
       " 0.24049276113510132,\n",
       " 0.11295416951179504,\n",
       " 0.036629851907491684,\n",
       " 0.04462680220603943,\n",
       " 0.09373340755701065,\n",
       " 0.18020299077033997,\n",
       " 0.05627775192260742,\n",
       " 0.07564792037010193,\n",
       " 0.158340722322464,\n",
       " 0.3283982574939728,\n",
       " 0.2558274567127228,\n",
       " 0.1750219166278839,\n",
       " 0.3264853060245514,\n",
       " 0.19163662195205688,\n",
       " 0.03222108632326126,\n",
       " 0.0916144922375679,\n",
       " 0.20821930468082428,\n",
       " 0.05397653207182884,\n",
       " 0.14010116457939148,\n",
       " 0.03600352257490158,\n",
       " 0.049656037241220474,\n",
       " 0.08992324024438858,\n",
       " 0.1641194075345993,\n",
       " 0.15734556317329407,\n",
       " 0.05934656783938408,\n",
       " 0.2851629853248596,\n",
       " 0.05065363273024559,\n",
       " 0.3450964093208313,\n",
       " 0.10964834690093994,\n",
       " 0.12775997817516327,\n",
       " 0.08700592815876007,\n",
       " 0.11457688361406326,\n",
       " 0.44288206100463867,\n",
       " 0.2198721319437027,\n",
       " 0.28651800751686096,\n",
       " 0.058778323233127594,\n",
       " 0.22718408703804016,\n",
       " 0.1526387333869934,\n",
       " 0.4398980736732483,\n",
       " 0.1738067865371704,\n",
       " 0.07577207684516907,\n",
       " 0.20331281423568726,\n",
       " 0.18003463745117188,\n",
       " 0.277216374874115,\n",
       " 0.06849592179059982,\n",
       " 0.054949916899204254,\n",
       " 0.12280645221471786,\n",
       " 0.44363418221473694,\n",
       " 0.2865038812160492,\n",
       " 0.09404531121253967,\n",
       " 0.18588215112686157,\n",
       " 0.10584425926208496,\n",
       " 0.09865251183509827,\n",
       " 0.029848452657461166,\n",
       " 0.16919027268886566,\n",
       " 0.03586168214678764,\n",
       " 0.07851698249578476,\n",
       " 0.12852796912193298,\n",
       " 0.07672064006328583,\n",
       " 0.2306852787733078,\n",
       " 0.10860256105661392,\n",
       " 0.33225852251052856,\n",
       " 0.08297891169786453,\n",
       " 0.12949833273887634,\n",
       " 0.1409265398979187,\n",
       " 0.25643911957740784,\n",
       " 0.13606950640678406,\n",
       " 0.16984261572360992,\n",
       " 0.07875706255435944,\n",
       " 0.1607375293970108,\n",
       " 0.2544329762458801,\n",
       " 0.0615132637321949,\n",
       " 0.42602431774139404,\n",
       " 0.03372683748602867,\n",
       " 0.2162727564573288,\n",
       " 0.058521222323179245,\n",
       " 0.1357332020998001,\n",
       " 0.10373390465974808,\n",
       " 0.11058302223682404,\n",
       " 0.14695480465888977,\n",
       " 0.07673536986112595,\n",
       " 0.4617941975593567,\n",
       " 0.06111280620098114,\n",
       " 0.10995995253324509,\n",
       " 0.03830665349960327,\n",
       " 0.04477952420711517,\n",
       " 0.07270548492670059,\n",
       " 0.1293710172176361,\n",
       " 0.3931984007358551,\n",
       " 0.23878008127212524,\n",
       " 0.08526205271482468,\n",
       " 0.058605849742889404,\n",
       " 0.19410952925682068,\n",
       " 0.09351997077465057,\n",
       " 0.03435210511088371,\n",
       " 0.11053559184074402,\n",
       " 0.0791596844792366,\n",
       " 0.14256460964679718,\n",
       " 0.07126393169164658,\n",
       " 0.1587763875722885,\n",
       " 0.03728996217250824,\n",
       " 0.10744156688451767,\n",
       " 0.2267460972070694,\n",
       " 0.2155335694551468,\n",
       " 0.10110754519701004,\n",
       " 0.045150287449359894,\n",
       " 0.074754998087883,\n",
       " 0.04821571707725525,\n",
       " 0.15325628221035004,\n",
       " 0.08584075421094894,\n",
       " 0.04191707819700241,\n",
       " 0.03407268598675728,\n",
       " 0.09591922909021378,\n",
       " 0.07587327063083649,\n",
       " 0.1922142654657364,\n",
       " 0.16256649792194366,\n",
       " 0.12902988493442535,\n",
       " 0.10096316784620285,\n",
       " 0.4643837809562683,\n",
       " 0.04785005748271942,\n",
       " 0.043088775128126144,\n",
       " 0.13820575177669525,\n",
       " 0.09016392379999161,\n",
       " 0.04402835667133331,\n",
       " 0.18622104823589325,\n",
       " 0.22535240650177002,\n",
       " 0.09738876670598984,\n",
       " 0.173101544380188,\n",
       " 0.057160258293151855,\n",
       " 0.07273747026920319,\n",
       " 0.12201353162527084,\n",
       " 0.06071591377258301,\n",
       " 0.18542718887329102,\n",
       " 0.4280843734741211,\n",
       " 0.1178736537694931,\n",
       " 0.05918682739138603,\n",
       " 0.04996118322014809,\n",
       " 0.4469432532787323,\n",
       " 0.05518849566578865,\n",
       " 0.06950058043003082,\n",
       " 0.09535059332847595,\n",
       " 0.039449166506528854,\n",
       " 0.126085564494133,\n",
       " 0.2634410858154297,\n",
       " 0.13513213396072388,\n",
       " 0.1251557171344757,\n",
       " 0.18081332743167877,\n",
       " 0.11456718295812607,\n",
       " 0.04542834684252739,\n",
       " 0.11058302223682404,\n",
       " 0.1036691963672638,\n",
       " 0.27571913599967957,\n",
       " 0.25949519872665405,\n",
       " 0.08980067819356918,\n",
       " 0.3005243241786957,\n",
       " 0.09734373539686203,\n",
       " 0.20045797526836395,\n",
       " 0.12240120768547058,\n",
       " 0.110652856528759,\n",
       " 0.12924756109714508,\n",
       " 0.0842067152261734,\n",
       " 0.16534973680973053,\n",
       " 0.04337311163544655,\n",
       " 0.03654175624251366,\n",
       " 0.27711132168769836,\n",
       " 0.06650915741920471,\n",
       " 0.04219064116477966,\n",
       " 0.3494890332221985,\n",
       " 0.32503437995910645,\n",
       " 0.1429576873779297,\n",
       " 0.19122765958309174,\n",
       " 0.060370251536369324,\n",
       " 0.09766727685928345,\n",
       " 0.3694031238555908,\n",
       " 0.09591255336999893,\n",
       " 0.06372658908367157,\n",
       " 0.17602242529392242,\n",
       " 0.10069431364536285,\n",
       " 0.21116089820861816,\n",
       " 0.4280843734741211,\n",
       " 0.05350809171795845,\n",
       " 0.11910498887300491,\n",
       " 0.08906333148479462,\n",
       " 0.4099311828613281,\n",
       " 0.21375000476837158,\n",
       " 0.1505744606256485,\n",
       " 0.08244723081588745,\n",
       " 0.19997534155845642,\n",
       " 0.10247005522251129,\n",
       " 0.05540168657898903,\n",
       " 0.1725972592830658,\n",
       " 0.04165608808398247,\n",
       " 0.05344323813915253,\n",
       " 0.16799293458461761,\n",
       " 0.04774993285536766,\n",
       " 0.4174681305885315,\n",
       " 0.03129412606358528,\n",
       " 0.028334448114037514,\n",
       " 0.2383906990289688,\n",
       " 0.1123797595500946,\n",
       " 0.10656259953975677,\n",
       " 0.46534207463264465,\n",
       " 0.04268444702029228,\n",
       " 0.09591255336999893,\n",
       " 0.09281346201896667,\n",
       " 0.052914246916770935,\n",
       " 0.27808892726898193,\n",
       " 0.03488638252019882,\n",
       " 0.040651313960552216,\n",
       " 0.11926272511482239,\n",
       " 0.0537789911031723,\n",
       " 0.09045078605413437,\n",
       " 0.03242775797843933,\n",
       " 0.14773981273174286,\n",
       " 0.23265276849269867,\n",
       " 0.03109089843928814,\n",
       " 0.08018530160188675,\n",
       " 0.046744588762521744,\n",
       " 0.07772745192050934,\n",
       " 0.14051108062267303,\n",
       " 0.03600851446390152,\n",
       " 0.0863845944404602,\n",
       " 0.15729881823062897,\n",
       " 0.21837621927261353,\n",
       " 0.25950756669044495,\n",
       " 0.057321757078170776,\n",
       " 0.08174997568130493,\n",
       " 0.03400252386927605,\n",
       " 0.04594643414020538,\n",
       " 0.1251715123653412,\n",
       " 0.1427788883447647,\n",
       " 0.19110450148582458,\n",
       " 0.05344323813915253,\n",
       " 0.09841639548540115,\n",
       " 0.11186455190181732,\n",
       " 0.15469390153884888,\n",
       " 0.10318929702043533,\n",
       " 0.18386204540729523,\n",
       " 0.10058369487524033,\n",
       " 0.4086936414241791,\n",
       " 0.210342139005661,\n",
       " 0.03288058191537857,\n",
       " 0.06531758606433868,\n",
       " 0.13614559173583984,\n",
       " 0.05179879069328308,\n",
       " 0.142268568277359,\n",
       " 0.13828545808792114,\n",
       " 0.05647830665111542,\n",
       " 0.05344323813915253,\n",
       " 0.04730688035488129,\n",
       " 0.03457801789045334,\n",
       " 0.08305642753839493,\n",
       " 0.251231849193573,\n",
       " 0.04000648483633995,\n",
       " 0.0974312350153923,\n",
       " 0.301483154296875,\n",
       " 0.13674303889274597,\n",
       " 0.061582162976264954,\n",
       " 0.107577845454216,\n",
       " 0.04123359173536301,\n",
       " 0.07172050327062607,\n",
       " 0.06731369346380234,\n",
       " 0.0992574542760849,\n",
       " 0.04652244597673416,\n",
       " 0.4698098599910736,\n",
       " 0.18530623614788055,\n",
       " 0.11372439563274384,\n",
       " 0.3617072105407715,\n",
       " 0.12808598577976227,\n",
       " 0.1632339507341385,\n",
       " 0.07835791260004044,\n",
       " 0.04972410574555397,\n",
       " 0.2389373928308487,\n",
       " 0.04988379031419754,\n",
       " 0.18902717530727386,\n",
       " 0.0864475667476654,\n",
       " 0.039442844688892365,\n",
       " 0.14906443655490875,\n",
       " 0.07547415047883987,\n",
       " 0.11281447112560272,\n",
       " 0.08005663752555847,\n",
       " 0.0770861804485321,\n",
       " 0.07570408284664154,\n",
       " 0.09321587532758713,\n",
       " 0.0429808646440506,\n",
       " 0.12686046957969666,\n",
       " 0.03937042877078056,\n",
       " 0.03190898150205612,\n",
       " 0.17818918824195862,\n",
       " 0.09831362962722778,\n",
       " 0.11078455299139023,\n",
       " 0.11676155775785446,\n",
       " 0.1546097695827484,\n",
       " 0.1411743462085724,\n",
       " 0.07030494511127472,\n",
       " 0.18412171304225922,\n",
       " 0.05976920574903488,\n",
       " 0.05339111015200615,\n",
       " 0.11158069223165512,\n",
       " 0.05172735080122948,\n",
       " 0.12770986557006836,\n",
       " 0.1927134096622467,\n",
       " 0.06189080327749252,\n",
       " 0.04924054816365242,\n",
       " 0.12911094725131989,\n",
       " 0.36327266693115234,\n",
       " 0.29609254002571106,\n",
       " 0.04902689531445503,\n",
       " 0.1410025954246521,\n",
       " 0.10571761429309845,\n",
       " 0.05751487985253334,\n",
       " 0.07972400635480881,\n",
       " 0.043504271656274796,\n",
       " 0.08601824194192886,\n",
       " 0.03514232113957405,\n",
       " 0.03872048482298851,\n",
       " 0.09665416181087494,\n",
       " 0.40003734827041626,\n",
       " 0.035106293857097626,\n",
       " 0.07872582226991653,\n",
       " 0.1412687748670578,\n",
       " 0.08913914114236832,\n",
       " 0.035727109760046005,\n",
       " 0.2067594975233078,\n",
       " 0.060082823038101196,\n",
       " 0.1670559197664261,\n",
       " 0.3802383840084076,\n",
       " 0.13195668160915375,\n",
       " 0.1774226874113083,\n",
       " 0.09534259885549545,\n",
       " 0.21858970820903778,\n",
       " 0.054096464067697525,\n",
       " 0.3139926791191101,\n",
       " 0.18706507980823517,\n",
       " 0.03734540566802025,\n",
       " 0.03675346076488495,\n",
       " 0.11416129767894745,\n",
       " 0.0815715417265892,\n",
       " 0.037140533328056335,\n",
       " 0.23965544998645782,\n",
       " 0.1493387669324875,\n",
       " 0.05895542353391647,\n",
       " 0.19857563078403473,\n",
       " 0.2296658605337143,\n",
       " 0.08453887701034546,\n",
       " 0.36235103011131287,\n",
       " 0.05864635109901428,\n",
       " 0.1712942272424698,\n",
       " 0.3268774449825287,\n",
       " 0.3035525679588318,\n",
       " 0.1447509080171585,\n",
       " 0.10460204631090164,\n",
       " 0.04752887412905693,\n",
       " 0.43862223625183105,\n",
       " 0.09019435197114944,\n",
       " 0.0814325362443924,\n",
       " 0.15690068900585175,\n",
       " 0.2574761211872101,\n",
       " 0.03947196900844574,\n",
       " 0.038999930024147034,\n",
       " 0.10471771657466888,\n",
       " 0.1011766791343689,\n",
       " 0.04371432587504387,\n",
       " 0.15428093075752258,\n",
       " 0.15009398758411407,\n",
       " 0.08768519759178162,\n",
       " 0.13339614868164062,\n",
       " 0.11780447512865067,\n",
       " 0.10641714185476303,\n",
       " 0.09897199273109436,\n",
       " 0.20200347900390625,\n",
       " 0.16885295510292053,\n",
       " 0.06789177656173706,\n",
       " 0.13824346661567688,\n",
       " 0.048238787800073624,\n",
       " 0.19122765958309174,\n",
       " 0.04804939404129982,\n",
       " 0.057579897344112396,\n",
       " 0.05266905575990677,\n",
       " 0.38491302728652954,\n",
       " 0.04811830446124077,\n",
       " 0.1757649928331375,\n",
       " 0.041561536490917206,\n",
       " 0.11233728379011154,\n",
       " 0.1725221425294876,\n",
       " 0.08250381797552109,\n",
       " 0.05233967676758766,\n",
       " 0.14627481997013092,\n",
       " 0.04910033196210861,\n",
       " 0.18824829161167145,\n",
       " 0.21371640264987946,\n",
       " 0.13146257400512695,\n",
       " 0.08123579621315002,\n",
       " 0.11228762567043304,\n",
       " 0.0852990373969078,\n",
       " 0.03435060381889343,\n",
       " 0.0977075845003128,\n",
       " 0.11150756478309631,\n",
       " 0.3544638454914093,\n",
       " 0.13444268703460693,\n",
       " 0.1981702744960785,\n",
       " 0.146210715174675,\n",
       " 0.1862543225288391,\n",
       " 0.15709185600280762,\n",
       " 0.3135252296924591,\n",
       " 0.041847676038742065,\n",
       " 0.14530205726623535,\n",
       " 0.17858298122882843,\n",
       " 0.15275311470031738,\n",
       " 0.11805365234613419,\n",
       " 0.12541112303733826,\n",
       " 0.17222721874713898,\n",
       " 0.11343957483768463,\n",
       " 0.04138810560107231,\n",
       " 0.17670123279094696,\n",
       " 0.05758369341492653,\n",
       " 0.18368327617645264,\n",
       " 0.14111365377902985,\n",
       " 0.057322390377521515,\n",
       " 0.21507786214351654,\n",
       " 0.039584726095199585,\n",
       " 0.05124366283416748,\n",
       " 0.15172500908374786,\n",
       " 0.14214655756950378,\n",
       " 0.08367043733596802,\n",
       " 0.11170225590467453,\n",
       " 0.0934075117111206,\n",
       " 0.12200786918401718,\n",
       " 0.36023834347724915,\n",
       " 0.08639194816350937,\n",
       " 0.3766311705112457,\n",
       " 0.1896592229604721,\n",
       " 0.09703107178211212,\n",
       " 0.44073110818862915,\n",
       " 0.2355549931526184,\n",
       " 0.21165117621421814,\n",
       " 0.14227473735809326,\n",
       " 0.06778569519519806,\n",
       " 0.1140347495675087,\n",
       " 0.059403933584690094,\n",
       " 0.07751782983541489,\n",
       " 0.08451463282108307,\n",
       " 0.46107739210128784,\n",
       " 0.0388941653072834,\n",
       " 0.11528360843658447,\n",
       " 0.12106805294752121,\n",
       " 0.04181358963251114,\n",
       " 0.08078249543905258,\n",
       " 0.04972563311457634,\n",
       " 0.08070418238639832,\n",
       " 0.1321992129087448,\n",
       " 0.048603422939777374,\n",
       " 0.10480229556560516,\n",
       " 0.3056705594062805,\n",
       " 0.08786068111658096,\n",
       " 0.04754726216197014,\n",
       " 0.28737694025039673,\n",
       " 0.05525539070367813,\n",
       " 0.082932248711586,\n",
       " 0.11038678884506226,\n",
       " 0.0675225779414177,\n",
       " 0.09903014451265335,\n",
       " 0.130638986825943,\n",
       " 0.15882769227027893,\n",
       " 0.06828668713569641,\n",
       " 0.1901262402534485,\n",
       " 0.13338226079940796,\n",
       " 0.13330623507499695,\n",
       " 0.1296215057373047,\n",
       " 0.10387548059225082,\n",
       " 0.1087382361292839,\n",
       " 0.05841963365674019,\n",
       " 0.1766669899225235,\n",
       " 0.030514901503920555,\n",
       " 0.28375864028930664,\n",
       " 0.0767635852098465,\n",
       " 0.16528496146202087,\n",
       " 0.10977731645107269,\n",
       " 0.38963139057159424,\n",
       " 0.056274961680173874,\n",
       " 0.08456588536500931,\n",
       " 0.04641062021255493,\n",
       " 0.17593708634376526,\n",
       " 0.1600418984889984,\n",
       " 0.05909761041402817,\n",
       " 0.25153517723083496,\n",
       " 0.42735642194747925,\n",
       " 0.2125273197889328,\n",
       " 0.36663714051246643,\n",
       " 0.1525164693593979,\n",
       " 0.25959542393684387,\n",
       " 0.47853097319602966,\n",
       " 0.06945450603961945,\n",
       " 0.22038547694683075,\n",
       " 0.07269406318664551,\n",
       " 0.09476025402545929,\n",
       " 0.18572527170181274,\n",
       " 0.25116220116615295,\n",
       " 0.22385366261005402,\n",
       " 0.06628230214118958,\n",
       " 0.10846466571092606,\n",
       " 0.15246336162090302,\n",
       " 0.20439478754997253,\n",
       " 0.1646149903535843,\n",
       " 0.3533909022808075,\n",
       " 0.16754409670829773,\n",
       " 0.304725706577301,\n",
       " 0.3051312267780304,\n",
       " 0.07228946685791016,\n",
       " 0.24309231340885162,\n",
       " 0.24289162456989288,\n",
       " 0.14462043344974518,\n",
       " 0.055905453860759735,\n",
       " 0.11872313171625137,\n",
       " 0.0846695676445961,\n",
       " 0.05238030105829239,\n",
       " 0.04297821968793869,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_label</th>\n",
       "      <th>test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.234513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.112885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_label  test_pred\n",
       "0             0.0   0.044050\n",
       "1             1.0   0.234513\n",
       "2             0.0   0.103990\n",
       "3             0.0   0.047530\n",
       "4             0.0   0.100665\n",
       "5             0.0   0.130442\n",
       "6             1.0   0.074756\n",
       "7             0.0   0.081658\n",
       "8             0.0   0.043097\n",
       "9             0.0   0.175160\n",
       "10            0.0   0.072494\n",
       "11            0.0   0.103932\n",
       "12            0.0   0.093342\n",
       "13            0.0   0.134844\n",
       "14            0.0   0.132231\n",
       "15            1.0   0.064603\n",
       "16            0.0   0.174934\n",
       "17            0.0   0.092554\n",
       "18            1.0   0.090979\n",
       "19            0.0   0.089404\n",
       "20            0.0   0.078061\n",
       "21            0.0   0.182722\n",
       "22            0.0   0.102090\n",
       "23            0.0   0.034804\n",
       "24            0.0   0.156201\n",
       "25            0.0   0.046206\n",
       "26            0.0   0.117993\n",
       "27            0.0   0.035984\n",
       "28            0.0   0.120713\n",
       "29            0.0   0.080058\n",
       "...           ...        ...\n",
       "14980         0.0   0.044478\n",
       "14981         0.0   0.119267\n",
       "14982         0.0   0.115789\n",
       "14983         0.0   0.052931\n",
       "14984         0.0   0.046220\n",
       "14985         0.0   0.034953\n",
       "14986         0.0   0.046738\n",
       "14987         0.0   0.047969\n",
       "14988         0.0   0.050662\n",
       "14989         0.0   0.064498\n",
       "14990         0.0   0.046406\n",
       "14991         0.0   0.042929\n",
       "14992         0.0   0.040483\n",
       "14993         0.0   0.268438\n",
       "14994         1.0   0.152190\n",
       "14995         0.0   0.061429\n",
       "14996         0.0   0.053289\n",
       "14997         1.0   0.048365\n",
       "14998         0.0   0.036220\n",
       "14999         1.0   0.046892\n",
       "15000         0.0   0.134401\n",
       "15001         1.0   0.041471\n",
       "15002         0.0   0.037378\n",
       "15003         1.0   0.112885\n",
       "15004         1.0   0.288659\n",
       "15005         0.0   0.106602\n",
       "15006         1.0   0.038999\n",
       "15007         0.0   0.155563\n",
       "15008         0.0   0.056725\n",
       "15009         0.0   0.086582\n",
       "\n",
       "[15010 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'test_label': test_label, 'test_pred': test_pred}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15010, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Mnasnet_test_res.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
